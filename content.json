{"meta":{"title":"长亭的网志空间","subtitle":"Linux|云计算|网络|编程|读书|思维|认知","description":"专注于Linux/云计算/网络/CC++/Python/Go等技术栈，分享读书、写作、思维、认知等话题","author":"bike","url":"https://chambai.github.io"},"pages":[{"title":"about","date":"2019-02-20T14:53:15.000Z","updated":"2019-02-20T14:53:15.811Z","comments":true,"path":"about/index.html","permalink":"https://chambai.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-02-20T14:52:30.000Z","updated":"2019-02-20T14:52:30.495Z","comments":true,"path":"categories/index.html","permalink":"https://chambai.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-02-20T14:53:06.000Z","updated":"2019-04-19T05:36:39.223Z","comments":true,"path":"tags/index.html","permalink":"https://chambai.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Docker 网络模型之 macvlan 详解","slug":"tech/docker-macvlan","date":"2019-04-14T05:16:14.000Z","updated":"2019-04-17T16:27:15.308Z","comments":true,"path":"2019/04/14/tech/docker-macvlan/","link":"","permalink":"https://chambai.github.io/2019/04/14/tech/docker-macvlan/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 上一篇文章我们详细介绍了 macvlan 这种技术，macvlan 详解，由于它高效易配置的特性，被用在了 Docker 的网络方案设计中，这篇文章就来说说这个。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 上一篇文章我们详细介绍了 macvlan 这种技术，macvlan 详解，由于它高效易配置的特性，被用在了 Docker 的网络方案设计中，这篇文章就来说说这个。 01macvlan 用于 Docker 网络在 Docker 中，macvlan 是众多 Docker 网络模型中的一种，并且是一种跨主机的网络模型，作为一种驱动（driver）启用（-d 参数指定），Docker macvlan 只支持 bridge 模式。 关于 Docker 的众多跨主机网络模型的科普，参照我之前写的一篇文章：容器网络之多主机网络。 下面我们做两个实验，分别验证相同 macvlan 网络和不同 macvlan 网络的连通性。 1.1 相同 macvlan 网络之间的通信首先准备两个主机节点的 Docker 环境，搭建如下拓扑图示： 1 首先使用 docker network create 分别在两台主机上创建两个 macvlan 网络： 1root@ubuntu:~# docker network create -d macvlan --subnet=172.16.10.0/24 --gateway=172.16.10.1 -o parent=enp0s8 mac1 这条命令中， -d 指定 Docker 网络 driver --subnet 指定 macvlan 网络所在的网络 --gateway 指定网关 -o parent 指定用来分配 macvlan 网络的物理网卡 之后可以看到当前主机的网络环境，其中出现了 macvlan 网络： 123456root@ubuntu:~# docker network lsNETWORK ID NAME DRIVER SCOPE128956db798a bridge bridge local19fb1af129e6 host host local2509b3717813 mac1 macvlan locald5b0798e725e none null local 2 在 host1 运行容器 c1，并指定使用 macvlan 网络： 1root@ubuntu:~# docker run -itd --name c1 --ip=172.16.10.2 --network mac1 busybox 这条命令中， --ip 指定容器 c1 使用的 IP，这样做的目的是防止自动分配，造成 IP 冲突 --network 指定 macvlan 网络 同样在 host2 中运行容器 c2： 1root@ubuntu:~# docker run -itd --name c2 --ip=172.16.10.3 --network mac1 busybox 3 在 host1 c1 中 ping host2 c2： 123456789root@ubuntu:~# docker exec c1 ping -c 2 172.16.10.3PING 172.16.10.3 (172.16.10.3): 56 data bytes64 bytes from 172.16.10.3: seq=0 ttl=64 time=0.641 ms64 bytes from 172.16.10.3: seq=1 ttl=64 time=0.393 ms--- 172.16.10.3 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.393/0.517/0.641 ms 注意：以上的实验都需要物理网卡 enp0s8 开启混杂模式，不然会 ping 不通。 1.2 不同 macvlan 网络之间的通信接下来，我们来看看不同 macvlan 网络之间的连通性，搭建以下的拓扑环境： 由于 macvlan 网络会独占物理网卡，也就是说一张物理网卡只能创建一个 macvlan 网络，如果我们想创建多个 macvlan 网络就得用多张网卡，但主机的物理网卡是有限的，怎么办呢？ 好在 macvlan 网络也是支持 VLAN 子接口的，所以，我们可以通过 VLAN 技术将一个网口划分出多个子网口，这样就可以基于子网口来创建 macvlan 网络了，下面是具体的创建过程。 1 首先分别在两台主机上将物理网口 enp0s8 创建出两个 VLAN 子接口。 1234567891011# 使用 vconfig 命令在 eth0 配置两个 VLANroot@ubuntu:~# vconfig add enp0s8 100root@ubuntu:~# vconfig add enp0s8 200# 设置 VLAN 的 REORDER_HDR 参数，默认就行了root@ubuntu:~# vconfig set_flag enp0s8.100 1 1root@ubuntu:~# vconfig set_flag enp0s8.200 1 1# 启用接口root@ubuntu:~# ifconfig enp0s8.100 uproot@ubuntu:~# ifconfig enp0s8.200 up 2 分别在 host1 和 host2 上基于两个 VLAN 子接口创建 2 个 macvlan 网络，mac10 和 mac20。 12root@ubuntu:~# docker network create -d macvlan --subnet=172.16.10.0/24 --gateway=172.16.10.1 -o parent=enp0s8.100 mac10root@ubuntu:~# docker network create -d macvlan --subnet=172.16.20.0/24 --gateway=172.16.20.1 -o parent=enp0s8.200 mac20 3 分别在 host1 和 host2 上运行容器，并指定不同的 macvlan 网络。 1234567# host1root@ubuntu:~# docker run -itd --name d1 --ip=172.16.10.10 --network mac10 busyboxroot@ubuntu:~# docker run -itd --name d2 --ip=172.16.20.10 --network mac20 busybox# host2 root@ubuntu:~# docker run -itd --name d3 --ip=172.16.10.11 --network mac10 busyboxroot@ubuntu:~# docker run -itd --name d4 --ip=172.16.20.11 --network mac20 busybox 通过验证，d1 和 d3，d2 和 d4 在同一 macvlan 网络下，互相可以 ping 通，d1 和 d2，d1 和 d4 在不同的 macvlan 网络下，互相 ping 不通。 这个原因也很明确，不同 macvlan 网络处于不同的网络，而且通过 VLAN 隔离，自然 ping 不了。 但这也只是在二层上通不了，通过三层的路由是可以通的，我们这就来验证下。 重新找一台主机 host3，通过打开 ip_forward 把它改造成一台路由器（至于为什么可以这样，可以参考我之前的一篇文章xxx），用来打通两个 macvlan 网络，大概的图示如下所示： 1 首先对 host3 执行 sysctl -w net.ipv4.ip_forward=1 打开路由开关。 2 然后创建两个 VLAN 子接口，一个作为 macvlan 网络 mac10 的网关，一个作为 mac20 的网关。 12345678[root@localhost ~]# vconfig add enp0s8 100[root@localhost ~]# vconfig add enp0s8 200[root@localhost ~]# vconfig set_flag enp0s8.100 1 1[root@localhost ~]# vconfig set_flag enp0s8.200 1 1# 对 vlan 子接口配置网关 IP 并启用[root@localhost ~]# ifconfig enp0s8.100 172.16.10.1 netmask 255.255.255.0 up[root@localhost ~]# ifconfig enp0s8.200 172.16.20.1 netmask 255.255.255.0 up 3 这样之后再从 d1 ping d2 和 d4，就可以 ping 通了。 12345678root@ubuntu:~# docker exec d1 ping -c 2 172.16.20.10PING 172.16.20.10 (172.16.20.10): 56 data bytes64 bytes from 172.16.20.10: seq=0 ttl=63 time=0.661 ms64 bytes from 172.16.20.10: seq=1 ttl=63 time=0.717 ms--- 172.16.20.10 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.661/0.689/0.717 ms 12345678root@ubuntu:~# docker exec d1 ping -c 2 172.16.20.11PING 172.16.20.11 (172.16.20.11): 56 data bytes64 bytes from 172.16.20.11: seq=0 ttl=63 time=0.548 ms64 bytes from 172.16.20.11: seq=1 ttl=63 time=0.529 ms--- 172.16.20.11 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.529/0.538/0.548 ms PS：可能有些系统做了安全限制，可能 ping 不通，这时候可以添加以下 iptables 规则，目的是让系统能够转发不通 VLAN 的数据包。 123456789101112iptables -t nat -A POSTROUTING -o enp0s8.100 -j MASQUERADEiptables -t nat -A POSTROUTING -oenp0s8.200 -j MASQUERADEiptables -A FORWARD -i enp0s8.100 -o enp0s8.200 -m state --state RELATED,ESTABLISHED -j ACCEPTiptables -A FORWARD -i enp0s8.200 -o enp0s8.100 -m state --state RELATED,ESTABLISHED -j ACCEPTiptables -A FORWARD -i enp0s8.100 -o enp0s8.200 -j ACCEPTiptables -A FORWARD -i enp0s8.200 -o enp0s8.100 -j ACCEPT 为什么配置 VLAN 子接口，配上 IP 就可以通了，我们可以看下路由表就知道了。 首先看容器 d1 的路由： 123root@ubuntu:~# docker exec d1 ip routedefault via 172.16.10.1 dev eth0 172.16.10.0/24 dev eth0 scope link src 172.16.10.10 我们在创建容器的时候指定了网关 172.16.10.1，所以数据包自然会被路由到 host3 的接口。再来看下 host3 的路由： 123456[root@localhost ~]# ip routedefault via 192.168.108.1 dev enp0s3 proto dhcp metric 100 172.16.10.0/24 dev enp0s8.100 proto kernel scope link src 172.16.10.1 172.16.20.0/24 dev enp0s8.200 proto kernel scope link src 172.16.20.1 192.168.56.0/24 dev enp0s8 proto kernel scope link src 192.168.56.122 metric 101 192.168.108.0/24 dev enp0s3 proto kernel scope link src 192.168.108.2 metric 100 可以看到，去往 172.16.10.0/24 网段的数据包会从 enp0s8.100 出去，同理 172.16.20.0/24 网段也是，再加上 host3 的 ip_forward 打开，这就打通了两个 macvlan 网络之间的通路。 02 总结在 Docker 中，macvlan 只支持 bridge 模式。 相同 macvlan 可以通信，不同 macvlan 二层无法通信，可以借助三层路由完成通信。 参考： https://www.cnblogs.com/CloudMan6/p/7400580.html https://blog.csdn.net/dog250/article/details/45788279 https://www.hi-linux.com/posts/40904.html –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"macvlan","slug":"macvlan","permalink":"https://chambai.github.io/tags/macvlan/"}]},{"title":"Linux网络命令必知必会之 tcpdump","slug":"tech/linux网络命令之tcpdump","date":"2019-04-11T05:16:14.000Z","updated":"2019-04-17T16:25:12.055Z","comments":true,"path":"2019/04/11/tech/linux网络命令之tcpdump/","link":"","permalink":"https://chambai.github.io/2019/04/11/tech/linux网络命令之tcpdump/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 01 简介tcpdump 是一款 Linux 平台的抓包工具。它可以抓取涵盖整个 TCP/IP 协议族的数据包，支持针对网络层、协议、主机、端口的过滤，并提供 and、or、not 等逻辑语句来过滤无用的信息。 tcpdump 是一个非常复杂的工具，掌握它的方方面面实属不易，也不推荐，能够用它来解决日常工作问题才是关系。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 01 简介tcpdump 是一款 Linux 平台的抓包工具。它可以抓取涵盖整个 TCP/IP 协议族的数据包，支持针对网络层、协议、主机、端口的过滤，并提供 and、or、not 等逻辑语句来过滤无用的信息。 tcpdump 是一个非常复杂的工具，掌握它的方方面面实属不易，也不推荐，能够用它来解决日常工作问题才是关系。 02 tcpdump 命令选项tcpdump 有很多命令选项，想了解所有选项可以 Linux 命令行输入 tcpdump -h，man tcpdump 查看每个选项的意思。 123456789101112[root@by ~]# tcpdump -htcpdump version 4.9.2libpcap version 1.5.3OpenSSL 1.0.2k-fips 26 Jan 2017Usage: tcpdump [-aAbdDefhHIJKlLnNOpqStuUvxX#] [ -B size ] [ -c count ] [ -C file_size ] [ -E algo:secret ] [ -F file ] [ -G seconds ] [ -i interface ] [ -j tstamptype ] [ -M secret ] [ --number ] [ -Q|-P in|out|inout ] [ -r file ] [ -s snaplen ] [ --time-stamp-precision precision ] [ --immediate-mode ] [ -T type ] [ --version ] [ -V file ] [ -w file ] [ -W filecount ] [ -y datalinktype ] [ -z postrotate-command ] [ -Z user ] [ expression ] 下面列举一些常用选项： -A 只使用 ASCII 打印报文的全部数据，不要和 -X 一起使用，获取 http 可以用 tcpdump -nSA port 80 -b 在数据链路层上选择协议，包括 ip, arp, rarp, ipx 等 -c 指定要抓取包的数量 -D 列出操作系统所有可以用于抓包的接口 -i 指定监听的网卡，-i any 显示所有网卡 -n 表示不解析主机名，直接用 IP 显示，默认是用 hostname 显示 -nn 表示不解析主机名和端口，直接用端口号显示，默认显示是端口号对应的服务名 -p 关闭接口的混杂模式 -P 指定抓取的包是流入的包还是流出的，可以指定参数 in, out, inout 等，默认是 inout -q 快速打印输出，即只输出少量的协议相关信息 -s len 设置要抓取数据包长度为 len，默认只会截取前 96bytes 的内容，-s 0 的话，会截取全部内容。 -S 将 TCP 的序列号以绝对值形式输出，而不是相对值 -t 不要打印时间戳 -vv 输出详细信息（比如 tos、ttl、checksum等） -X 同时用 hex 和 ascii 显示报文内容 -XX 同 -X，但同时显示以太网头部 03 过滤器网络报文是很多的，很多时候我们在主机上抓包，会抓到很多我们并不关心的无用包，然后要从这些包里面去找我们需要的信息，无疑是一件费时费力的事情，tcpdump 提供了灵活的语法可以精确获取我们关心的数据，这些语法说得专业点就是过滤器。 过滤器简单可分为三类：协议（proto）、传输方向（dir）和类型（type）。 一般的表达式格式为： 图片来自 关于 proto：可选有 ip, arp, rarp, tcp, udp, icmp, ether 等，默认是所有协议的包 关于 dir：可选有 src, dst, src or dst, src and dst，默认为 src or dst 关于 type：可选有 host, net, port, portrange（端口范围，比如 21-42），默认为 host 04 常用操作测试环境 IP：172.18.82.173 4.1 抓取某主机的数据包抓取主机 172.18.82.173 上所有收到（DST_IP）和发出（SRC_IP）的所有数据包 1tcpdump host 172.18.82.173 抓取经过指定网口 interface ，并且 DST_IP 或 SRC_IP 是 172.18.82.173 的数据包 1tcpdump -i eth0 host 172.18.82.173 筛选 SRC_IP，抓取经过 interface 且从 172.18.82.173 发出的包 1tcpdump -i eth0 src host 172.18.82.173 筛选 DST_IP，抓取经过 interface 且发送到 172.18.82.173 的包 1tcpdump -i eth0 dst host 172.18.82.173 抓取主机 200.200.200.1 和主机 200.200.200.2 或 200.200.200.3 通信的包 1tcpdump host 200.200.200.1 and \\(200.200.200.2 or 200.200.200.3\\) 抓取主机 200.200.200.1 和除了主机 200.200.200.2 之外所有主机通信的包 1tcpdump ip host 200.200.200.1 and ! 200.200.200.2 4.2 抓取某端口的数据包抓取所有端口，显示 IP 地址 1tcpdump -nS 抓取某端口上的包 1tcpdump port 22 抓取经过指定 interface，并且 DST_PORT 或 SRC_PORT 是 22 的数据包 1tcpdump -i eth0 port 22 筛选 SRC_PORT 1tcpdump -i eth0 src port 22 筛选 DST_PORT 1tcpdump -i eth0 dst port 22 比如希望查看发送到 host 172.18.82.173 的网口 eth0 的 22 号端口的包 1234[root@by ~]# tcpdump -i eth0 -nnt dst host 172.18.82.173 and port 22 -c 1 -vvtcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytesIP (tos 0x14, ttl 114, id 27674, offset 0, flags [DF], proto TCP (6), length 40) 113.98.59.61.51830 &gt; 172.18.82.173.22: Flags [.], cksum 0x7fe3 (correct), seq 19775964, ack 1564316089, win 2053, length 0 4.3 抓取某网络（网段）的数据包抓取经过指定 interface，并且 DST_NET 或 SRC_NET 是 172.18.82 的包 1tcpdump -i eth0 net 172.18.82 筛选 SRC_NET 1tcpdump -i eth0 src net 172.18.82 筛选 DST_NET 1tcpdump -i eth0 dst net 172.18.82 4.4 抓取某协议的数据包12345tcpdump -i eth0 icmptcpdump -i eth0 iptcpdump -i eth0 tcptcpdump -i eth0 udptcpdump -i eth0 arp 4.5 复杂的逻辑表达式抓取过滤条件抓取经过 interface eth0 发送到 host 200.200.200.1 或 200.200.200.2 的 TCP 协议 22 号端口的数据包 1tcpdump -i eth0 -nntvv -c 10 &apos;((tcp) and (port 22) and ((dst host 200.200.200.1) or (dst host 200.200.200.2)))&apos; PS：对于复杂的过滤器表达式，为了逻辑清晰，可以使用 ()，不过默认情况下，tcpdump 会将 () 当做特殊字符，所以必须使用 &#39;&#39; 来消除歧义。 抓取经过 interface eth0， DST_MAC 或 SRC_MAC 地址是 00:16:3e:12:16:e7 的 ICMP 数据包 1tcpdump -i eth0 &apos;((icmp) and ((ether host 00:16:3e:12:16:e7)))&apos; -nnvv 抓取经过 interface eth0，目标网络是 172.18 但目标主机又不是 172.18.82.173 的 TCP 且非 22 号端口号的数据包 1tcpdump -i eth0 -nntvv &apos;((dst net 172.18) and (not dst host 172.18.82.173) and (tcp) and (not port 22))&apos; 抓取流入 interface eth0，host 为 172.18.82.173 且协议为 ICMP 的数据包 1tcpdump -i eth0 -nntvv -P in host 172.18.82.173 and icmp 抓取流出 interface eth0，host 为 172.18.82.173 且协议为 ICMP 的数据包 1tcpdump -i eth0 -nntvv -P out host 172.18.82.173 and icmp 05 与 wireshark、Snort 等工具的结合tcpdump 抓包的时候，默认是打印到屏幕输出，如果是抓取包少还好，如果包很多，很多行数据，刷刷刷从眼前一闪而过，根本来不及看清内容。不过，tcpdump 提供了将抓取的数据保存到文件的功能，查看文件就方便分析多了，而且还能与其他图形工具一起配合分析，比如 wireshark、Snort 等。 -w 选项表示把数据报文输出到文件 1tcpdump -w capture_file.pcap port 80 # 把所有 80 端口的数据导出到文件 -r 选项表示读取文件里的数据报文，显示到屏幕上 1tcpdump -nXr capture_file.pcap host host1 PS：.pcap 格式的文件需要用 wireshark、Snort 等工具查看，使用 vim 或 cat 会出现乱码。 06 tcpdump 的输出格式tcpdump 的输出格式总体上为： 1系统时间 源主机.端口 &gt; 目标主机.端口 数据包参数 比如下面的例子，显示了 TCP 的三次握手过程： 1234567821:27:06.995846 IP (tos 0x0, ttl 64, id 45646, offset 0, flags [DF], proto TCP (6), length 64) 192.168.1.106.56166 &gt; 124.192.132.54.80: Flags [S], cksum 0xa730 (correct), seq 992042666, win 65535, options [mss 1460,nop,wscale 4,nop,nop,TS val 663433143 ecr 0,sackOK,eol], length 021:27:07.030487 IP (tos 0x0, ttl 51, id 0, offset 0, flags [DF], proto TCP (6), length 44) 124.192.132.54.80 &gt; 192.168.1.106.56166: Flags [S.], cksum 0xedc0 (correct), seq 2147006684, ack 992042667, win 14600, options [mss 1440], length 021:27:07.030527 IP (tos 0x0, ttl 64, id 59119, offset 0, flags [DF], proto TCP (6), length 40) 192.168.1.106.56166 &gt; 124.192.132.54.80: Flags [.], cksum 0x3e72 (correct), ack 2147006685, win 65535, length 0 第一条是 SYN 报文，通过 Flags[S] 看出。第二条是 [S.]，表示 SYN-ACK 报文。常见的 TCP 报文的 Flags 如下： [S]： SYN（开始连接） [.]: 没有 Flag [P]: PSH（推送数据） [F]: FIN （结束连接） [R]: RST（重置连接） 06 总结本文可以当字典查阅，记住一些常用的 tcpdump 抓包案例，其他的用到再通过 man tcpdump 辅助编写。和 wireshark 等图形化工具配合使用，能更加深理解。 参考： https://blog.csdn.net/Jmilk/article/details/86618205?tdsourcetag=s_pctim_aiomsg https://www.cnblogs.com/f-ck-need-u/p/7064286.html?tdsourcetag=s_pctim_aiomsg https://danielmiessler.com/study/tcpdump/ http://bencane.com/2014/10/13/quick-and-practical-reference-for-tcpdump/ –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"tcpdump","slug":"tcpdump","permalink":"https://chambai.github.io/tags/tcpdump/"}]},{"title":"Linux云网络基础之网卡虚拟化技术 macvlan 详解","slug":"tech/linux-macvlan","date":"2019-04-01T05:16:14.000Z","updated":"2019-04-17T16:28:17.590Z","comments":true,"path":"2019/04/01/tech/linux-macvlan/","link":"","permalink":"https://chambai.github.io/2019/04/01/tech/linux-macvlan/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 01 macvlan 简介前面的文章讲过了几种 Linux 虚拟网络设备：tap/tun、veth-pair、bridge，它们本质上是 Linux 系统 提供的网络虚拟化解决方案，今天要讲的 macvlan 也是其中的一种，准确说这是一种网卡虚拟化的解决方案。因为 macvlan 这种技术能将 一块物理网卡虚拟成多块虚拟网卡 ，相当于物理网卡施展了 多重影分身之术 ，由一个变多个。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 01 macvlan 简介前面的文章讲过了几种 Linux 虚拟网络设备：tap/tun、veth-pair、bridge，它们本质上是 Linux 系统 提供的网络虚拟化解决方案，今天要讲的 macvlan 也是其中的一种，准确说这是一种网卡虚拟化的解决方案。因为 macvlan 这种技术能将 一块物理网卡虚拟成多块虚拟网卡 ，相当于物理网卡施展了 多重影分身之术 ，由一个变多个。 02 macvlan 的工作原理macvlan 是 Linux kernel 支持的新特性，支持的版本有 v3.9-3.19 和 4.0+，比较稳定的版本推荐 4.0+。它一般是以内核模块的形式存在，我们可以通过以下方法判断当前系统是否支持： 123# modprobe macvlan# lsmod | grep macvlanmacvlan 24576 0 如果第一个命令报错，或者第二个命令没有返回，说明当前系统不支持 macvlan，需要升级内核。 macvlan 这种技术听起来有点像 VLAN，但它们的实现机制是完全不一样的。macvlan 子接口和原来的主接口是完全独立的，可以单独配置 MAC 地址和 IP 地址，而 VLAN 子接口和主接口共用相同的 MAC 地址。VLAN 用来划分广播域，而 macvlan 共享同一个广播域。 通过不同的子接口，macvlan 也能做到流量的隔离。macvlan 会根据收到包的目的 MAC 地址判断这个包需要交给哪个虚拟网卡，虚拟网卡再把包交给上层的协议栈处理。 03 四种模式根据 macvlan 子接口之间的通信模式，macvlan 有四种网络模式： private 模式 vepa(virtual ethernet port aggregator) 模式 bridge 模式 passthru 模式 默认使用的是 vepa 模式。 3.1 private这种模式下，同一主接口下的子接口之间彼此隔离，不能通信。即使从外部的物理交换机导流，也会被无情地丢掉。 3.2 vepa这种模式下，子接口之间的通信流量需要导到外部支持 802.1Qbg/VPEA 功能的交换机上（可以是物理的或者虚拟的），经由外部交换机转发，再绕回来。 注：802.1Qbg/VPEA 功能简单说就是交换机要支持 发夹（hairpin） 功能，也就是数据包从一个接口上收上来之后还能再扔回去。 3.3 bridge这种模式下，模拟的是 Linux bridge 的功能，但比 bridge 要好的一点是每个接口的 MAC 地址是已知的，不用学习。所以，这种模式下，子接口之间就是直接可以通信的。 3.4 passthru这种模式，只允许单个子接口连接主接口，且必须设置成混杂模式，一般用于子接口桥接和创建 VLAN 子接口的场景。 3.5 mactap和 macvlan 相似的技术还有一种是 mactap。和 macvlan 不同的是，mactap 收到包之后不是交给协议栈，而是交给一个 tapX 文件，然后通过这个文件，完成和用户态的直接通信。 04 实践在 Linux 系统下，创建 macvlan 的命令形式如下： 12ip link add link DEVICE name NAME type &#123; macvlan | macvtap &#125; mode &#123; private | vepa | bridge | passthru [ nopromisc ] &#125; 通常，单独使用 macvlan 毫无意义，一般都是结合 VM 和容器来构建网络。下面我们就简单使用 namespace 来看看 Linux 是怎么使用 macvlan 的。 实验拓扑如下： 在我的系统中，以接口 enp0s8 为例创建两个 macvlan 子接口（使用 bridge 模式），配置 IP 并将其挂到两个 namespace 中，测试连通性。 123456789101112131415161718# 创建两个 macvlan 子接口ip link add link enp0s8 dev mac1 type macvlan mode bridgeip link add link enp0s8 dev mac2 type macvlan mode bridge# 创建两个 namespaceip netns add ns1ip netns add ns2# 将两个子接口分别挂到两个 namespace 中ip link set mac1 netns ns1ip link set mac2 netns ns2# 配置 IP 并启用ip netns exec ns1 ip a a 192.168.56.122/24 dev mac1ip netns exec ns1 ip l s mac1 upip netns exec ns1 ip a a 192.168.56.123/24 dev mac2ip netns exec ns2 ip l s mac2 up 注：enp0s8 的 IP 是 192.168.56.110/24，配置的子接口 IP 也必须是同一网段的。 完了两个子接口 ping 一下： 123456789101112131415root@ubuntu:~# ip netns exec ns1 ip a show mac19: mac1@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1 link/ether 2e:6e:d9:08:c5:05 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 192.168.56.122/24 scope global mac1 valid_lft forever preferred_lft forever inet6 fe80::2c6e:d9ff:fe08:c505/64 scope link valid_lft forever preferred_lft foreverroot@ubuntu:~# ip netns exec ns1 ping 192.168.56.123PING 192.168.56.123 (192.168.56.123) 56(84) bytes of data.64 bytes from 192.168.56.123: icmp_seq=1 ttl=64 time=0.052 ms64 bytes from 192.168.56.123: icmp_seq=2 ttl=64 time=0.028 ms^C--- 192.168.56.123 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1000msrtt min/avg/max/mdev = 0.028/0.040/0.052/0.012 ms 可以看到，能够 ping 通，如果把上面的 mode 换成其他模式就行不通了，这个就留给大家去实验了（默认是 vepa 模式）。 另外，在 docker 中，macvlan 是一种较为重要的跨主机网络模型，这块的内容就留作下篇文章再做讲解了。 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"macvlan","slug":"macvlan","permalink":"https://chambai.github.io/tags/macvlan/"}]},{"title":"一文带你全面了解虚拟机的四种网络模型","slug":"tech/虚拟机的四种网络模型","date":"2019-03-25T05:16:14.000Z","updated":"2019-04-17T16:28:11.146Z","comments":true,"path":"2019/03/25/tech/虚拟机的四种网络模型/","link":"","permalink":"https://chambai.github.io/2019/03/25/tech/虚拟机的四种网络模型/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 01 从物理网络到虚拟网络著名的「六度分隔定理」说到，世界上任何两个互不相识的人，只需要最多六个人就能够建立起联系。这个定理成立的前提就是依托于庞大的网络结构。 在虚拟化技术没出现之前，构成网络的元素都是实体的物理设备，比如交换机、路由器、网线等等，人们想要构建一个小型的局域网自己玩玩，都要买各种设备，成本高还不灵活。虚拟化技术普及之后，云计算开始大行其道，我们在自己的单机上就可以建各种虚拟机，想怎么玩就怎么玩。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 01 从物理网络到虚拟网络著名的「六度分隔定理」说到，世界上任何两个互不相识的人，只需要最多六个人就能够建立起联系。这个定理成立的前提就是依托于庞大的网络结构。 在虚拟化技术没出现之前，构成网络的元素都是实体的物理设备，比如交换机、路由器、网线等等，人们想要构建一个小型的局域网自己玩玩，都要买各种设备，成本高还不灵活。虚拟化技术普及之后，云计算开始大行其道，我们在自己的单机上就可以建各种虚拟机，想怎么玩就怎么玩。 随之而来的就是网络变得更复杂了，由以前看得见摸得着的物理网络一下变成玄乎的虚拟网络了，好不容易建了几台虚拟机，发现网络不通，或者网络通了，但并不知道是怎么通的，这难言的苦水哽在喉咙实在令人不适。 这篇文章就来说说虚拟机世界里的几种网络模型，我们主要以 VirtualBox 和 VMware Workstation 这两款目前最主流的桌面虚拟化软件作为例子。 总的来说，目前有四种常见的网络模型： 桥接（Bridge Adapter） NAT 主机（Host-only Adapter） 内部网络（Internal） 这也是 VirtualBox 支持的四种模型，对于 VMware，则只有前三种。 下图显示了 VirtualBox 支持的几种网络模型： 02 桥接（Bridge Adapter）虚拟机桥接网络模型就是使用虚拟交换机（Linux Bridge），将虚拟机和物理机连接起来，它们处于同一个网段，IP 地址是一样的。如下图所示： 在这种网络模型下，虚拟机和物理机都处在一个二层网络里面，所以有： 虚拟机之间彼此互通 虚拟机与主机彼此可以互通 只要物理机可以上网，那么虚拟机也可以。我们来验证下： 桥接网络的好处是简单方便，但也有一个很明显的问题，就是一旦虚拟机太多，广播就会很严重。所以，桥接网络一般也只适用于桌面虚拟机或者小规模网络这种简单的形式。 03 NAT另一种模型是 NAT，即网络地址转换（Network Address Translatation）。这种模型严格来讲，又可以分为 NAT 和 NAT 网络两种，我们看上面的图 1 也可以看到。 根据 NAT 的原理，虚拟机所在的网络和物理机所在的网络不在同一个网段，虚拟机要访问物理所在网络必须经过一个地址转换的过程，也就是说在虚拟机网络内部需要内置一个虚拟的 NAT 设备来做这件事。 但其中 NAT 和 NAT 网络 两者还有些许的不同： NAT：主机上的虚拟机之间是互相隔离的，彼此不能通信（它们有独立的网络栈，独立的虚拟 NAT 设备） NAT 网络：虚拟机之间共享虚拟 NAT 设备，彼此互通。 如下图，展示了两者细微的差别： PS：NAT 网络模式中一般还会内置一个虚拟的 DHCP 服务器来进行 IP 地址的管理。 下面我们通过实验来验证一下两种模式的区别，首先是 NAT 模式： 访问外网没问题： 访问其他虚拟机： 可以看到，两个虚拟机由于有隔离的网络栈，所以它们的 IP 地址并不在一个网段，所以 ping 不通。 再来看 NAT 网络，访问外网同样没问题，我们来看下 VM 之间的互通： 可以看到，差别体现出来了，NAT 网络 虚拟机之间共享网络栈，它们的 IP 地址处于同一个网段，所以彼此是互通的。 总结一下，以上两种 NAT 模式，如果不做其他配置，那么有： 虚拟机可以访问主机，反之不行 如果主机可以上外网，那么虚拟机也可以 对于 NAT，同主机上的虚拟机之间不能互通 对于 NAT 网络，虚拟机之间可以互通 PS：如果做了 端口映射 配置，那么主机也可以访问虚拟机。 04 主机网络（Host-only Adapter）主机网络顾名思义，就是只限于主机内部访问的网络，虚拟机之间彼此互通，虚拟机与主机之间彼此互通。但是默认情况下虚拟机不能访问外网（注意：这里说的是默认情况下，如果稍作配置，也是可以的）。 主机网络看似简单，其实它的网络模型是相对比较复杂的，可以说前面几种模式实现的功能，在这种模式下，都可以通过虚拟机和网卡的配置来实现，这得益于它特殊的网络模型。 主机网络模型会在主机中模拟出一块虚拟网卡供虚拟机使用，所有虚拟机都连接到这块网卡上，这块网卡默认会使用网段 192.168.56.x（在主机的网络配置界面可以看到这块网卡），如下是基本的拓扑图示： 默认情况下，虚拟机之间可以互通，虚拟机只能和主机上的虚拟网卡互通，不能和不同网段的网卡互通，更不能访问外网，如果想做到这样，那么需要如图中 红虚线 所示，将物理网卡和虚拟网卡桥接或共享。在主机上做如下设置即可： 通过以上配置，我们来验证一下，虚拟机可以访问主机物理网卡和外网了： 05 内部网络（internal）最后一种网络模型是内部网络，这种模型是相对最简单的一种，虚拟机与外部环境完全断开，只允许虚拟机之间互相访问，这种模型一般不怎么用，所以在 VMware 虚拟机中是没有这种网络模式的。这里我们就不多说了。 06 总结虚拟机的四种网络模型：桥接、NAT、主机和内网模型。 下面以一张表来描述它们之间的通信行为： Model VM -&gt; host host -&gt; VM VM VM VM -&gt; Internet Internet -&gt; VM Bridged + + + + + NAT + Port Forwarding - + Port Forwarding NAT Network + Port Forwarding + + Port Forwarding Host-only + + + - - Internal - - + - - 参考： https://technology.amis.nl/2018/07/27/virtualbox-networking-explained/#prettyPhoto https://blog.csdn.net/niqinwen/article/details/11761487 https://www.jianshu.com/p/5b8da7a1ad63 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"Bridge","slug":"Bridge","permalink":"https://chambai.github.io/tags/Bridge/"},{"name":"NAT","slug":"NAT","permalink":"https://chambai.github.io/tags/NAT/"}]},{"title":"Linux云网络基础之 IP 隧道详解","slug":"tech/ip隧道","date":"2019-03-18T05:16:14.000Z","updated":"2019-04-17T16:28:04.651Z","comments":true,"path":"2019/03/18/tech/ip隧道/","link":"","permalink":"https://chambai.github.io/2019/03/18/tech/ip隧道/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 通过之前的文章tap/tun 详解，我们知道 tun 是一个网络层的设备，也被叫做点对点设备，之所以叫这个名字，是因为 tun 常常被用来做隧道通信（tunnel）。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 通过之前的文章tap/tun 详解，我们知道 tun 是一个网络层的设备，也被叫做点对点设备，之所以叫这个名字，是因为 tun 常常被用来做隧道通信（tunnel）。 IP 隧道Linux 原生支持多种三层隧道，其底层实现原理都是基于 tun 设备。我们可以通过命令 ip tunnel help 查看 IP 隧道的相关操作。 12345678910111213[root@localhost ~]# ip tunnel helpUsage: ip tunnel &#123; add | change | del | show | prl | 6rd &#125; [ NAME ] [ mode &#123; ipip | gre | sit | isatap | vti &#125; ] [ remote ADDR ] [ local ADDR ] [ [i|o]seq ] [ [i|o]key KEY ] [ [i|o]csum ] [ prl-default ADDR ] [ prl-nodefault ADDR ] [ prl-delete ADDR ] [ 6rd-prefix ADDR ] [ 6rd-relay_prefix ADDR ] [ 6rd-reset ] [ ttl TTL ] [ tos TOS ] [ [no]pmtudisc ] [ dev PHYS_DEV ]Where: NAME := STRING ADDR := &#123; IP_ADDRESS | any &#125; TOS := &#123; STRING | 00..ff | inherit | inherit/STRING | inherit/00..ff &#125; TTL := &#123; 1..255 | inherit &#125; KEY := &#123; DOTTED_QUAD | NUMBER &#125; 可以看到，Linux 原生一共支持 5 种 IP 隧道。 ipip：即 IPv4 in IPv4，在 IPv4 报文的基础上再封装一个 IPv4 报文。 gre：即通用路由封装（Generic Routing Encapsulation），定义了在任意一种网络层协议上封装其他任意一种网络层协议的机制，IPv4 和 IPv6 都适用。 sit：和 ipip 类似，不同的是 sit 是用 IPv4 报文封装 IPv6 报文，即 IPv6 over IPv4。 isatap：即站内自动隧道寻址协议（Intra-Site Automatic Tunnel Addressing Protocol），和 sit 类似，也是用于 IPv6 的隧道封装。 vti：即虚拟隧道接口（Virtual Tunnel Interface），是 cisco 提出的一种 IPsec 隧道技术。 实践 IPIP 隧道我们下面以 ipip 作为例子，来实践下 Linux 的隧道通信。本文以前文的 Linux 路由机制作为基础，不清楚 Linux 路由的可以先翻看下那篇文章再来看。 实践之前，需要知道的是，ipip 需要内核模块 ipip.ko 的支持，通过 lsmod | grep ipip 查看内核是否加载，若没有则用 modprobe ipip 先加载，正常加载应该显示： 12345[root@by ~]# modprobe ipip[root@by ~]# lsmod | grep ipipipip 13465 0tunnel4 13252 1 ipipip_tunnel 25163 1 ipip 加载 ipip 模块后，就可以创建隧道了，方法是先创建一个 tun 设备，然后将该 tun 设备绑定为一个 ipip 隧道即可。 我们的实验拓扑如下： 首先参照路由那篇文章，保证 v1 和 v2 能够通信，这里就不再赘述了。 然后创建 tun 设备，并设置为 ipip 隧道。 12345# 1) 在 ns1 上创建 tun1 和 ipip tunnelip netns exec ns1 ip tunnel add tun1 mode ipip remote 10.10.20.2 local 10.10.10.2ip netns exec ns1 ip l s tun1 upip netns exec ns1 ip a a 10.10.100.10 peer 10.10.200.10 dev tun1 上面的命令是在 NS1 上创建 tun 设备 tun1，并设置隧道模式为 ipip，然后还需要设置隧道端点，用 remote 和 local 表示，这是 隧道外层 IP，对应的还有 隧道内层 IP，用 ip addr xx peer xx 配置。大体的示意图如下所示。 同理，我们也在 NS2 上做如上配置。 12345# 1) 在 ns2 上创建 tun2 和 ipip tunnelip netns exec ns2 ip tunnel add tun2 mode ipip remote 10.10.10.2 local 10.10.20.2ip netns exec ns2 ip l s tun2 upip netns exec ns2 ip a a 10.10.200.10 peer 10.10.100.10 dev tun2 当做完上述配置，两个 tun 设备端点就可以互通了，如下： 12345678910[root@by ~]# ip netns exec ns1 ping 10.10.200.10 -c 4PING 10.10.200.10 (10.10.200.10) 56(84) bytes of data.64 bytes from 10.10.200.10: icmp_seq=1 ttl=64 time=0.090 ms64 bytes from 10.10.200.10: icmp_seq=2 ttl=64 time=0.148 ms64 bytes from 10.10.200.10: icmp_seq=3 ttl=64 time=0.112 ms64 bytes from 10.10.200.10: icmp_seq=4 ttl=64 time=0.110 ms--- 10.10.200.10 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3000msrtt min/avg/max/mdev = 0.090/0.115/0.148/0.020 ms 我们试着来分析下上述这个过程。 1、首先 ping 命令构建一个 ICMP 请求包，ICMP 包封装在 IP 包中，源目的 IP 地址分别为 tun1(10.10.100.10) 和 tun2(10.10.200.10) 的地址。 2、由于 tun1 和 tun2 不在同一网段，所以会查路由表，当通过 ip tunnel 命令建立 ipip 隧道之后，会自动生成一条路由，如下，表明去往目的地 10.10.200.10 的路由直接从 tun1 出去。 123456[root@by ~]# ip netns exec ns1 route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface10.10.10.0 0.0.0.0 255.255.255.0 U 0 0 0 v110.10.20.0 10.10.10.1 255.255.255.0 UG 0 0 0 v110.10.200.10 0.0.0.0 255.255.255.255 UH 0 0 0 tun1 3、由于配置了隧道端点，数据包出了 tun1，到达 v1，根据 ipip 隧道的配置，会封装上一层新的 IP 报头，源目的 IP 地址分别为 v1(10.10.10.2) 和 v2(10.10.20.2)。 4、v1 和 v2 同样不在一个网段，同样查路由表，发现去往 10.10.20.0 网段可以从 10.10.10.1 网关发出。 5、Linux 打开了 ip_forward，相当于一台路由器，10.10.10.0 和 10.10.20.0 是两条直连路由，所以直接查表转发，从 NS1 过渡到 NS2。 6、数据包到达 NS2 的 v2，解封装数据包，发现内层 IP 报文的目的 IP 地址是 10.10.200.10，这正是自己配置的 ipip 隧道的 tun2 地址，于是就将报文交给 tun2 设备。至此，tun1 的 ping 请求包就成功到达 tun2。 7、由于 ICMP 报文的传输特性，有去必有回，所以 NS2 上会构造 ICMP 响应包，并根据以上相同步骤封装和解封装数据包，直至到达 tun1，整个 ping 过程完成。 以上便是大体的 ipip 隧道通信过程，下面我们可以再抓包进一步验证。 如下是通过 wireshark 抓取的 v1 口的包： 可以看到，有两层 IP 报文头，外层使用的 ipip 协议构成隧道的端点，内层是正常的通信报文，封装了 ICMP 报文作为 payload。 总结现在的 Linux 内核原生支持 5 种隧道协议，它们底层实现都是采用 tun 虚拟设备。 我们熟知的各种 VPN 软件，其底层实现都离不开这 5 种隧道协议。 我们可以把上面的 ipip 改成其他隧道模式，其他不变，同样可以完成不同隧道的实验。 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"tunnel","slug":"tunnel","permalink":"https://chambai.github.io/tags/tunnel/"},{"name":"ipip","slug":"ipip","permalink":"https://chambai.github.io/tags/ipip/"}]},{"title":"Linux云网络基础之 Linux 虚拟路由","slug":"tech/Linux路由功能","date":"2019-03-14T05:16:14.000Z","updated":"2019-04-17T16:27:49.634Z","comments":true,"path":"2019/03/14/tech/Linux路由功能/","link":"","permalink":"https://chambai.github.io/2019/03/14/tech/Linux路由功能/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 之前文章有读者留言： 我的回答基本上是一句废话，因为只要你知道点网络的基础知识，肯定知道这种情况要走三层路由。 但知道归知道，不实践永远不知道自己是不是真的知道（有点绕），我相信那位读者也是希望我能讲讲这其中具体是怎么路由的，今天这篇文章就来说说这个。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 之前文章有读者留言： 我的回答基本上是一句废话，因为只要你知道点网络的基础知识，肯定知道这种情况要走三层路由。 但知道归知道，不实践永远不知道自己是不是真的知道（有点绕），我相信那位读者也是希望我能讲讲这其中具体是怎么路由的，今天这篇文章就来说说这个。 Linux 本身就是一台路由器前面的文章我们学习了多种虚拟的网络设备，包括网卡、交换机等，也了解了怎么用工具来操作这些设备，那么，回到今天的主题，路由器有没有对应的虚拟设备，能不能也用相关工具来操作呢，这个答案如果要深究的话，也是有的，比如 OpenStack 的 DVR、一些开源的虚拟路由器实现等等。 不过我们不做那么深究的讨论，简化问题，Linux 系统实际上没有实现相关的虚拟路由器设备，自然也没有工具可以操作路由器，因为 Linux 本身就是一台路由器。 Linux 提供一个开关来操作路由功能，就是 /proc/sys/net/ipv4/ip_forward，默认这个开关是关的，打开只需： 1echo 1 &gt; /proc/sys/net/ipv4/ip_forward 但这种打开方式只是临时的，如果要一劳永逸，可以修改配置文件 /etc/sysctl.conf，添加或修改项 net.ipv4.ip_forward 为： 1net.ipv4.ip_forward = 1 即可。 实践为了降低大家实践的难度，我们就不创建虚拟机了，直接使用 namespace，一条 ip 命令就可以搞定所有的操作。 我们按照下面的图示进行操作（NS1 和 NS2 分布在不同网段）： 创建两个 namespace： 12ip netns add ns1ip netns add ns2 创建两对 veth-pair，一端分别挂在两个 namespace 中： 12345ip link add v1 type veth peer name v1_rip link add v2 type veth peer name v2_rip link set v1 netns ns1ip link set v2 netns ns2 分别给两对 veth-pair 端点配上 IP 并启用： 123456789ip a a 10.10.10.1/24 dev v1_rip l s v1_r upip a a 10.10.20.1/24 dev v2_rip l s v2_r upip netns exec ns1 ip a a 10.10.10.2/24 dev v1ip netns exec ns1 ip l s v1 upip netns exec ns2 ip a a 10.10.20.2/24 dev v2ip netns exec ns2 ip l s v2 up 验证一下： v1 ping v2，结果不通。 看下 ip_forward 的值： 12[root@by ~]# cat /proc/sys/net/ipv4/ip_forward0 没开路由怎么通，改为 1 再试，还是不通。 看下 ns1 的路由表： 1234[root@by ~]# ip netns exec ns1 route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface10.10.10.0 0.0.0.0 255.255.255.0 U 0 0 0 v1 只有一条直连路由，没有去往 10.10.20.0/24 网段的路由，怎么通？那就给它配一条： 1234567[root@by ~]# ip netns exec ns1 route add -net 10.10.20.0 netmask 255.255.255.0 gw 10.10.10.1[root@by ~]# ip netns exec ns1 route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface10.10.10.0 0.0.0.0 255.255.255.0 U 0 0 0 v110.10.20.0 10.10.10.1 255.255.255.0 UG 0 0 0 v1 同理也给 ns2 配上去往 10.10.10.0/24 网段的路由。 最后再 ping，成功了！ 12345678[root@by ~]# ip netns exec ns1 ping 10.10.20.2PING 10.10.20.2 (10.10.20.2) 56(84) bytes of data.64 bytes from 10.10.20.2: icmp_seq=1 ttl=63 time=0.071 ms64 bytes from 10.10.20.2: icmp_seq=2 ttl=63 time=0.070 ms^C--- 10.10.20.2 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1000msrtt min/avg/max/mdev = 0.070/0.070/0.071/0.008 ms 总结Linux 本身是一台路由器。 上面的实验使用 namespace 效果和使用虚拟机是一样的，关键是知道有这个功能，知道怎么用就差不多了。 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"vrouter","slug":"vrouter","permalink":"https://chambai.github.io/tags/vrouter/"}]},{"title":"Linux云网络基础之虚拟网络设备 Bridge 详解","slug":"tech/bridge详解","date":"2019-03-10T05:16:14.000Z","updated":"2019-04-17T16:29:02.752Z","comments":true,"path":"2019/03/10/tech/bridge详解/","link":"","permalink":"https://chambai.github.io/2019/03/10/tech/bridge详解/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 前面几篇文章介绍了 tap/tun、veth-pair，今天这篇来看看 Bridge。 Bridge 是什么同 tap/tun、veth-pair 一样，Bridge 也是一种虚拟网络设备，所以具备虚拟网络设备的所有特性，比如可以配置 IP、MAC 等。 除此之外，Bridge 还是一个交换机，具有交换机所有的功能。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 前面几篇文章介绍了 tap/tun、veth-pair，今天这篇来看看 Bridge。 Bridge 是什么同 tap/tun、veth-pair 一样，Bridge 也是一种虚拟网络设备，所以具备虚拟网络设备的所有特性，比如可以配置 IP、MAC 等。 除此之外，Bridge 还是一个交换机，具有交换机所有的功能。 对于普通的网络设备，就像一个管道，只有两端，数据从一端进，从另一端出。而 Bridge 有多个端口，数据可以从多个端口进，从多个端口出。 Bridge 的这个特性让它可以接入其他的网络设备，比如物理设备、虚拟设备、VLAN 设备等。Bridge 通常充当主设备，其他设备为从设备，这样的效果就等同于物理交换机的端口连接了一根网线。比如下面这幅图通过 Bridge 连接两个 VM 的 tap 虚拟网卡和物理网卡 eth0。 VM 同主机通信以这个图来简单说明下，借助 Bridge 来完成同主机两台 VM 的之间的通信流程。 首先准备一个 centos 或 ubuntu 虚拟机，然后创建一个 bridge： 12ip link add br0 type bridgeip link set br0 up 然后通过 virt-manager 创建两个 kvm 虚拟机：kvm1 和 kvm2（前提得支持嵌套虚拟化），将它们的 vNIC 挂到 br0 上，如下图： kvm 虚机会使用 tap 设备作为它的虚拟网卡，我们验证下： 12# ps -ef | grep kvm1libvirt+ 3549 1 87 ? 00:22:09 qemu-system-x86_64 -enable-kvm -name kvm1 ... -netdev tap,fd=26,id=hostnet0,vhost=on,vhostfd=28 ... 可以看到，其中网络部分参数，-netdev tap,fd=26 表示的就是连接主机上的 tap 设备。 创建的 fd=26 为读写 /dev/net/tun 的文件描述符。 使用 lsof -p 3549 验证下： 12345# lsof -p 3549COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME...qemu-system 3549 libvirt-qemu 26u CHR 10,200 0t107 135 /dev/net/tun... 可以看到，PID 为 3549 的进程打开了文件 /dev/net/tun，分配的文件描述符 fd 为 26。 因此，我们可以得出以下结论：在 kvm 虚机启动时，会向内核注册 tap 虚拟网卡，同时打开设备文件 /dev/net/tun，拿到文件描述符 fd，然后将 fd 和 tap 关联，tap 就成了一端连接着用户空间的 qemu-kvm，一端连着主机上的 bridge 的端口，促使两者完成通信。 下面分别给两虚机配上 IP：10.1.1.2/24 和 10.1.1.3/24，ping 一下： 在 bridge 上抓个包看看： 可以看到，br0 上抓到 ping 的 ICMP echo 包和 ARP 包。 Bridge 常用使用场景Bridge 设备通常就是结合 tap/tun、veth-pair 设备用于虚拟机、容器网络里面。这两种网络，在数据传输流程上还有些许不同，我们简单来看下： 首先是虚拟机网络，虚拟机一般通过 tap/tun 设备将虚拟机网卡同宿主机里的 Bridge 连接起来，完成同主机和跨主机的通信。如下图所示： 【图片来源于网络，侵权必删】 虚拟机发出的数据包通过 tap 设备先到达 br0，然后经过 eth0 发送到物理网络中，数据包不需要经过主机的的协议栈，效率是比较高的。 其次是容器网络（容器网络有多种引申的形式，这里我们只说 Bridge 网络），容器网络和虚拟机网络类似，不过一般是使用 veth-pair 来连接容器和主机，因为在主机看来，容器就是一个个被隔离的 namespace，用 veth-pair 更有优势。如下图所示： 【图片来源于网络，侵权必删】 容器的 Bridge 网络通常配置成内网形式，要出外网需要走 NAT，所以它的数据传输不像虚拟机的桥接形式可以直接跨过协议栈，而是必须经过协议栈，通过 NAT 和 ip_forward 功能从物理网卡转发出去，因此，从性能上看，Bridge 网络虚拟机要优于容器。 总结Linux Bridge 是虚拟交换机，功能和物理交换机一样，用于连接虚拟机和容器。 虚拟机网络和容器网络的区别。 Bridge 是偏低级的工具，更高级的工具是 Open vSwitch，这个工具后面再详说。 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"Bridge","slug":"Bridge","permalink":"https://chambai.github.io/tags/Bridge/"}]},{"title":"未来幸存者","slug":"life/未来幸存者","date":"2019-03-09T05:16:14.000Z","updated":"2019-04-17T14:48:52.552Z","comments":true,"path":"2019/03/09/life/未来幸存者/","link":"","permalink":"https://chambai.github.io/2019/03/09/life/未来幸存者/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 《未来世界的幸存者》是知名 IT 博主阮一峰的专栏作品，书中深刻剖析了随着 IT 技术的发展，未来人们的生活将会受到如何的冲击和颠覆，整体上作者是偏悲观的，但是他也给出了一些建议，值得一读。 01 作者有一个比较悲观的预感：未来只有两种途径可以改变人生，一种是学习技术，另一种是购买彩票。 虽然很悲观，但也不无道理。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 《未来世界的幸存者》是知名 IT 博主阮一峰的专栏作品，书中深刻剖析了随着 IT 技术的发展，未来人们的生活将会受到如何的冲击和颠覆，整体上作者是偏悲观的，但是他也给出了一些建议，值得一读。 01 作者有一个比较悲观的预感：未来只有两种途径可以改变人生，一种是学习技术，另一种是购买彩票。 虽然很悲观，但也不无道理。 技术确确实实正在悄然改变人们的衣食住行。现在，一个人足不出户，仅凭一部手机就可以解决所有的问题。将来，会更夸张，随着人工智能、虚拟现实（VR/AR）、机器人技术、纳米技术、基因工程等技术的发展，人们基本上都要依赖机器人才能生存。就像美国科幻电视剧《西部世界》（West World）中描述的那样： 这是一个大乐园，里面都是 3D 打印出来的智能机器人陪着游客玩。游客分辨不出谁是真人，谁是机器人，除非事前知道。 这看似挺遥远，但其实已有现实的影子。比如无人驾驶、机器人驾驶，书中举了一个有趣的例子： 由于人类不如机器可靠，将被规定不得驾驶汽车，只能由机器驾驶，如果你想开车过过瘾，必须去专门的游乐场，就好像现在骑马只能去马场一样。 类似的还有一些针对不同场景的机器人，比如为家庭服务的家居机器人、扫地机器人，负责企业安保工作的安保机器人，应用在农业灌溉方面的飞行机器人等等。这些都在不同程度上冲击着人类的生活，而你不太可能拒绝使用它们，只会更加依赖它们。 02 技术带来了现代化的生活，但也带来了前所未有的危机。 首先，蓝领白领的界限会逐渐消失。蓝领代表着那些做着重复体力活的人，比如售货员、服务员、打字员、装配工、出纳、保安……（你可以列出一大串职业），由于他们的工作偏低技能，所以会被自动化替代，他们将会面临失业甚至无法再就业的局面。 而白领则代表了那些依靠智力的办公室一族，比如税务顾问、银行职员、信贷员、财务会计等等，随着办公自动化的出现，他们的饭碗也将会不保。 其次，技术将会动摇人类社会结构，将整个社会一分为二：懂技术的人和不懂技术的人。懂技术的人会变得越来越有钱，而不懂技术的人收入根本不增长，贫富差距会越来越大。最终这些不懂技术的人将会沦为： 清贫青年，流沙中年，下流老人 03 那么，有没有技术不能取代的工作，所需要的技能是依靠技术也无法学会的。作家吴晓波把这种技术难以替代的能力，称为“柔软的能力”。 书中举了三种这样的能力： 人性化和人格魅力 创意 决策和领导力 这三种能力并非一朝一夕能够练就的，不管处于哪个年龄层的人，都应该时刻保持“自主、跨界、终身学习”的心态，才不至于让自己沦为替代品。 世界上没有安全的工作，即使有这些能力的人，也不免会遇到什么天灾人祸。书中谈到任何人都有必要给自己的人生制定一份 B 计划，来应对各种各样的危机。 对于没有这些能力的人，从现在开始，就应该多努力培养自己这方面的能力。那普通人该怎么培养这些能力呢？最好的方法就是学习编程技术，因为编程技术可能是这个世界上最有创意的工作了，但这也不适合每个人，而且普通人要学好编程，需要比常人付出更多的努力才行。 技术不是万能的，技术也是有边界的。对技术的妄加使用，最终也会对人类造成毁灭性的打击。 最终更悲观的结果就是世界上将会没有幸存者。 –END– 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有大量书籍和视频资源，后台回复 「1024」 即可领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"读书","slug":"读书","permalink":"https://chambai.github.io/categories/读书/"}],"tags":[]},{"title":"一文总结虚拟网络设备 eth, tap/tun, veth-pair","slug":"tech/eth-taptun-vethpair总结","date":"2019-03-08T05:16:14.000Z","updated":"2019-04-17T16:28:53.057Z","comments":true,"path":"2019/03/08/tech/eth-taptun-vethpair总结/","link":"","permalink":"https://chambai.github.io/2019/03/08/tech/eth-taptun-vethpair总结/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 本文翻译自：http://t.cn/EIdjMTc Linux 虚拟网络的背后都是由一个个的虚拟设备构成的。虚拟化技术没出现之前，计算机网络系统都只包含物理的网卡设备，通过网卡适配器，线缆介质，连接外部网络，构成庞大的 Internet。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 本文翻译自：http://t.cn/EIdjMTc Linux 虚拟网络的背后都是由一个个的虚拟设备构成的。虚拟化技术没出现之前，计算机网络系统都只包含物理的网卡设备，通过网卡适配器，线缆介质，连接外部网络，构成庞大的 Internet。 然而，随着虚拟化技术的出现，网络也随之被虚拟化，相较于单一的物理网络，虚拟网络变得非常复杂，在一个主机系统里面，需要实现诸如交换、路由、隧道、隔离、聚合等多种网络功能。 而实现这些功能的基本元素就是虚拟的网络设备，比如 tap、tun 和 veth-pair。 tap/tuntap/tun 提供了一台主机内用户空间的数据传输机制。它虚拟了一套网络接口，这套接口和物理的接口无任何区别，可以配置 IP，可以路由流量，不同的是，它的流量只在主机内流通。 tap/tun 有些许的不同，tun 只操作三层的 IP 包，而 tap 操作二层的以太网帧。 veth-pairveth-pair 是成对出现的一种虚拟网络设备，一端连接着协议栈，一端连接着彼此，数据从一端出，从另一端进。 它的这个特性常常用来连接不同的虚拟网络组件，构建大规模的虚拟网络拓扑，比如连接 Linux Bridge、OVS、LXC 容器等。 一个很常见的案例就是它被用于 OpenStack Neutron，构建非常复杂的网络形态。 总结最后，总结一下，我们提到几种网络设备，eth0、tap、tun、veth-pair，这些都构成了如今云网络必不可少的元素。 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"tap","slug":"tap","permalink":"https://chambai.github.io/tags/tap/"},{"name":"tun","slug":"tun","permalink":"https://chambai.github.io/tags/tun/"},{"name":"veth-pair","slug":"veth-pair","permalink":"https://chambai.github.io/tags/veth-pair/"}]},{"title":"Linux云网络基础之虚拟网络设备 veth-pair 详解","slug":"tech/veth-pair详解","date":"2019-03-03T05:16:14.000Z","updated":"2019-04-19T05:23:25.682Z","comments":true,"path":"2019/03/03/tech/veth-pair详解/","link":"","permalink":"https://chambai.github.io/2019/03/03/tech/veth-pair详解/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 前面这篇文章介绍了 tap/tun 设备之后，大家应该对虚拟网络设备有了一定的了解，本文来看另外一种虚拟网络设备 veth-pair。 01 veth-pair 是什么顾名思义，veth-pair 就是一对的虚拟设备接口，和 tap/tun 设备不同的是，它都是成对出现的。一端连着协议栈，一端彼此相连着。如下图所示：","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 前面这篇文章介绍了 tap/tun 设备之后，大家应该对虚拟网络设备有了一定的了解，本文来看另外一种虚拟网络设备 veth-pair。 01 veth-pair 是什么顾名思义，veth-pair 就是一对的虚拟设备接口，和 tap/tun 设备不同的是，它都是成对出现的。一端连着协议栈，一端彼此相连着。如下图所示： 正因为有这个特性，它常常充当着一个桥梁，连接着各种虚拟网络设备，典型的例子像“两个 namespace 之间的连接”，“Bridge、OVS 之间的连接”，“Docker 容器之间的连接” 等等，以此构建出非常复杂的虚拟网络结构，比如 OpenStack Neutron。 02 veth-pair 的连通性我们给上图中的 veth0 和 veth1 分别配上 IP：10.1.1.2 和 10.1.1.3，然后从 veth0 ping 一下 veth1。理论上它们处于同网段，是能 ping 通的，但结果却是 ping 不通。 抓个包看看，tcpdump -nnt -i veth0 12345root@ubuntu:~# tcpdump -nnt -i veth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth0, link-type EN10MB (Ethernet), capture size 262144 bytesARP, Request who-has 10.1.1.3 tell 10.1.1.2, length 28ARP, Request who-has 10.1.1.3 tell 10.1.1.2, length 28 可以看到，由于 veth0 和 veth1 处于同一个网段，且是第一次连接，所以会事先发 ARP 包，但 veth1 并没有响应 ARP 包。 经查阅，这是由于我使用的 Ubuntu 系统内核中一些 ARP 相关的默认配置限制所导致的，需要修改一下配置项： 12345echo 1 &gt; /proc/sys/net/ipv4/conf/veth1/accept_localecho 1 &gt; /proc/sys/net/ipv4/conf/veth0/accept_localecho 0 &gt; /proc/sys/net/ipv4/conf/all/rp_filterecho 0 &gt; /proc/sys/net/ipv4/conf/veth0/rp_filterecho 0 &gt; /proc/sys/net/ipv4/conf/veth1/rp_filter 完了再 ping 就行了。 12345678root@ubuntu:~# ping -I veth0 10.1.1.3 -c 2PING 10.1.1.3 (10.1.1.3) from 10.1.1.2 veth0: 56(84) bytes of data.64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.047 ms64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.064 ms--- 10.1.1.3 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 3008msrtt min/avg/max/mdev = 0.047/0.072/0.113/0.025 ms 我们对这个通信过程比较感兴趣，可以抓包看看。 对于 veth0 口： 123456789root@ubuntu:~# tcpdump -nnt -i veth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth0, link-type EN10MB (Ethernet), capture size 262144 bytesARP, Request who-has 10.1.1.3 tell 10.1.1.2, length 28ARP, Reply 10.1.1.3 is-at 5a:07:76:8e:fb:cd, length 28IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 1, length 64IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 2, length 64IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 3, length 64IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2244, seq 1, length 64 对于 veth1 口： 123456789root@ubuntu:~# tcpdump -nnt -i veth1tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytesARP, Request who-has 10.1.1.3 tell 10.1.1.2, length 28ARP, Reply 10.1.1.3 is-at 5a:07:76:8e:fb:cd, length 28IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 1, length 64IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 2, length 64IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 3, length 64IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2244, seq 1, length 64 奇怪，我们并没有看到 ICMP 的 echo reply 包，那它是怎么 ping 通的？ 其实这里 echo reply 走的是 localback 口，不信抓个包看看： 1234567root@ubuntu:~# tcpdump -nnt -i lotcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on lo, link-type EN10MB (Ethernet), capture size 262144 bytesIP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 2244, seq 1, length 64IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 2244, seq 2, length 64IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 2244, seq 3, length 64IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 2244, seq 4, length 64 为什么？ 我们看下整个通信流程就明白了。 首先 ping 程序构造 ICMP echo request，通过 socket 发给协议栈。 由于 ping 指定了走 veth0 口，如果是第一次，则需要发 ARP 请求，否则协议栈直接将数据包交给 veth0。 由于 veth0 连着 veth1，所以 ICMP request 直接发给 veth1。 veth1 收到请求后，交给另一端的协议栈。 协议栈看本地有 10.1.1.3 这个 IP，于是构造 ICMP reply 包，查看路由表，发现回给 10.1.1.0 网段的数据包应该走 localback 口，于是将 reply 包交给 lo 口（会优先查看路由表的 0 号表，ip route show table 0 查看）。 lo 收到协议栈的 reply 包后，啥都没干，转手又回给协议栈。 协议栈收到 reply 包之后，发现有 socket 在等待包，于是将包给 socket。 等待在用户态的 ping 程序发现 socket 返回，于是就收到 ICMP 的 reply 包。 整个过程如下图所示： 03 两个 namespace 之间的连通性namespace 是 Linux 2.6.x 内核版本之后支持的特性，主要用于资源的隔离。有了 namespace，一个 Linux 系统就可以抽象出多个网络子系统，各子系统间都有自己的网络设备，协议栈等，彼此之间互不影响。 如果各个 namespace 之间需要通信，怎么办呢，答案就是用 veth-pair 来做桥梁。 根据连接的方式和规模，可以分为“直接相连”，“通过 Bridge 相连” 和 “通过 OVS 相连”。 3.1 直接相连直接相连是最简单的方式，如下图，一对 veth-pair 直接将两个 namespace 连接在一起。 给 veth-pair 配置 IP，测试连通性： 1234567891011121314151617181920212223242526# 创建 namespaceip netns a ns1ip netns a ns2# 创建一对 veth-pair veth0 veth1ip l a veth0 type veth peer name veth1# 将 veth0 veth1 分别加入两个 nsip l s veth0 netns ns1ip l s veth1 netns ns2# 给两个 veth0 veth1 配上 IP 并启用ip netns exec ns1 ip a a 10.1.1.2/24 dev veth0ip netns exec ns1 ip l s veth0 upip netns exec ns2 ip a a 10.1.1.3/24 dev veth1ip netns exec ns2 ip l s veth1 up# 从 veth0 ping veth1[root@localhost ~]# ip netns exec ns1 ping 10.1.1.3PING 10.1.1.3 (10.1.1.3) 56(84) bytes of data.64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.073 ms64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.068 ms--- 10.1.1.3 ping statistics ---15 packets transmitted, 15 received, 0% packet loss, time 14000msrtt min/avg/max/mdev = 0.068/0.084/0.201/0.032 ms 3.2 通过 Bridge 相连Linux Bridge 相当于一台交换机，可以中转两个 namespace 的流量，我们看看 veth-pair 在其中扮演什么角色。 如下图，两对 veth-pair 分别将两个 namespace 连到 Bridge 上。 同样给 veth-pair 配置 IP，测试其连通性： 123456789101112131415161718192021222324252627282930313233# 首先创建 bridge br0ip l a br0 type bridgeip l s br0 up # 然后创建两对 veth-pairip l a veth0 type veth peer name br-veth0ip l a veth1 type veth peer name br-veth1# 分别将两对 veth-pair 加入两个 ns 和 br0ip l s veth0 netns ns1ip l s br-veth0 master br0ip l s br-veth0 upip l s veth1 netns ns2ip l s br-veth1 master br0ip l s br-veth1 up# 给两个 ns 中的 veth 配置 IP 并启用ip netns exec ns1 ip a a 10.1.1.2/24 dev veth0ip netns exec ns1 ip l s veth0 upip netns exec ns2 ip a a 10.1.1.3/24 dev veth1ip netns exec ns2 ip l s veth1 up# veth0 ping veth1[root@localhost ~]# ip netns exec ns1 ping 10.1.1.3PING 10.1.1.3 (10.1.1.3) 56(84) bytes of data.64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.060 ms64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.105 ms--- 10.1.1.3 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 999msrtt min/avg/max/mdev = 0.060/0.082/0.105/0.024 ms 3.3 通过 OVS 相连OVS 是第三方开源的 Bridge，功能比 Linux Bridge 要更强大，对于同样的实验，我们用 OVS 来看看是什么效果。 如下图所示： 同样测试两个 namespace 之间的连通性： 1234567891011121314151617181920212223242526272829303132# 用 ovs 提供的命令创建一个 ovs bridgeovs-vsctl add-br ovs-br# 创建两对 veth-pairip l a veth0 type veth peer name ovs-veth0ip l a veth1 type veth peer name ovs-veth1# 将 veth-pair 两端分别加入到 ns 和 ovs bridge 中ip l s veth0 netns ns1ovs-vsctl add-port ovs-br ovs-veth0ip l s ovs-veth0 upip l s veth1 netns ns2ovs-vsctl add-port ovs-br ovs-veth1ip l s ovs-veth1 up# 给 ns 中的 veth 配置 IP 并启用ip netns exec ns1 ip a a 10.1.1.2/24 dev veth0ip netns exec ns1 ip l s veth0 upip netns exec ns2 ip a a 10.1.1.3/24 dev veth1ip netns exec ns2 ip l s veth1 up# veth0 ping veth1[root@localhost ~]# ip netns exec ns1 ping 10.1.1.3PING 10.1.1.3 (10.1.1.3) 56(84) bytes of data.64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.311 ms64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.087 ms^C--- 10.1.1.3 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 999msrtt min/avg/max/mdev = 0.087/0.199/0.311/0.112 ms 总结veth-pair 在虚拟网络中充当着桥梁的角色，连接多种网络设备构成复杂的网络。 veth-pair 的三个经典实验，直接相连、通过 Bridge 相连和通过 OVS 相连。 参考： http://www.opencloudblog.com/?p=66 https://segmentfault.com/a/1190000009251098 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"veth-pair","slug":"veth-pair","permalink":"https://chambai.github.io/tags/veth-pair/"}]},{"title":"如何用 tap/tun 设备编写一个 ICMP 程序","slug":"tech/基于taptun写一个ICMP程序","date":"2019-03-01T05:16:14.000Z","updated":"2019-04-17T16:28:29.467Z","comments":true,"path":"2019/03/01/tech/基于taptun写一个ICMP程序/","link":"","permalink":"https://chambai.github.io/2019/03/01/tech/基于taptun写一个ICMP程序/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 前面两篇文章已经介绍过 tap/tun 的原理和配置工具。这篇文章通过一个编程示例来深入了解 tap/tun 的程序结构。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 前面两篇文章已经介绍过 tap/tun 的原理和配置工具。这篇文章通过一个编程示例来深入了解 tap/tun 的程序结构。 01 准备工作首先通过 modinfo tun 查看系统内核是否支持 tap/tun 设备驱动。 12345678910111213141516[root@by ~]# modinfo tunfilename: /lib/modules/3.10.0-862.14.4.el7.x86_64/kernel/drivers/net/tun.ko.xzalias: devname:net/tunalias: char-major-10-200license: GPLauthor: (C) 1999-2004 Max Krasnyansky &lt;maxk@qualcomm.com&gt;description: Universal TUN/TAP device driverretpoline: Yrhelversion: 7.5srcversion: 50878D5D5A0138445B25AA8depends:intree: Yvermagic: 3.10.0-862.14.4.el7.x86_64 SMP mod_unload modversionssigner: CentOS Linux kernel signing keysig_key: E4:A1:B6:8F:46:8A:CA:5C:22:84:50:53:18:FD:9D:AD:72:4B:13:03sig_hashalgo: sha256 在 linux 2.4 及之后的内核版本中，tun/tap 驱动是默认编译进内核中的。 如果你的系统不支持，请先选择手动编译内核或者升级内核。编译时开启下面的选项即可： 1Device Drivers =&gt; Network device support =&gt; Universal TUN/TAP device driver support tap/tun 也支持编译成模块，如果编译成模块，需要手动加载它： 123[root@localhost ~]# modprobe tun[root@localhost ~]# lsmod | grep tuntun 31665 0 关于以上的详细步骤，网上有很多教程，这里就不再赘述了。 https://blog.csdn.net/lishuhuakai/article/details/70305543 上面只是加载了 tap/tun 模块，要完成 tap/tun 的编码，还需要有设备文件，运行命令： 1mknod /dev/net/tun c 10 200 # c表示为字符设备，10和200分别是主设备号和次设备号 这样在 /dev/net 下就创建了一个名为 tun 的文件。 02 编程示例2.1 启动设备使用 tap/tun 设备，需要先进行一些初始化工作，如下代码所示： 123456789101112131415161718192021222324252627282930int tun_alloc(char *dev, int flags)&#123; assert(dev != NULL); struct ifreq ifr; int fd, err; char *clonedev = \"/dev/net/tun\"; if ((fd = open(clonedev, O_RDWR)) &lt; 0) &#123; return fd; &#125; memset(&amp;ifr, 0, sizeof(ifr)); ifr.ifr_flags = flags; if (*dev != '\\0') &#123; strncpy(ifr.ifr_name, dev, IFNAMSIZ); &#125; if ((err = ioctl(fd, TUNSETIFF, (void *) &amp;ifr)) &lt; 0) &#123; close(fd); return err; &#125; // 一旦设备开启成功，系统会给设备分配一个名称，对于tun设备，一般为tunX，X为从0开始的编号； // 对于tap设备，一般为tapX strcpy(dev, ifr.ifr_name); return fd;&#125; 首先打开字符设备文件 /dev/net/tun，然后用 ioctl 注册设备的工作模式，是 tap 还是 tun。这个模式由结构体 struct ifreq 的属性 ifr_flags 来定义，它有以下表示： IFF_TUN: 表示创建一个 tun 设备。 IFF_TAP: 表示创建一个 tap 设备。 IFF_NO_PI: 表示不包含包头信息，默认的，每个数据包传到用户空间时，都会包含一个附加的包头来保存包信息，这个表示不加包头。 IFF_ONE_QUEUE：表示采用单一队列模式。 还是有一个属性是 ifr_name，表示设备的名字，它可以由用户自己指定，也可以由系统自动分配，比如 tapX、tunX，X 从 0 开始编号。 ioctl 完了之后，文件描述符 fd 就和设备建立起了关联，之后就可以根据 fd 进行 read 和 write 操作了。 2.2 写一个 ICMP 的调用函数为了测试上面的程序，我们写一个简单的 ICMP echo 程序。我们会使用 tun 设备，然后给 tunX 接口发送一个 ping 包，程序简单响应这个包，完成 ICMP 的 request 和 reply 的功能。 如下代码所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int main()&#123; int tun_fd, nread; char buffer[4096]; char tun_name[IFNAMSIZ]; tun_name[0] = '\\0'; /* Flags: IFF_TUN - TUN device (no Ethernet headers) * IFF_TAP - TAP device * IFF_NO_PI - Do not provide packet information */ tun_fd = tun_alloc(tun_name, IFF_TUN | IFF_NO_PI); if (tun_fd &lt; 0) &#123; perror(\"Allocating interface\"); exit(1); &#125; printf(\"Open tun/tap device: %s for reading...\\n\", tun_name); while (1) &#123; unsigned char ip[4]; // 收包 nread = read(tun_fd, buffer, sizeof(buffer)); if (nread &lt; 0) &#123; perror(\"Reading from interface\"); close(tun_fd); exit(1); &#125; printf(\"Read %d bytes from tun/tap device\\n\", nread); // 简单对收到的包调换一下顺序 memcpy(ip, &amp;buffer[12], 4); memcpy(&amp;buffer[12], &amp;buffer[16], 4); memcpy(&amp;buffer[16], ip, 4); buffer[20] = 0; *((unsigned short *)&amp;buffer[22]) += 8; // 发包 nread = write(tun_fd, buffer, nread); printf(\"Write %d bytes to tun/tap device, that's %s\\n\", nread, buffer); &#125; return 0;&#125; 下面测试一下。 2.3 给 tap/tun 设备配置 IP 地址编译： 123[root@localhost coding]# gcc -o taptun taptun.c[root@localhost coding]# ./taptunOpen tun/tap device: tun0 for reading... 开另一个终端，查看生成了 tun0 接口： 123[root@localhost coding]# ip a6: tun0: &lt;POINTOPOINT,MULTICAST,NOARP&gt; mtu 1500 qdisc noop state DOWN qlen 500 link/none 给 tun0 接口配置 IP 并启用，比如 10.1.1.2/24。 12[root@localhost ~]# ip a a 10.1.1.2/24 dev tun0[root@localhost ~]# ip l s tun0 up 再开一个终端，用 tcpdump 抓 tun0 的包。 1[root@localhost ~]# tcpdump -nnt -i tun0 然后在第二个终端 ping 一下 10.1.1.0/24 网段的 IP，比如 10.1.1.3，看到： 12345678910[root@localhost ~]# ping -c 4 10.1.1.3PING 10.1.1.3 (10.1.1.3) 56(84) bytes of data.64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.133 ms64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.188 ms64 bytes from 10.1.1.3: icmp_seq=3 ttl=64 time=0.092 ms64 bytes from 10.1.1.3: icmp_seq=4 ttl=64 time=0.110 ms--- 10.1.1.3 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3290msrtt min/avg/max/mdev = 0.092/0.130/0.188/0.038 ms 由于 tun0 接口建好之后，会生成一条到本网段 10.1.1.0/24 的默认路由，根据默认路由，数据包会走 tun0 口，所以能 ping 通，可以用 route -n 查看。 再看 tcpdump 抓包终端，成功显示 ICMP 的 request 包和 reply 包。 1234567[root@localhost ~]# tcpdump -nnt -i tun0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on tun0, link-type RAW (Raw IP), capture size 262144 bytesIP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 3250, seq 1, length 64IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 3250, seq 1, length 64IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 3250, seq 2, length 64IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 3250, seq 2, length 64 再看程序 taptun.c 的输出： 123456[root@localhost coding]# ./taptunOpen tun/tap device: tun0 for reading...Read 48 bytes from tun/tap deviceWrite 48 bytes to tun/tap deviceRead 48 bytes from tun/tap deviceWrite 48 bytes to tun/tap device ok，以上便验证了程序的正确性。 03 总结通过这个小例子，让我们知道了基于 tap/tun 编程的流程，对 tap/tun 又加深了一层理解。 使用 tap/tun 设备需要包含头文件 #include &lt;linux/if_tun.h&gt;，以下是完整代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/****************************************************************************** * File Name: taptun.c * Author: 公众号: Linux云计算网络 * Created Time: 2019年02月23日 星期六 21时28分24秒 *****************************************************************************/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;assert.h&gt;#include &lt;net/if.h&gt;#include &lt;sys/ioctl.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;#include &lt;linux/if_tun.h&gt;int tun_alloc(char *dev, int flags)&#123; assert(dev != NULL); struct ifreq ifr; int fd, err; char *clonedev = \"/dev/net/tun\"; if ((fd = open(clonedev, O_RDWR)) &lt; 0) &#123; return fd; &#125; memset(&amp;ifr, 0, sizeof(ifr)); ifr.ifr_flags = flags; if (*dev != '\\0') &#123; strncpy(ifr.ifr_name, dev, IFNAMSIZ); &#125; if ((err = ioctl(fd, TUNSETIFF, (void *) &amp;ifr)) &lt; 0) &#123; close(fd); return err; &#125; // 一旦设备开启成功，系统会给设备分配一个名称，对于tun设备，一般为tunX，X为从0开始的编号； // 对于tap设备，一般为tapX strcpy(dev, ifr.ifr_name); return fd;&#125;int main()&#123; int tun_fd, nread; char buffer[4096]; char tun_name[IFNAMSIZ]; tun_name[0] = '\\0'; /* Flags: IFF_TUN - TUN device (no Ethernet headers) * IFF_TAP - TAP device * IFF_NO_PI - Do not provide packet information */ tun_fd = tun_alloc(tun_name, IFF_TUN | IFF_NO_PI); if (tun_fd &lt; 0) &#123; perror(\"Allocating interface\"); exit(1); &#125; printf(\"Open tun/tap device: %s for reading...\\n\", tun_name); while (1) &#123; unsigned char ip[4]; // 收包 nread = read(tun_fd, buffer, sizeof(buffer)); if (nread &lt; 0) &#123; perror(\"Reading from interface\"); close(tun_fd); exit(1); &#125; printf(\"Read %d bytes from tun/tap device\\n\", nread); // 简单对收到的包调换一下顺序 memcpy(ip, &amp;buffer[12], 4); memcpy(&amp;buffer[12], &amp;buffer[16], 4); memcpy(&amp;buffer[16], ip, 4); buffer[20] = 0; *((unsigned short *)&amp;buffer[22]) += 8; // 发包 nread = write(tun_fd, buffer, nread); printf(\"Write %d bytes to tun/tap device, that's %s\\n\", nread, buffer); &#125; return 0;&#125; –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"tap","slug":"tap","permalink":"https://chambai.github.io/tags/tap/"},{"name":"tun","slug":"tun","permalink":"https://chambai.github.io/tags/tun/"},{"name":"ICMP","slug":"ICMP","permalink":"https://chambai.github.io/tags/ICMP/"}]},{"title":"Linux网络命令必知必会之创建 tap/tun 设备","slug":"tech/创建taptun设备","date":"2019-02-28T05:16:14.000Z","updated":"2019-04-17T16:28:37.658Z","comments":true,"path":"2019/02/28/tech/创建taptun设备/","link":"","permalink":"https://chambai.github.io/2019/02/28/tech/创建taptun设备/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 在这篇文章中，我们已经介绍了 tap/tun 的基本原理，本文将介绍如何使用工具 tunctl和 ip tuntap 来创建并使用 tap/tun 设备。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 在这篇文章中，我们已经介绍了 tap/tun 的基本原理，本文将介绍如何使用工具 tunctl和 ip tuntap 来创建并使用 tap/tun 设备。 tunctl安装首先在 centos 的环境中安装 tunctl。 12345678[root@localhost ~]# vim /etc/yum.repos.d/nux-misc.repo[nux-misc]name=Nux Miscbaseurl=http://li.nux.ro/download/nux/misc/el7/x86_64/enabled=0gpgcheck=1gpgkey=http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro ubuntu 是 apt-get install uml-utilities。 man tunctl 查看 tunctl 手册，用法如下： 12Synopsistunctl [ OPTIONS ] [ -u owner ] [-g group] [ -t device-name ] -u 参数指定用户名，表明这个接口只受该用户控制，这个接口发生的事不会影响到系统的接口。 -g 指定一组用户 -t 指定要创建的 tap/tun 设备名。 [OPTIONS] 部分： -b 简单打印创建的接口名字 -n 创建 tun 设备 -p 创建 tap 设备，默认创建该设备 -f tun-clone-device 指定 tun 设备对应的文件名，默认是 /dev/net/tun，有些系统是 /dev/misc/net/tun。 -d interfacename 删除指定接口 使用常见用法： 默认创建 tap 接口： 1tunctl 以上等价于 tunctl -p 为用户 user 创建一个 tap 接口： 1# tunctl -u user 创建 tun 接口： 1tunctl -n 为接口配置 IP 并启用： 1# ifconfig tap0 192.168.0.254 up 为接口添加路由： 1# route add -host 192.168.0.1 dev tap0 删除接口： 1# tunctl -d tap0 ip tuntap安装命令行输入 ip help 查看 ip 命令是否支持 tuntap 工具，支持的话就会显示 tuntap 选项： 123456[root@localhost ~]# ip helpUsage: ip [ OPTIONS ] OBJECT &#123; COMMAND | help &#125; ip [ -force ] -batch filenamewhere OBJECT := &#123; link | addr | addrlabel | route | rule | neigh | ntable | tunnel | tuntap | maddr | mroute | mrule | monitor | xfrm | netns | l2tp | tcp_metrics | token &#125; 不支持就请升级或下载最新的 iproute2 工具包，或者使用上面介绍的 tunctl 工具。 使用输入 ip tuntap help 查看详细使用命令： 1234567[root@localhost ~]# ip tuntap helpUsage: ip tuntap &#123; add | del &#125; [ dev PHYS_DEV ] [ mode &#123; tun | tap &#125; ] [ user USER ] [ group GROUP ] [ one_queue ] [ pi ] [ vnet_hdr ] [ multi_queue ]Where: USER := &#123; STRING | NUMBER &#125; GROUP := &#123; STRING | NUMBER &#125; 常见用法： 创建 tap/tun 设备： 12ip tuntap add dev tap0 mod tap # 创建 tap ip tuntap add dev tun0 mod tun # 创建 tun 删除 tap/tun 设备： 12ip tuntap del dev tap0 mod tap # 删除 tap ip tuntap del dev tun0 mod tun # 删除 tun PS: user 和 group 参数和 tunctl 的 -u、 -g 参数是一样的。 以上两个工具，我们更推荐使用 ip tuntap，一个是因为 iproute2 更全更新，已经逐步在替代老旧的一些工具，另一个是因为 tunctl 在某些 Debian 类的系统上支持不全。 总结tunctl 和 ip tuntap 的常见使用方式。 更推荐使用 ip tuntap 工具。 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"tap","slug":"tap","permalink":"https://chambai.github.io/tags/tap/"},{"name":"tun","slug":"tun","permalink":"https://chambai.github.io/tags/tun/"}]},{"title":"Linux云网络基础之虚拟网络设备 tap/tun 详解","slug":"tech/taptun详解","date":"2019-02-26T05:16:14.000Z","updated":"2019-04-17T16:28:43.347Z","comments":true,"path":"2019/02/26/tech/taptun详解/","link":"","permalink":"https://chambai.github.io/2019/02/26/tech/taptun详解/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 在云计算时代，虚拟机和容器已经成为标配。它们背后的网络管理都离不开一样东西，就是虚拟网络设备，或者叫虚拟网卡，tap/tun 就是在云计算时代非常重要的虚拟网络网卡。 tap/tun 是什么tap/tun 是 Linux 内核 2.4.x 版本之后实现的虚拟网络设备，不同于物理网卡靠硬件网路板卡实现，tap/tun 虚拟网卡完全由软件来实现，功能和硬件实现完全没有差别，它们都属于网络设备，都可以配置 IP，都归 Linux 网络设备管理模块统一管理。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 在云计算时代，虚拟机和容器已经成为标配。它们背后的网络管理都离不开一样东西，就是虚拟网络设备，或者叫虚拟网卡，tap/tun 就是在云计算时代非常重要的虚拟网络网卡。 tap/tun 是什么tap/tun 是 Linux 内核 2.4.x 版本之后实现的虚拟网络设备，不同于物理网卡靠硬件网路板卡实现，tap/tun 虚拟网卡完全由软件来实现，功能和硬件实现完全没有差别，它们都属于网络设备，都可以配置 IP，都归 Linux 网络设备管理模块统一管理。 作为网络设备，tap/tun 也需要配套相应的驱动程序才能工作。tap/tun 驱动程序包括两个部分，一个是字符设备驱动，一个是网卡驱动。这两部分驱动程序分工不太一样，字符驱动负责数据包在内核空间和用户空间的传送，网卡驱动负责数据包在 TCP/IP 网络协议栈上的传输和处理。 用户空间与内核空间的数据传输在 Linux 中，用户空间和内核空间的数据传输有多种方式，字符设备就是其中的一种。tap/tun 通过驱动程序和一个与之关联的字符设备，来实现用户空间和内核空间的通信接口。 在 Linux 内核 2.6.x 之后的版本中，tap/tun 对应的字符设备文件分别为： tap：/dev/tap0 tun：/dev/net/tun 设备文件即充当了用户空间和内核空间通信的接口。当应用程序打开设备文件时，驱动程序就会创建并注册相应的虚拟设备接口，一般以 tunX 或 tapX 命名。当应用程序关闭文件时，驱动也会自动删除 tunX 和 tapX 设备，还会删除已经建立起来的路由等信息。 tap/tun 设备文件就像一个管道，一端连接着用户空间，一端连接着内核空间。当用户程序向文件 /dev/net/tun 或 /dev/tap0 写数据时，内核就可以从对应的 tunX 或 tapX 接口读到数据，反之，内核可以通过相反的方式向用户程序发送数据。 tap/tun 和网络协议栈的数据传输tap/tun 通过实现相应的网卡驱动程序来和网络协议栈通信。一般的流程和物理网卡和协议栈的交互流程是一样的，不同的是物理网卡一端是连接物理网络，而 tap/tun 虚拟网卡一般连接到用户空间。 如下图的示意图，我们有两个应用程序 A、B，物理网卡 eth0 和虚拟网卡 tun0 分别配置 IP：10.1.1.11 和 192.168.1.11，程序 A 希望构造数据包发往 192.168.1.0/24 网段的主机 192.168.1.1。 基于上图，我们看看数据包的流程： 应用程序 A 构造数据包，目的 IP 是 192.168.1.1，通过 socket A 将这个数据包发给协议栈。 协议栈根据数据包的目的 IP 地址，匹配路由规则，发现要从 tun0 出去。 tun0 发现自己的另一端被应用程序 B 打开了，于是将数据发给程序 B. 程序 B 收到数据后，做一些跟业务相关的操作，然后构造一个新的数据包，源 IP 是 eth0 的 IP，目的 IP 是 10.1.1.0/24 的网关 10.1.1.1，封装原来的数据的数据包，重新发给协议栈。 协议栈再根据本地路由，将这个数据包从 eth0 发出。 后续步骤，当 10.1.1.1 收到数据包后，会进行解封装，读取里面的原始数据包，继而转发给本地的主机 192.168.1.1。当接收回包时，也遵循同样的流程。 在这个流程中，应用程序 B 的作用其实是利用 tun0 对数据包做了一层隧道封装。其实 tun 设备的最大用途就是用于隧道通信的。 tap/tun 的区别看到这里，你可能还不大明白 tap/tun 的区别。tap 和 tun 虽然都是虚拟网络设备，但它们的工作层次还不太一样。 tap 是一个二层设备（或者以太网设备），只能处理二层的以太网帧； tun 是一个点对点的三层设备（或网络层设备），只能处理三层的 IP 数据包。 tap/tun 的应用从上面的数据流程中可以看到，tun 设备充当了一层隧道，所以，tap/tun 最常见的应用也就是用于隧道通信，比如 VPN，包括 tunnel 和应用层的 IPsec 等，其中比较有名的两个开源项目是 openvpn 和 VTun。 总结tun/tap 虚拟网卡，对应于物理网卡，如 eth0。 tun/tap 驱动包括字符设备驱动和网卡驱动。 tun/tap 常用于隧道通信。 参考： https://opengers.github.io/openstack/openstack-base-virtual-network-devices-tuntap-veth/ https://segmentfault.com/a/1190000009249039 https://mirrors.edge.kernel.org/pub/linux/kernel/people/marcelo/linux-2.4/Documentation/networking/tuntap.txt https://zh.wikipedia.org/wiki/TUN%E4%B8%8ETAP http://blog.chinaunix.net/uid-317451-id-92474.html https://blog.csdn.net/bytxl/article/details/26586109 https://blog.csdn.net/u013982161/article/details/51816162 https://www.cnblogs.com/yml435/p/5917628.html –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"tap","slug":"tap","permalink":"https://chambai.github.io/tags/tap/"},{"name":"tun","slug":"tun","permalink":"https://chambai.github.io/tags/tun/"}]},{"title":"小趋势解构","slug":"life/小趋势解构","date":"2019-01-15T05:16:14.000Z","updated":"2019-04-16T16:00:18.682Z","comments":true,"path":"2019/01/15/life/小趋势解构/","link":"","permalink":"https://chambai.github.io/2019/01/15/life/小趋势解构/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 这篇文章是年初听完罗振宇的跨年演讲写的，算是笔记吧，当时只是发在简书上，因为是非技术文，所以就没发在这里。今天看到有网友喜欢，想着文章应该多多少少有点用，干脆就搬过来给大家看看，如果掉粉多，我后面就多发点技术文吧。 今年罗振宇的跨年演讲还是有些干货的。在演讲开始，罗胖就开宗明义，说今晚的演讲只关注「大环境下小个体的命运」，这对于我们这种小人物来说也许是莫大的福音。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 这篇文章是年初听完罗振宇的跨年演讲写的，算是笔记吧，当时只是发在简书上，因为是非技术文，所以就没发在这里。今天看到有网友喜欢，想着文章应该多多少少有点用，干脆就搬过来给大家看看，如果掉粉多，我后面就多发点技术文吧。 今年罗振宇的跨年演讲还是有些干货的。在演讲开始，罗胖就开宗明义，说今晚的演讲只关注「大环境下小个体的命运」，这对于我们这种小人物来说也许是莫大的福音。 确实，整个过程中，都能感受到那种认知的碰撞升级。但说实话，就像一句话说的，听过太多的大道理，仍然过不好这一生，这里的问题我觉得是出在我们没有将这些新的认知转化成自己的思想体系。 趁着演讲刚过去的这点余温，我想尝试着解构一下「小趋势」，这也是全篇演讲最核心的一点。通过这次解构，真正将「小趋势」化为己用。 我打算采用「5W+1H 法」进行解构，也就是 What、Where、When、Who、Why 和 How 问题分析法。 01 What首先，我们得知道，「小趋势」是什么？ 从字面上看，有两层含义，第一是“小”，第二这是个“趋势”。 “小”说明很难察觉，它不在我们熟悉的领域内，超出我们的认知范围。 “趋势”说明它的存在影响了周围的事物，它带动了周围事物往良性的方向发展。所以，罗胖才说「小趋势」是： 影响趋势的趋势，带来改变的改变。 知道了这一点，基本上没什么卵用。没有实际的例子，很难形成共鸣。 罗胖举了两个非常典型的例子：移动支付和猫砂。怎么理解这两个例子呢，紧扣小趋势的定义，其实不难理解。 移动支付对于互联网人来说，是比较显现的趋势，比如前几年滴滴打车和快的打车的疯狂烧钱，那是微信和支付宝在互相较量，抢占移动支付的入口，对于我们做这一行的人来说，能不觉得它是个大趋势吗？ 我们虽然看清了，但是有很多人看不清啊，特别是传统行业的人。对于这些人来说，移动支付就是个小趋势。 移动支付还有人看得出它是个趋势，猫砂就完全没人能够察觉。我们来看看它是不是个趋势？ 没有猫砂之前，猫和人类的关系很疏远，有了猫砂之后，解决了猫咪臭臭的异味，于是猫和人类成为了好朋友，紧接着围绕猫、猫粮、猫玩具等产业开始蓬勃发展，进而影响到了互联网行业，很多公司以猫作为原型设计品牌 logo，带来了巨大流量。在将来，借助一些大趋势，这又将会带来疯狂扩张，比如借助人工智能的机器猫。 说到这里，我相信你应该比较清楚小趋势的定义了吧。我再举几个例子，这几个例子即使是同行，你也许也很难看得清它是个趋势。 一个是视频，一直以来，视频都是刚需，这是现代人娱乐的神器，也是学习的利器。但就是一直不温不火，人们已经习以为常，像吃饭穿衣那么平常。近两年却突然大火，特别是以直播、短视频为首的视频形式。我想这是因为我们已经进入一个个性化+信息泛滥的时代，任何「短平快」的东西都会特别容易受到重视。由此看来，当下环境的变化是个大趋势，视频只是个小趋势。 另一个是微信公众号，刚推出时有多少人能看得清它是个趋势，今天回看，这已然成为了一个内容红海，带动了自由职业、内容创业等多种个性化产业的发展。未来随着人工智能发展，很多人都说最没有可能被淘汰的工种就是内容创作，所以说将来仍有很多发展空间，这仍然是一个小趋势。 02 Where第二点想聊聊小趋势的适用场景，也就是它一般出现在什么地方。我觉得小趋势可以出现在任何地方。上到中央政府，下到街边小商小贩。中央政府基本上是趋势的仲裁者，任何想要发展的趋势都必须经过这一关。但反过来，中央政府也是趋势的受益者，很多来自地方的新鲜想法可以带动地方经济发展，但政策不允许，迫于舆情的压力，中央政府也会适当调整，适应当下的趋势。 小商小贩就更不用说了，看看现在街边一个要饭的人都懂得用二维码支付。很多农村的人纷纷用上网络，淘宝，微商，代购，干起的买卖丝毫不亚于城里。很多大学生利用所学纷纷回到农村进行科技养殖、科技种植、人工智能养猪，等等，这样的例子太多了。 所以，小趋势适用于任何场合，在一个场合是大趋势，但在另一个场合兴许就是小趋势。 03 Who有适用场景，自然就有适用人群。小趋势并不适用于所有人，只适用于那些不甘平凡，想要进步的人。这很好理解，一个自甘堕落，或者是甘于平凡、得过且过的人，你跟他说这件事是将来的一个趋势，好好做，他肯定只会用看病人的眼神看你。 另外，已经在大趋势中游走的人，也没必要关注小趋势，你只要把当下的事做好，就比大多数人赢得了先机。当下科技圈最火的技术当属人工智能了吧，这个巨无霸将会指导未来几十年甚至上百年的发展。很多人很幸运已经踏入这个领域，也有很多人想踏入，但因为门槛太高，一直在边缘游走，绝大多数人则是一直在观望。后面两类人即使没有第一类人幸运，但也挺好的，起码意识到了趋势，只要用心耕耘好自己的一亩三分地，找准时机，蹭也能蹭到。别忘了小趋势蝴蝶效应的威力。 04 When这一点想聊聊小趋势出现的时间。像猫砂这种，我们基本上是没人能感知，因为对我们来说太平常不过了。那我们该怎么样才能把握小趋势出现的时机呢？别想了，这个世上我相信没几个人能把握准确。 但是它既然是个趋势，我们就有办法去把握，即便准确率不高，那也比什么都不做要强。 办法就是把握大趋势的时机。这个应该比较容易的，今天的传播媒介多得让人抓狂，只要一有什么热点新闻，巴不得让你第一时间知道。 举一个杨超越的例子，这是一个超级颠覆我认知的例子。起初我怎么也想不通，一个五音不全，肢体僵硬的人，却受到那么多人喜欢。直到转发锦鲤这个事件出来，我才明白，噢，原来大家都需要一种幸运的寄托，就像我们拜观世音菩萨一样的道理。 那这个事件说明什么呢，是不是能说明这是个让人焦虑的时代，快节奏的生活让人们都来不及处理所有不幸的遭遇，只能寄托于那些被公认能带来好运的事与人身上。 其实这也没什么不好，这是一个趋势带动一个趋势逐步形成的，快节奏就是一个趋势，看到趋势的人，就推出很多快节奏的产品，也有人反其道而行之，推出慢节奏的产品。 这个例子可能不够接地气，但我想说的是小趋势你也许看不到，但大趋势你肯定看得清，我们的目的不是要进入大趋势的阵地（当然你能进入更好），而是吸取新观点，引用到自己的阵地。有朝一日，大趋势成熟时，你也能分到一杯羹。 05 Why这一点想聊聊为什么会有小趋势？罗胖在讲小趋势前，讲了一个大背景。简单说就是 2018 年科技圈风云变幻，扎堆上市的很多，遗憾出局的也不少，更有裁员、停招等等令人忧伤的事。 在这样的一个节骨眼上，很多人焦虑已经跟不上时代了，每天都担心面临被淘汰的风险。罗胖引出小趋势，我觉得就是告诉这些人大可不必焦虑，因为对于一个「做事」的人来说， 永远都不会有末班车，只有下一班车。 专注做好当下事，才能有精力去感知自己身边的小趋势，否则自乱阵脚，最后难以控制。 06 How最后一点聊聊作为一个普通小人物的我们，该如何去感知小趋势，让自己的人生之路走得更加顺畅一些。我觉得可以参考以下几点： 关注大趋势，时常看看自己从事的领域能不能沾到大趋势的光。 以百岁人生为目标而过活，如果不这样，一点小小的人生变动都会让你觉得人生完了。 多元化发展，能够让我们感知到不熟悉领域的小趋势。 做好当下的事，剩下的事交给上天安排吧。 以上，第一次以这种方式来解构一个知识点，完了发现，这次演讲没有白听，停留在耳边的大道理终于吸收进去了。 –END– 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有大量书籍和视频资源，后台回复 「1024」 即可领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[]},{"title":"一文搞懂 network namespace","slug":"tech/模板","date":"2019-01-10T05:16:14.000Z","updated":"2019-04-17T16:23:08.944Z","comments":true,"path":"2019/01/10/tech/模板/","link":"","permalink":"https://chambai.github.io/2019/01/10/tech/模板/","excerpt":"","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有 10T 书籍和视频资源，后台回复「1024」即可免费领取，欢迎大家关注，二维码文末可以扫。 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"Namespace","slug":"Namespace","permalink":"https://chambai.github.io/tags/Namespace/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"}]},{"title":"一文搞懂 network namespace","slug":"tech/一文搞懂network_namespace","date":"2019-01-10T05:16:14.000Z","updated":"2019-04-17T16:28:58.098Z","comments":true,"path":"2019/01/10/tech/一文搞懂network_namespace/","link":"","permalink":"https://chambai.github.io/2019/01/10/tech/一文搞懂network_namespace/","excerpt":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 本文通过 IP 命令操作来简单介绍 network namespace 的基本概念和用法。 深入了解可以看看我之前写的两篇文章 Docker 基础技术之 Linux namespace 详解 和 Docker 基础技术之 Linux namespace 源码分析。 和 network namespace 相关的操作的子命令是 ip netns 。","text":"本文首发于我的公众号 「Linux云计算网络」(id: cloud_dev) ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 本文通过 IP 命令操作来简单介绍 network namespace 的基本概念和用法。 深入了解可以看看我之前写的两篇文章 Docker 基础技术之 Linux namespace 详解 和 Docker 基础技术之 Linux namespace 源码分析。 和 network namespace 相关的操作的子命令是 ip netns 。 1. ip netns add xx 创建一个 namespace123# ip netns add net1# ip netns lsnet1 2. ip netns exec xx yy 在新 namespace xx 中执行 yy 命令12345678# ip netns exec net1 ip addr 1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00# ip netns exec net1 bash // 在 net1 中打开一个shell终端# ip addr // 在net1中的shell终端1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00# exit // 退出net1 上面 bash 不好区分是当前是在哪个 shell，可以采用下面的方法解决： 12# ip netns exec net1 /bin/bash --rcfile &lt;(echo &quot;PS1=\\&quot;namespace net1&gt; \\&quot;&quot;)namespace net1&gt; ping www.baidu.com 每个 namespace 在创建的时候会自动创建一个回环接口 lo ，默认不启用，可以通过 ip link set lo up 启用。 3. network namespace 之间的通信新创建的 namespace 默认不能和主机网络，以及其他 namespace 通信。 可以使用 Linux 提供的 veth pair 来完成通信。下面显示两个 namespace 之间通信的网络拓扑： 3.1 ip link add type veth 创建 veth pair123456# ip link add type veth# ip link3: veth0@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 1a:53:39:5a:26:12 brd ff:ff:ff:ff:ff:ff4: veth1@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 46:df:46:1f:bf:d6 brd ff:ff:ff:ff:ff:ff 使用命令 ip link add xxx type veth peer name yyy 指定 veth pair 的名字。 3.2 ip link set xx netns yy 将 veth xx 加入到 namespace yy 中12345678# ip link set veth0 netns net0# ip link set veth1 netns net1## ip netns exec net0 ip addr1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0010: veth0@if11: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 1a:53:39:5a:26:12 brd ff:ff:ff:ff:ff:ff link-netnsid 1 3.3 给 veth pair 配上 ip 地址12345678910111213141516# ip netns exec net0 ip link set veth0 up# ip netns exec net0 ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever10: veth0@if11: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state LOWERLAYERDOWN group default qlen 1000 link/ether 1a:53:39:5a:26:12 brd ff:ff:ff:ff:ff:ff link-netnsid 1# ip netns exec net0 ip addr add 10.1.1.1/24 dev veth0# ip netns exec net0 ip route10.1.1.0/24 dev veth0 proto kernel scope link src 10.1.1.1 linkdown## ip netns exec net1 ip link set veth1 up# ip netns exec net1 ip addr add 10.1.1.2/24 dev veth1 可以看到，在配完 ip 之后，还自动生成了对应的路由表信息。 3.4. ping 测试两个 namespace 的连通性123456# ip netns exec net0 ping 10.1.1.2PING 10.1.1.2 (10.1.1.2) 56(84) bytes of data.64 bytes from 10.1.1.2: icmp_seq=1 ttl=64 time=0.069 ms64 bytes from 10.1.1.2: icmp_seq=2 ttl=64 time=0.054 ms64 bytes from 10.1.1.2: icmp_seq=3 ttl=64 time=0.053 ms64 bytes from 10.1.1.2: icmp_seq=4 ttl=64 time=0.053 ms Done! 4. 多个不同 namespace 之间的通信2 个 namespace 之间通信可以借助 veth pair ，多个 namespace 之间的通信则可以使用 bridge 来转接，不然每两个 namespace 都去配 veth pair 将会是一件麻烦的事。下面就看看如何使用 bridge 来转接。 拓扑图如下： 4.1 使用 ip link 和 brctl 创建 bridge通常 Linux 中和 bridge 有关的操作是使用命令 brctl (yum install -y bridge-utils ) 。但为了前后照应，这里都用 ip 相关的命令来操作。 1234567// 建立一个 bridge# ip link add br0 type bridge# ip link set dev br0 up9: br0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000 link/ether 42:55:ed:eb:a0:07 brd ff:ff:ff:ff:ff:ff inet6 fe80::4055:edff:feeb:a007/64 scope link valid_lft forever preferred_lft forever 4.2 创建 veth pair1234//（1）创建 3 个 veth pair# ip link add type veth# ip link add type veth# ip link add type veth 4.3 将 veth pair 的一头挂到 namespace 中，一头挂到 bridge 上，并设 IP 地址1234567891011121314151617181920212223242526// （1）配置第 1 个 net0# ip link set dev veth1 netns net0# ip netns exec net0 ip link set dev veth1 name eth0# ip netns exec net0 ip addr add 10.0.1.1/24 dev eth0# ip netns exec net0 ip link set dev eth0 up## ip link set dev veth0 master br0# ip link set dev veth0 up// （2）配置第 2 个 net1# ip link set dev veth3 netns net1# ip netns exec net1 ip link set dev veth3 name eth0# ip netns exec net1 ip addr add 10.0.1.2/24 dev eth0# ip netns exec net1 ip link set dev eth0 up## ip link set dev veth2 master br0# ip link set dev veth2 up// （3）配置第 3 个 net2# ip link set dev veth5 netns net2# ip netns exec net2 ip link set dev veth5 name eth0# ip netns exec net2 ip addr add 10.0.1.3/24 dev eth0# ip netns exec net2 ip link set dev eth0 up# # ip link set dev veth4 master br0# ip link set dev veth4 up 这样之后，竟然通不了，经查阅 参见 ，是因为 原因是因为系统为bridge开启了iptables功能，导致所有经过br0的数据包都要受iptables里面规则的限制，而docker为了安全性，将iptables里面filter表的FORWARD链的默认策略设置成了drop，于是所有不符合docker规则的数据包都不会被forward，导致你这种情况ping不通。 解决办法有两个，二选一： 关闭系统bridge的iptables功能，这样数据包转发就不受iptables影响了：echo 0 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables 为br0添加一条iptables规则，让经过br0的包能被forward：iptables -A FORWARD -i br0 -j ACCEPT 第一种方法不确定会不会影响docker，建议用第二种方法。 我采用以下方法解决： 1iptables -A FORWARD -i br0 -j ACCEPT 结果： 1234567891011121314151617# ip netns exec net0 ping -c 2 10.0.1.2PING 10.0.1.2 (10.0.1.2) 56(84) bytes of data.64 bytes from 10.0.1.2: icmp_seq=1 ttl=64 time=0.071 ms64 bytes from 10.0.1.2: icmp_seq=2 ttl=64 time=0.072 ms--- 10.0.1.2 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 999msrtt min/avg/max/mdev = 0.071/0.071/0.072/0.008 ms# ip netns exec net0 ping -c 2 10.0.1.3PING 10.0.1.3 (10.0.1.3) 56(84) bytes of data.64 bytes from 10.0.1.3: icmp_seq=1 ttl=64 time=0.071 ms64 bytes from 10.0.1.3: icmp_seq=2 ttl=64 time=0.087 ms--- 10.0.1.3 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1000msrtt min/avg/max/mdev = 0.071/0.079/0.087/0.008 ms Done! 5. Bridge 之间的同住机通信以上所说的是一个 bridge 同网段的通信，现在看看不同 bridge 跨网段的通信，如下拓扑： 6. Bridge 之间的跨住机通信https://www.cnblogs.com/iiiiher/p/8057922.html 参考资料： linux 网络虚拟化： network namespace 简介 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"Namespace","slug":"Namespace","permalink":"https://chambai.github.io/tags/Namespace/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"}]},{"title":"Linux 系统下实践 VLAN","slug":"tech/Linux系统下实践VLAN","date":"2019-01-07T05:16:14.000Z","updated":"2019-04-17T16:28:47.797Z","comments":true,"path":"2019/01/07/tech/Linux系统下实践VLAN/","link":"","permalink":"https://chambai.github.io/2019/01/07/tech/Linux系统下实践VLAN/","excerpt":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 01 准备环境环境：ubuntu 16.04 环境（物理 or 虚拟） 确认 CPU 是否支持虚拟化： 12# egrep -o &apos;(vmx|svm)&apos; /proc/cpuinfo# vmx 如果不支持，开启 KVM 嵌套虚拟化之后再重启。","text":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 01 准备环境环境：ubuntu 16.04 环境（物理 or 虚拟） 确认 CPU 是否支持虚拟化： 12# egrep -o &apos;(vmx|svm)&apos; /proc/cpuinfo# vmx 如果不支持，开启 KVM 嵌套虚拟化之后再重启。 1.1 安装 KVM 环境1sudo apt-get install -y qemu-kvm qemu-system libvirt-bin virt-manager bridge-utils vlan 1.2 安装 Ubuntu 图形化界面1sudo apt-get install -y xinit gdm kubuntu-desktop 02 创建 KVM 虚拟机使用 virt-manager 创建 KVM 虚拟机，方法比较简单，由于篇幅有限，大家可以查阅相关资料自行了解。 创建完之后用 virsh list --all 查看创建的 VM： 12345Id Name State---------------------------------------------------- - kvm1 shut off - kvm2 shut off - kvm3 shut off 我们的实验拓扑如下： 图中创建了 2 个 Linux Bridge：brvlan1 和 brvlan2，宿主机的物理网卡 eth0 抽象出两个虚拟设备 eth0.1 和 eth0.2，也就是两个 VLAN 设备，它们分别定义了两个 VLAN：VLAN1 和 VLAN2。挂接到两个 Bridge 上的网络设备自动加入到相应的 VLAN 中。VLAN1 接两个 VM，VLAN 接一个 VM。 实验的目的是要验证属于同一个 VLAN1 中 VM1 和 VM2 能 ping 通，而属于不同 VLAN 中的 VM ping 不通。 03 实验开始3.1 配置 VLAN编辑 /etc/network/interfaces，加入两个 Bridge 和两个 VLAN 设备的配置，如下： 12345678910111213141516171819202122232425# The primary network interfaceauto ens33iface ens33 inet dhcpauto ens33.1iface ens33.1 inet manual vlan-raw-device ens33auto brvlan1iface brvlan1 inet manual bridge_stp off bridge_waitport 0 bridge_fd 0 bridge_ports ens33.1auto ens33.2iface ens33.2 inet manual vlan-raw-device ens33auto brvlan2iface brvlan2 inet manual bridge_stp off bridge_waitport 0 bridge_fd 0 bridge_ports ens33.2 注意，这里务必和自己电脑的接口名称统一，比如我这里叫 ens33，就配 ens33.1 和 ens33.2 的 VLAN 设备，当然你也可以改成 eth0 的形式。 重启宿主机，ifconfig 查看网络接口： 用 brctl show 查看当前 Linux Bridge 的配置，ens33.1 和 ens33.2 分别挂载 brvlan1 和 brvlan2 上了。 12345# brctl showbridge name bridge id STP enabled interfacesbrvlan1 8000.000c298c57e8 no ens33.1brvlan2 8000.000c298c57e8 no ens33.2virbr0 8000.000000000000 yes 3.2 配置 VM我们先配置 VM1，启动 virt-manager，在图形界面中将 VM1 的虚拟网卡挂到 brvlan1 上： 同样的方式配置 VM2 和 VM3，VM2 也配到 brvlan1 上，VM3 配到 brvlan2 上。 3.3 查看 VM 配置用 virsh start xxx 启动 3 个 VM： 123# virsh start kvm1# virsh start kvm2# virsh start kvm3 再通过 brctl show 查看 Bridge，这时发现 brvlan1 下接了 vnet0 和 vnet1，brvlan2 下接了 vnet2： 12345678# brctl showbridge name bridge id STP enabled interfacesbrvlan1 8000.000c298c57e8 no ens33.1 vnet0 vnet1brvlan2 8000.000c298c57e8 no ens33.2 vnet2virbr0 8000.000000000000 yes 通过 virsh domiflist xxx 确认这就是 VM 的虚拟网卡： 1234567891011121314# virsh domiflist kvm1Interface Type Source Model MAC-------------------------------------------------------vnet0 bridge brvlan1 rtl8139 52:54:00:b3:dd:3a# virsh domiflist kvm2Interface Type Source Model MAC-------------------------------------------------------vnet1 bridge brvlan1 rtl8139 52:54:00:b7:4f:ef# virsh domiflist kvm3Interface Type Source Model MAC-------------------------------------------------------vnet2 bridge brvlan2 rtl8139 52:54:00:d8:b8:2a 04 验证为了验证相同 VLAN 之间的连通性和不同 VLAN 之间的隔离性，我们为 3 个 VM 都配置同一网段的 IP。 使用 virt-manager 进入 VM console 控制面。 配置 VM1 的 IP： 1ifconfig eth0 192.168.100.10 netmask 255.255.255.0 配置 VM2 的 IP： 1ifconfig eth0 192.168.100.20 netmask 255.255.255.0 配置 VM3 的 IP： 1ifconfig eth0 192.168.100.30 netmask 255.255.255.0 使用 VM1 ping VM2 能 ping 通，VM2 ping VM3 不能 ping 通。 验证完毕。 大家如果有兴趣，可以抓个包看看，在发送 ping 包之前，需要知道对方的 MAC 地址，所以会先在网络中广播 ARP 包。ARP 是二层协议，VLAN 的作用就是隔离二层的广播域，ARP 包自然就不能在不同 VLAN 中流通，所以在相同 VLAN 中，通信双方能够拿到对方的 MAC 地址，也就能 ping 通，不同 VLAN 反之。 –END– 后台回复「加群」，带你进入高手如云交流群。 我的公众号 「Linux云计算网络」(id: cloud_dev) ，号内有 10T 书籍和视频资源，后台回复 「1024」 即可领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"06 网络","slug":"06-网络","permalink":"https://chambai.github.io/categories/06-网络/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"VLAN","slug":"VLAN","permalink":"https://chambai.github.io/tags/VLAN/"}]},{"title":"Kubernetes 笔记 012 Pod 的自动扩容与缩容","slug":"tech/Kubernetes_笔记_012_Pod_的自动扩容与缩容","date":"2018-09-30T05:16:14.000Z","updated":"2019-04-11T16:01:06.222Z","comments":true,"path":"2018/09/30/tech/Kubernetes_笔记_012_Pod_的自动扩容与缩容/","link":"","permalink":"https://chambai.github.io/2018/09/30/tech/Kubernetes_笔记_012_Pod_的自动扩容与缩容/","excerpt":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 Hi，大家好，我是 CloudDeveloper，欢迎大家和我一起学 K8S，这是系列第 12 篇。 上一篇我们了解了 Pod 的手动扩容和缩容，本篇来看看自动的方式。","text":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 Hi，大家好，我是 CloudDeveloper，欢迎大家和我一起学 K8S，这是系列第 12 篇。 上一篇我们了解了 Pod 的手动扩容和缩容，本篇来看看自动的方式。 K8S 作为一个集群式的管理软件，自动化、智能化是免不了的功能。Google 在 K8S v1.1 版本中就加入了这个 Pod 横向自动扩容的功能（Horizontal Pod Autoscaling，简称 HPA）。 HPA 与之前的 Deployment、Service 一样，也属于一种 K8S 资源对象。 HPA 的目标是希望通过追踪集群中所有 Pod 的负载变化情况，来自动化地调整 Pod 的副本数，以此来满足应用的需求和减少资源的浪费。 HAP 度量 Pod 负载变化情况的指标有两种： CPU 利用率（CPUUtilizationPercentage） 自定义的度量指标，比如服务在每秒之内的请求数（TPS 或 QPS） 如何统计和查询这些指标，要依托于一个组件——Heapster。Heapster 会监控一段时间内集群内所有 Pod 的 CPU 利用率的平均值或者其他自定义的值，在满足条件时（比如 CPU 使用率超过 80% 或 降低到 10%）会将这些信息反馈给 HPA 控制器，HPA 控制器就根据 RC 或者 Deployment 的定义调整 Pod 的数量。 HPA 实现的方式有两种：配置文件和命令行 配置文件 这种方式是通过定义 yaml 配置文件来创建 HPA，如下是基本定义： 123456789101112apiVersion: autoscaling/v1kind: HorizontalPodAutoscalermetadata: name: php-apache namespace: defaultspec: scaleTargetRef: # (1) kind: Deployment name: php-apache minReplicas: 1 # (2) maxReplicas: 10 targetAverageUtilization: 50 # (3) 文件 kind 类型是 HorizontalPodAutoscaler，其中有 3 个地方需要额外注意下： （1）scaleTargetRef 字段指定需要管理的 Deployment/RC 的名字，也就是提前需要存在一个 Deployment/RC 对象。 （2） minReplicas 和 maxReplicas 字段定义 Pod 可伸缩的数量范围。这个例子中扩容最高不能超过 10 个，缩容最低不能少于 1 个。 （3）targetAverageUtilization 指定 CPU 使用率，也就是自动扩容和缩容的触发条件，当 CPU 使用率超过 50% 时会触发自动动态扩容的行为，当回落到 50% 以下时，又会触发自动动态缩容的行为。 命令行 这种方式就是通过 kubectl autoscale 命令来实现创建 HPA 对象，实现自动扩容和缩容行为。比如和上面的例子等价的命令如下： kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10 通过参数来引入各个字段。 OK，本文就到这里，更多实践的例子大家可以参考 K8S 官网。下文我们将会探索 K8S 的容错机制。 –END– 我的公众号 「Linux云计算网络」 ，号内有大量书籍和视频资源，后台回复「1024」即可领取，分享的内容包括但不限于云计算虚拟化、容器、OpenStack、K8S、雾计算、网络、工具、SDN、OVS、DPDK、Linux、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 笔记 11 Pod 扩容与缩容 双十一前后的忙碌","slug":"tech/Kubernetes_笔记_11_Pod_扩容与缩容_双十一前后的忙碌","date":"2018-09-29T05:16:14.000Z","updated":"2019-04-11T15:58:36.247Z","comments":true,"path":"2018/09/29/tech/Kubernetes_笔记_11_Pod_扩容与缩容_双十一前后的忙碌/","link":"","permalink":"https://chambai.github.io/2018/09/29/tech/Kubernetes_笔记_11_Pod_扩容与缩容_双十一前后的忙碌/","excerpt":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 11 篇。 资源的伸缩在云计算环境中是至关重要的，云计算的动机就是企图提高资源的利用率，在用户请求高峰期的时候能够对资源进行横向扩容，反之，当用户请求回落低谷的时候，能够及时缩减资源，避免资源的浪费。","text":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 11 篇。 资源的伸缩在云计算环境中是至关重要的，云计算的动机就是企图提高资源的利用率，在用户请求高峰期的时候能够对资源进行横向扩容，反之，当用户请求回落低谷的时候，能够及时缩减资源，避免资源的浪费。 这就像双十一的时候，随着用户不断地涌入，阿里后台需要不断调配更多的资源来支撑用户大量的请求，当过了双十一当天，再慢慢缩减资源的使用。 Kubernetes 作为一个集群管理系统，提供了两种资源伸缩的方式：手动和自动。本文先来看手动方式。 Kubernetes 的资源伸缩本质上指的是 Pod 的扩容和缩容（scale up/down），也就是增加或减少 Pod 的副本数。 手动的方式是使用 kubectl scale 命令手动进行，或者基于 YAML 配置来实现。 首先，定义一个 nginx-deployment.yaml 配置文件： 1234567891011121314apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx-deploymentspec: replicas: 3 template: metadata: labels: app: web_server spec: containers: - name: nginx images: nginx:1.12.1 其中定义了 3 个副本，执行 kubectl create -f nginx-deployment.yaml 创建 Pod。 如果现在遇到高峰请求，我们急需进行扩容，执行1kubectl scale deployment nginx-deployment --replicas 5 将 Pod 扩增到 5 个。 其中，用 --replicas 来指示增缩的数量，对于缩容，将 --replicas 设置为比当前 Pod 副本数量更小的数字即可，比如缩容到 2 个如下： 可以看到，Pod 销毁会经历一个 Terminating 的过程，最终 3 个副本被删除，只保留了 2 个副本。 以上是通过命令的形式来实现手动的扩容和缩容，我们也可以修改 YAML 配置文件中的 replicas 来实现，只要修改完之后执行 kubectl apply 即可。 OK，本文到此为止，下文我们再来 Pod 伸缩的另一种方式——自动扩容和缩容。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 我的公众号 「Linux云计算网络」 ，号内有大量书籍和视频资源，后台回复「1024」即可领取，分享的内容包括但不限于云计算虚拟化、容器、OpenStack、K8S、雾计算、网络、工具、SDN、OVS、DPDK、Linux、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 笔记 10 Job 机器人加工厂","slug":"tech/Kubernetes_笔记_10_Job_机器人加工厂","date":"2018-09-26T05:16:14.000Z","updated":"2019-04-11T15:59:54.399Z","comments":true,"path":"2018/09/26/tech/Kubernetes_笔记_10_Job_机器人加工厂/","link":"","permalink":"https://chambai.github.io/2018/09/26/tech/Kubernetes_笔记_10_Job_机器人加工厂/","excerpt":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 10 篇。 通常，我们在执行任务时，会启用多个服务，有些任务需要长时间运行，全天 24 小时不中断，所以一般会启用 Daemon 类的 服务；而有些任务则只需要短暂执行，任务执行完，服务就没有存在的必要了。","text":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 10 篇。 通常，我们在执行任务时，会启用多个服务，有些任务需要长时间运行，全天 24 小时不中断，所以一般会启用 Daemon 类的 服务；而有些任务则只需要短暂执行，任务执行完，服务就没有存在的必要了。 容器提供服务运行的环境，根据任务持续运行的时间，将容器分为两类：服务类容器和工作类容器。 服务类容器需要一直运行来提供持续性的服务，而工作类容器则是运行一次性的任务，任务完成后便会退出。 前面学习的 Deployment、ReplicaSet 和 DaemonSet 都用于管理服务类容器，而工作类容器则由本文要讲得 Job 来管理。 Job 多用于执行一次性的任务，批处理任务等，Job 就像是现代化机械加工厂的机器人，当有任务来的时候，便会启动，按照预先设定好的程序执行任务，直至任务执行完，便会进入休眠状态。 进一步，Job 根据任务的类型和执行的动作又分为以下几类： 单 Job 单任务：只启动一个 Job 来完成任务，同时 Job 只启用一个 Pod ，适用于简单的任务。 多 Job 多任务：启动多个 Job 来处理批量任务，每个任务对应一个 Job，Pod 的数量可以自定义。 单 Job 多任务：采用一个任务队列来存放任务，启动一个 Job 作为消费者来处理这些任务，Job 会启动多个 Pod，Pod 的数量可以自定义。 定时 Job：也叫 CronJob，启动一个 Job 来定时执行任务，类似 Linux 的 Crontab 程序。 上述 Job 的分类需要注意两点： 1）Job 执行失败的重启策略；Job 执行的是一次性的任务，但也不保证一定能执行成功，如果执行失败，应该怎么处理？这个是由前面所讲的 Pod 重启策略来决定的。在 Job Controller 中，只允许定义两种策略： Never：Pod 执行失败，不会重启该 Pod，但会根据 Job 定义的期望数重新创建 Pod。 OnFailure：Pod 执行失败，则会尝试重启该 Pod。 两种策略尝试的次数由 spec.backoffLimits 来限制，默认是 6 次（K8S 1.8.0 新加的特性）。 2）批量任务的多次并行处理的限制；对于批量任务，通常是一个 Pod 对应一个任务，但有时为了加快任务的处理，会启动多个 Pod 来并行处理单个任务。可以通过下面两个参数来设置并行度： spec.completions：总的启动 Pod 数，只有当所有 Pod 执行成功结束，任务才结束。 spec.parallelism：每个任务对应的 Pod 的并行数，当有一个 Pod 执行成功结束，该任务就执行结束。 下面通过几个例子来实践一下上面的几种 Job 类别。 几个例子单 Job 单 Pod 执行一次性任务首先，定义 Job 的 yaml 配置文件 myjob.yaml： 1234567891011121314apiVersion: batch/v1kind: Jobmetadata: name: myjobspec: template: metadata: name: myjob spec: containers: - name: hello images: busybox command: [&quot;echo&quot;, &quot;hello, I&apos;m Linux云计算网络, Welcome&quot;] restartPolicy: Never 执行 kubectl create -f myjob.yaml 创建 job 对象： 可以看到期望创建的 Job 数为 1，成功执行的 Job 数也为 1，这表明该 Job 已经执行完任务退出了。这个 Job 执行的任务就是创建一个 Pod，Pod 中创建一个 busybox 容器，并进入容器输出一段字符串：“hello, I’m Linux云计算网络, Welcome”。 查看一下 Pod 的状态： 可以看到，该 Pod 的状态为 Completed，表示它已经执行完任务并成功退出了。那怎么看该任务的执行结果呢？可以执行 kubectl logs myjob 调出该 Pod 的历史执行信息进行查看： 看到历史输出： 1hello, I&apos;m Linux云计算网络, Welcome 以上是执行成功的情况，如果执行失败，会根据 restartPolicy 进行重启，重启的方式上面也说了。大家可以自己实践下。 多 Job 多 Pod 执行批量任务首先，定义 Job 的 yaml 模板文件 job.yaml.txt，然后再根据这个模板文件创建多个 Job yaml 文件。模板文件如下： 1234567891011121314apiVersion: batch/v1kind: Jobmetadata: name: work-item-$ITEMspec: template: metadata: name: job spec: containers: - name: c images: busybox command: [&quot;sh&quot;, &quot;-c&quot;, &quot;echo work item $ITEM &amp;&amp; sleep 2&quot;] restartPolicy: Never 其中，$ITEM 作为各个 Job 项的标识。接着，使用以下脚本，根据 Job 模板创建三个 Job 配置文件： 123456#!/bin/bashfor i in app book phonedo cat myjob_tmp.yaml | sed &quot;s/\\$ITEM/$i/g&quot; &gt; ./jobs/job-$i.yamldone 最后，创建三个 Job 对象，如下： 单 Job 多 Pod 执行批量任务这种方式是用一个队列来存放任务，然后启动一个 Job 来执行任务，Job 可以根据需求启动多个 Pod 来承载任务的执行。定义下面的配置文件： 12345678910111213141516apiVersion: batch/v1kind: Jobmetadata: name: myjobspec: completions: 6 parallelism: 2 template: metadata: name: myjob spec: containers: - name: hello images: busybox command: [&quot;echo&quot;, &quot;hello Linux云计算网络&quot;] restartPolicy: OnFailure 这里用到了上面说的两个参数：completions 和 parallelism，表示每次并行运行两个 Pod，直到总共 6 个 Pod 成功运行完成。如下： 可以看到 DESIRED 和 SUCCESSFUL 最终均为 6，符合预期，实际上也有 6 个 Pod 成功运行并退出，呈 Completed 状态。 随便查看其中一个 Pod 的历史执行情况： 12# kubectl logs myjob-5lfnphello Linux云计算网络 定时任务 CronJob定义一个 CronJob 配置文件，如下： 123456789101112131415apiVersion: batch/v1beta1kind: CronJobmetadata: name: hellospec: schedule: &quot;*/1 * * * *&quot; jobTemplate: spec: template: spec: containers: - name: hello images: busybox command: [&quot;echo&quot;, &quot;Hello Linux云计算网络&quot;] restartPolicy: OnFailure kind 类型为 CronJob，spec.schedule 表示定时调度，指定什么时候运行 Job，格式与 Linux 的 Crontab 命令是一样的，这里 */1 * * * * 的含义是每一分钟启动一次。 创建 CronJob 对象，通过 kubectl get cronjob 查看 CronJob 的状态： 过一段时间再查看 Pod 的状态： 可以看到，此时产生了 3 个 Pod，3 个 Jobs，这是每隔一分钟就会启动一个 Job。执行 kubectl logs 查看其中一个的历史执行情况： 12# kubectl logs hello-1536764760-lm5ktHello Linux云计算网络 到此，本文就结束了。我们从理论结合实践，梳理了 Job 的几种类型，下文我们开始看一种有状态的 Controller——StatefulSet。 同样，需要学习资料的后台回复“K8S” 和 “K8S2”，想加群学习回复“加群”。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 我的公众号 「Linux云计算网络」 ，号内有大量书籍和视频资源，后台回复「1024」即可领取，分享的内容包括但不限于云计算虚拟化、容器、OpenStack、K8S、雾计算、网络、工具、SDN、OVS、DPDK、Linux、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 笔记 09 DaemonSet 我是一只看门狗","slug":"tech/Kubernetes_笔记_09_DaemonSet_我是一只看门狗","date":"2018-09-19T05:16:14.000Z","updated":"2019-04-11T16:00:32.410Z","comments":true,"path":"2018/09/19/tech/Kubernetes_笔记_09_DaemonSet_我是一只看门狗/","link":"","permalink":"https://chambai.github.io/2018/09/19/tech/Kubernetes_笔记_09_DaemonSet_我是一只看门狗/","excerpt":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 9 篇。 和上文中的 Deployment 一样，DaemonSet 也是一种副本管理机制，和 Deployment 可以在每个 Node 上运行好几个 Pod 副本不同的是，DaemonSet 始终保证每个 Node 最多只会运行一个副本，就像它的名称一样，作为一只看门狗（Daemon）守护在主人家里。","text":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 9 篇。 和上文中的 Deployment 一样，DaemonSet 也是一种副本管理机制，和 Deployment 可以在每个 Node 上运行好几个 Pod 副本不同的是，DaemonSet 始终保证每个 Node 最多只会运行一个副本，就像它的名称一样，作为一只看门狗（Daemon）守护在主人家里。 那么，哪些应用适合用 DaemonSet 的方式来部署呢？ 主要有以下几类： 监控类的，比如 Prometheus，collectd，New Relic agent，Ganglia gmond 等。 系统管理类的，比如 kube-proxy, kube-flannel 等。 日志收集类的，比如 fluentd，logstash 等。 数据存储类的，比如 glusterd, ceph 等。 …… 其中，系统管理类的应用主要是 K8S 自身的一些系统组件，我们可以通过 kubectl get daemonset --namespace=kube-system 查看到： DaemonSet kube-proxy 和 kube-flannel-ds 有 3 个副本，分别负责在每个节点上运行 kube-proxy 和 flannel 组件。 kube-proxy 前面的文章讲过，它有负载均衡的功能，主要将外部对 Service 的访问导向后端的 Pod 上。显然，一个 Node 运行一个负载均衡器足矣。 我们可以通过 kubectl edit daemonset kube-proxy --namespace=kube-system 来查看 kube-proxy 的 yaml 配置文件。 可以看到它的 kind 是 DaemonSet。 接着再来看 kube-flannel-ds，这是一个网络插件组件，主要用于构建 K8S 的集群网络，这里大家不懂可以跳过，不影响本文的理解，后面在讲到 K8S 网络的时候会重点讲这个网络方案。 这里我们只需要知道，各个 Pod 间的网络连通就是 flannel 来实现的。 这是一个第三方的插件，我们可以直接下载它的 yaml 文件进行安装，执行下面的命令： 1wget https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml 得到 kube-flannel.yml 文件： 这里只列出了一部分内容，kind 类型是 DaemonSet。 其实 DaemonSet 配置文件的语法和结构和 Deployment 几乎完全一样，不同就在于将 kind 设为 DaemonSet。 OK，DaemonSet 的探讨就到这里，下文我们继续讨论另外一种 Controller：Job。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 我的公众号 「Linux云计算网络」 ，号内有大量书籍和视频资源，后台回复「1024」即可领取，分享的内容包括但不限于云计算虚拟化、容器、OpenStack、K8S、雾计算、网络、工具、SDN、OVS、DPDK、Linux、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 笔记 08 Deployment 副本管理 重新招一个员工来填坑","slug":"tech/Kubernetes_笔记_08_Deployment_副本管理_重新招一个员工来填坑","date":"2018-09-16T05:16:14.000Z","updated":"2019-04-11T16:01:03.442Z","comments":true,"path":"2018/09/16/tech/Kubernetes_笔记_08_Deployment_副本管理_重新招一个员工来填坑/","link":"","permalink":"https://chambai.github.io/2018/09/16/tech/Kubernetes_笔记_08_Deployment_副本管理_重新招一个员工来填坑/","excerpt":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 8 篇。 Deployment 是 K8S v1.2 引入的概念，与之一起引入还有 ReplicaSet。这两个概念是等同的，准确说是 Deployment 内部调用 ReplicaSet 来实现。","text":"本文首发于我的公众号 「Linux云计算网络」 ，专注于干货分享，号内有大量书籍和视频资源，后台回复「1024」即可领取，欢迎大家关注，二维码文末可以扫。 Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 8 篇。 Deployment 是 K8S v1.2 引入的概念，与之一起引入还有 ReplicaSet。这两个概念是等同的，准确说是 Deployment 内部调用 ReplicaSet 来实现。 之前这个概念是由 Replication Controller 来实现的，但由于和 K8S 代码中的模块重名，所以就改成 Deployment + ReplicaSet 的组合。 Deployment 实现了 Pod 的副本管理，使得应用的表现形态和用户期望的状态保持一致。比如用户期望应用部署为 3 副本，如果在运行过程中有一个副本挂了，那么 Deployment 会自动拉起一个副本。 Deployment 对于应用的编排、自动扩容和缩容、升级回滚等功能都是至关重要的。 下面我们通过一个例子来看看 Deployment 是如何工作的。 定义一个 nginx.yaml 文件（对 yaml 文件不熟悉的可以查阅这篇文章）： 12345678910111213141516apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 2 template: metadata: labels: app: web-server spec: containers: - name: nginx images: nginx:1.12.1 ports: - containerPort: 80 这个文件定义了一个 nginx 容器应用，两个 Pod 副本。也就是每个 Pod 中会跑一个 nginx 应用。 执行kubectl create -f nginx.yaml创建 Deployment 对象，在执行 kubectl get deploy 查看创建的 Deployment。 可以看到，其中两个参数 desired（期待副本数）和 current（当前副本数）都为 2，保持一致，我们再执行 kubectl get pod -o wide 查看当前 Pod 的情况： 可以看到，创建了两个 Pod 自动调度到了 Node1 和 Node2 上。这说明每个 Pod 副本是由 Deployment 统一创建并维护的。 为了一探究竟，我们继续深挖 Deployment。 执行 kubectl describe deployment nginx-deployment 查看该 Deployment 的详细信息。 图中圈住的地方告诉我们，这里创建了一个 ReplicaSet，也就是说 Deployment 内部是调用 ReplicaSet 来完成 Pod 副本的创建的。是否是这样，我们继续验证。 执行 kubeclt get replicaset 显示创建的 ReplicaSet 对象： 可以看到这里的 ReplicaSet 名称和上面 Deployment 信息里显示的是一样的，同样，执行 kubectl describe replicaset xxx 显示该 ReplicaSet 的详细信息。 图中，有两处地方值得注意。一处是 Controlled By，表明 ReplicaSet 是由谁创建并控制的，显然这里显示是 Deployment。第二处是 Events，Events 记录了 K8S 中每一种对象的日志信息，这里的信息有助于排错查问题。我们可以看到这里记录了两个 Pod 副本的创建，Pod 的名称和我们在上面执行 kubectl get pod 看到的结果是一样的。 继续执行 kubectl describe pod xxx 查看其中一个 Pod 的详细信息： 可以看到这个 Pod 是由 ReplicaSet 创建的。 到此，我们不难得出下面这幅图： 用户通过 kubeclt 创建 Deployment，Deployment 又创建 ReplicaSet，最终由 ReplicaSet 创建 Pod。 从命名上我们也可以看出，子对象的名字 = 父对象的名字 + 随机字符串。 总结本文我们从实践上剖析了 Deployment 创建 Pod，实际上经过 ReplicaSet 进行创建。Deployment 最主要是对 Pod 进行副本管理，这样可以进行很多自动化管理的复杂操作，后面我们逐步从实践上去剖析 Pod 的各种操作。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 我的公众号 「Linux云计算网络」 ，号内有大量书籍和视频资源，后台回复「1024」即可领取，分享的内容包括但不限于云计算虚拟化、容器、OpenStack、K8S、雾计算、网络、工具、SDN、OVS、DPDK、Linux、Go、Python、C/C++编程技术等内容，欢迎大家关注。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"历史上那些具有跨时代意义的云计算创业公司","slug":"tech/历史上那些具有跨时代意义的云计算创业公司","date":"2018-09-13T05:16:14.000Z","updated":"2019-04-11T14:38:24.063Z","comments":true,"path":"2018/09/13/tech/历史上那些具有跨时代意义的云计算创业公司/","link":"","permalink":"https://chambai.github.io/2018/09/13/tech/历史上那些具有跨时代意义的云计算创业公司/","excerpt":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 这里所说的不是像 Google、VMware、Cisco、Intel 等等这些巨头公司，而是在巨头的夹缝中冉冉升起的那些新星。由于知识面有限，列举不尽完全，大家可以留言说说你心目中还有哪些值得铭记的公司。","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 这里所说的不是像 Google、VMware、Cisco、Intel 等等这些巨头公司，而是在巨头的夹缝中冉冉升起的那些新星。由于知识面有限，列举不尽完全，大家可以留言说说你心目中还有哪些值得铭记的公司。 Rackspace Rackspace 理应不算新星了，但说到“跨时代意义”，它是绝对的名副其实。原因就在于它和 NASA（美国国家航空航天局）合作开发了 OpenStack——一个让云计算产业进入井喷时代的项目。OpenStack 一经开源，短短两年时间就力压群雄成为开源社区仅次于 Linux 的全球第二大开源项目。 可以说是 OpenStack 拯救了 Rackspace。Rackspace 于 1998 成立，是最早期的一批云计算提供商，OpenStack 出来之前，一直不温不火，2010 年 OpenStack 出来之后，名声大震，一步跃居为全球仅次于 Amazon 和 VMware 的三大云计算中心之一。 如今 OpenStack 已经更新到 Rocky 版本，在众多竞争者和效仿者的围追堵截之下，依然很强势，这和它优秀的架构是分不开的。我很好奇它更新到 Z 版本之后会发生什么？ dotCloud OpenStack 带动了 IaaS 的发展，在这个节骨眼上，人们开始意识到，只有 IaaS 已经无法满足用户变态的需求了。 时间也落在 2010 年，这个时候几个大胡子年轻人在旧金山成立了一家做 PaaS 的公司，起名 dotCloud，开始杀入 PaaS 领域。 年轻一辈都意识到了商机，大佬们（Google、Microsoft、Amazon 等）能不意识到吗？于是大佬们也纷纷涉足 PaaS 领域，最终 dotCloud 寡不敌众，不得不缴械投降。 dotCloud 的工程师于心不甘啊，辛辛苦苦画下的大饼就这样被割分完了。但也没办法，谁让人家是大佬呢。 鉴于工程师们血液里都流淌着一股热爱分享的劲儿，他们决定将 dotCloud 的核心技术开源给世人。 谁能想到，无心插柳柳成荫。这门技术瞬间风靡全球，开启了又一个新的时代。 这门技术就是 Docker。 dotCloud 又火了，但为了纪念这个神圣的时刻，dotCloud 改名为 Docker Inc，全身心投入 Docker 的研发中。至于原来的 PaaS 业务，Docker 将其卖给了德国人的 cloudControl。但好景不长，cloudControl 于 2016 年就关闭了。 如今，Docker 技术依然可圈可点，虽然很多人在 Kubernetes 出来之后，叫衰 Docker，但我却不以为然。 Nicira 2007 年，斯坦福大学的 Nick McKeown 教授和他的天才学生 Martin Casado 博士根据他们的研究成果创办了 Nicira。这是 SDN 网络的鼻祖公司，Nick 教授和 Martin 博士也因此被人们称为 SDN 之父。 Nicira 公司做了很多牛逼的事：发明了世界上第一个 SDN 控制器 NOX，第一个分布式交换机 Open vSwitch 及其配套协议 OpenFlow 协议，领导研发 OpenStack 网络驱动模块 Quantum/Neutron，开源了业界第一个与硬件无关，支持多种 X86 虚拟化平台的分布式网络虚拟化架构（DVNI），等等等等。 Nicira 当时那套 SDN 的解决方案，放在今天来说都是很超前的东西。很快，Nicira 就被 VMware 和 Cisco 这些巨头盯上了。巨头们看上的不仅是 Nicira 的技术，更是 Nicira 那帮工程师天才般的智慧和对技术敏锐的洞察力。 巨头们开始了疯狂的收购战，最终 VMware 以 12.6 亿美元拔得头筹。Martin 博士也带领他的一般众将归入了 VMware 的麾下。 至此，Nicira 的舞台也算退出了。Open vSwitch 如今仍然占据 SDN 数据面的头把交椅。 Palo Alto Networks 2005 年，以色列的一个天才少年 Nir Zuk 在一间简陋的办公室里，一手创办了 PAN，这就是当下极富盛名的下一代防火墙的初创者（很多公司都宣称自己的防火墙是下一代防火墙，众说纷坛，其实争论这个没多大意义，人家 PAN 都还没说话呢）。 回看 Nir 的一生，也是颇具传奇，经历像极了乔布斯，但没乔布斯那么惨是被老东家赶出的，Nir 是因为老东家小气不肯给他资源做项目而无奈出走。谁能想到，PAN 能在短时间之内就超越了老东家。 小公司要在大公司的夹缝中生长，需要天时地利人和，以及运气，就像 Docker，上帝为你关上一扇门，就会为你打开一扇窗。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"01 云计算","slug":"01-云计算","permalink":"https://chambai.github.io/categories/01-云计算/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"OpenStack","slug":"OpenStack","permalink":"https://chambai.github.io/tags/OpenStack/"}]},{"title":"Kubernetes 笔记 07 豌豆荚之旅（二）","slug":"tech/Kubernetes_笔记_07_豌豆荚之旅（二）","date":"2018-09-11T05:16:14.000Z","updated":"2019-04-11T14:38:24.060Z","comments":true,"path":"2018/09/11/tech/Kubernetes_笔记_07_豌豆荚之旅（二）/","link":"","permalink":"https://chambai.github.io/2018/09/11/tech/Kubernetes_笔记_07_豌豆荚之旅（二）/","excerpt":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学习 K8S，这是系列第 7 篇。 上篇我们简单学习了 Pod 的基础知识，本篇开始讲述一些 Pod 的高阶知识（本文只做理论的简单阐述，后面会针对每个点进行实践）。","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学习 K8S，这是系列第 7 篇。 上篇我们简单学习了 Pod 的基础知识，本篇开始讲述一些 Pod 的高阶知识（本文只做理论的简单阐述，后面会针对每个点进行实践）。 Pod 的生命周期管理豌豆荚自诞生之日起，便注定要经历生老病死的一生。Pod 是由容器组成的，Pod 生命周期实际上是由容器的生命周期决定的。 在整个生命周期过程中，Pod 会被定义为各种状态，如下： 这些状态包括正常状态和异常状态，当出现异常状态时，K8S 的监控机制会检测到这种异常，并执行相应的异常处理。 Pod 的监控机制Pod 的监控主要是监控 Pod 内容器的健康状况，并进行相关的异常处理和容错管理。 当监控到某个容器异常退出或健康检查失败时，Pod 会执行重启策略，使得 Pod 内的容器健康运转。 如下记录了 Pod 的重启策略和健康检查机制： Pod 的调度管理K8S Master 上的 Scheduler 服务负责实现 Pod 的调度管理，Pod 是静态的，只有真正被调度到具体的节点上才能发挥它的作用。K8S 根据不同的应用场景，定义了多种不同的调度策略。这些策略可以是根据算法自动完成的，也可以是人为指定的。具体可以看下面这张导图： 笼统来看，有时候为了权衡应用场景和集群资源的需求，需要对 Pod 进行扩容和缩容，这同样属于 Pod 调度管理的范畴。 Pod 的存储管理Pod 和容器的数据存储使用 Volume，K8S Volume 和 Docker 的 Volume 是一样的原理，都是文件系统上的一个目录，只不过在 K8S 中实现了更多的 backend driver。包括 emptyDir、hostPath、GCE Persistent Disk、NFS、Ceph 等。 Volume 提供了对各种 driver 的抽象，容器在使用 Volume 读写数据的时候不需要关心底层具体存储方式的实现，对它来说，所有类型的 Volume 都是一个目录。 当 Volume 被挂载到 Pod 中时，这个 Pod 中的容器都会共享这个 Volume，当其中的容器销毁时，Volume 中的数据也不会丢失，当 Pod 销毁时，根据不同的 driver 实现，数据也可以保存下来。 Volume 提高了 Pod 内数据的持久化管理，延长了 Pod 和容器的生命周期。 Pod 的网络管理在 K8S 中，定义了多种资源对象，很多对象本身就是一个通信的实体，比如容器、Pod、Service、Node。 K8S 维护这多种对象之间的通信关系，比如：Pod 内容器之间的通信、Pod 与容器之间的通信、Pod 之间的通信、Pod 与 Service 之间的通信，以及外部的访问。 这些通信机制的建立离不开 K8S 建立的完善的网络模型。K8S 使用了 CNI（容器网络规范）来标准化、归一化网络模型。 第三方的厂商或开发者可以根据自身网络需求，遵从 CNI 的规范，实现各种网络方案，并以插件的形式提供给 K8S 使用。目前比较知名的网络方案有：flannel、calico、weave、canal 等。 这些网络方案各有千秋、虽然实现方式各有区别，但殊途同归，最终都是满足 K8S 中各种实体间的通信需求。 OK，本文就到这里，我们通过两篇文章大致梳理了豌豆荚从出生到死亡要面临的多种人生的关卡。跨过去了，就成熟了，希望我们都能跨过自己人生的关卡。 下文我们开始进入实践的部分。 为了给大家更多的福利，这个系列的每一篇文章我都会送一些电子书，可能有重的，也有一些新书，之前送了《K8S 指南》和《容器与容器云》，这次送一本新书《》，大家有需要的后台回复“K8S2”。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 笔记 06 豌豆荚之旅（一）","slug":"tech/Kubernetes_笔记_06_豌豆荚之旅（一）","date":"2018-09-09T05:16:14.000Z","updated":"2019-04-11T14:38:24.073Z","comments":true,"path":"2018/09/09/tech/Kubernetes_笔记_06_豌豆荚之旅（一）/","link":"","permalink":"https://chambai.github.io/2018/09/09/tech/Kubernetes_笔记_06_豌豆荚之旅（一）/","excerpt":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学习 K8S，这是系列第 6 篇。 Pod 中文译为豌豆荚，很形象，豌豆荚里面包裹的多颗小豌豆就是容器，小豌豆和亲密无间的老伙计壳荚子自出生之日起就得面对各种各样的人生大事：","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学习 K8S，这是系列第 6 篇。 Pod 中文译为豌豆荚，很形象，豌豆荚里面包裹的多颗小豌豆就是容器，小豌豆和亲密无间的老伙计壳荚子自出生之日起就得面对各种各样的人生大事： 容器、Pod、Node 之间的关系 Pod 的生命周期管理 Pod 的调度管理 Pod 的监控 Pod 的升级与回滚 Pod 的扩容与缩容 Pod 的存储管理 Pod 的网络管理 …… 为什么需要 Pod？我们假设没有 Pod，应用部署的最小单元就是容器，会有什么问题？首先，应用调度粒度太细，不便于管理。想象一下淘宝网站运行着海量应用，每个应用又拆分成多个服务，每个服务部署在一个容器里，一个集群管理系统要管理庞大的容器集群，既要顾忌不同应用之间的隔离性，又要考虑相同应用之间的关联性，这在管理上将会是灾难性的难题。 其次，资源利用率低。有很多应用之间存在某种强关联关系，它们需要彼此能共享对方的资源，双方的交互需要快捷有效，如果把它们部署到单独的容器中，资源利用和通信将成为最主要的系统瓶颈。 Pod 的提出改变了这种局面，它将强关联的应用整合在一起，作为一个整体对外提供服务，既简化了管理的难度，又提高了资源的利用率。 那哪些应用是强关联，适合放到一个 Pod 中呢？举个例子，比如下面这个 Pod 包含两个容器，一个 File Puller，一个是 Web Server。 File Puller 会定期从外部的 Content Manager 中拉取最新的文件，将其存放在 Volume 中。然后 Web Server 从 Volume 中读取文件，来响应 Consumer 的请求。 这两个容器通过 Volume 来共享实时的数据，协作处理一个 Consumer 的请求，把它们放到同一个 Pod 中就是合适的。 如果有应用和任何应用之间都不存在联系，那么它们就单独部署在一个 Pod 中，称为one-container-per-pod。即便只有一个容器，K8S 管理的也是 Pod 而不是直接管理容器。 综上，Pod 在设计的时候，主要动机有以下两点： 方便管理 Pod 提供了比容器更高一层的抽象，K8S以 Pod 为最小单元进行应用的部署、调度、扩展、共享资源和管理周期。 资源共享和通信 Pod 内的所有容器共享同一个网络空间，它们之间可以通过 localhost 相互通信。同样，所有容器共享 Volume，一个容器挂载一个 Volume，其余容器都可以访问这个 Volume。 容器、Pod、Node 之间的关系容器是 Pod 的一个属性，定义了应用的类型及共享的资源。每个容器会分配一个 Port，Pod 内的容器通过 localhost:Port 的形式来通信。 一个 Pod 包含一个或多个容器，每个 Pod 会分配一个唯一的 IP 地址，Pod 内的多个容器共享这个 IP 地址，每个容器的 Port 加上 Pod IP 共同组成一个 Endpoint，共同对外提供服务。 在部署应用的时候，Pod 会被 Master 作为一个整体调度到一个 Node 上。如果开启多副本管理，则多个 Pod 会根据调度策略调度到不同的 Node 上。如果 Node 宕机，则该 Node 上的所有 Pod 会被自动调度到其他 Node 上。 下面是容器、Pod、Node 三者之间的关系图： Pod 根容器Pod 中有一个特殊的容器，叫 Pod 的根容器——Pause 容器，这是一个很小的容器，镜像大小大概为 200KB。 Pause 容器存在的意义是: 维护 Pod 的状态信息。 由于 Pod 是作为一个整体进行调度，我们难以对这个整体的信息进行简单的判断和有效地进行行动。 想象一下，假如 Pod 内一个容器死亡了，是算整体死亡呢还是 N/M 死亡率，如果 Pod 内所有容器都死亡了，那是不是该 Pod 也就死亡了，如果加入新的容器或原有容器故障恢复呢，如何让新成员快速融入环境？ 理论上，虽然 Pod 是由一组容器组成的，但 Pod 和容器是彼此独立的，也就是容器的故障不应该影响 Pod 的存在，Pod 有相应的手段来保证容器的健康状况。 引入与业务无关的，并且不易死亡的 Pause 容器就可以很好的解决这个问题，Pause 容器的状态就代表了 Pod 的状态，只要 Pause 不死，那么不管应用容器发生什么变化，Pod 的状态信息都不会改变。 这样，Pod 内的多个应用容器共享 Pause 容器的 IP 和 Volume，当加入新的容器或者原有的容器因故障重启后就可以根据 Pause 保存的状态快速学习到当前 Pod 的状态。 总结本文简单学习了 Pod 的初级知识，包括 Pod 的设计动机，容器、Pod 和 Node 之间的关系，以及 Pod 的守护者——Pause 容器。 容器的 Port + Pod IP = Endpoint，构成一个 Pod 的通信实体，Pod 中的容器共享网络和存储，这些共享信息是由 Pause 容器来维护的。 下文继续豌豆荚之旅的第二个部分，学习 Pod 的管理哲学。 为了给大家更多的福利，这个系列的每一篇文章我都会送一些电子书，可能有重的，也有一些新书，之前送了《K8S 指南》和《容器与容器云》，这次送一本由 K8S 中文社区主编的《K8S 中文手册》，大家有需要的后台回复“K8S2” PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 笔记 05 使用产品前请先阅读说明书","slug":"tech/Kubernetes_笔记_05_使用产品前请先阅读说明书","date":"2018-09-07T05:16:14.000Z","updated":"2019-04-11T14:38:24.078Z","comments":true,"path":"2018/09/07/tech/Kubernetes_笔记_05_使用产品前请先阅读说明书/","link":"","permalink":"https://chambai.github.io/2018/09/07/tech/Kubernetes_笔记_05_使用产品前请先阅读说明书/","excerpt":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 5 篇。 生活中，随处可见，几乎每一款产品都会附带一份说明书，说明书可以记录产品的使用方法，也可以记录产品的配方。有了说明书，我们完全可以窥探一款产品的全貌。","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 5 篇。 生活中，随处可见，几乎每一款产品都会附带一份说明书，说明书可以记录产品的使用方法，也可以记录产品的配方。有了说明书，我们完全可以窥探一款产品的全貌。 在 K8S 中，yaml 配置文件就是 K8S 资源对象的说明书，定义了对象包含的元素及采取的动作，每种对象都可以通过 yaml 配置文件来创建。 yaml 是什么yaml 是一种用来写配置文件的语言，没错，它是一门语言。如果你用过 json，那么对它就不会陌生，yaml 又被称为是 json 的超集，使用起来比 json 更方便。 结构上它有两种可选的类型：Lists 和 Maps。 List 用 -（破折号） 来定义每一项，Map 则是一个 key:value 的键值对来表示。如下是一个 json 文件到 yaml 文件的转换： json: 12345678910111213141516171819202122&#123; &quot;apiVersion&quot;: &quot;v1&quot;, &quot;kind&quot;: &quot;Pod&quot;, &quot;metadata&quot;: &#123; &quot;name&quot;: &quot;xx&quot; &#125; &quot;spec&quot;: &#123; &quot;containers&quot;: [&#123; &quot;name&quot;: &quot;front-end&quot;, &quot;images&quot;: &quot;nginx&quot;, &quot;ports&quot;: [&#123; &quot;containerPort&quot;: &quot;80&quot; &#125;] &#125;, &#123; &quot;name&quot;: &quot;flaskapp-demo&quot;, &quot;images&quot;: &quot;jcdemo/flaskapp&quot;, &quot;ports&quot;: [&#123; &quot;containerPort&quot;: &quot;5000&quot; &#125;] &#125;] &#125;&#125; yaml:1234567891011121314---apiVersion: v1kind: Podmetadata: name: xxspec: containers: - name: front-end images: nginx ports: - containerPort: 80 - name: flaskapp-demo images: jcdemo/flaskapp ports: 8080 这个文件简单地定义了一个 Pod 对象，包含两个容器，我们可以很清晰地看到两者是如何转换的。 K8S 创建资源的两种方式在 K8S 中，有两种创建资源的方式：kubectl 命令和 yaml 配置文件。 两种方式各有各的好处。命令行的方式最为简单，一条命令就万事大吉，但缺点也很明显，你并不知道这条命令背后到底做了哪些事，配置文件就提供了一种让你知其然更知其所以然的方式。总的来说，它有以下好处： 完整性：配置文件描述了一个资源的完整状态，可以很清楚地知道一个资源的创建背后究竟做了哪些事； 灵活性：配置文件可以创建比命令行更复杂的结构； 可维护性：配置文件提供了创建资源对象的模板，能够重复使用； 可扩展性：适合跨环境、规模化的部署。 …… 当然，复杂的东西对用户就难以做到友好，我们需要熟悉它的配置文件的语法，有一定难度。下面举几个例子，让你对 yaml 配置文件有一个基本的认识。 几个例子下面，我们分别来看看 deployment、pod、service 这三种资源的说明书都长啥样。 由于 K8S 对每种资源的定义非常庞杂，限于篇幅，我们只看一些必选的参数，目的是通过这几个例子，读懂 yaml 配置文件。 deployment定义 deployment 配置文件，命名为：nginx-deployment.yaml12345678910111213141516171819apiVersion: apps/v1 # 1.9.0 之前的版本使用 apps/v1beta2，可通过命令 kubectl api-versions 查看kind: Deployment #指定创建资源的角色/类型metadata: #资源的元数据/属性 name: nginx-deployment #资源的名字，在同一个namespace中必须唯一spec: replicas: 2 #副本数量2 selector: #定义标签选择器 matchLabels: app: web-server template: #这里Pod的定义 metadata: labels: #Pod的label app: web-server spec: # 指定该资源的内容 containers: - name: nginx #容器的名字 images: nginx:1.12.1 #容器的镜像地址 ports: - containerPort: 80 #容器对外的端口 执行kubectl create -f nginx.yaml创建 deployment 资源： pod定义 pod 配置文件，命名为 redis-pod.yaml 123456789101112apiVersion: v1kind: Pod metadata: name: pod-redis labels: name: redisspec: containers: - name: pod-redis images: docker.io/redis ports: - containerPort: 80 #容器对外的端口 执行kubectl create -f pod-redis.yaml创建 pod 资源： 可以看到，成功创建一个 Pod，ContainerCreating表示 Pod 中的容器正在执行镜像的下载和安装过程，过一会儿，就显示Running了，表明 Pod 应用部署完成。 service定义 service 配置文件，命名为 httpd-svc.yaml 12345678910111213apiVersion: v1 kind: Service # 指明资源类型是 servicemetadata: name: httpd-svc # service 的名字是 httpd-svc labels: name: httpd-svc spec: ports: # 将 service 8080 端口映射到 pod 的 80 端口，使用 TCP 协议 - port: 8080 targetPort: 80 protocol: TCP selector: run: httpd # 指明哪些 label 的 pod 作为 service 的后端 执行kubectl create -f httpd-svc.yaml创建 service 资源： 可以看到，service httpd-svc 分配到一个 Cluster-IP 10.96.0.1，我们可以通过该 IP 访问 service 所维护的后端 Pod。 另外，还有一个 service kubernetes，这个是 Kubernetes API Server 的 service，Cluster 内部的各组件就是通过这个 service 来访问 API Server。 总结yaml 是 K8S 资源对象的说明书，每个对象拥有哪些属性都可以在 yaml 中找到详尽的说明，初学者建议多写 yaml 文件，少用命令行。 以上三个例子只是对 yaml 文件做个简单说明，更详细的信息还是参考官网。 OK，本文就到此为止，下文我们开始进入豌豆荚之旅。觉得不错，别忘了转发分享给你的朋友哦。 参考：https://www.kubernetes.org.cn/1414.html PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 笔记 04 架构是个好东西","slug":"tech/Kubernetes_笔记_04_架构是个好东西","date":"2018-09-05T05:16:14.000Z","updated":"2019-04-11T14:38:24.077Z","comments":true,"path":"2018/09/05/tech/Kubernetes_笔记_04_架构是个好东西/","link":"","permalink":"https://chambai.github.io/2018/09/05/tech/Kubernetes_笔记_04_架构是个好东西/","excerpt":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 4 篇。 任何技术的诞生，都会经历从架构设计到开发测试的过程，好的技术，往往也会有一套好的架构。架构是个好东西，它能帮助我们站在高处看清楚事物的整体结构，避免过早地进入细节而迷失方向。","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 4 篇。 任何技术的诞生，都会经历从架构设计到开发测试的过程，好的技术，往往也会有一套好的架构。架构是个好东西，它能帮助我们站在高处看清楚事物的整体结构，避免过早地进入细节而迷失方向。 上篇文章扫清了 K8S 的一些基本概念，今天这篇文章我们就来看看 K8S 的架构。 先上图： 图中包括两种类型的节点：Master 和 Node，每个节点上运行着多种 K8S 服务。 Master 节点Master 是 K8S 集群的大脑，运行着如下 Daemon 服务：kube-apiserver、kube-controller-manager、kube-scheduler、etcd 等。 API Server如果把 K8S 环境看作是一个公司，那 API Server 就是这个公司的基础平台部，是公司最为核心的技术能力输出出口。它对外提供 HTTP/HTTPS REST API，统称 K8S API，可以供各类客户端工具（CLI 或 WebUI）、K8S 其他组件，以及第三方的平台接入。对内提供了 K8S 各类资源（如 Pod、Deployment、Service等）的增删改查和监控等操作，是集群内各个功能模块之间数据交互和通信的中心枢纽。 Controller ManagerController Manager 更像是公司的人力资源部，负责统筹公司的人员分布。它管理着 K8S 各类资源的生命周期，保证资源处于预期状态，如果现有状态和预期状态不符，它会自动化执行修正。 Controller Manager 由多种 Controller 组成，包括 Replication Controller、Node Controller、ResourceQuota Controller、Namespace Controller、ServiceAccount Controller、Service Controller、Token Controller 及 Endpoint Controller 等。每种 Controller 都负责一种具体的资源管控流程，而 Controller Manager 正是这些 Controller 的核心管理者。 SchedulerScheduler 则像是公司各个部门的项目经理之类的角色，负责将具体的人力放到他们擅长的位置上，知人善用。具体来说，Scheduler 负责将待调度的 Pod 对象按照特定的调度策略绑定到集群中某个合适的节点上，调度策略会综合考虑集群的拓扑结构、节点的负载情况、以及应用对高可用、性能、数据亲和性的需求。 etcdetcd 是一个高可用的分布式数据库，负责保存 K8S 的配置信息和各种资源的状态信息。当数据发生变化时，etcd 会及时告知集群中的其他组件。 kubectlkubectl 是 K8S 的 CLI 工具，这是使用 K8S API 建立的一套命令行工具，使用它，可以非常方便地管理 K8S 集群。 Node 节点Node 是 K8S 集群的具体执行者，也运行着多种服务，如：kubelet、kube-proxy、container runtime、Pod 网络等。Node 可以看作是 Master 的代理，负责处理 Master 下发到本节点的任务，管理 Pod 和 Pod 中的容器，定期向 Master 汇报自身资源的使用情况。 kubeletkubelet 更像是部门中各个小组的 Leader，对外从 API Server 拿资源，对内负责小组内各种资源的管理，比如从 Master 拿到 Pod 的具体配置信息（images、Volume 等）之后，kubelet 根据这些信息创建和运行容器。 kube-proxykube-proxy 则像穿插在公司各个部门之间的接口人，对内和内部人员沟通，对外协调部门之间的各种事宜，展示部门风采。kube-proxy 作用于 Service，通过前面学习，我们知道 Service 是对一组 Pod 的抽象，统一对外提供某种服务，当外部访问 Service 时，实际上是需要访问 Service 所管辖的 Pod 中的容器，kube-proxy 在这里就是负责将访问 Service 的数据流转发到后端的容器，如果有多个副本，kube-proxy 会实现负载均衡。 cAdvisorcAdvisor 对 Node 上的资源进行实时监控和性能数据采集，包括 CPU 使用情况、内存使用情况、网络吞吐量及文件系统使用情况等。cAdvisor 集成在 kubelet 中，当 kubelet 启动时会自动启动 cAdvisor，一个cAdvisor 仅对一台 Node 机器进行监控。 container runtimecontainer runtime 是真正运行容器的地方，为容器提供运行环境，主流的三种 container runtime 是 lxc、runc 和 rkt，K8S 都支持它们，但常用的事 runc，原因是 runc 是 Docker 默认的 runtime。在 K8S 的容器应用中，Docker 是主流。 OK，K8S 架构介绍就到此为止。 最后，还是继续送书，容器网络专家倪朋飞写的《K8S 指南》电子书，如有需要后台回复“K8S”（之前回复过就不用回复了）。如需加群学习回复“加群”。 下文我们开始对 K8S 的说明书一探究竟。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 笔记 03 扫清概念","slug":"tech/Kubernetes_笔记_03_扫清概念","date":"2018-09-03T05:16:14.000Z","updated":"2019-04-11T14:38:24.058Z","comments":true,"path":"2018/09/03/tech/Kubernetes_笔记_03_扫清概念/","link":"","permalink":"https://chambai.github.io/2018/09/03/tech/Kubernetes_笔记_03_扫清概念/","excerpt":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第三篇。 每一种技术，为了描述清楚它的设计理念，都会自定义一堆概念或术语。在进入一门技术的研究之前，我们有必要扫清它的基本概念。","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第三篇。 每一种技术，为了描述清楚它的设计理念，都会自定义一堆概念或术语。在进入一门技术的研究之前，我们有必要扫清它的基本概念。 资源对象K8S 的操作实体，在 K8S 中，有很多的操作对象，比如容器、Pod、Deployment、Service、Node 等，我们统统称它们为资源对象。 ClusterK8S 集群，是计算、存储和网络资源的集合，K8S 基于这些资源来承载容器化的应用。 MasterK8S 集群的大脑，负责整个集群的管控、资源调度。可以部署在普通物理机或虚拟机上，为了实现高可用，可以部署多个 Master。 NodeK8S 集群的执行者，受 Master 指挥，负责运行和监控容器应用、管理容器的生命周期，并向 Master 定期汇报容器的状态。同样，Node 也可以部署在物理机或虚拟机之上，也可以部署多个。 Pod在 K8S 集群中，Pod 是资源调度的最小单位，一个 Pod 可以包含一个或多个容器应用，这些容器应用彼此之间存在某种强关联。Pod 内的所有容器应用共享计算、存储、网络资源。 ControllerController 是 K8S 中负责管理 Pod 的资源对象，它定义 Pod 的部署属性，比如有几个副本，副本异常怎么处理等，如果把 Pod 副本看做是一个公司职员，那么 Controller 就像是 HR，会不断根据人员的变动来招人满足公司的发展需求。 为了满足多种业务场景，K8S 提供了多种 Controller，包括 Deployment、ReplicaSet、DaemonSet、StatefulSet、Job 等。 DeploymentDeployment 是最常用的 Controller，定义了用户的期望场景，实现了 Pod 的多副本管理，如果运行过程中有一个副本挂了（员工离职），那么 K8S 会根据 Deployment 的定义重新拉起一个副本继续工作（招一个新员工），始终保证 Pod 按照用户期望的状态运行。 ReplicaSetReplicaSet 和 Deployment 实现了同样的功能，确切的说是 Deployment 通过 ReplicaSet 来实现 Pod 的多副本管理。我们通常不需要直接使用 ReplicaSet。 DaemonSetDaemonSet 用于每个 Node 最多只运行一个副本的场景，通常用于运行 Daemon。 JobJob 用于运行结束就删除的应用，而其他 Controller 则是会长期保持运行。 StatefulSet以上 Controller 都是无状态的，也就是说副本的状态信息会改变，比如当某个 Pod 副本异常重启时，其名称会改变。StatefulSet 提供有状态的服务，能够保证 Pod 的每个副本在其生命周期中名称保持不变。这是通过持久化的存储卷来实现的。 LabelLabel 定义了其他资源对象所属的标签，类似于你在公司被分到 A 小组、B 小组。有了标签，就可以针对性地对每个小组进行管理。比如把某个小组搬到哪个办公区（把某个 Pod 部署到哪个 Node 上）。给指定的资源对象定义一个或多个不同的标签能够实现多维度的资源分组管理，方便进行资源分配、调度、配置、部署等管理工作。 SelectorLabel 选择器，K8S 通过 Selector 来过滤筛选指定的资源对象，类似于 SQL 语句中的 where 查询条件，Label 实现了简单又通用的对象查询机制。 Service在 K8S 中，Service 是对 Pod 对象的抽象，通常，Pod 会以多副本的形式部署，每个 Pod 都有自己的 IP，都可以对外提供服务，但 Pod 是脆弱的，也就是说，它随时都有可能被频繁地销毁和重启，IP 也会随之改变，这样，服务的访问就会出现问题。 Service 就是提出来解决这个问题的，它定义了一个虚拟 IP（也叫集群 IP），这个 IP 在 Service 的整个生命周期内都不会改变。当有访问到达时，Service 会将请求导向 Pod，如果存在多个 Pod，Service 还能实现负载均衡。 VolumeK8S 的存储卷，定义了一个 Pod 中多个容器可访问的共享目录。和 Docker 的 Volume 不太一样的是，K8S 的 Volume 是以 Pod 为单位的，也就是 Volume 的生命周期和 Pod 相关，和 Pod 内的容器不相关，即使容器终止或重启，Volume 中的数据也不会丢失，只有当 Pod 被删除时，数据才会丢失。 Namespace当有多个用户或租户使用同一个 K8S 集群时，如何区分它们创建的资源呢？答案就是 Namespace。 Namespace 将一个物理的集群从逻辑上划分成多个虚拟的集群，每个集群就是一个 Namespace，不同 Namespace 里的资源是完全隔离的。每个用户在自己创建的 Namespace 里操作，都不会影响到其他用户。 AnnotationAnnotation 与 Label 类似，但和 Label 不同 的事，Annotation 不用于过滤筛选，它只是用户定义的某一种资源的附加信息，目的是方便外部查找该资源。有点类似于我们常说的别名，没有它完全可以，但有了它可以很方便查找。 最后，还是继续送书，容器网络专家倪朋飞写的《K8S 指南》电子书，如有需要后台回复“K8S”（之前回复过就不用回复了）。如需加群学习回复“加群”。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 笔记 02 demo 初体验","slug":"tech/Kubernetes_笔记_02_demo_初体验","date":"2018-08-31T05:16:14.000Z","updated":"2019-04-11T14:38:24.067Z","comments":true,"path":"2018/08/31/tech/Kubernetes_笔记_02_demo_初体验/","link":"","permalink":"https://chambai.github.io/2018/08/31/tech/Kubernetes_笔记_02_demo_初体验/","excerpt":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络！欢迎大家和我一起学习 K8S。 从前面的文章我们知道，Kubernetes 脱胎于 Google 的 Borg，Borg 在 Kubernetes 诞生之初已经在 Google 内部身经百战 10 余年，且不说它的历史源远流长，就凭它是出自 Google 那帮天才工程师之手，就知道它的学习难度不低。","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络！欢迎大家和我一起学习 K8S。 从前面的文章我们知道，Kubernetes 脱胎于 Google 的 Borg，Borg 在 Kubernetes 诞生之初已经在 Google 内部身经百战 10 余年，且不说它的历史源远流长，就凭它是出自 Google 那帮天才工程师之手，就知道它的学习难度不低。 对于这种有一定学习门槛的技术，最好的入门方式是先玩起来，如果刚开始就沉迷在那些理论中，很容易从入门到放弃。 可喜的是，Google 已经考虑到了这一点，官方文档提供了一个很小的 demo，麻雀虽小，五脏俱全，这个 demo 基本涵盖了 K8S 的基本概念，通过它，可以轻松构建一个 K8S 集群，玩转 K8S，我们现在就去玩一玩。（PS：下面提到的概念，我们后面会详细讨论，不理解可以暂时跳过） 打开：https://kubernetes.io/docs/tutorials/kubernetes-basics 映入眼帘的是图文并茂的 6 个步骤： 创建一个 K8S 集群 部署 APP 探索 APP 访问 APP APP 弹性伸缩 更新 APP 在开始每个步骤之前，先来了解个东西——minikube。顾名思义，这是一个迷你版的 K8S，一个轻量级的 K8S 实现，对于平常的学习体验，使用它可以达到和使用 K8S 一样的效果。它的部署方式足够简单，All-In-One，一个集群只有一个节点，K8S 所有组件都部署在这个节点上。 用户也可以使用 Web UI 和 minikube CLI 的方式来管理 K8S 集群，比如：启动，停止，删除，获取状态等。官方的 demo 就是使用 minikube CLI 来完成的。 话不多说，下面我们就开始体验下 K8S 之旅吧。 第一步：创建一个 K8S 集群 在交互界面输入 minikube start 就创建了一个 K8S 集群，这个集群创建在一台 VM 上，K8S 所有组件都跑在这台 VM 上。 接下来我们就可以使用 K8S 命令行工具 kubectl 来操作这个集群了。 kubectl version 查看 K8S 的版本号： 看到两个 version，client version 指 kubectl 的 version，server version 就是 K8S 的 version。 kubectl get nodes 获取集群节点数： 可以看到这个 demo 只有一个节点，就是前面创建的 VM。status 是 ready，说明该节点准备好部署 APP 了。 第二步：部署一个 APP 执行命令：1kubectl run kubernetes-bootcamp --images=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080 就完成了一个 APP 的部署。 其中，--images 指定 APP 的 Docker 镜像，--port 设置 APP 对外服务的端口，kubectl run 会下载镜像，然后创建 deployment，根据 deployment 创建 APP。deployment 就像是 APP 的说明书，它指导怎么创建 和维护 APP。APP 创建完运行在 Docker 容器中，使用 kubectl get deployments 可以查看 deployment 的信息。 第三步：探索 APP 上一步创建完 deployment，会接着创建 Pod 来运行 APP 容器，K8S 使用 Pod 来管理容器资源，一个 Pod 可以包含一个或多个容器，在这个例子，一个 Pod 就只有一个 APP 容器。使用 kubectl get pods 查看当前 Pod 信息。 更详细信息使用 kubectl describe pods 查看。 kubectl 工具对于排错很有帮助，下面几个是较为常用的命令： kubectl get - 列出资源 kubectl describe - 显示资源的详细信息 kubectl logs - 输出 Pod 中容器的日志 kubectl exec - 在 Pod 容器中执行命令 第四步：访问 APP 默认情况下，所有 Pod 都只能在集群内部访问，上面看到每个 Pod 有 IP 和端口，Pod 之间可以直接访问。外部想要访问 Pod， 需要将端口暴露出去，执行如下命令：1kubectl expose deployment/kubernetes-bootcamp --type=&quot;NodePort&quot; --port 8080 将容器的端口（8080）映射到节点的端口。 执行 kubectl get services 查看映射到的节点的端口。 可以看到容器的 8080 端口已经映射到节点的 31915 端口。外部可以通过 NodeIP:Port 的方式就可以访问到 Pod 内的容器，如下： service 是 K8S 中对 Pod 的进一步抽象，是外部访问 Pod 的入口。如果把 K8S 集群想象成一个组织，那么 service 就是这个组织的接口人，为什么需要 service，这个留作后面的内容再讲，在这里你可以把它暂时理解成端口映射。 第五步：APP 的弹性伸缩 为了满足高可用，Pod 可以自动扩容和缩容。默认情况下，Pod 只会运行一个副本，这是由 deployment 定义的，可以通过 kubectl get deployments 查看副本数，通过 kubectl scale deployments/app --replicas=num 增加或减少副本数。 比如，增加副本数到 4 个： 看到 Pod 数也增加到了 4 个。 减少副本数为 2 个： 看到两个副本显示 Terminating，表示正在中止，过段时间再看就只有两个了。 对于多副本的情况，访问 APP 会实现负载均衡，如下： 看到每次请求访问都落在不同的 Pod 上，这个功能是由 service 来完成的。 第六步：更新 APP 当前 APP 使用的镜像版本是 v1，需要升级到 v2，执行如下命令： 1kubectl set images deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2 看到升级过程是先中止之前的 4 个副本，再重开 4 个副本。 如果回退到 v1 版本，只用执行如下命令即可： 1kubectl rollout undo deployments/kubernetes-bootcamp 至此，我们已经通过官方这个 demo 体验了一把 K8S 的功能和使用方法，下面我会陆陆续续把自己学习 K8S 的笔记整理出来，分享给你，希望对你有帮助。如有可能，请随手转发分享一下，让更多的人也参与进来。 最后，还是继续送书，容器网络专家倪朋飞写的《K8S 指南》电子书，如有需要后台回复“K8S”（之前回复过就不用回复了）。如需加群学习回复“加群”。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 笔记 01 初识 Kubernetes 新时代的领航者","slug":"tech/Kubernetes_笔记_01_初识_Kubernetes_新时代的领航者","date":"2018-08-30T05:16:14.000Z","updated":"2019-04-11T14:38:24.071Z","comments":true,"path":"2018/08/30/tech/Kubernetes_笔记_01_初识_Kubernetes_新时代的领航者/","link":"","permalink":"https://chambai.github.io/2018/08/30/tech/Kubernetes_笔记_01_初识_Kubernetes_新时代的领航者/","excerpt":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络！欢迎大家和我一起学习 K8S。 大明王朝时期，明成祖朱棣为了发展海外贸易和建立自己的声望，派郑和七下西洋，创下了这段中国古代规模最大、船只最多（240多艘）、海员最多（2.7 万人）、时间最久的，比欧洲国家航海时间早半个多世纪的远洋航行壮举。","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Hi，大家好，我是 Linux云计算网络！欢迎大家和我一起学习 K8S。 大明王朝时期，明成祖朱棣为了发展海外贸易和建立自己的声望，派郑和七下西洋，创下了这段中国古代规模最大、船只最多（240多艘）、海员最多（2.7 万人）、时间最久的，比欧洲国家航海时间早半个多世纪的远洋航行壮举。 Kubernetes 这个名字起源于古希腊，是「舵手」的意思，所以它的 Logo 既像一张渔网，又像一个罗盘。如果 Docker 把自己定位为驮着集装箱在大海上遨游的鲸鱼，那么 Kubernetes 就是掌舵大航海时代话语权的舵手，指挥着这条鲸鱼按照主人设定的路线巡游。 Kubernetes 脱胎于 Google 老牌的集群管理软件「Borg」，虽然自诞生至今才三年多（第一个正式版本 Kubernetes 1.0 于 2015 年 7 月才正式发布），但要论其历史，却是早已在 Google 内部身经百战 10 余年，Kubernetes 站在 Borg 这个前辈的肩膀上，吸取了它过去十年间的经验和教训，才有了今天的成绩。这也是 Docker 火了之后，Google 迫不及待想推 Kubernetes 的原因。 Kubernetes 也常被人们称为「K8S」，原因是 K 和 S 之间正好有 8 个字母，读音上也和 8 相似，为了阅读方便，人们都乐于这么称呼。 有了 Google 的背书，K8S 一经推出就一鸣惊人，迅速称霸容器技术领域。 可以说，K8S 是以容器技术为基础打造的一个云计算时代的全新分布式系统架构，它的架构设计开放，除了支持 Docker，还支持其他容器技术，比如 Rocket、RKT 等。 Google 的加持，开放的生态，让它在与其他竞争对手的 博弈中占据上风，轻松拿下容器编排这个市场。 2017年9月，Mesosphere 宣布支持 K8S，接着，10月，Docker 在 DockerCon EU 2017 大会上也宣布拥抱 K8S，至此，K8S 正式霸占容器技术领域，彻底掌控容器技术的未来。 K8S 为了扩大影响力，推出没多久就加入 OpenStack 阵营，目的是希望 K8S 能被 OpenStack 生态圈所容纳，与 KVM 虚拟机一样成为 OpenStack 平台上的一等公民。 这意味着以容器为代表的应用形态和以虚拟机为代表的系统形态将完美融合于 OpenStack 之上，并与软件定义网络和软件定义存储一起统治下一代数据中心。 K8S 在云计算领域刮起了一道强劲之风，但凡跟云计算相关的公司都无法无视它的存在，错过它，也许就错过了未来。我们来看看它从诞生至今的 Google 趋势（和 Docker Swarm 和 Mesos 进行了对比）： 可以看到，K8S 从诞生之初便一路飙升，将对手甩开了十几条街，未来也将会以火箭的速度保持上升。 目前，除了云计算相关的公司，很多互联网公司、甚至传统企业都在纷纷布局自家的 K8S 产品，可以说，K8S 是当前容器行业最炙手可热的明星。 作为一个 IT 从业人员，你无法忽视它的存在。谁能比别人领先一步掌握新技术，谁就能在竞争中赢得了先机。 虽然说，现在学习 K8S 并不是最佳时机，但还不算太晚，就像一句话说的： 学习一门技术最好的时间是 10 年前，其次是现在。 后面我会推一个我学习 K8S 的笔记教程，一方面是加深自己对知识的理解，另一方面也是希望能分享给有需要的人。分享是一种美德，你在看到我的分享的同时，也希望你能动动手指把它分享给你的朋友，这样我的分享也没有白费。 最后，我这里有一份 《K8S 指南》，这是容器网络专家倪朋飞利用自己业余时间写的一本小册子，质量还是挺不错的，有需要的后台回复“K8S”。另外需要加群学习的后台回复“加群”。 文中图片来源于网络，侵权必删参考：k8s 指南 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"Kubernetes 新时代的宠儿","slug":"tech/Kubernetes_新时代的宠儿","date":"2018-08-28T05:16:14.000Z","updated":"2019-04-11T14:38:24.064Z","comments":true,"path":"2018/08/28/tech/Kubernetes_新时代的宠儿/","link":"","permalink":"https://chambai.github.io/2018/08/28/tech/Kubernetes_新时代的宠儿/","excerpt":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Kubernetes 是什么 Kubernetes 简称为 K8S。简单说，K8S 是一个用于容器集群的分布式系统架构。首先，它是基于容器技术，容器是和虚拟机并列的一种虚拟化技术，相比虚拟机来说，容器更加轻量，资源利用率更高，更适合于云原生应用。","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Kubernetes 是什么 Kubernetes 简称为 K8S。简单说，K8S 是一个用于容器集群的分布式系统架构。首先，它是基于容器技术，容器是和虚拟机并列的一种虚拟化技术，相比虚拟机来说，容器更加轻量，资源利用率更高，更适合于云原生应用。 其次，K8S 掌管的是容器集群，就像它的名字一样，一个舵手指挥着一个个的集装箱航行。容器会被频繁地销毁、重建和调度，为了最大化地利用集群资源和减少人力成本，K8S 在其中以高效的策略，自动化的运维方式指挥着这一切，就像一台永动机一样，管理员可以一劳永逸。 最后，K8S 的架构非常开放，分布式的组件结构，使得它可以轻松地适应大规模的集群环境，Google 庞大的数据中心就是它最好的历练。 为什么 K8S 能赢？ 随着 2014 年 Docker 大火之后，已经涌现出大量的容器集群管理平台，其中，Docker 自家的 Swarm，在 Twitter 内部久经考验的 Mesos，以及 Google 的 K8S 最为知名，号称容器编排三驾马车。下图是三家的热度走势图： K8S 自诞生日起便一骑绝尘，甩对手十几条街。为什么 K8S 能赢？我自以为是生态。 K8S 架构开放，向下可以容纳各种 container runtime，便不是没了 Docker 不行。向上可以承载各种 PaaS 平台，还能和 OpenStack、VMware 这些 IaaS 平台和平相处。它由此组建的生态系统，随随便便可以吃下任何一个平台。再加上 Google 的加持，谁能不爱？ 有哪些公司在使用 K8S？ 据不完全统计，除了 AWS、Azure、Google、Microsoft 等巨头在容器领域里多年的博弈外，国内的很多互联网公司，如 BAT、蚂蚁、今日头条、滴滴等技术大厂，也都将容器和 K8S 列入我来的战略重心，无数中小型企业也正走在容器化的道路上。 从长远角度来看，K8S 将会成为企业服务器端技术栈标准中的一环，并连同它所推崇的容器化理念，成为广大后端技术人员和开发者的一门必修课。 怎么学 K8S？ 现在快餐时代，如何学习才能更高效？我觉得排在第一位的应该是站在巨人的肩膀上学习。国内有很多研究 K8S 的大牛，其中一批是浙江大学研究所的研究员，他们出了国内第一本深入解读 Docker 和 K8S 原理的书《容器与容器云》。 看书虽然效果是奇好的，但效率并不高，想要效率高，我觉得学习大牛的知识总结可能才是最有效的。 正巧，今天我看到那批研究员中的一位作者张磊（现在在微软研究院）在极客时间开了一个 K8S 专栏，我觉得是雨后逢甘露，第一时间就买了。 这里简单给大家介绍下，有需要的朋友一定不要错过。 课程有 51 节，原价 99 元，现在优惠 68 元，9月8日恢复原价，如果你扫我下面的二维码买的话，我返你 8 元（注意：这个是我特地给你的福利，别的地方是没有的），也就是说，你只用 60 元就可以买了，每节课 1 块多一点。另外，你买了之后还可以以同样的方式分享给你的好友，双方都受益。如果你讨厌这样的方式，那么忽略就好。 我作为一名云计算爱好者，一方面是希望为前辈们宣传一波，另一方面我也是给我的读者们尽量争取一些实打实的福利。希望能帮助到你。 大家买了之后记得加我微信哈，我返你钱。 另外，K8S 是用 Go 语言写的，我推荐大家和 Go 一起学效果最好，大家可以看我之前写的这篇文章学习 Go 语言最好的时间是 10 年前，其次是现在。 下面还有一个目录，大家可以看看，真的很良心。 课程目录： PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"}]},{"title":"集群：孙悟空分身术","slug":"tech/集群：孙悟空分身术","date":"2018-08-23T05:16:14.000Z","updated":"2019-04-11T14:38:24.071Z","comments":true,"path":"2018/08/23/tech/集群：孙悟空分身术/","link":"","permalink":"https://chambai.github.io/2018/08/23/tech/集群：孙悟空分身术/","excerpt":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 在孙悟空的七十二变中，我觉得最厉害的非分身能力莫属，这也是他百试不得其爽的终极大招，每每都能打得妖怪摸不着北。","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 在孙悟空的七十二变中，我觉得最厉害的非分身能力莫属，这也是他百试不得其爽的终极大招，每每都能打得妖怪摸不着北。 集群，学名叫 Cluster，可以翻译为簇、聚类、集群等多种意思，不同的翻译，在技术世界里所表示的意思都不尽相同，但都有一个共同的指向，即群体。集群就是由一组计算机所组成的实体，通常作为一个整体向用户提供资源。集群的研究和发展离不开人们对高性能计算的追求，像我们熟悉的向量机、对称多处理机、工作站、超级计算机等等都是对高性能计算追求下的产物。 这些系统要么是提高 CPU 的主频和总线带宽来提高系统性能，要么是增加 CPU 个数和内存容量来提高性能，但这些手段对性能的提高都是有限的。有人做过实验，当 CPU 个数超过某一阈值时，系统的性能反而会变差。其主要的瓶颈就在于 CPU 访问内存的带宽并不能随着 CPU 个数的增加而有效增加。 相反，集群系统的性能可扩展能力是线性增长的。我们可以简单通过增加机器数来增加集群的运算能力，相比购买高性能的大型计算机，同等运算能力下，我们可以获得更高的性价比。同时，系统的可靠性也得到了增强。 历史 早在七十年代计算机厂商和研究机构就开始了对集群系统的研究和开发，首先创造性发明集群的是 Seymour Cray（西摩·克雷）—— 超级计算机之父。 Seymour 是一位美国工程师，在 1960 年代，CDC 公司涉足高性能计算领域，彼时还是大型机的天下，这些大型机设计非常复杂，生产周期漫长，价格还非常昂贵。当时在 CDC 公司担任总设计师的 Seymour 决心建造出心目中的高性能计算机。 Seymour 出于工程师的直觉，很快想到并行是提高计算机性能的有效方式。他使用廉价的方式来获得跟大型机一样的运算能力。他将多个普通的处理器连接起来，使它们能够协同工作，这就是高性能计算机的原型。 后来，IBM、HP 等公司学习了 Seymour 的这套架构，高性能计算机开始迅速推广，逐步取代原有的大型机。高性能计算机为当时的登月计划等大型科研项目作出了非常重要的贡献。 然后进入八十年代，在摩尔定律的指导下，CPU 频率不断提高，芯片不断降价，个人计算机强势崛起。苹果、微软等公司借助这股东风成为个人计算机时代的王者。随之而来的就是高性能计算机市场遭到了吞噬，被迫只能退守公司服务器市场。 但很快，随着互联网的普及，高性能计算机又迎来新的一波热潮。互联网上用户量庞大，普通 PC 难以应付如此众多的网络请求，必须要依赖由高性能计算机组成的服务器集群。在 2000 年左右的网络泡沫时期，成就了很多像 Sun 这样的服务器生产商。 如今，IT 行业向云计算冲击，诸如 Google、Apple、Amazon 等很巨头纷纷建立起了自己的数据中心。集群的规模在不断扩大，为海量的数据提高基础设施提供了支撑。根据不同的应用场景，集群也演变出多种形态，比如高性能集群、高可用集群、负载均衡集群等等。 集群元素 集群不是简单的硬件堆叠，而是硬件和软件的结合。从软件上说，集群至少需要： 构建于 TCP/IP 协议上的通信软件，用于集群中节点之间的通信。 一套中心管理软件，用于统一管理集群中节点的资源、任务和容错等等。 这两点比较好理解，集群的规模往往是比较庞大的，对于管理员来说，需要随时能够知晓集群中各节点的业务正常与否，出问题了应该怎么保证业务能够不中断，遇到流量高峰和低谷的时候，又该怎么响应，这些操作如果纯靠人工来完成那必将很惨烈。依靠软件和网络来完成自动化的管理方式，可以将管理员解放出来。当然，以上说的两点是比较宽泛的，用户可以根据自身需求来部署不同的集群元素。 一个比较经典的集群模型当属 Beowulf 集群，它通过一个节点统一将来自网络的请求分配给各个节点进行计算处理。 集群与分布式 集群与分布式像一对孪生兄弟，傻傻分不清楚。在我看来，它们之间没有特别明确的分界线，集群离不开分布式，分布式也需要集群。如果一定要做个区分，可以套用一个比喻来描述两者的区别： 一家餐厅刚开业，由于成本限制招了一个厨师，慢慢地，餐厅生意越做越好，一个厨师已经很难应付过来，于是又招了一个，这两个厨师水平相当，都能做同样的事，两个厨师之间的关系就是集群。两厨师除了炒菜，还要负责洗菜、配菜等等的活，工作负荷已经严重超标，为了让厨师能专心炒菜，把菜做到极致，餐厅又招了配菜师来辅助厨师，厨师和配菜师之间的关系就是分布式。 这个例子比较形象，在网站开发中也有类似的关系，两个全栈工程师之间就是集群的关系，前端工程师和后端工程师之间就属于分布式的关系。 @知乎大闲人柴毛毛 所以，一定要有区分的话就是：集群是一个业务部署在多个服务器上，而分布式是一个业务拆分成多个子业务部署在不同的服务器上。但在实际部署中，为了高性能，需要分布式部署，为了高可用，需要集群部署，这两者都是业务所必须的指标。所以，集群和分布式之间的关系是相互补充的。 虚拟化 随着虚拟化技术的发展，一台服务器可以虚拟出多个虚拟机，对外提供业务，这种方式大大提高了资源的利用率，集群的部署也逐步从物理机过渡到虚拟机，灵活性大大提高。但同时也带来了更多新的研究课题。虚拟化计算、虚拟化存储、虚拟化网络、虚拟化安全等等这些课题共同推动着云计算产业迈出一个又一个的台阶。 数据中心 数据中心是集中存放和运行服务器的地方，是规模最大的集群。随着云计算和大数据概念的风起云涌，Google、Amazon 等这些明星公司幕后的数据中心也开始走入大众的视野。数据中心要求有优秀的架构设计、电路设计、空间设计等等，还要有机制能够应对各种各样的意外，否则一点小小的失误，公司的股价恐怕就要跳水。 地理位置的选择也是数据中心考虑的一个指标，随着绿色数据中心概念的兴起，越来越多人关注数据中心所带来的能源问题和环境问题，选择一个远离市区，并且能利用天然水源和气温的地方，将会为数据中心的建设节约大量的成本。Google 等大公司的数据中心就有意放在高纬度、高海拔的地区，以及有湖泊、河流流经地区，以享受天然的空调和冷却水。 云计算之所以能被称之为“云”计算，是因为具有体量庞大的资源池，集群就是用来构建这个资源池的，说集群是云计算的基石一点都不为过。目前有很多集群管理软件，大家比较熟悉的像 Mesos，k8s 都属于这个范畴，后面会带来相关的干货，大家尽情期待。 PS：文中图片均来自于网络，侵权必删参考：http://dwz.cn/h9lwjvOR PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/categories/Kubernetes/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"},{"name":"集群","slug":"集群","permalink":"https://chambai.github.io/tags/集群/"}]},{"title":"再谈云计算技能图谱","slug":"tech/再谈云计算技能图谱","date":"2018-08-15T05:16:14.000Z","updated":"2019-04-11T14:38:24.079Z","comments":true,"path":"2018/08/15/tech/再谈云计算技能图谱/","link":"","permalink":"https://chambai.github.io/2018/08/15/tech/再谈云计算技能图谱/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 之前，我写过一篇「云计算技能图谱」的文章，涵盖了云计算领域绝大部分的分支，很多人看了表示不淡定了——学完这个要等到猴年马月！ 其实那份图谱涉及到很多应用场景，比如说大数据，机器学习，这些是基于云计算引申的技术分支，底层用的是云计算的基础设施，但要说可不可以独立于云计算来做，可以，只是一个规模的问题罢了。 为了能给很多初学者一个好的引导，我重新整理了这份图谱，把一些相关联的技术分支去掉了，只保留了基础设施部分（包括计算、存储、网络、安全这几个部分）。如下： 备注：图片为防抄袭迫不得已加水印，想要原图的可以加我微信私信我 这样来看，就显得精简多了。 可能你看到这个还是会很焦虑，其实大可不必焦虑，图谱更多告诉你的是这个领域有什么，至于做不做完全根据你自己的情况选择，比如你想做个 T 型人才 ，那就尽可能去学，想做个 I 型人才，那就专注在某一个领域就好了。这两者没有绝对的孰是孰非，最终都是要解决问题。就像一句话说的，不管黑猫白猫，能捉到老鼠的就是好猫。 我知道关注我的读者当中，什么人才都有，我目前知道的，有学生，有工作了好几年的老司机，也有博士，首先要感谢大家的关注，我相信大家关注我肯定是因为我的哪一篇文章触动了你或者对你有帮助才会关注的。 我想说，大家关注我肯定是没错的，我这个号专注的内容就是上面这份图谱提到的内容，你可以在这里看到最基础的开发实践内容（比如 Linux、C/C++、Python、Go 技术栈），也可以看到云计算框架的解读（比如 KVM，OpenStack，Docker，Kubernetes），还可以看到最前沿技术的探讨。当然也有一些非技术的内容，比如行业资讯，以及我一些不吐不快的碎碎念。 其实我进入这个领域也不算早，跟很多读者比起来，是不折不扣的菜鸟，但正因为我是菜鸟，我写出的文章才会通俗易懂，因为我要保证和我一样的菜鸟能听得懂，当然了，质量肯定是第一位的，你们要是看过我以前写的一些文章就知道质量如何了，绝对是很良心的分享。说这个主要是希望大家能多多向你身边的朋友推荐下我这个号，有更多的朋友加入，我的写作动力就越强，就能给你们输出更多更好的文章。 为了能让大家有一个交流的氛围，我建了一个群，想加入的可以后台回复“加群”。 另外，我这里还收藏了一套很有价值的技能图谱，包括上面说的很多细分领域，比如 Python、Docker、Kubernetes、DevOps，还有一些其他的分支，比如机器学习，大数据，架构师，运维，嵌入式等等等等，大概就像下面这样子： 这些资料是我精心为大家整理的，整理不易，大家如果需要，有一点点要求，只要你乐于分享即可。这里要说明一点，我觉得好的东西，就是要让更多的人看到，你可以说是诱导你分享，但扪心自问，遇到好的东西谁又不乐意分享呢，让你的朋友看到你分享好东西给他们又何尝不是一种快乐呢。 获取技能图谱方法： 转发本文到你的朋友圈； 添加我的微信号：aLinux云计算网络，或长按下方二维码加我微信； 加好友后发朋友圈截图给我，我看到会发一整套技能图谱给你，或者你也可以回复“加群”，我拉你进我的技术交流群。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"01 云计算","slug":"01-云计算","permalink":"https://chambai.github.io/categories/01-云计算/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"技能图谱","slug":"技能图谱","permalink":"https://chambai.github.io/tags/技能图谱/"}]},{"title":"Linux探秘之 I/O 效率","slug":"tech/Linux探秘之_I:O_效率","date":"2018-07-20T05:16:14.000Z","updated":"2019-04-11T14:38:24.059Z","comments":true,"path":"2018/07/20/tech/Linux探秘之_I:O_效率/","link":"","permalink":"https://chambai.github.io/2018/07/20/tech/Linux探秘之_I:O_效率/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 文章来由 最近看了《UNIX环境高级编程》，以前一些比较模糊的知识又清晰了一步，特别是前两章讲到不带缓冲的文件 I/O 和带缓冲的标准 I/O，对 read、write、fread、fwrite、printf 等等这些函数又有了新的认识。 一个很大的感受是，我们很多时候开发都只注重上层逻辑，虽然一个项目接一个项目，看上去做了不少事，但是夜深人静掐指一想，究竟我们是否真正掌握了这些知识点，对于每一个知识点实现的机制我们是否能完整地说出来？这些东西最能体现一个人的基础知识是否扎实，我发现互联网公司的面试中最喜欢问这些基础知识，由一个很基本的函数层层递进引申出很多的问题。 很多时候我们内心可能会很排斥，甚至不屑于这些基础知识，想着等用到的时候，再来查，现在专注上层逻辑就好了，这样有助于提升我的开发效率。这样的想法貌似也没什么错，但是往往这就是瓶颈的来源，程序员最可怕的就是遇到瓶颈了。因为瓶颈这个东西是很难意识到的，一味追求实践而放弃理论学习，很容易就遇到瓶颈。（个人见解，不喜勿喷） 本文算是自己看完《UNIX 环境高级编程》文件 I/O 和标准 I/O 两章的读书笔记，文件 I/O 一章说不带缓冲，但后面又出现可带缓冲，搞得人有点晕，特意记下自己对此的理解。如果有什么不对的，欢迎指出，如果觉得本文对你有帮助，就动动手指推荐下，或者是粉我下，你的支持是我分享的最大动力。^_^ 缓冲机制 众所周知，CPU 和内存的数据交换要远大于磁盘，通过缓存机制，可以减少磁盘读写的次数，提高并发处理程序的效率，因此，缓存是一种提高任务存储和处理效率的有效方法。我们很多时候可以看到，缓存不仅在操作系统方面被采用，更是在 Web 技术、服务器端、分布式系统等领域发挥着及其重要的作用。 从宏观上看，Linux 操作系统分为用户态和内核态，在处理 I/O 操作的时候，两者都提供了缓存。用户态的称为标准 I/O 缓存，也称为用户空间缓存，而内核态的称为缓冲区高速缓存，也叫页面高速缓存。既然都提供了缓存，那为什么这本书上却分不带 I/O 的缓存和带 I/O 的缓存，原因其实是“不带 I/O缓存”指的是用户空间中不为这些 I/O 操作设有缓冲，而内核是带缓冲的，这样来看，就不会糊涂了。 系统 I/O 和标准 I/O 系统 I/O，又称文件 I/O，或是内核态 I/O，引用文件的方式是通过文件描述符 fd，一个文件对应一个文件描述符。一个文件描述符用一个非负整数表示，0、1、2 系统默认表示标准输入、标准输出、标准错误。 某些 UNIX 系统规定了描述符的上限值 OPEN_MAX，这些常量都定义在头文件&lt;unistd.h&gt;中。当读或写一个文件时，使用 open 或 create 系统调用返回的文件描述符标识该文件，并将其作为参数传递给 read 或 write 系统调用。 123#include &lt;unistd.h&gt;ssize_t read(int filedes, void *buf, size_t nbytes);ssize_t write(int filedes, const void *buf, size_t nbytes); 标准 I/O，又叫用户态 I/O，引用文件的方式则是通过文件流（stream），一般用 fopen 和 freopen 函数打开一个流，返回一个指向 FILE 对象的指针，其他函数如果要引用这个流，就将 FILE 指针作为参数传递。 一个进程预定义了三个流，并且这三个流自动被进程使用，它们是标准输入流、标准输出流和标准出错流。这三个流和系统 I/O 所规定的三个文件描述符所引用的文件相同。 当读或写一个文件时，不像系统 I/O，仅定义了 read 和 write 两个系统调用函数，标准 I/O 定义了多个函数，程序员可以根据自己的需求灵活使用。这些函数可以分为每次一个字符的 I/O，每次一行的 I/O 和直接 I/O（或者二进制 I/O、一次一个对象 I/O、面向记录的 I/O、面向结构的 I/O）。 1）每次一个字符的 I/O12345678910#include&lt;sdio.h&gt;/* 输入函数 */int getc(FILE *fp) //-&gt; 宏int fgetc(FILE *fp) //-&gt; 函数int getchar(void) //等价于getc(stdin)/* 输出函数 */int putc(int c, FILE *fp)int fputc(int c, FILE *fp)int putchar(int c) //等效于putc(c, stdout) 2）每次一行 I/O12345678#include &lt;stdio.h&gt;/* 输入函数 */char *fgets(char *restrict buf, int n, FILE *restrict fp)char *gets(char *buf)/* 输出函数 */int fputs(cont char *restrict str, FILE *restrict fp)int puts(const char *str) 3）直接I/O123#include &lt;stdio.h&gt;size_t fread(void *restrict ptr, size_t size, size_t nobj, FILE *restrict fp)size_t fwrite(const void *restrict ptr, size_t size, size_t nobj, FILE *restrict fp) 到此，我们大概了解了系统 I/O 和标准 I/O 引用文件的方法，以及一些常用的 I/O 函数。下面通过一个图来详细看下当用户调用一个 I/O 函数时，用户态和内核态的一个执行流程是什么样的，进一步了解缓存在 I/O 操作中的作用，以及用户态 I/O 和内核态 I/O 在执行效率上的区别。 I/O 操作的流程 如上图所示，用户进程空间和内核进程空间读写磁盘的操作都要经过缓冲区缓存，缓存的作用前面提到过，是为了减少磁盘读写的次数，提高 I/O 的效率。（来源于公众号：aLinux云计算网络，此处是防那些无脑SB抄袭，如影响阅读，还请大家见谅）当读写一个文件时，首先看系统 I/O 的操作流程。 1、系统I/O： 属于内核系统调用，没有涉及用户态的参与。以图中标号为例： ③ 调用 write 函数向文件中写数据，buf 中存放的就是要写入的数据，如write(fd, ‘abc’, 3)。调用前需要先设置 BUFFSIZE。不同的 BUFFSIZE 会影响I/O 效率，后面再来说这个问题。 ⑤ 延迟写：当缓存区高速缓存满或者内核要重写缓冲区的时候，才将数据写入输出队列，等数据到队列首部的时候，才真正触发磁盘的写操作。 ⑥ 预读：当检测到正进行顺序读取时，内核就试图读入比应用程序所要求更多的数据，并假想应用程序很快就会读到这些数据。这样，当缓冲区没有数据时，能够快速填充下次要读取的数据。 ④ 调用 read 从缓冲区高速缓存读取所需数据到逻辑单元中进行处理。 以上，就是系统 I/O 所涉及到的四步操作。 2、标准 I/O： 属于 ISO C 实现的标准库函数，调用的是底层的系统调用。 ① 将逻辑单元中的数据写入文件，根据需求，有三种函数类型可以调用，以fputc、fputs、fwrite 为例，这些函数不用人为去控制缓冲区的大小，而是系统自动申请的，当用户定义了相应的 I/O 函数之后，根据不同的缓存类型（是全缓冲、行缓冲还是无缓冲），系统自动调用 malloc 等函数申请缓冲区，即标准 I/O 缓存。 ③⑤ 当用户缓冲区满了之后，如系统 I/O 操作一般，此时调用 write 从标准I/O 缓存中复制数据到内核缓冲区，再写入磁盘。 ④⑥ 同系统 I/O 操作，从内核缓冲区调用 read 读入到用户缓冲区。 ② 同样有三种函数类型可以调用，以 fgetc、fgets、fread 为例，读入逻辑单元进行后续的处理。 可见，标准 I/O 实现的机制就是基于系统 I/O，这样看来，标准 I/O 在效率上肯定不如系统 I/O，但事实是标准 I/O 与系统 I/O 相比并不慢很多，而且还有很多其他的优点，下面一一述说（本篇文章最重要的就是下一小节）。 I/O 效率 从图中可以看出，系统 I/O 效率受限于 read、write 系统调用的次数，而系统调用次数又受限于内核缓冲区的大小，即 BUFFSIZE，通过设置不同的 BUFFSIZE，得到的系统 CPU 时间是不同的，其最小值出现在 BUFFSIZE=4096 处，原因是该测试所采用的是 Linux ext2 文件系统，其块长为 4096 字节，也即缓冲区所能申请到的最大缓冲区大小，我们把 4096 字节看做是本次最佳 I/O 长度。 如果继续扩大缓冲区大小，对此时间几乎没有影响。所以，对于系统 I/O 操作，一个最大的问题就是：需要人为控制缓存的大小及最佳 I/O 长度的选择，另外就是系统调用与普通函数调用相比通常需要花费更多的时间，因为系统调用具体内核要执行这样的操作：1）内核捕获调用，2）检查系统调用参数的有效性，3）在用户空间和内核空间之间传输数据。 因此，引入标准 I/O 的目的就是为了通过标准 I/O 缓存来避免 BUFFSIZE 选择不当而带来的频繁的系统调用。根据用户不同的需求，选择不同的 I/O 函数，然后根据不同的缓存类型，自动调用 malloc 等缓存分配函数分配合适的缓存，等分配的缓存满之后，再调用系统 I/O 从标准 I/O 缓存向内核缓存拷贝数据，这样就进一步减少了系统调用的次数。 但是不同的标准 I/O 函数，不同的缓存类型也会带来不同的效率。如上图，当选择系统最佳 I/O 长度，即 BUFFSIZE 的大小和文件系统的块长一致，可以得到最佳的时间。 当选用标准 I/O 函数时，每次一个字符函数 fgetc、fputc 和每次一行函数 fgets、fputs 函数相比要花费较多的 CPU 时间，而每次单个字节调用系统 I/O 则花费更多的时间，如果是一个 100M 的文件，则要执行大概 2亿 次函数调用，也就引起 2亿 次系统调用（从用户缓冲区到内核缓冲区，再到磁盘），而 fgetc 版本也执行了 2亿 次函数调用，但只引起了大约 25222 次系统调用，所以，时间就大大减少了。 综合以上，标准 I/O 函数虽然基于系统 I/O 实现，但很大程度上减少了系统调用的次数，而且不用人为关心缓冲区大小的选择，整体上提高了 I/O 的效率。另外，标准 I/O 提供了多种缓存类型，方便程序员根据不同的应用需求选择不同的缓存要求，提高了编程的灵活性，当选择无缓存时，就相当于直接调用系统 I/O。 OK，大概的内容就以上这些，当然关于 I/O 操作这块还有很多需要注意的点，而且还有很多更加高级的 I/O 函数，这些在后面遇到再来做总结。最后，如果你觉得这篇文章对你有帮助就点赞转发支持下我吧，还是那句话，你的支持是我分享的最大动力。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"I/O","slug":"I-O","permalink":"https://chambai.github.io/tags/I-O/"}]},{"title":"Linux探秘之用户态与内核态","slug":"tech/Linux探秘之用户态与内核态","date":"2018-07-06T05:16:14.000Z","updated":"2019-04-11T14:38:24.054Z","comments":true,"path":"2018/07/06/tech/Linux探秘之用户态与内核态/","link":"","permalink":"https://chambai.github.io/2018/07/06/tech/Linux探秘之用户态与内核态/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Unix/Linux的体系架构 如下图所示，从宏观上来看，Linux 操作系统的体系架构分为用户态和内核态（或者用户空间和内核）。 内核从本质上看是一种软件——控制计算机的硬件资源，并提供上层应用程序运行的环境。用户态即上层应用程序的活动空间，应用程序的执行必须依托于内核提供的资源，包括 CPU 资源、存储资源、I/O 资源等。为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口：即系统调用。 系统调用是操作系统的最小功能单位，这些系统调用根据不同的应用场景可以进行扩展和裁剪，现在各种版本的 Unix 实现都提供了不同数量的系统调用，如 Linux 的不同版本提供了 240-260 个系统调用，FreeBSD 大约提供了 320 个（reference：UNIX 环境高级编程）。 我们可以把系统调用看成是一种不能再化简的操作（类似于原子操作，但是不同概念），有人把它比作一个汉字的一个“笔画”，而一个“汉字”就代表一个上层应用，我觉得这个比喻非常贴切。因此，有时候如果要实现一个完整的汉字（给某个变量分配内存空间），就必须调用很多的系统调用。如果从实现者（程序员）的角度来看，这势必会加重程序员的负担，良好的程序设计方法是：重视上层的业务逻辑操作，而尽可能避免底层复杂的实现细节。 库函数正是为了将程序员从复杂的细节中解脱出来而提出的一种有效方法。它实现对系统调用的封装，将简单的业务逻辑接口呈现给用户，方便用户调用，从这个角度上看，库函数就像是组成汉字的“偏旁”。这样的一种组成方式极大增强了程序设计的灵活性，对于简单的操作，我们可以直接调用系统调用来访问资源，如“人”，对于复杂操作，我们借助于库函数来实现，如“仁”。显然，这样的库函数依据不同的标准也可以有不同的实现版本，如ISO C 标准库，POSIX 标准库等。 Shell 是一个特殊的应用程序，俗称命令行，本质上是一个命令解释器，它下通系统调用，上通各种应用，通常充当着一种“胶水”的角色，来连接各个小功能程序，让不同程序能够以一个清晰的接口协同工作，从而增强各个程序的功能。 同时，Shell 是可编程的，它可以执行符合 Shell 语法的文本，这样的文本称为 Shell 脚本，通常短短的几行 Shell 脚本就可以实现一个非常大的功能，原因就是这些 Shell 语句通常都对系统调用做了一层封装。为了方便用户和系统交互，一般，一个 Shell 对应一个终端，终端是一个硬件设备，呈现给用户的是一个图形化窗口。我们可以通过这个窗口输入或者输出文本。这个文本直接传递给 Shell 进行分析解释，然后执行。 总结一下，用户态的应用程序可以通过三种方式来访问内核态的资源： 系统调用 库函数 Shell 脚本 下图是对上图的一个细分结构，从这个图上可以更进一步对内核所做的事有一个“全景式”的印象。主要表现为：向下控制硬件资源，向内管理操作系统资源：包括进程的调度和管理、内存的管理、文件系统的管理、设备驱动程序的管理以及网络资源的管理，向上则向应用程序提供系统调用的接口。 从整体上来看，整个操作系统分为两层：用户态和内核态，这种分层的架构极大地提高了资源管理的可扩展性和灵活性，而且方便用户对资源的调用和集中式的管理，带来一定的安全性。 用户态和内核态的切换 因为操作系统的资源是有限的，如果访问资源的操作过多，必然会消耗过多的资源，而且如果不对这些操作加以区分，很可能造成资源访问的冲突。 所以，为了减少有限资源的访问和使用冲突，Unix/Linux 的设计哲学之一就是：对不同的操作赋予不同的执行等级，就是所谓特权的概念。简单说就是有多大能力做多大的事，与系统相关的一些特别关键的操作必须由最高特权的程序来完成。Intel 的 X86 架构的 CPU 提供了 0 到 3 四个特权级，数字越小，特权越高。 Linux 操作系统中主要采用了 0 和 3 两个特权级，分别对应的就是内核态和用户态。运行于用户态的进程可以执行的操作和访问的资源都会受到极大的限制，而运行在内核态的进程则可以执行任何操作并且在资源的使用上没有限制。 很多程序开始时运行于用户态，但在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从用户态切换到内核态的过程。比如C函数库中的内存分配函数 malloc()，它具体是使用 sbrk() 系统调用来分配内存，当malloc() 调用 sbrk() 的时候就涉及一次从用户态到内核态的切换，类似的函数还有 printf()，调用的是 wirte() 系统调用来输出字符串，等等。 那到底在什么情况下会发生从用户态到内核态的切换，一般存在以下三种情况： 当然就是系统调用：原因如上的分析。 异常事件： 当 CPU 正在执行运行在用户态的程序时，突然发生某些预先不可知的异常事件，这个时候就会触发从当前用户态执行的进程转向内核态执行相关的异常事件，典型的如缺页异常。 外围设备的中断：当外围设备完成用户的请求操作后，会向 CPU 发出中断信号，此时，CPU 就会暂停执行下一条即将要执行的指令，转而去执行中断信号对应的处理程序，如果先前执行的指令是在用户态下，则自然就发生从用户态到内核态的转换。 注意： 系统调用的本质其实也是中断，相对于外围设备的硬中断，这种中断称为软中断，这是操作系统为用户特别开放的一种中断，如 Linux int 80h 中断。所以，从触发方式和效果上来看，这三种切换方式是完全一样的，都相当于是执行了一个中断响应的过程。但是从触发的对象来看，系统调用是进程主动请求切换的，而异常和硬中断则是被动的。 总结 本文仅是从宏观的角度去理解 Linux 用户态和内核态的设计，并没有去深究它们的具体实现方式。从实现上来看，必须要考虑到的一点我想就是性能问题，因为用户态和内核态之间的切换会消耗大量资源。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"}]},{"title":"一文掌握 Linux 性能分析之网络篇（续）","slug":"tech/一文掌握_Linux_性能分析之网络篇（续）","date":"2018-06-15T05:16:14.000Z","updated":"2019-04-11T14:38:24.069Z","comments":true,"path":"2018/06/15/tech/一文掌握_Linux_性能分析之网络篇（续）/","link":"","permalink":"https://chambai.github.io/2018/06/15/tech/一文掌握_Linux_性能分析之网络篇（续）/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 这是 Linux 性能分析系列的第五篇，前四篇在这里：一文掌握 Linux 性能分析之 CPU 篇一文掌握 Linux 性能分析之内存篇一文掌握 Linux 性能分析之 IO 篇一文掌握 Linux 性能分析之网络篇 在上篇中，我们已经介绍了几个 Linux 网络方向的性能分析工具，本文再补充几个。总结下来，余下的工具包括但不限于以下几个： sar：统计信息历史 traceroute：测试网络路由 dtrace：TCP/IP 栈跟踪 iperf / netperf / netserver：网络性能测试工具 perf 性能分析神器 由于篇幅有限，本文会先介绍前面两个，其他工具留作后面介绍，大家可以持续关注。 sarsar 是一个系统历史数据统计工具。统计的信息非常全，包括 CPU、内存、磁盘 I/O、网络、进程、系统调用等等信息，是一个集大成的工具，非常强大。在 Linux 系统上 sar --help 一下，可以看到它的完整用法。 -A：所有报告的总和 -u：输出 CPU 使用情况的统计信息 -v：输出 inode、文件和其他内核表的统计信息 -d：输出每一个块设备的活动信息 -r：输出内存和交换空间的统计信息 -b：显示 I/O和传送速率的统计信息 -a：文件读写情况 -c：输出进程统计信息，每秒创建的进程数 -R：输出内存页面的统计信息 -y：终端设备活动情况 -w：输出系统交换活动信息 -n：输出网络设备统计信息 在平时使用中，我们常常用来分析网络状况，其他几项的通常有更好的工具来分析。所以，本文会重点介绍 sar 在网络方面的分析手法。 Linux 系统用以下几个选项提供网络统计信息： -n DEV：网络接口统计信息。 -n EDEV：网络接口错误。 -n IP：IP 数据报统计信息。 -n EIP：IP 错误统计信息。 -n TCP：TCP 统计信息。 -n ETCP：TCP 错误统计信息。 -n SOCK：套接字使用。 我们来看几个示例： （1）每秒打印 TCP 的统计信息： sar -n TCP 1 几个参数了解一下： active/s：新的 TCP 主动连接（也就是 socket 中的 connect() 事件），单位是：连接数/s。 passive/s：新的 TCP 被动连接（也就是 socket 中的 listen() 事件）。 iseg/s：接收的段（传输层以段为传输单位），单位是：段/s oseg/s：发送的段。通过这几个参数，我们基本可以知道当前系统 TCP 连接的负载情况。 （2）每秒打印感兴趣的网卡的统计信息： sar -n DEV 1 | awk &#39;NR == 3 || $3 == &quot;eth0&quot;&#39; 几个参数了解一下： rxpck/s / txpck/s：网卡接收/发送的数据包，单位是：数据包/s。 rxkB/s / txkB/s：网卡接收/发送的千字节，单位是：千字节/s。 rxcmp/s / txcmp/s：网卡每秒接受/发送的压缩数据包，单位是：数据包/s。 rxmcst/s：每秒接收的多播数据包，单位是：数据包/s。 %ifutil：网络接口的利用率。这几个参数对于分析网卡接收和发送的网络吞吐量很有帮助。 （3）错误包和丢包情况分析： sar -n EDEV 1 几个参数了解一下： rxerr/s / txerr/s：每秒钟接收/发送的坏数据包 coll/s：每秒冲突数 rxdrop/s：因为缓冲充满，每秒钟丢弃的已接收数据包数 txdrop/s：因为缓冲充满，每秒钟丢弃的已发送数据包数 txcarr/s：发送数据包时，每秒载波错误数 rxfram/s：每秒接收数据包的帧对齐错误数 rxfifo/s / txfifo/s：接收/发送的数据包每秒 FIFO 过速的错误数 当发现接口传输数据包有问题时，查看以上参数能够让我们快速判断具体是出的什么问题。 OK，这个工具就介绍到这里，以上只是抛砖引玉，更多技巧还需要大家动手去探索，只有动手，才能融会贯通。 traceroutetraceroute 也是一个排查网络问题的好工具，它能显示数据包到达目标主机所经过的路径（路由器或网关的 IP 地址）。如果发现网络不通，我们可以通过这个命令来进一步判断是主机的问题还是网关的问题。 它通过向源主机和目标主机之间的设备发送一系列的探测数据包（UDP 或者 ICMP）来发现设备的存在，实现上利用了递增每一个包的 TTL 时间，来探测最终的目标主机。比如开始 TTL = 1，当到达第一个网关设备的时候，TTL - 1，当 TTL = 0 导致网关响应一个 ICMP 超时报文，这样，如果没有防火墙拦截的话，源主机就知道网关设备的地址。以此类推，逐步增加 TTL 时间，就可以探测到目标主机之间所经过的路径。 为了防止发送和响应过程出现问题导致丢包，traceroute 默认会发送 3 个探测包，我们可以用 -q x 来改变探测的数量。如果中间设备设置了防火墙限制，会导致源主机收不到响应包，就会显示 * 号。如下是 traceroute baidu 的结果： 每一行默认会显示设备名称（IP 地址）和对应的响应时间。发送多少个探测包，就显示多少个。如果只想显示 IP 地址可以用 -n 参数，这个参数可以避免 DNS 域名解析，加快响应时间。 和这个工具类似的还有一个工具叫 pathchar，但平时用的不多，我就不介绍了。以上就是两个工具的简单介绍，工具虽然简单，但只要能解决问题，就是好工具。当然，性能分析不仅仅依靠工具就能解决的，更多需要我们多思考、多动手、多总结，逐步培养自己的系统能力，才能融会贯通。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"性能分析","slug":"性能分析","permalink":"https://chambai.github.io/tags/性能分析/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"}]},{"title":"一文掌握 Linux 性能分析之网络篇","slug":"tech/一文掌握_Linux_性能分析之网络篇","date":"2018-06-01T05:16:14.000Z","updated":"2019-04-11T14:38:24.072Z","comments":true,"path":"2018/06/01/tech/一文掌握_Linux_性能分析之网络篇/","link":"","permalink":"https://chambai.github.io/2018/06/01/tech/一文掌握_Linux_性能分析之网络篇/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 这是 Linux 性能分析系列的第四篇。 比较宽泛地讲，网络方向的性能分析既包括主机测的网络配置查看、监控，又包括网络链路上的包转发时延、吞吐量、带宽等指标分析。包括但不限于以下分析工具： ping：测试网络连通性 ifconfig：接口配置 ip：网络接口统计信息 netsat：多种网络栈和接口统计信息 ifstat：接口网络流量监控工具 netcat：快速构建网络连接 tcpdump：抓包工具 sar：统计信息历史 traceroute：测试网络路由 pathchar：确定网络路径特征 dtrace：TCP/IP 栈跟踪 iperf / netperf / netserver：网络性能测试工具 perf ：性能分析神器 本文先来看前面 7 个。 ping ping 发送 ICMP echo 数据包来探测网络的连通性，除了能直观地看出网络的连通状况外，还能获得本次连接的往返时间（RTT 时间），丢包情况，以及访问的域名所对应的 IP 地址（使用 DNS 域名解析），比如： 我们 ping baidu.com，-c参数指定发包数。可以看到，解析到了 baidu 的一台服务器 IP 地址为 220.181.112.244。RTT 时间的最小、平均、最大和算术平均差分别是 40.732ms、40.762ms、40.791ms 和 0.248。 ifconfig ifconfig 命令被用于配置和显示 Linux 内核中网络接口的统计信息。通过这些统计信息，我们也能够进行一定的网络性能调优。 1）ifconfig 显示网络接口配置信息 其中，RX/TX packets 是对接收/发送数据包的情况统计，包括错误的包，丢掉多少包等。RX/TX bytes 是接收/发送数据字节数统计。其余还有很多参数，就不一一述说了，性能调优时可以重点关注 MTU（最大传输单元） 和 txqueuelen（发送队列长度），比如可以用下面的命令来对这两个参数进行微调：12ifconfig eth0 txqueuelen 2000ifconfig eth0 mtu 1500 2）网络接口地址配置 ifconfig 还常用来配置网口的地址，比如：为网卡配置和删除 IPv6 地址：12ifconfig eth0 add 33ffe:3240:800:1005::2/64 #为网卡eth0配置IPv6地址ifconfig eth0 del 33ffe:3240:800:1005::2/64 #为网卡eth0删除IPv6地址 修改MAC地址：1ifconfig eth0 hw ether 00:AA:BB:CC:dd:EE 配置IP地址：123ifconfig eth0 192.168.2.10ifconfig eth0 192.168.2.10 netmask 255.255.255.0ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255 IP ip 命令用来显示或设置 Linux 主机的网络接口、路由、网络设备、策略路由和隧道等信息，是 Linux 下功能强大的网络配置工具，旨在替代 ifconfig 命令，如下显示 IP 命令的强大之处，功能涵盖到 ifconfig、netstat、route 三个命令。 netstat netstat 可以查看整个 Linux 系统关于网络的情况，是一个集多钟网络工具于一身的组合工具。 常用的选项包括以下几个： 默认：列出连接的套接字 -a：列出所有套接字的信息 -s：各种网络协议栈统计信息 -i：网络接口信息 -r：列出路由表 -l：仅列出有在 Listen 的服务状态 -p：显示 PID 和进程名称 各参数组合使用实例如下： netstat -at 列出所有 TCP 端口 netstat -au 列出所有 UDP 端口 netstat -lt 列出所有监听 TCP 端口的 socket netstat -lu 列出所有监听 UDP 端口的 socket netstat -lx 列出所有监听 UNIX 端口的 socket netstat -ap | grep ssh 找出程序运行的端口 netstat -an | grep ‘:80’ 找出运行在指定端口的进程 1）netstat 默认显示连接的套接字数据 整体上来看，输出结果包括两个部分： Active Internet connections ：有源 TCP 连接，其中 Recv-Q 和 Send-Q 指的是接收队列和发送队列，这些数字一般都是 0，如果不是，说明请求包和回包正在队列中堆积。 Active UNIX domain sockets：有源 UNIX 域套接口，其中 proto 显示连接使用的协议，RefCnt 表示连接到本套接口上的进程号，Types 是套接口的类型，State 是套接口当前的状态，Path 是连接到套接口的进程使用的路径名。 2）netstat -i 显示网络接口信息 接口信息包括网络接口名称（Iface）、MTU，以及一系列接收（RX-）和传输（TX-）的指标。其中 OK 表示传输成功的包，ERR 是错误包，DRP 是丢包，OVR 是超限包。 这些参数有助于我们对网络收包情况进行分析，从而判断瓶颈所在。 3）netstat -s 显示所有网络协议栈的信息 可以看到，这条命令能够显示每个协议详细的信息，这有助于我们针对协议栈进行更细粒度的分析。 4）netstat -r 显示路由表信息 这条命令能够看到主机路由表的一个情况。当然查路由我们也可以用 ip route 和 route 命令，这个命令显示的信息会更详细一些。 ifstat ifstat 主要用来监测主机网口的网络流量，常用的选项包括： -a：监测主机所有网口 -i：指定要监测的网口 -t：在每行输出信息前加上时间戳 -b：以 Kbit/s 显示流量数据，而不是默认的 KB/s delay：采样间隔（单位是 s），即每隔 delay 的时间输出一次统计信息 count：采样次数，即共输出 count 次统计信息 比如，通过以下命令统计主机所有网口某一段时间内的流量数据： 可以看出，分别统计了三个网口的流量数据，前面输出的时间戳，有助于我们统计一段时间内各网口总的输入、输出流量。 netcat netcat，简称 nc，命令简单，但功能强大，在排查网络故障时非常有用，因此它也在众多网络工具中有着“瑞士军刀”的美誉。 它主要被用来构建网络连接。可以以客户端和服务端的方式运行，当以服务端方式运行时，它负责监听某个端口并接受客户端的连接，因此可以用它来调试客户端程序；当以客户端方式运行时，它负责向服务端发起连接并收发数据，因此也可以用它来调试服务端程序，此时它有点像 Telnet 程序。 常用的选项包括以下几种： -l：以服务端的方式运行，监听指定的端口。默认是以客户端的方式运行。 -k：重复接受并处理某个端口上的所有连接，必须与 -l 一起使用。 -n：使用 IP 地址表示主机，而不是主机名，使用数字表示端口号，而不是服务名称。 -p：当以客户端运行时，指定端口号。 -s：设置本地主机发出的数据包的 IP 地址。 -C：将 CR 和 LF 两个字符作为结束符。 -U：使用 UNIX 本地域套接字通信。 -u：使用 UDP 协议通信，默认使用的是 TCP 协议。 -w：如果 nc 客户端在指定的时间内未检测到任何输入，则退出。 -X：当 nc 客户端与代理服务器通信时，该选项指定它们之间的通信协议，目前支持的代理协议包括 “4”（SOCKS v.4），“5”（SOCKS v.5）和 “connect” （HTTPs Proxy），默认使用 SOCKS v.5。 -x：指定目标代理服务器的 IP 地址和端口号。 下面举一个简单的例子，使用 nc 命令发送消息：首先，启动服务端，用 nc -l 0.0.0.0 12345 监听端口 12345 上的所有连接。 然后，启动客户端，用 nc -p 1234 127.0.0.1 12345 使用 1234 端口连接服务器 127.0.0.1::12345。 接着就可以在两端互发数据了。这里只是抛砖引玉，更多例子大家可以多实践。 tcpdump 最后是 tcpdump，强大的网络抓包工具。虽然有 wireshark 这样更易使用的图形化抓包工具，但 tcpdump 仍然是网络排错的必备利器。 tcpdump 选项很多，我就不一一列举了，大家可以看文章末尾的引用来进一步了解。这里列举几种 tcpdump 常用的用法。 1）捕获某主机的数据包 比如想要捕获主机 200.200.200.100 上所有收到和发出的所有数据包，使用：1tcpdump host 200.200.200.100 2）捕获多个主机的数据包 比如要捕获主机 200.200.200.1 和主机 200.200.200.2 或 200.200.200.3 的通信，使用：1tcpdump host 200.200.200.1 and \\(200.200.200.2 or \\) 同样要捕获主机 200.200.200.1 除了和主机 200.200.200.2 之外所有主机通信的 IP 包。使用：1tcpdump ip host 200.200.200.1 and ! 200.200.200.2 3）捕获某主机接收或发出的某种协议类型的包比如要捕获主机 200.200.200.1 接收或发出的 Telnet 包，使用：1tcpdump tcp port 23 host 200.200.200.1 4）捕获某端口相关的数据包 比如捕获在端口 6666 上通过的包，使用：1tcpdump port 6666 5）捕获某网口的数据包比如捕获在网口 eth0 上通过的包，使用：1tcpdump -i eth0 下面还是举个例子，抓取 TCP 三次握手的包：首先，用 nc 启动一个服务端，监听端口 12345 上客户端的连接：1nc -v -l 0.0.0.0 12345 接着，启动 tcpdump 监听端口 12345 上通过的包：1tcpdump -i any &apos;port 12345&apos; -XX -nn -vv -S 然后，再用 nc 启动客户端，连接服务端：1nc -v 127.0.0.1 12345 最后，我们看到 tcpdump 抓到包如下： 怎么分析是 TCP 的三次握手，就当做小作业留给大家吧，其实看图就已经很明显了。 总结 本文总结了几种初级的网络工具，一般的网络性能分析，通过组合以上几种工具，基本都能应付，但对于复杂的问题，以上工具可能就无能为力了。更多高阶的工具将在下文送上，敬请期待。 Reference： ip 和 ipconfig：https://blog.csdn.net/freeking101/article/details/68939059 性能之巅：Linux网络性能分析工具http://www.infoq.com/cn/articles/linux-networking-performance-analytics 抓包工具tcpdump用法说明https://www.cnblogs.com/f-ck-need-u/p/7064286.html PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"性能分析","slug":"性能分析","permalink":"https://chambai.github.io/tags/性能分析/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"}]},{"title":"一文掌握 Linux 性能分析之 IO 篇","slug":"tech/一文掌握Linux性能分析之IO篇","date":"2018-05-24T05:16:14.000Z","updated":"2019-04-11T14:38:24.065Z","comments":true,"path":"2018/05/24/tech/一文掌握Linux性能分析之IO篇/","link":"","permalink":"https://chambai.github.io/2018/05/24/tech/一文掌握Linux性能分析之IO篇/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 这是 Linux 性能分析系列的第三篇。 IO 和 存储密切相关，存储可以概括为磁盘，内存，缓存，三者读写的性能差距非常大，磁盘读写是毫秒级的（一般 0.1-10ms），内存读写是微妙级的（一般 0.1-10us），cache 是纳秒级的（一般 1-10ns）。但这也是牺牲其他特性为代价的，速度快的，价格越贵，容量也越小。 IO 性能这块，我们更多关注的是读写磁盘的性能。首先，先了解下磁盘的基本信息。 磁盘基本信息 fdisk查看磁盘信息，包括磁盘容量，扇区大小，IO 大小等信息，常用 fdisk -l查看： 可以看到 /dev/ 下有一个 40G 的硬盘，一共 8K 多万个扇区，每个扇区 512字节，IO 大小也是 512 字节。 df查看磁盘使用情况，通常看磁盘使用率： 磁盘性能分析 主要分析磁盘的读写效率（IOPS：每秒读写的次数；吞吐量：每秒读写的数据量），IO 繁忙程度，及 IO 访问对 CPU 的消耗等性能指标。 vmstat第一个较为常用的还是这个万能的 vmstat： 对于 IO，我们常关注三个部分： b 值：表示因为 IO 阻塞排队的任务数 bi 和 bo 值：表示每秒读写磁盘的块数，bi（block in）是写磁盘，bo（block out）是读磁盘。 wa 值：表示因为 IO 等待（wait）而消耗的 CPU 比例。 一般这几个值偏大，都意味着系统 IO 的消耗较大，对于读请求较大的服务器，b、bo、wa 的值偏大，而写请求较大的服务器，b、bi、wa 的值偏大。 iostatvmstat 虽然万能，但是它分析的东西有限，iostat 是专业分析 IO 性能的工具，可以方便查看 CPU、网卡、tty 设备、磁盘、CD-ROM 等等设备的信息，非常强大，总结下来，共有以下几种用法： 1）iostat -c 查看部分 CPU 使用情况： 这里显示的是多个 CPU 的平均值，每个字段的含义我就不多解释了，我一般会重点关注 %iowait 和 %idle，分别表示 CPU 等待 IO 完成时间的百分比和 CPU 空闲时间百分比。 如果 %iowait 较高，则表明磁盘存在 IO 瓶颈，如果 %idle 较高，则 CPU 比较空闲，如果两个值都比较高，则有可能 CPU 在等待分配内存，瓶颈在内存，此时应该加大内存，如果 %idle 较低，则此时瓶颈在 CPU，应该增加 CPU 资源。 2）iostat -d 查看磁盘使用情况，主要是显示 IOPS 和吞吐量信息（-k : 以 KB 为单位显示，-m：以 M 为单位显示）： 其中，几个参数分别解释如下： tps：设备每秒的传输次数（transfers per second），也就是读写次数。 kB_read/s 和 kB_wrtn/s：每秒读写磁盘的数据量。 kB_read 和 kB_wrtn：读取磁盘的数据总量。 3）iostat -x 查看磁盘详细信息： 其中，几个参数解释如下； rrqm/s 和 wrqm/s：分别每秒进行合并的读操作数和写操作数，这是什么意思呢，合并就是说把多次 IO 请求合并成少量的几次，这样可以减小 IO 开销，buffer 存在的意义就是为了解决这个问题的。 r/s 和 w/s：每秒磁盘读写的次数。这两个值相加就是 tps。 rkB/s 和 wkB/s：每秒磁盘读写的数据量，这两个值和上面的 kB_read/s、kB_wrnt/s 是一样的。 avgrq-sz：平均每次读写磁盘扇区的大小。 avgqu-sze：平均 IO 队列长度。队列长度越短越好。 await：平均每次磁盘读写的等待时间（ms）。 svctm：平均每次磁盘读写的服务时间（ms）。 %util：一秒钟有百分之多少的时间用于磁盘读写操作。 以上这些参数太多了，我们并不需要每个都关注，可以重点关注两个： a. %util：衡量 IO 的繁忙程度 这个值越大，说明产生的 IO 请求较多，IO 压力较大，我们可以结合 %idle 参数来看，如果 %idle &lt; 70% 就说明 IO 比较繁忙了。也可以结合 vmstat 的 b 参数（等待 IO 的进程数）和 wa 参数（IO 等待所占 CPU 时间百分比）来看，如果 wa &gt; 30% 也说明 IO 较为繁忙。 b. await：衡量 IO 的响应速度 通俗理解，await 就像我们去医院看病排队等待的时间，这个值和医生的服务速度（svctm）和你前面排队的人数（avgqu-size）有关。如果 svctm 和 await 接近，说明磁盘 IO 响应时间较快，排队较少，如果 await 远大于 svctm，说明此时队列太长，响应较慢，这时可以考虑换性能更好的磁盘或升级 CPU。 4）iostat 1 2 默认显示 cpu 和 吞吐量信息，1 定时 1s 显示，2 显示 2 条信息 进程 IO 性能分析 有了以上两个命令，基本上能对磁盘 IO 的信息有个全方位的了解了。但如果要确定具体哪个进程的 IO 开销较大，这就得借助另外的工具了。 iotop这个命令类似 top，可以显示每个进程的 IO 情况，有了这个命令，就可以定位具体哪个进程的 IO 开销比较大了。 总结 OK，最后还是总结下，fdisk -l 和 df 查看磁盘基本信息，iostat -d 查看磁盘 IOPS 和吞吐量，iostat -x 结合 vmstat 查看磁盘的繁忙程度和处理效率。 下文我们将探讨网络方面的的性能分析问题。 Reference：1.linux 性能分析：http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/iostat.html linux 性能分析工具总结：http://rdc.hundsun.com/portal/article/731.html PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"性能分析","slug":"性能分析","permalink":"https://chambai.github.io/tags/性能分析/"},{"name":"I/O","slug":"I-O","permalink":"https://chambai.github.io/tags/I-O/"}]},{"title":"一文掌握 Linux 性能分析之内存篇","slug":"tech/一文掌握Linux性能分析之内存篇","date":"2018-05-18T05:16:14.000Z","updated":"2019-04-11T14:38:24.060Z","comments":true,"path":"2018/05/18/tech/一文掌握Linux性能分析之内存篇/","link":"","permalink":"https://chambai.github.io/2018/05/18/tech/一文掌握Linux性能分析之内存篇/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 内存信息 同样在分析内存之前，我们得知到怎么查看系统内存信息，有以下几种方法。 /proc/meminfo这个文件记录着比较详细的内存配置信息，使用 cat /proc/meminfo 查看。 我们比较关心的是下面几个字段： MemTotal：系统总内存，由于 BIOS、内核等会占用一些内存，所以这里和配置声称的内存会有一些出入，比如我这里配置有 2G，但其实只有 1.95G 可用。 MemFree：系统空闲内存。 MemAvailable：应用程序可用内存。有人会比较奇怪和 MemFree 的区别，可以从两个层面来区分，MemFree 是系统层面的，而 MemAvailable 是应用程序层面的。系统中有些内存虽然被使用了但是有一部分是可以回收的，比如 Buffers、Cached 及 Slab 这些内存，这部分可以回收的内存加上 MemFree 才是 MemAvailable 的内存值，这是内核通过特定算法算出来的，是一个估算值。 Buffers：缓冲区内存 Cached：缓存 上面信息没有 MemUsed 的值，虽然可以用现有的值大致估算出来，但是我们想一步到位，就用下面的 free 命令。 free这个命令估计用的人就多了（我一般都是用这个命令）。 这里存在一个计算公式： MemTotal = used + free + buff/cache（单位 K） 几个字段和上面 /proc/meminfo 的字段是对应的。还有个 shared 字段，这个是多进程的共享内存空间，不常用。 我们注意到 free 很小，buff/cache 却很大，这是 Linux 的内存设计决定的，Linux 的想法是内存闲着反正也是闲着，不如拿出来做系统缓存和缓冲区，提高数据读写的速率。但是当系统内存不足时，buff/cache 会让出部分来，非常灵活的操作。 要看比较直观的值，可以加 -h 参数： dmidecode同样可以使用这个命令，对于内存，可以使用 dmidecode -t memory 查看： vmstat这个命令也是非常常用了。但对于内存，显示信息有限。它更多是用于进行系统全局分析和 CPU 分析。详细可以看 CPU 分析一文。 进程内存使用情况分析 最常用的两个命令 ps 和 top，虽然很简单的两个命令，但还是有不少学问的。 top/htoptop 命令运行时默认是按照 CPU 利用率进行排序的，如果要按照内存排序，该怎么操作呢？两种方法，一种直接按 “M”（相应的按 “P” 是 CPU），另外一种是在键入 top 之后，按下 “F”，然后选择要排序的字段，再按下 “s” 确认即可。 可以看到，我按照 “%MEM” 排序的结果。这个结果对于查看系统占用内存较多的哪些进程是比较有用的。 然后这里我们会重点关注几个地方，上面横排区，和前面几个命令一样可以查看系统内存信息，中间标注的横条部分，和内存相关的有三个字段：VIRT、RES、SHR。 VIRT：virtual memory usage，进程占用的虚拟内存大小。 RES：resident memory usage，进程常驻内存大小，也就是实际内存占用情况，一般我们看进程占用了多少内存，就是看的这个值。 SHR：shared memory，共享内存大小，不常用。 psps 同样可以查看进程占用内存情况，一般常用来查看 Top n 进程占用内存情况，如： ps aux --sort=rss | head -n，表示按 rss 排序，取 Top n。 这里也关注三个字段： %MEM：进程使用物理内存所占百分比。 VSZ：进程使用虚拟内存大小。 RSS：进程使用物理内存大小，我们会重点关注这个值。 pmap这个命令用于查看进程的内存映像信息，能够查看进程在哪些地方用了多少内存。常用 pmap -x pid 来查看。 可以看到该进程内存被哪些库、哪些文件所占用，据此我们定位程序对内存的使用。 几个字段介绍一下： Address：占用内存的文件的内存起始地址。 Kbytes：占用内存的字节数。 RSS：实际占用内存大小。 Dirty：脏页大小。 Mapping：占用内存的文件，[anon] 为已分配的内存，[stack] 为程序堆栈 最后的 total 为统计的总值。我们可以使用 pmap -x pid | tail -1 这样只显示最后一行，循环显示最后一行，达到监控该进程的目的。使用：while true; do pmap -x pid | tail -1; sleep 1; done OK，以上工具都是 Linux 自带的，当然还有很多高阶的工具，比如 atop、memstat 等等，对于内存泄漏有一个比较常用的检测工具 Valgrind，这些等之后再找时间跟大家分享了。 通过以上手段，我们基本上就能定位内存问题所在了，究竟是内存太小，还是进程占用内存太多，有哪些进程占用较多，这些进程又究竟有哪些地方占用较多，这些问题通过以上方法都能解决。 最后简单总结下，以上不少工具可能有人会犯选择困难症了。对于我来说，查看系统内存用 free -h，分析进程内存占用用 ps 或者 top（首选 ps），深入分析选择 pmap，就酱。 Reference：1.Linux下查看内存使用情况的多种方法：http://stor.51cto.com/art/201804/570236.htm PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"性能分析","slug":"性能分析","permalink":"https://chambai.github.io/tags/性能分析/"},{"name":"内存","slug":"内存","permalink":"https://chambai.github.io/tags/内存/"}]},{"title":"CPU 拓扑：从 SMP 谈到 NUMA （理论篇）","slug":"tech/CPU拓扑：从SMP谈到NUMA（实践篇）","date":"2018-05-10T05:16:14.000Z","updated":"2019-04-11T14:38:24.086Z","comments":true,"path":"2018/05/10/tech/CPU拓扑：从SMP谈到NUMA（实践篇）/","link":"","permalink":"https://chambai.github.io/2018/05/10/tech/CPU拓扑：从SMP谈到NUMA（实践篇）/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 本文的一些概念依赖于上一篇 “CPU 拓扑：从 SMP 谈到 NUMA （理论篇）”，如果你对这块还没有概念，建议看完那篇再来看，如果对这块有自己独到的见解，欢迎探讨。 本文主要会侧重 NUMA 这块，我会通过自己的环境验证 NUMA 的几个概念，以便对 NUMA 的架构有个较深的印象。 NUMA 的几个概念：Node，Socket，Core，Thread NUMA 技术的主要思想是将 CPU 进行分组，Node 即是分组的抽象，一个 Node 表示一个分组，一个分组可以由多个 CPU 组成。每个 Node 都有自己的本地资源，包括内存、IO 等。每个 Node 之间通过互联模块（QPI）进行通信，因此每个 Node 除了可以访问自己的本地内存之外，还可以访问远端 Node 的内存，只不过性能会差一些，一般用 distance 这个抽象的概念来表示各个 Node 之间互访资源的开销。 Node 是一个逻辑上的概念，与之相对的 Socket，是物理上的概念。它表示一颗物理 CPU 的封装，是主板上的 CPU 插槽，所以，一般就称之为插槽（敲黑板，这 Y 不是套接字吗？emmm……） Core 就是 Socket 里独立的一组程序执行单元，称之为物理核。有了物理核，自然就有逻辑核，Thread 就是逻辑核。更专业的说法应该称之为超线程。 超线程是为了进一步提高 CPU 的处理能力，Intel 提出的新型技术。它能够将一个 Core 从逻辑上划分成多个逻辑核（一般是两个），每个逻辑核有独立的寄存器和中断逻辑，但是一个 Core 上的多个逻辑核共享 Core 内的执行单元和 Cache，频繁调度可能会引起资源竞争，影响性能。超线程必须要 CPU 支持才能开启。 综上所述，一个 NUMA Node 可以有一个或者多个 Socket，每个 Socket 也可以有一个（单核）或者多个（多核）Core，一个 Core 如果打开超线程，则会变成两个逻辑核（Logical Processor，简称 Processor）。 所以，几个概念从大到小排序依次是： Node &gt; Socket &gt; Core &gt; Processor。 验证 CPU 拓扑 了解了以上基本概念，下面在实际环境中查看这些概念并验证。 Node用 numactl --hardware 查看当前系统的 NUMA Node（numactl 是设定进程 NUMA 策略的命令行工具）：123456789101112Linux # numactl --hardwareavailable: 2 nodes (0-1)node 0 cpus: 0 1 2 3 4 5 12 13 14 15 16 17node 0 size: 49043 MBnode 0 free: 20781 MBnode 1 cpus: 6 7 8 9 10 11 18 19 20 21 22 23node 1 size: 49152 MBnode 1 free: 31014 MBnode distances:node 0 1 0: 10 21 1: 21 10 可以得出的信息有：1）系统的 Node 数为 2；2）每个 Node 包含的 Processor 数为 12；3）每个 Node 的总内存大小和空闲内存大小；4）每个 Node 之间的 distance。 还可以查看 /sys/devices/system/node/ 目录，这里记录着具体哪些 Node。 Socket/proc/cpuinfo 中记录着 Socket 信息，用 “physical id” 表示，可以用 cat /proc/cpuinfo | grep &quot;physical id&quot; 查看： 123456789Linux # cat /proc/cpuinfo | grep &quot;physical id&quot;physical id : 0physical id : 0physical id : 0physical id : 0physical id : 1physical id : 1physical id : 1physical id : 1 可以看到有 2 个 Socket，我们还可以查看以下这几种变种： 1）查看有几个 Socket1234Linux # grep &apos;physical id&apos; /proc/cpuinfo | awk -F: &apos;&#123;print $2 | &quot;sort -un&quot;&#125;&apos;01 123Linux # grep &apos;physical id&apos; /proc/cpuinfo | awk -F: &apos;&#123;print $2 | &quot;sort -un&quot;&#125;&apos; | wc -l2 2）查看每个 Socket 有几个 Processor1234Linux # grep &apos;physical id&apos; /proc/cpuinfo | awk -F: &apos;&#123;print $2&#125;&apos; | sort | uniq -c12 012 1 3）查看每个 Socket 有哪几个 Processor123456789101112131415161718Linux # awk -F: &apos;&#123; &gt; if ($1 ~ /processor/) &#123;&gt; gsub(/ /,&quot;&quot;,$2);&gt; p_id=$2;&gt; &#125; else if ($1 ~ /physical id/)&#123;&gt; gsub(/ /,&quot;&quot;,$2);&gt; s_id=$2;&gt; arr[s_id]=arr[s_id] &quot; &quot; p_id&gt; &#125;&gt; &#125; &gt; &gt; END&#123;&gt; for (i in arr) &gt; print arr[i];&gt; &#125;&apos; /proc/cpuinfo | cut -c2-0 1 2 3 4 5 12 13 14 15 16 176 7 8 9 10 11 18 19 20 21 22 23 Core同样在 /proc/cpuinfo 中查看 Core 信息： 1234567Linux # cat /proc/cpuinfo |grep &quot;core id&quot; | sort -ucore id : 0core id : 1core id : 2core id : 3core id : 4core id : 5 上面的结果表明一个 Socket 有 5 个 Core。上面查到有 2 个 Socket，则一共就有 10 个 Core。 Processor上面查看 Socket 信息时已经能够得到 Processor 的信息，总共有 24 个 Processor，不过也可以直接从 /proc/cpuinfo 中获取： 1）获取总的 Processor 数，查看 “processor” 字段：123Linux # cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l24 2）获取每个 Socket 的 Processor 数，查看 “siblings” 字段：123Linux # cat /proc/cpuinfo | grep &quot;siblings&quot; | sort -u12 CacheCache 也一样通过 /proc/cpuinfo 查看：12345processor : 0cache size : 15360 KBcache_alignment : 64 不过这里的值 cache size 比较粗略，我们并不知道这个值是哪一级的 Cache 值（L1？L2？L3？），这种方法不能确定，我们换一种方法。 其实详细的 Cache 信息可以通过 sysfs 查看，如下： 比如查看 cpu0 的 cache 情况：123Linux # ls /sys/devices/system/cpu/cpu0/cache/index0/ index1/ index2/ index3/ 其中包含四个目录：index0 存 L1 数据 Cache，index1 存 L1 指令 Cache，index2 存 L2 Cache，index3 存 L3 Cache。每个目录里面包含一堆描述 Cache 信息的文件。我们选 index0 具体看下： 其中，shared_cpu_list 和 shared_cpu_map 表示意思是一样的，都表示该 cache 被哪几个 processor 共享。对 shared_cpu_map 具体解释一下。 这个值表面上看是二进制，但其实是 16 进制，每个数字有 4 个bit，代表 4 个 cpu。比如上面的 001001 拆开后是：10000 0000 0001 0000 0000 0001，1 bit 处即对应 cpu 标号，即 cpu0 和 cpu12。 同样我们可以对其他 index 进行统计，可以得出：/proc/cpuinfo 中的 cache size 对应的 L3 Cache size。 最后，综合以上所有信息我们可以绘制出一下的 CPU 拓扑图： 我们发现以上命令用得不太顺手，要获取多个数据需要输入多条命令，能不能一条命令就搞定，当然是有的，lscpu 就可以做到，如下：1234567891011121314151617181920212223Linux # lscpu Architecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 24 //共有24个逻辑CPU（threads）On-line CPU(s) list: 0-23Thread(s) per core: 2 //每个 Core 有 2 个 ThreadsCore(s) per socket: 12 //每个 Socket 有 12 个 ThreadsSocket(s): 2 //共有 2 个 SocketsNUMA node(s): 2 //共有 2 个 NodesVendor ID: GenuineIntelCPU family: 6Model: 63Stepping: 2CPU MHz: 2401.000BogoMIPS: 4803.16Virtualization: VT-xL1d cache: 32K //L1 data cache 32kL1 cache: 32K //L1 instruction cache 32k L2 cache: 256K //L2 instruction cache 256kL3 cache: 15360K //L3 instruction cache 15MNUMA node0 CPU(s): 0-5,12-17NUMA node1 CPU(s): 6-11,18-23 当然了，没有完美的命令，lscpu 也只能显示一些宽泛的信息，只是相对比较全面而已，更详细的信息，比如 Core 和 Cache 信息就得借助 cpuinfo 和 sysfs 了。 下面给大家提供一个脚本，能够比较直观的显示以上所有信息，有 shell 版的和 python 版的（不是我写的，文末附上了引用出处）。 大家有需要可以回复 “CPU” 获取，我就不贴出来了，显示的结果大概就是长下面这个样子： python 版：123456789101112131415161718192021222324============================================================Core and Socket Information (as reported by &apos;/proc/cpuinfo&apos;)============================================================cores = [0, 1, 2, 3, 4, 5]sockets = [0, 1]Socket 0 Socket 1 -------- -------- Core 0 [0, 12] [6, 18] Core 1 [1, 13] [7, 19] Core 2 [2, 14] [8, 20] Core 3 [3, 15] [9, 21] Core 4 [4, 16] [10, 22] Core 5 [5, 17] [11, 23] Reference： 玩转 CPU 拓扑：http://blog.itpub.net/645199/viewspace-1421876/ NUMA 体系结构详解https://blog.csdn.net/ustc_dylan/article/details/45667227（shell 代码引用） dpdk 源代码（python 代码引用） PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"https://chambai.github.io/tags/CPU/"},{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"NUMA","slug":"NUMA","permalink":"https://chambai.github.io/tags/NUMA/"}]},{"title":"CPU 拓扑：从 SMP 谈到 NUMA （理论篇）","slug":"tech/CPU拓扑从SMP谈到NUMA（理论篇）","date":"2018-05-03T05:16:14.000Z","updated":"2019-04-11T14:38:24.075Z","comments":true,"path":"2018/05/03/tech/CPU拓扑从SMP谈到NUMA（理论篇）/","link":"","permalink":"https://chambai.github.io/2018/05/03/tech/CPU拓扑从SMP谈到NUMA（理论篇）/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 随着计算机技术（特别是以芯片为主的硬件技术）的快速发展，CPU 架构逐步从以前的单核时代进阶到如今的多核时代，在多核时代里，多颗 CPU 核心构成了一个小型的“微观世界”。每颗 CPU 各司其职，并与其他 CPU 交互，共同支撑起了一个“物理世界”。从这个意义上来看，我们更愿意称这样的“微观世界”为 CPU 拓扑，就像一个物理网络一样，各个网络节点通过拓扑关系建立起连接来支撑起整个通信系统。 单核 or 多核 or 多 CPU or 超线程 ? 在单核时代，为了提升 CPU 的处理能力，普遍的做法是提高 CPU 的主频率，但一味地提高频率对于 CPU 的功耗也是影响很大的（CPU 的功耗正比于主频的三次方）。 另外一种做法是提高 IPC （每个时钟周期内执行的指令条数），这种做法要么是提高指令的并行度，要么是增加核数。显然，后一种方法更具有可扩展性，这也是摩尔定律的必然性。 CPU 的性能到底是如何体现的呢？为了弄清楚这个问题，我们结合单核 CPU 和多核 CPU 的结构来进一步剖析。 首先，对于一个单核结构，即一颗物理 CPU 封装里只集成了一个物理核心，其主要组件可以简化为：CPU 寄存器集合、中断逻辑、执行单元和 Cache，如下图： 对于一个多线程程序，主要通过时间片轮转的方式来获得 CPU 的执行权，从内部来看，这其实是串行执行的，性能自然并不怎么高。 其次，对于多核结构，则是在一颗物理 CPU 封装里集成了多个对等的物理核心，所谓对等，就是每个核心都有相同的内部结构。多个核心之间通过芯片内部总线来完成通信。随着 CPU 制造工艺的提升，每颗 CPU 封装中集成的物理核心也在不断提高。 对于一个多线程程序，这种情况能够实现真正的并发，但线程在不同核之间切换会存在一定的开销，但由于走的是芯片内部总线，开销相对会比较小。 除了上述两种结构，还有另外一种结构是多 CPU 结构，也就是多颗单独封装的 CPU 通过外部总线相连，构成的一个统一的计算平台。每个 CPU 都需要独立的电路支持，有自己的 Cache。它们之间的通信通过主板上的总线来完成。 同样对于一个多线程程序，不同于上一种情况的是，线程间的切换走的是外部总线，延迟较大，开销自然较大，而且对于有共享的数据还会因 Cache 一致性带来一定的开销（关于 Cache 下一小节说明）。 上述结构，一个 CPU 核心同一时间内只能执行一个线程，效率低下，为了提高 CPU 的利用率，CPU 芯片厂商又推出超线程（Hyper-Thread-ing）技术，即让一个物理核心同时执行多个线程，使整体性能得到提升。虽然物理上只有一个核心，但逻辑上被划分了多个逻辑核心，它们之间是完全隔离的。 对于每个逻辑核心，拥有完整独立的寄存器集合和中断逻辑，共享执行单元和 Cache。由于是共享执行单元，所以对高 IPC 的应用，其性能提升有限。 Cache Cache 是一种 SRAM （Static Random Access Memory，静态访问随机存储器）。出于成本和生产工艺考虑，一般将 Cache 分为三级。一级（L1）访问速度最快，但是容量最小，一般只有几十 KB；二级（L2）次之，一般有几百 KB 到几 MB 不等，三级（LLC，Last Level Cache）最慢，但是容量也最大，一般有几 MB 到几十 MB。 一级 Cache 又分为数据 Cache 和指令 Cache，顾名思义，数据 Cache 用来存数据，指令 Cache 用来存指令。下图是一个简单的 Cache 系统逻辑示意图。 在多核结构中，每个物理核心都拥有独立的一级 Cache 和二级 Cache，而三级 Cache 是所有核心共享。这种共享需要解决的一个问题是公平地为每个核心分配 Cache 大小，避免 Cache 命中率低的问题。 对于现代计算机系统，说到 Cache，不得不提 TLB（Translation Look-aside Buffer） Cache。简单理解，如果说 Cache 存放的是内存中的内容，那么 TLB Cache 存放的是页表项。 为什么页表项需要用 Cache 存，原因当然是快。你可能觉得用三级 Cache 存就行了，为什么还要专门上 TLB Cache。 这里有两点考虑，一点是 TLB 采用基于内容的访问存储器 CAM，这种存储器能做到根据虚拟地址查询直接返回物理地址，效率极高，不需要像传统方式那样采用多级页表查询。另外一点是 Cache 的“淘汰”机制决定，Cache 会根据算法淘汰掉那些不常使用的内容，这对于页表这种需要频繁访问（每次程序寻址都要访问页表）的特性显然是矛盾的，所以就需要专门为页表提供一种特殊的 Cache，即 TLB Cache。 SMP or NUMA or MPP? 如果说前面咱们讨论的是 CPU 内部的“微观世界”，那么本节将跳出来，探讨一个系统级的“宏观世界”。 首先是 SMP，对称多处理器系统，指的是一种多个 CPU 处理器共享资源的电脑硬件架构，其中，每个 CPU 没有主从之分，地位平等，它们共享相同的物理资源，包括总线、内存、IO、操作系统等。每个 CPU 访问内存所用时间都是相同的，因此这种系统也被称为一致存储访问结构（UMA，Uniform Memory Access）。 这种系统由于共享资源，不可避免地要加锁来解决资源竞争的问题，带来一定的性能开销，另外，扩展能力还非常有限，实验证明，SMP 系统最好的情况是有 2-4 个 CPU，适用于 PC、笔记本电脑和小型服务器等。 tips: 查看系统是否是 SMP 结构：1ls /sys/devices/system/node/ # 如果只看到一个 node0 那就是 SMP 架构 为了应对大规模的系统要求（特别是云计算环境），就研制出了 NUMA 结构，即非一致存储访问结构。 这种结构引入了 CPU 分组的概念，用 Node 来表示，一个 Node 可能包含多个物理 CPU 封装，从而包含多个 CPU 物理核心。每个 Node 有自己独立的资源，包括内存、IO 等。每个 Node 之间可以通过互联模块总线（QPI）进行通信，所以，也就意味着每个 Node 上的 CPU 都可以访问到整个系统中的所有内存，但很显然，访问远端 Node 的内存比访问本地内存要耗时很多，这也是 NUMA 架构的问题所在，我们在基于 NUMA 架构开发上层应用程序要尽可能避免跨 Node 内存访问。 NUMA 架构在 SMP 架构的基础上通过分组的方式增强了可扩展性，但从性能上看，随着 CPU 数量的增加，并不能线性增加系统性能，原因就在于跨 Node 内存访问的问题。所以，一般 NUMA 架构最多支持几百个 CPU 就不错了。 但对于很多大型计算密集型的系统来说，NUMA 显然有些吃力，所以，后来又出现了 MPP 架构，即海量并行处理架构。这种架构也有分组的概念，但和 NUMA 不同的是，它不存在异地内存访问的问题，每个分组内的 CPU 都有自己本地的内存、IO，并且不与其他 CPU 共享，是一种完全无共享的架构，因此它的扩展性最好，可以支持多达数千个 CPU 的量级。 总结 1、在芯片技术已然发展成熟的今天，性能低，上核不是问题，但上核就一定能提高性能吗，另外上核怎么很好地利用多核来完成自身进化，这些问题都值得深思。 2、NUMA 架构算是多核时代应用较大的一种 CPU 架构，本文从核心谈到系统，让大家有个全面的了解，下文会特别针对 NUMA 架构做一些实验验证。 Reference：1.《深入浅出 DPDK》 SMP、NUMA、MPP体系结构介绍：https://www.cnblogs.com/yubo/archive/2010/04/23/1718810.html PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"https://chambai.github.io/tags/CPU/"},{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"NUMA","slug":"NUMA","permalink":"https://chambai.github.io/tags/NUMA/"}]},{"title":"一文掌握 Linux 性能分析之 CPU 篇","slug":"tech/一文掌握Linux性能分析之CPU篇","date":"2018-04-26T05:16:14.000Z","updated":"2019-04-11T14:38:24.061Z","comments":true,"path":"2018/04/26/tech/一文掌握Linux性能分析之CPU篇/","link":"","permalink":"https://chambai.github.io/2018/04/26/tech/一文掌握Linux性能分析之CPU篇/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 平常工作会涉及到一些 Linux 性能分析的问题，因此决定总结一下常用的一些性能分析手段，仅供参考。 说到性能分析，基本上就是 CPU、内存、磁盘 IO 以及网络这几个部分，本文先来看 CPU 这个部分。 1 CPU 基础信息 进行性能分析之前，首先得知道 CPU 有哪些信息，可以通过以下方法查看 CPU 配置信息。 lscpu在 Linux 下，类似 lsxxx 这样的命令都是用来查看基本信息的，如 ls 查看当前目录文件信息，lscpu 就用来查看 CPU 信息，类似还有 lspci 查看 PCI 信息。 可以看到我的机器配置很低，1 核 2.5GHz（在阿里云买的最低配的服务器）。 /proc/cpuinfo/proc 目录是内核透传出来给用户态使用的，里面记录着很多信息文件，比如还有内存文件 meminfo 等。可以使用 cat /proc/cpuinfo 查看 CPU 信息。 这里显示的信息可以具体到每个逻辑核上，由于我只有一个核，所以只显示一组信息。 dmidecode这个命令是用来获取 DMI（Desktop Management Interface）硬件信息的，包括 BIOS、系统、主板、处理器、内存、缓存等等。对于 CPU 信息，可以使用 dmidecode -t processor 来查看。 2 CPU 使用情况分析 知道了 CPU 的基本信息，我们就可以使用另外的命令来对 CPU 的使用情况分析一通了。 top相信大家对下面这玩意不陌生，Windows 的任务管理器，top 的作用和它是一样的。 top 显示的效果虽说不像它这么华丽，但已然让人惊呼他俩怎么长得这么像。 我们重点关注这么几个字段： load average：三个数字分别表示最近 1 分钟，5 分钟和 15 分钟的负责，数值越大负载越重。一般要求不超过核数，比如对于单核情况要 &lt; 1。如果机器长期处于高于核数的情况，说明机器 CPU 消耗严重了。 %Cpu(s)：表示当前 CPU 的使用情况，如果要查看所有核（逻辑核）的使用情况，可以按下数字 “1” 查看。这里有几个参数，表示如下： 12345678- us 用户空间占用 CPU 时间比例- sy 系统占用 CPU 时间比例- ni 用户空间改变过优先级的进程占用 CPU 时间比例- id CPU 空闲时间比- wa IO等待时间比（IO等待高时，可能是磁盘性能有问题了）- hi 硬件中断- si 软件中断- st steal time 每个进程的使用情况：这里可以罗列每个进程的使用情况，包括内存和 CPU 的，如果要看某个具体的进程，可以使用 top -p pid 查看。 和 top 一样的还有一个改进版的工具：htop，功能和 top 一样的，只不过比 top 表现更炫酷，使用更方便，可以看下它的效果。 ps可能很多人会忽略这个命令，觉得这不是查看进程状态信息的吗，其实非也，这个命令配合它的参数能显示很多功能。比如 ps aux。如果配合 watch，可以达到跟 top 一样的效果，如：watch -n 1 &quot;ps aux&quot;（-n 1 表示每隔 1s 更新一次） vmstat这个命令基本能看出当前机器的运行状态和问题，非常强大。可以使用 vmstat n 后面跟一个数字，表示每隔 ns 显示系统的状态，信息包括 CPU、内存和 IO 等。 几个关键的字段： r 值：表示在 CPU 运行队列中等待的进程数，如果这个值很大，表示很多进程在排队等待执行，CPU 压力山大。 in 和 cs 值：表示中断次数和上下文切换次数，这两个值越大，表示系统在进行大量的进程（或线程）切换。切换的开销是非常大的，这时候应该减少系统进程（或线程）数。 us、sy、id、wa 值：这些值上面也提到过，分别表示用户空间进程，系统进程，空闲和 IO 等待的 CPU 占比，这里只有 id 很高是好的，表示系统比较闲，其他值飚高都不好。 这个工具强大之处在于它不仅可以分析 CPU，还可以分析内存、IO 等信息，犹如瑞士军刀。 dstat这个命令也很强大，能显示 CPU 使用情况，磁盘 IO 情况，网络发包情况和换页情况，而且输出是彩色的，可读性比较强，相对于 vmstat 更加详细和直观。使用时可以直接输入命令，也可以带相关参数。 3 进程使用 CPU 情况分析 上面说的是系统级的分析，现在来看单个进程的 CPU 使用情况分析，以便于我们能对占用 CPU 过多的进程进行调试和分析，优化程序性能。 其实前面 top 和 ps 这样的命令就可以看每个进程的 CPU 使用情况，但我们需要更专业的命令。 pidstat这个命令默认统计系统信息，也包括 CPU、内存和 IO 等，我们常用 pidstat -u -p pid [times] 来显示 CPU 统计信息。如下统计 pid = 802 的 CPU 信息。 strace这个命令用来分析进程的系统调用情况，可以看进程都调用了哪些库和哪些系统调用，进而可以进一步优化程序。比如我们分析 ls 的系统调用情况，就可以用 strace ls： 可以看到，一个简单的 ls 命令，其实有不少系统调用的操作。 此外，还可以 attach（附着）到一个正在运行的进程上进行分析，比如我 attach 到 802 这个进程显示： 根据这些输出信息，其实就能够很好地帮我们分析问题，从而定位到问题所在了。 OK，以上就是平常比较常用的一些工具，当然除了这些，还有很多很多工具，下面放一张图，来自 Linux 大牛，Netflix 高级性能架构师 Brendan Gregg。看完了，你也许会感叹“这世界太疯狂了（just crazy）”。 Reference：[1]. http://rdc.hundsun.com/portal/article/731.html PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"https://chambai.github.io/tags/CPU/"},{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"性能分析","slug":"性能分析","permalink":"https://chambai.github.io/tags/性能分析/"}]},{"title":"各种容器网络方案对比","slug":"tech/各种容器网络方案对比","date":"2018-04-20T05:16:14.000Z","updated":"2019-04-11T14:38:24.068Z","comments":true,"path":"2018/04/20/tech/各种容器网络方案对比/","link":"","permalink":"https://chambai.github.io/2018/04/20/tech/各种容器网络方案对比/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 前面单主机容器网络和多主机容器网络两篇文章，咱们已经从原理上总结了多种容器网络方案，也通过这篇文章探讨了容器网络的背后原理。本文再基于一个宏观的视角，对比几种网络方案，让大家有个完整的认识。 单主机网络就不多说了，因为也比较简单，我们重点对比几种多主机网络方案。 对比的维度有以下几种：网络模型，IP 地址池管理（IP Address Management，IPAM），服务发现，连通与隔离，性能。 网络模型指的是构成跨主机通信的网络结构和实现技术，比如是纯二层转发，还是纯三层转发；是 overlay 网络还是 underlay 网络等等。 IPAM 指的是如何管理容器网络的 IP 池。当容器集群比较大，管理的主机比较多的时候，如何分配各个主机上容器的 IP 是一个比较棘手的问题。Docker 网络有个 subnet 的概念，通常一个主机分配一个 subnet，但也有多个主机共用一个 subnet 的情况，具体的网络方案有不同的考量。具体看下面的表格总结。 服务发现本质上是一个分布式的 key-value 存储系统，用于跨主机通信时保存并同步各主机的网络信息，便于快速建立起各主机之间的网络连接。由于各网络方案实现上各有千秋，并不是所有的跨主机网络方案都要依据服务发现。 连通与隔离指的是容器跨主机之间是否能够互相通信，以及容器与外网（外网不一定指 Internet）之间如何通信。 性能具体指的是通信的时延，我们仅从各个网络方案的原理上来分析得出结论，所以这里的结论并不一定正确，因为不同的部署环境会对性能有一些影响，建议大家还是根据自己的环境动手实验验证为妙。 从原理上说，underlay 网络性能要优于 overlay 网络，因为 overlay 网络存在封包和拆包操作，存在额外的 CPU 和网络开销，所以，几种方案中，macvlan、flannel host-gw、calico 的性能会优于 overlay、flannel vxlan 和 weave。但是这个也不能作为最终生产环境采用的标准，因为 overlay 网络采用 vxlan 作为隧道的话，能支持更多的二层网段，安全性也更高，所以，需要综合考虑。 通过以上分析，我们可以得出以下的结论： 参考：http://www.cnblogs.com/CloudMan6/p/7587532.html PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/categories/Docker/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"容器","slug":"容器","permalink":"https://chambai.github.io/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"容器网络","slug":"容器网络","permalink":"https://chambai.github.io/tags/容器网络/"}]},{"title":"那么多容器网络的解决方案，其背后的原理到底是什么？","slug":"tech/那么多容器网络的解决方案，其背后的原理到底是什么？","date":"2018-04-18T05:16:14.000Z","updated":"2019-04-11T14:38:24.049Z","comments":true,"path":"2018/04/18/tech/那么多容器网络的解决方案，其背后的原理到底是什么？/","link":"","permalink":"https://chambai.github.io/2018/04/18/tech/那么多容器网络的解决方案，其背后的原理到底是什么？/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 知其然而不知其所以然，不知也。老古人说得多好，学知识不懂得知识背后的原理，等于白学。 通过前面两篇文章，我们知道了容器的单主机网络和多主机网络，对于这么多网络方案，我们看到对 Docker 的整体网络结构好像没有改动，都是水平扩展的，那 Docker 网络究竟是怎么集成这么多网络方案而不改变自身原有的结构呢？本文就来一探究竟。 1 Docker 的总体框架 要回答这个问题，得从 Docker 的总体框架说起。 容器和虚拟机一样，都是虚拟化的产品，都包括计算虚拟化，存储虚拟化和 IO 虚拟化。容器作为轻量级的进程，不像虚拟机那般复杂，这三块分别靠三个 Driver 来完成的，execdriver 负责计算虚拟化，networkdriver 负责网络虚拟化，graphdriver 负责存储虚拟化。由此可见，Docker 靠 Driver 这种设计思想来支撑起它的基础平台，再往深了挖，它的每个子模块都随处可见这种设计思想，就网络这个子模块来看，也是如此。 2 Docker 的网络模型 docker engine + libcontainer 期初的 Docker 网络子模块的代码是分散在 docker daemon 和 libcontainer 中的，libcontainer 是一个独立的容器管理包，execdriver 和 networkdriver 都是通过 libcontainer 来实现对容器的具体操作。 随着业务场景越来越复杂，这种内嵌的方式很难针对不同的网络场景进行扩展。后来，Docker 收购了一个做多主机网络解决方案的公司 SocketPlane，然后让那帮人专门来解决这个问题。这就是接下来要介绍的 libnetwork。 libnetwork &amp;&amp; CNM libnetwork 起初的做法很简单，就是将 docker engine 和 libcontainer 中网络相关的代码抽出来，合并成一个单独的库，做成网络抽象层，并对外提供 API。Docker 的愿景就是希望 libnetwork 能够做像 libcontainer 那样，成为一个多平台的容器网络基础包。 后来受一个 GitHub issue ( https://github.com/moby/moby/issues/9983) 的启发，libnetwork 引入容器网络模型（Container Network Model，CNM），该模型进一步对 Docker 的网络结构进行了细分，提出了三个概念：network、sandbox 和 endpoint。 networknetwork 是一个抽象的概念，你可以把它理解成一个网络的插件，或者是网络的 Driver，比如说单主机网络的 Driver 就有 none、host、bridge，joined container 这四种，多主机网络就有 overlay、macvlan、flannel 这些。network 可以独立出去做，只需调用 Docker 对外提供的 API 就可以作为插件集成到 Docker 网络中使用。 sandboxsandbox 实现了容器内部的网络栈，它定义容器的虚拟网卡，路由表和 DNS 等配置，其实就是一个标准的 linux network namespace 实现。 endpointnetwork 实现了一个第三方的网络栈，sandbox 则实现了容器内部的网络栈，那这两者怎么联系起来呢？答案就是通过 endpoint，endpoint 实现了 veth pair，一个 endpoint 就表示一对 veth pair，一端挂在容器中，另一端挂在 network 中。 network、sandbox 和 endpoint 三者之间的关系：一个 network 可以包含多个 endpoint，自然也就包含多个 sandbox。一个 sandbox 可以包含多个 endpoint，可以属于多个 network。一个 endpoint 只可以属于一个 network，并且只属于一个 sandbox。 如上图显示三个容器，每个容器一个 sandbox，除了第二个容器有两个 endpoint 分别接入 network1 和 network2 之外，其余 sandbox 都只有一个 endpoint 分别接入不同的 network。 到此，我们就可以解答文章开篇提到的问题，“不同的网络方案如何集成到 Docker 网络模型中而不改变原有结构？” 答案就是基于 libnetwork CNM，将各个网络模型以插件或 Driver 的形式集成到 Docker 网络中来，与 docker daemon 协同工作，实现容器网络。Docker 原生的 Driver 包括单主机的 none、bridge、joined container 和 多主机的 overlay、macvlan，第三方 Driver 就包括多主机的 flannel、weave、calico 等。 3 总结 libnetwork 基于 CNM 模型将 Docker 网络结构从原生方案中抽离出来，增强了网络扩展性，以至于现在各种网络方案层出不穷，都可以轻松集成到 Docker 中。 network，sandbox，endpoint 三个概念。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/categories/Docker/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"容器","slug":"容器","permalink":"https://chambai.github.io/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"容器网络","slug":"容器网络","permalink":"https://chambai.github.io/tags/容器网络/"},{"name":"libnetwork","slug":"libnetwork","permalink":"https://chambai.github.io/tags/libnetwork/"},{"name":"CNM","slug":"CNM","permalink":"https://chambai.github.io/tags/CNM/"}]},{"title":"容器网络之多主机网络","slug":"tech/容器网络之多主机网络","date":"2018-04-16T05:16:14.000Z","updated":"2019-04-11T14:38:24.053Z","comments":true,"path":"2018/04/16/tech/容器网络之多主机网络/","link":"","permalink":"https://chambai.github.io/2018/04/16/tech/容器网络之多主机网络/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 上篇文章介绍了容器网络的单主机网络，本文将进一步介绍多主机网络，也就是跨主机的网络。总结下来，多主机网络解决方案包括但不限于以下几种：overlay、macvlan、flannel、weave、cacico 等，下面将分别一一介绍这几种网络， PS：本文仅从原理上对几种网络进行简单的对比总结，不涉及太多的细节。 1 overlay 俗称隧道网络，它是基于 VxLAN 协议来将二层数据包封装到 UDP 中进行传输的，目的是扩展二层网段，因为 VLAN 使用 12bit 标记 VLAN ID，最多支持 4094 个 VLAN，这对于大型云网络会成为瓶颈，而 VxLAN ID 使用 24bit 来标记，支持多达 16777216 个二层网段，所以 VxLAN 是扩展了 VLAN，也叫做大二层网络。 overlay 网络需要一个全局的“上帝”来记录它网络中的信息，比如主机地址，子网等，这个上帝在 Docker 中是由服务发现协议来完成的，服务发现本质上是一个 key-value 数据库，要使用它，首先需要向它告知（注册）一些必要的信息（如网络中需要通信的主机），然后它就会自动去收集、同步网络的信息，同时，还会维护一个 IP 地址池，分配给主机中的容器使用。Docker 中比较有名的服务发现有 Consul、Etcd 和 ZooKeeper。overlay 网络常用 Consul。 创建 overlay 网络会创建一个 Linux bridge br0，br0 会创建两个接口，一个 veth2 作为与容器的虚拟网卡相连的 veth pair，另一个 vxlan1 负责与其他 host 建立 VxLAN 隧道，跨主机的容器就通过这个隧道来进行通信。 为了保证 overlay 网络中的容器与外网互通，Docker 会创建另一个 Linux bridge docker_gwbridge，同样，该 bridge 也存在一对 veth pair，要与外围通信的容器可以通过这对 veth pair 到达 docker_gwbridge，进而通过主机 NAT 访问外网。 2 macvlan macvlan 就如它的名字一样，是一种网卡虚拟化技术，它能够将一个物理网卡虚拟出多个接口，每个接口都可以配置 MAC 地址，同样每个接口也可以配自己的 IP，每个接口就像交换机的端口一样，可以为它划分 VLAN。 macvlan 的做法其实就是将这些虚拟出来的接口与 Docker 容器直连来达到通信的目的。一个 macvlan 网络对应一个接口，不同的 macvlan 网络分配不同的子网，因此，相同的 macvlan 之间可以互相通信，不同的 macvlan 网络之间在二层上不能通信，需要借助三层的路由器才能完成通信，如下，显示的就是两个不同的 macvlan 网络之间的通信流程。 我们用一个 Linux 主机，通过配置其路由表和 iptables，将其配成一个路由器（当然是虚拟的），就可以完成不同 macvlan 网络之间的数据交换，当然用物理路由器也是没毛病的。 3 flannel flannel 网络也需要借助一个全局的上帝来同步网络信息，一般使用的是 etcd。 flannel 网络不会创建新的 bridge，而是用默认的 docker0，但创建 flannel 网络会在主机上创建一个虚拟网卡，挂在 docker0 上，用于跨主机通信。 组件方式让 flannel 多了几分灵活性，它可以使用二层的 VxLAN 隧道来封装数据包完成跨主机通信，也可以使用纯三层的方案来通信，比如 host-gw，只需修改一个配置文件就可以完成转化。 4 weave weave 网络没有借助服务发现协议，也没有 macvlan 那样的虚拟化技术，只需要在不同主机上启动 weave 组件就可以完成通信。 创建 weave 网络会创建两个网桥，一个是 Linux bridge weave，一个是 datapath，也就是 OVS，weave 负责将容器加入 weave 网络中，OVS 负责将跨主机通信的数据包封装成 VxLAN 包进行隧道传输。 同样，weave 网络也不支持与外网通信，Docker 提供 docker0 来满足这个需求。 weave 网络通过组件化的方式使得网络分层比较清晰，两个网桥的分工也比较明确，一个用于跨主机通信，相当于一个路由器，一个负责将本地网络加入 weave 网络。 5 calico calico 是一个纯三层的网络，它没有创建任何的网桥，它之所以能完成跨主机的通信，是因为它记住 etcd 将网络中各网段的路由信息写进了主机中，然后创建的一对的 veth pair，一块留在容器的 network namespace 中，一块成了主机中的虚拟网卡，加入到主机路由表中，从而打通不同主机中的容器通信。 calico 相较其他几个网络方案最大优点是它提供 policy 机制，用户可以根据自己的需求自定义 policy，一个 policy 可能对应一条 ACL，用于控制进出容器的数据包，比如我们建立了多个 calico 网络，想控制其中几个网络可以互通，其余不能互通，就可以修改 policy 的配置文件来满足要求，这种方式大大增加了网络连通和隔离的灵活性。 6 总结 1、除了以上的几种方案，跨主机容器网络方案还有很多，比如：Romana，Contiv 等，本文就不作过多展开了，大家感兴趣可以查阅相关资料了解。 2、跨主机的容器网络通常要为不同主机的容器维护一个 IP 池，所以大多方案需要借助第三方的服务发现方案。 3、跨主机容器网络按传输方式可以分为纯二层网络，隧道网络（大二层网络），以及纯三层网络。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/categories/Docker/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"容器","slug":"容器","permalink":"https://chambai.github.io/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"容器网络","slug":"容器网络","permalink":"https://chambai.github.io/tags/容器网络/"},{"name":"macvlan","slug":"macvlan","permalink":"https://chambai.github.io/tags/macvlan/"},{"name":"overlay","slug":"overlay","permalink":"https://chambai.github.io/tags/overlay/"},{"name":"flannel","slug":"flannel","permalink":"https://chambai.github.io/tags/flannel/"},{"name":"weave","slug":"weave","permalink":"https://chambai.github.io/tags/weave/"},{"name":"cacico","slug":"cacico","permalink":"https://chambai.github.io/tags/cacico/"}]},{"title":"virtio-user 简介","slug":"tech/virtio_user_简介","date":"2018-04-11T05:16:14.000Z","updated":"2019-04-11T14:38:24.075Z","comments":true,"path":"2018/04/11/tech/virtio_user_简介/","link":"","permalink":"https://chambai.github.io/2018/04/11/tech/virtio_user_简介/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 在看本文之前，建议先看 virtio 简介，vhost 简介，vhost-user 简介。 virtio-user 是 DPDK 针对特定场景提出的一种解决方案，它主要有两种场景的用途，一种是用于 DPDK 应用容器对 virtio 的支持，这是 DPDK v16.07 开始支持的；另一种是用于和内核通信，这是 DPDK v17.02 推出的。 1 virtio_user 用于容器网络 我们知道，对于虚拟机，有 virtio 这套半虚拟化的标准协议来指导虚拟机和宿主机之间的通信，但对于容器的环境，直接沿用 virtio 是不行的，原因是虚拟机是通过 Qemu 来模拟的，Qemu 会将它虚拟出的整个 KVM 虚拟机的信息共享给宿主机，但对于 DPDK 加速的容器化环境来说显然是不合理的。因为 DPDK 容器与宿主机的通信只用得到虚拟内存中的大页内存部分，其他都是用不到的，全部共享也没有任何意义，DPDK 主要基于大页内存来收发数据包的。 所以，virtio_user 其实就是在 virtio PMD 的基础上进行了少量修改形成的，简单来说，就是添加大页共享的部分逻辑，并精简了整块共享内存部分的逻辑。 有兴趣可以对照 /driver/net/virtio 中的代码和 DPDK virtio_user 代码，其实大部分是相同的。 从 DPDK 的角度看，virtio_user 是作为一个虚拟设备（vdev）来加载的，它充当的是一个 virtio 前端驱动，与之对应的后端通信驱动，是用户态的 vhost_user，在使用的时候，我们只需要定义好相应的适配接口即可，如下： vhost 和 vhost_user 本质上是采用共享内存的 IPC 方式，通过在 host 端创建 vhost_user 共享内存文件，然后 virtio_user 启动的时候指定该文件即可，如：12341）首先创建 vhost_user 共享内存文件--vdev &apos;eth_vhost_user0,iface=/tmp/vhost_user0&apos;2）启动 virtio_user 指定文件路径--vdev=virtio_user0,path=/tmp/vhost_user0 2 virtio_user 作为 exception path 用于与内核通信 virtio_user 的一个用途就是作为 exception path 用于与内核通信。我们知道，DPDK 是旁路内核的转包方案，这也是它高性能的原因，但有些时候从 DPDK 收到的包（如控制报文）需要丢到内核网络协议栈去做进一步的处理，这个路径在 DPDK 中就被称为 exception path。 在这之前，已经存在几种 exception path 的方案，如传统的 Tun/Tap，KNI（Kernel NIC Interface），AF_Packet 以及基于 SR-IOV 的 Flow Bifurcation。这些方案就不做过多介绍了，感兴趣的可看 DPDK 官网，上面都有介绍。 和容器网络的方案使用 vhost_user 作为后端驱动一样，要使得 virtio_user 和内核通信，只需加载内核模块 vhost.ko，让它充当的是 virtio_user 的后端通信驱动即可。 所以，我们可以看到，其实这两种方案本质上是一样，只是换了个后端驱动而已，这也是 virtio 的优势所在，定义一套通用的接口标准，需要什么类型的通信方式只需加载相应驱动即可，改动非常少，扩展性非常高。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"DPDK","slug":"DPDK","permalink":"https://chambai.github.io/categories/DPDK/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"DPDK","slug":"DPDK","permalink":"https://chambai.github.io/tags/DPDK/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"容器网络","slug":"容器网络","permalink":"https://chambai.github.io/tags/容器网络/"}]},{"title":"DPDK 入门最佳指南","slug":"tech/DPDK_入门最佳指南","date":"2018-04-10T05:16:14.000Z","updated":"2019-04-11T14:38:24.050Z","comments":true,"path":"2018/04/10/tech/DPDK_入门最佳指南/","link":"","permalink":"https://chambai.github.io/2018/04/10/tech/DPDK_入门最佳指南/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 01 写在前面 我的读者当中应该有一部分人是做 DPDK 相关的，我自己虽然现在已经不做 DPDK 了，但对这块仍然有兴趣，今天这篇文章就来总结下 DPDK 的技术栈。注意：这篇文章是小白文，不适合大神哦。 文章从 DPDK 的产生背景，到核心技术，再到应用场景，都进行了阐述，有可能是你见过的讲得最全面的文章了，当然，讲得全面自然会少了深度，你如果不屑忽略就好了。 其实，本文之前已经发过，但在整理的时候不小心删了，索性就重发一次，但这一次多了一些内容，文末我还会推荐一些学习资料，有需要的可以拉到最下面查看获取方法。 02 高性能网络技术 随着云计算产业的异军突起，网络技术的不断创新，越来越多的网络设备基础架构逐步向基于通用处理器平台的架构方向融合，从传统的物理网络到虚拟网络，从扁平化的网络结构到基于 SDN 分层的网络结构，无不体现出这种创新与融合。 这在使得网络变得更加可控制和成本更低的同时，也能够支持大规模用户或应用程序的性能需求，以及海量数据的处理。究其原因，其实是高性能网络编程技术随着网络架构的演进不断突破的一种必然结果。 03 C10K 到 C10M 问题的演进 说到高性能网络编程，一定逃不过 C10K 问题（即单机 1 万个并发连接问题），不过这个问题已经成为历史了，很多技术可以解决它，如常用的 I/O 多路复用模型，select, poll, epoll 等。在此基础上也出了很多优秀的框架，比如 Nginx 基于事件驱动的 Web 服务框架，以及基于 Python 开发的 Tornado 和 Django 这种非阻塞的 Web 框架。 如今，关注的更多是 C10M 问题（即单机 1 千万个并发连接问题）。很多计算机领域的大佬们从硬件上和软件上都提出了多种解决方案。从硬件上，比如说，现在的类似很多 40Gpbs、32-cores、256G RAM 这样配置的 X86 服务器完全可以处理 1 千万个以上的并发连接。 但是从硬件上解决问题就没多大意思了，首先它成本高，其次不通用，最后也没什么挑战，无非就是堆砌硬件而已。所以，抛开硬件不谈，我们看看从软件上该如何解决这个世界难题呢？ 这里不得不提一个人，就是 Errata Security 公司的 CEO Robert Graham，他在 Shmoocon 2013 大会上很巧妙地解释了这个问题。有兴趣可以查看其 YouTube 的演进视频： C10M Defending The Internet At Scale。 他提到了 UNIX 的设计初衷其实为电话网络的控制系统而设计的，而不是一般的服务器操作系统，所以，它仅仅是一个负责数据传送的系统，没有所谓的控制层面和数据层面的说法，不适合处理大规模的网络数据包。最后他得出的结论是： OS 的内核不是解决 C10M 问题的办法，恰恰相反 OS 的内核正式导致 C10M 问题的关键所在。 04 为什么这么说？基于 OS 内核的数据传输有什么弊端？ 1、中断处理： 当网络中大量数据包到来时，会产生频繁的硬件中断请求，这些硬件中断可以打断之前较低优先级的软中断或者系统调用的执行过程，如果这种打断频繁的话，将会产生较高的性能开销。 2、内存拷贝： 正常情况下，一个网络数据包从网卡到应用程序需要经过如下的过程：数据从网卡通过 DMA 等方式传到内核开辟的缓冲区，然后从内核空间拷贝到用户态空间，在 Linux 内核协议栈中，这个耗时操作甚至占到了数据包整个处理流程的 57.1%。 3、上下文切换： 频繁到达的硬件中断和软中断都可能随时抢占系统调用的运行，这会产生大量的上下文切换开销。另外，在基于多线程的服务器设计框架中，线程间的调度也会产生频繁的上下文切换开销，同样，锁竞争的耗能也是一个非常严重的问题。 4、局部性失效： 如今主流的处理器都是多个核心的，这意味着一个数据包的处理可能跨多个 CPU 核心，比如一个数据包可能中断在 cpu0，内核态处理在 cpu1，用户态处理在 cpu2，这样跨多个核心，容易造成 CPU 缓存失效，造成局部性失效。如果是 NUMA 架构，更会造成跨 NUMA 访问内存，性能受到很大影响。 5、内存管理： 传统服务器内存页为 4K，为了提高内存的访问速度，避免 cache miss，可以增加 cache 中映射表的条目，但这又会影响 CPU 的检索效率。 综合以上问题，可以看出内核本身就是一个非常大的瓶颈所在。那很明显解决方案就是想办法绕过内核。 05 解决方案探讨 针对以上弊端，分别提出以下技术点进行探讨。 1、控制层和数据层分离： 将数据包处理、内存管理、处理器调度等任务转移到用户空间去完成，而内核仅仅负责部分控制指令的处理。这样就不存在上述所说的系统中断、上下文切换、系统调用、系统调度等等问题。 2、多核技术： 使用多核编程技术代替多线程技术，并设置 CPU 的亲和性，将线程和 CPU 核进行一比一绑定，减少彼此之间调度切换。 3、NUMA 亲和性： 针对 NUMA 系统，尽量使 CPU 核使用所在 NUMA 节点的内存，避免跨内存访问。 4、大页内存： 使用大页内存代替普通的内存，减少 cache-miss。 5、无锁技术： 采用无锁技术解决资源竞争问题。 经研究，目前业内已经出现了很多优秀的集成了上述技术方案的高性能网络数据处理框架，如 6wind、Windriver、Netmap、DPDK 等，其中，Intel 的 DPDK 在众多方案脱颖而出，一骑绝尘。 DPDK 为 Intel 处理器架构下用户空间高效的数据包处理提供了库函数和驱动的支持，它不同于 Linux 系统以通用性设计为目的，而是专注于网络应用中数据包的高性能处理。 也就是 DPDK 绕过了 Linux 内核协议栈对数据包的处理过程，在用户空间实现了一套数据平面来进行数据包的收发与处理。在内核看来，DPDK 就是一个普通的用户态进程，它的编译、连接和加载方式和普通程序没有什么两样。 06 DPDK 的突破 相对传统的基于内核的网络数据处理，DPDK 对从内核层到用户层的网络数据流程进行了重大突破，我们先看看传统的数据流程和 DPDK 中的网络流程有什么不同。 传统 Linux 内核网络数据流程：12硬件中断---&gt;取包分发至内核线程---&gt;软件中断---&gt;内核线程在协议栈中处理包---&gt;处理完毕通知用户层用户层收包--&gt;网络层---&gt;逻辑层---&gt;业务层 dpdk 网络数据流程：12硬件中断---&gt;放弃中断流程用户层通过设备映射取包---&gt;进入用户层协议栈---&gt;逻辑层---&gt;业务层 下面就具体看看 DPDK 做了哪些突破？ 6.1 UIO （用户空间的 I/O 技术）的加持。 DPDK 能够绕过内核协议栈，本质上是得益于 UIO 技术，通过 UIO 能够拦截中断，并重设中断回调行为，从而绕过内核协议栈后续的处理流程。 UIO 设备的实现机制其实是对用户空间暴露文件接口，比如当注册一个 UIO 设备 uioX，就会出现文件 /dev/uioX，对该文件的读写就是对设备内存的读写。除此之外，对设备的控制还可以通过 /sys/class/uio 下的各个文件的读写来完成。 6.2 内存池技术 DPDK 在用户空间实现了一套精巧的内存池技术，内核空间和用户空间的内存交互不进行拷贝，只做控制权转移。这样，当收发数据包时，就减少了内存拷贝的开销。 6.3 大页内存管理 DPDK 实现了一组大页内存分配、使用和释放的 API，上层应用可以很方便使用 API 申请使用大页内存，同时也兼容普通的内存申请。 6.4 无锁环形队列 DPDK 基于 Linux 内核的无锁环形缓冲 kfifo 实现了自己的一套无锁机制。支持单生产者入列/单消费者出列和多生产者入列/多消费者出列操作，在数据传输的时候，降低性能的同时还能保证数据的同步。 6.5 poll-mode 网卡驱动 DPDK 网卡驱动完全抛弃中断模式，基于轮询方式收包，避免了中断开销。 6.6 NUMA DPDK 内存分配上通过 proc 提供的内存信息，使 CPU 核心尽量使用靠近其所在节点的内存，避免了跨 NUMA 节点远程访问内存的性能问题。 6.7 CPU 亲和性 DPDK 利用 CPU 的亲和性将一个线程或多个线程绑定到一个或多个 CPU 上，这样在线程执行过程中，就不会被随意调度，一方面减少了线程间的频繁切换带来的开销，另一方面避免了 CPU 缓存的局部失效性，增加了 CPU 缓存的命中率。 6.8 多核调度框架 DPDK 基于多核架构，一般会有主从核之分，主核负责完成各个模块的初始化，从核负责具体的业务处理。 除了上述之外，DPDK 还有很多的技术突破，可以用下面这张图来概之。 07 DPDK 的应用 DPDK 作为优秀的用户空间高性能数据包加速套件，现在已经作为一个“胶水”模块被用在多个网络数据处理方案中，用来提高性能。如下是众多的应用。 数据面（虚拟交换机） OVS Open vSwitch 是一个多核虚拟交换机平台，支持标准的管理接口和开放可扩展的可编程接口，支持第三方的控制接入。 https://github.com/openvswitch/ovs VPP VPP 是 cisco 开源的一个高性能的包处理框架，提供了 交换/路由 功能，在虚拟化环境中，使它可以当做一个虚拟交换机来使用。在一个类 SDN 的处理框架中，它往往充当数据面的角色。经研究表明，VPP 性能要好于 OVS+DPDK 的组合，但它更适用于 NFV，适合做特定功能的网络模块。 https://wiki.fd.io/view/VPP Lagopus Lagopus 是另一个多核虚拟交换的实现，功能和 OVS 差不多，支持多种网络协议，如 Ethernet，VLAN，QinQ，MAC-in-MAC，MPLS 和 PBB，以及隧道协议，如 GRE，VxLan 和 GTP。 https://github.com/lagopus/lagopus/blob/master/QUICKSTART.md Snabb Snabb 是一个简单且快速的数据包处理工具箱。 https://github.com/SnabbCo/snabbswitch/blob/master/README.md 数据面（虚拟路由器） OPENCONTRAIL 一个集成了 SDN 控制器的虚拟路由器，现在多用在 OpenStack 中，结合 Neutron 为 OpenStack 提供一站式的网络支持。 http://www.opencontrail.org/ CloudRouter 一个分布式的路由器。 https://cloudrouter.org/ 用户空间协议栈 mTCP mTCP 是一个针对多核系统的高可扩展性的用户空间 TCP/IP 协议栈。 https://github.com/eunyoung14/mtcp/blob/master/README IwIP IwIP 针对 RAM 平台的精简版的 TCP/IP 协议栈实现。 http://git.savannah.gnu.org/cgit/lwip.git/tree/README Seastar Seastar 是一个开源的，基于 C++ 11/14 feature，支持高并发和低延迟的异步编程高性能库。 http://www.seastar-project.org/ f-stack 腾讯开源的用户空间协议栈，移植于 FreeBSD协议栈，粘合了 POSIX API，上层应用（协程框架，Nginx,Redis），纯 C 编写，易上手。 https://github.com/f-stack/f-stack 存储加速 SPDK SPDK 是 DPDK 的孪生兄弟，专注存储性能加速，目前的火热程度丝毫不亚于 DPDK，Intel 近来对 SPDK 特别重视，隔三差五就发布新版本。 https://github.com/spdk/spdk 08 总结 DPDK 绕过了 Linux 内核协议栈，加速数据的处理，用户可以在用户空间定制协议栈，满足自己的应用需求，目前出现了很多基于 DPDK 的高性能网络框架，OVS 和 VPP 是常用的数据面框架，mTCP 和 f-stack 是常用的用户态协议栈，SPDK 是存储性能加速器，很多大公司都在使用 DPDK 来优化网络性能。 PS：本文所有的图来自网络，侵权必删。 09 DPDK 资料推荐 在我看来，DPDK 最好的学习资料是官网，没有之一： http://core.dpdk.org/doc/ 其次是看 Intel 技术专家出的书 《深入浅出 DPDK》。 本书详细介绍了DPDK 技术发展趋势，数据包处理，硬件加速技术，包处理和虚拟化 ，以及 DPDK 技术在 SDN，NFV ，网络存储等领域的实际应用。 本书是国内第一本全面的阐述网络数据面的核心技术的书籍，面向 IT 网络通讯行业的从业人员，以及大专院校的学生，用通俗易懂的文字打开了一扇通向新一代网络处理架构的大门。 本书我有电子版（但只有一部分，推荐大家买书），需要的公众号后台回复 “DPDK” 查看获取方式。 除了书之外，就是看大牛的博客，加入相关的群和优秀的人一起学习，我整理了几份网上较好的博客资料，和书一起附赠，如果想加群学习，回复 “加群”。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"DPDK","slug":"DPDK","permalink":"https://chambai.github.io/categories/DPDK/"}],"tags":[{"name":"NUMA","slug":"NUMA","permalink":"https://chambai.github.io/tags/NUMA/"},{"name":"SDN","slug":"SDN","permalink":"https://chambai.github.io/tags/SDN/"},{"name":"DPDK","slug":"DPDK","permalink":"https://chambai.github.io/tags/DPDK/"},{"name":"性能分析","slug":"性能分析","permalink":"https://chambai.github.io/tags/性能分析/"},{"name":"UIO","slug":"UIO","permalink":"https://chambai.github.io/tags/UIO/"},{"name":"大页内存","slug":"大页内存","permalink":"https://chambai.github.io/tags/大页内存/"},{"name":"OVS","slug":"OVS","permalink":"https://chambai.github.io/tags/OVS/"},{"name":"VPP","slug":"VPP","permalink":"https://chambai.github.io/tags/VPP/"},{"name":"mTCP","slug":"mTCP","permalink":"https://chambai.github.io/tags/mTCP/"},{"name":"fstack","slug":"fstack","permalink":"https://chambai.github.io/tags/fstack/"},{"name":"SPDK","slug":"SPDK","permalink":"https://chambai.github.io/tags/SPDK/"}]},{"title":"Docker 容器网络之单主机网络","slug":"tech/Docker_容器网络之单主机网络","date":"2018-04-06T05:16:14.000Z","updated":"2019-04-11T14:38:24.079Z","comments":true,"path":"2018/04/06/tech/Docker_容器网络之单主机网络/","link":"","permalink":"https://chambai.github.io/2018/04/06/tech/Docker_容器网络之单主机网络/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 当容器逐步向容器集群，容器云技术演进的时候，一个不得不面对的问题就是各个容器的管理问题，有些容器需要交互，有些容器需要隔离，如何保证这些操作能够顺利地进行，这个时候，很多容器管理和编排的平台就应运而生了。首先，当然是 Docker 社区自己开发的 Swarm+Machine+Compose 的集群管理套件，然后还有 Twitter 主推 Apache 的 Mesos，最有名的应该为 Google 开源的 Kubernetes。 这些平台综合了容器集群资源管理，服务发现和扩容缩融等问题，是一个集大成的解决方案，但其实这些问题本质上都离不开网络，资源在各容器之间调度需要网络，服务发现需要网络，所以，可以说网络是容器集群环境下最基础的一环。 Docker 容器网络根据容器的部署位置，可以分为单主机网络（host）和多主机网络（multi-host），本文先看 Docker host 网络。 Docker host 网络分为 none，host，joined container 和 bridge 网络。 none 网络模式下，Docker 容器拥有自己的 network namespace，但是并不为容器进行任何的网络配置，也就是说容器除了 network namespace 本身自带的 localback 网卡外什么都没有，包括网卡、IP、路由等信息。用户如何要使用 none 网络，就需要自己添加特定的网卡，并配置 IP、路由等信息，但一般不会这么干，none 网络很好地做到了隔离，一般是用来跑那些对安全性要求极高且不需要联网的应用。 比如某个容器的唯一用途是生成随机密码，就可以放到 none 网络中避免密码被窃取。 想要使 Docker 使用 none 网络，只需要在创建容器的时候附带 –network = none 即可。 host 网络，顾名思义就是 Docker 容器使用宿主机的网络，相当于和 host 共用了同一个 network namespace，Docker 容器使用 host 的网卡、IP 和路由等功能对外通信。 虽然这种模式下 Docker 没有创建独立的 network namespace，但其他 namespace 仍然是隔离的，如文件系统、进程列表等。host 网络最大的好处就是使得 Docker 容器对外通信变得简单，直接使用 host 的 IP 进行通信即可，但缺点也很明显，就是降低了隔离性，同时还会存在和其他容器对网络资源的竞争与冲突的问题。 同样要使用 host 网络，只需创建容器时附带 –network = host 即可。 joined container 网络和 host 网络不同的是，它是和其他的 container 共享一个 network namespace，一个 network namespace 可以被一个或者多个 Docker 容器共享。在这种模式下，两个容器之间可以通过 localback 回环网卡通信，增加了容器间通信的便利性。 同样可以在创建容器时，使用参数 –network = container:another_container_name 来和另外容器共享网络。 bridge 网络是最常用的网络模式，它兼顾了安全性和功能的完备性，但其与外部通信要通过 NAT 转换，在复杂的网络场景下会存在诸多不便。 bridge 网络在创建的时候通过 –network = bridge 指定，Docker daemon 会为创建的容器自动创建一个 Docker 网桥——docker0（也可以人为指定名称 –driver bridge my_net），这个 docker0 就用来联结 Docker 容器和 host 的桥梁。 然后，Docker daemon 会创建一对虚拟网卡 veth pair，一块网卡留在宿主机的 root network namespace 中，并绑定到 docker0 上，另一块放在新创建的 network namespace 中，命名为 eth0，并为其配置 IP 和路由，将其网关设为 docker0，如下，这样整个容器的 bridge 网络通信环境就建立起来了，其他容器的建立方式也是如此，最终各容器之间就通过 docker0 这个桥梁互联互通了。 下文将讨论更为复杂的 multi-host 网络。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/categories/Docker/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"容器","slug":"容器","permalink":"https://chambai.github.io/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"容器网络","slug":"容器网络","permalink":"https://chambai.github.io/tags/容器网络/"},{"name":"Bridge","slug":"Bridge","permalink":"https://chambai.github.io/tags/Bridge/"}]},{"title":"Docker 基础技术之 Linux cgroups 详解","slug":"tech/Docker_基础技术之_Linux_cgroups_详解","date":"2018-03-28T05:16:14.000Z","updated":"2019-04-11T14:38:24.084Z","comments":true,"path":"2018/03/28/tech/Docker_基础技术之_Linux_cgroups_详解/","link":"","permalink":"https://chambai.github.io/2018/03/28/tech/Docker_基础技术之_Linux_cgroups_详解/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 前面两篇文章我们总结了 Docker 背后使用的资源隔离技术 Linux namespace，本篇将讨论另外一个技术——资源限额，这是由 Linux cgroups 来实现的。 cgroups 是 Linux 内核提供的一种机制，这种机制可以根据需求把一系列任务及子任务整合（或分隔）到按资源划分等级的不同组内，从而为系统资源管理提供一个统一的框架。（来自 《Docker 容器与容器云》） 通俗来说，cgroups 可以限制和记录任务组（进程组或线程组）使用的物理资源（包括 CPU、内存、IO 等）。 为了方便用户（程序员）操作，cgroups 以一个伪文件系统的方式实现，并对外提供 API，用户对文件系统的操作就是对 cgroups 的操作。 从实现上来，cgroups 实际上是给每个执行任务挂了一个钩子，当任务执行过程中涉及到对资源的分配使用时，就会触发钩子上的函数对相应的资源进行检测，从而对资源进行限制和优先级分配。 cgroups 的作用 总结下来，cgroups 提供以下四个功能： 资源限制： cgroups 可以对任务使用的资源总额进行限制，如设定应用运行时使用内存的上限，一旦超过这个配额就发出 OOM（Out of Memory）提示。 优先级分配： 通过分配的 CPU 时间片数量和磁盘 IO 带宽大小，实际上就相当于控制了任务运行的优先级。 资源统计： cgroups 可以统计系统的资源使用，如 CPU 使用时长、内存用量等，这个功能非常适用于计费。 任务控制： cgroups 可以对任务执行挂起、恢复等操作。 cgroups 的子系统 cgroups 在设计时根据不同的资源类别分为不同的子系统，一个子系统本质上是一个资源控制器，比如 CPU 资源对应 CPU 子系统，负责控制 CPU 时间片的分配，内存对应内存子系统，负责限制内存的使用量。进一步，一个子系统或多个子系统可以组成一个 cgroup，cgroups 中的资源控制都是以 cgroup 为单位来实现，一个任务（或进程或线程）可以加入某个 cgroup，也可以从一个 cgroup 移动到另一个 cgroup，但这里有一些限制，在此就不再赘述了，详细查阅相关资料了解。 对于我们来说，最关键的是知道怎么用，下面就针对 CPU、内存和 IO 资源来看 Docker 是如何使用的？ 对于 CPU，Docker 使用参数 -c 或 –cpu-shares 来设置一个容器使用的 CPU 权重，权重的大小也影响了 CPU 使用的优先级。 如下，启动两个容器，并分配不同的 CPU 权重，最终 CPU 使用率情况：12docker run --name &quot;container_A&quot; -c 1024 ubuntudocker run --name &quot;container_B&quot; -c 512 ubuntu 当只有一个容器时，即使指定较少的 CPU 权重，它也会占满整个 CPU，说明这个权重只是相对权重，如下将上面的 “container_A” 停止，“container_B” 就分配到全部可用的 CPU。 对于内存，Docker 使用 -m（设置内存的限额）和 –memory-swap（设置内存和 swap 的限额）来控制容器内存的使用量，如下，给容器限制 200M 的内存和 100M 的 swap，然后给容器内的一个工作线程分配 280M 的内存，因为 280M 在容许的 300M 范围内，没有问题。其内存分配过程是不断分配又释放，如下： 如果让工作线程使用内存超过 300M，则出现内存超限的错误，容器退出，如下： 对于 IO 资源，其使用方式与 CPU 一样，使用 –blkio-weight 来设置其使用权重，IO 衡量的两个指标是 bps（byte per second，每秒读写的数据量） 和 iops（io per second， 每秒 IO 的次数）,实际使用，一般使用这两个指标来衡量 IO 读写的带宽，几种使用参数如下： –device-read-bps，限制读某个设备的 bps。 –device-write-bps，限制写某个设备的 bps。 –device-read-iops，限制读某个设备的 iops。 –device-write-iops，限制写某个设备的 iops。 假如限制容器对其文件系统 /dev/sda 的 bps 写速率为 30MB/s，则在容器中用 dd 测试其写磁盘的速率如下，可见小于 30MB/s。 如果是正常情况下，我的机器可以达到 56.7MB/s，一般都是超 1G 的。 上面几个资源使用限制的例子，本质上都是调用了 Linux kernel 的 cgroups 机制来实现的，每个容器创建后，Linux 会为每个容器创建一个 cgroup 目录，以容器的 ID 命名，目录在 /sys/fs/cgroup/ 中，针对上面的 CPU 资源限制的例子，我们可以在 /sys/fs/cgroup/cpu/docker 中看到相关信息，如下： 其中，cpu.shares 中保存的就是限制的数值，其他还有很多项，感兴趣可以动手实验看看。 总结 cgroups 的作用，cgroups 的实现，cgroups 的子系统机制，CPU、内存和 IO 的使用方式，以及对应 Linux 的 cgroups 文件目录。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/categories/Docker/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"容器","slug":"容器","permalink":"https://chambai.github.io/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"Cgroup","slug":"Cgroup","permalink":"https://chambai.github.io/tags/Cgroup/"}]},{"title":"Docker 基础技术之 Linux namespace 源码分析","slug":"tech/Docker_基础技术之_Linux_namespace_源码分析","date":"2018-03-13T05:16:14.000Z","updated":"2019-04-11T14:38:24.052Z","comments":true,"path":"2018/03/13/tech/Docker_基础技术之_Linux_namespace_源码分析/","link":"","permalink":"https://chambai.github.io/2018/03/13/tech/Docker_基础技术之_Linux_namespace_源码分析/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 上篇我们从进程 clone 的角度，结合代码简单分析了 Linux 提供的 6 种 namespace，本篇从源码上进一步分析 Linux namespace，让你对 Docker namespace 的隔离机制有更深的认识。我用的是 Linux-4.1.19 的版本，由于 namespace 模块更新都比较少，所以，只要 3.0 以上的版本都是差不多的。 从内核进程描述符 task_struct 开始切入 由于 Linux namespace 是用来做进程资源隔离的，所以在进程描述符中，一定有 namespace 所对应的信息，我们可以从这里开始切入代码。 首先找到描述进程信息 task_struct，找到指向 namespace 的结构 struct *nsproxy（sched.h）：123456struct task_struct &#123;....../* namespaces */struct nsproxy *nsproxy;......&#125; 其中 nsproxy 结构体定义在 nsproxy.h 中：123456789101112131415161718192021/** A structure to contain pointers to all per-process* namespaces - fs (mount), uts, network, sysvipc, etc.** &apos;count&apos; is the number of tasks holding a reference.* The count for each namespace, then, will be the number* of nsproxies pointing to it, not the number of tasks.** The nsproxy is shared by tasks which share all namespaces.* As soon as a single namespace is cloned or unshared, the* nsproxy is copied.*/struct nsproxy &#123; atomic_t count; struct uts_namespace *uts_ns; struct ipc_namespace *ipc_ns; struct mnt_namespace *mnt_ns; struct pid_namespace *pid_ns; struct net *net_ns;&#125;;extern struct nsproxy init_nsproxy; 这个结构是被所有 namespace 所共享的，只要一个 namespace 被 clone 了，nsproxy 也会被 clone。注意到，由于 user namespace 是和其他 namespace 耦合在一起的，所以没出现在上述结构中。 同时，nsproxy.h 中还定义了一些对 namespace 的操作，包括 copy_namespaces 等。123456int copy_namespaces(unsigned long flags, struct task_struct *tsk);void exit_task_namespaces(struct task_struct *tsk);void switch_task_namespaces(struct task_struct *tsk, struct nsproxy *new);void free_nsproxy(struct nsproxy *ns);int unshare_nsproxy_namespaces(unsigned long, struct nsproxy **,struct fs_struct *); task_struct，nsproxy，几种 namespace 之间的关系如下所示： 各个 namespace 的初始化 在各个 namespace 结构定义下都有个 init 函数，nsproxy 也有个 init_nsproxy 函数，init_nsproxy 在 task 初始化的时候会被初始化，附带的，init_nsproxy 中定义了各个 namespace 的 init 函数，如下：在 init_task 函数中（init_task.h）:12345678910/** INIT_TASK is used to set up the first task table, touch at* your own risk!. Base=0, limit=0x1fffff (=2MB)*/#define INIT_TASK(tsk) \\&#123;.......nsproxy = &amp;init_nsproxy, ......&#125; 继续跟进 init_nsproxy，在 nsproxy.c 中：123456789101112struct nsproxy init_nsproxy = &#123;.count = ATOMIC_INIT(1),.uts_ns = &amp;init_uts_ns,#if defined(CONFIG_POSIX_MQUEUE) || defined(CONFIG_SYSVIPC).ipc_ns = &amp;init_ipc_ns,#endif.mnt_ns = NULL,.pid_ns_for_children = &amp;init_pid_ns,#ifdef CONFIG_NET.net_ns = &amp;init_net,#endif&#125;; 可见，init_nsproxy 中，对 uts, ipc, pid, net 都进行了初始化，但 mount 却没有。 创建新的 namespace 初始化完之后，下面看看如何创建一个新的 namespace，通过前面的文章，我们知道是通过 clone 函数来完成的，在 Linux kernel 中，fork/vfork() 对 clone 进行了封装，如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546#ifdef __ARCH_WANT_SYS_FORKSYSCALL_DEFINE0(fork)&#123;#ifdef CONFIG_MMU return do_fork(SIGCHLD, 0, 0, NULL, NULL);#else /* can not support in nommu mode */ return -EINVAL;#endif&#125;#endif#ifdef __ARCH_WANT_SYS_VFORKSYSCALL_DEFINE0(vfork)&#123; return do_fork(CLONE_VFORK | CLONE_VM | SIGCHLD, 0, 0, NULL, NULL);&#125;#endif#ifdef __ARCH_WANT_SYS_CLONE#ifdef CONFIG_CLONE_BACKWARDSSYSCALL_DEFINE5(clone, unsigned long, clone_flags, unsigned long, newsp, int __user *, parent_tidptr, int, tls_val, int __user *, child_tidptr)#elif defined(CONFIG_CLONE_BACKWARDS2)SYSCALL_DEFINE5(clone, unsigned long, newsp, unsigned long, clone_flags, int __user *, parent_tidptr, int __user *, child_tidptr, int, tls_val)#elif defined(CONFIG_CLONE_BACKWARDS3)SYSCALL_DEFINE6(clone, unsigned long, clone_flags, unsigned long, newsp, int, stack_size, int __user *, parent_tidptr, int __user *, child_tidptr, int, tls_val)#elseSYSCALL_DEFINE5(clone, unsigned long, clone_flags, unsigned long, newsp, int __user *, parent_tidptr, int __user *, child_tidptr, int, tls_val)#endif&#123; return do_fork(clone_flags, newsp, 0, parent_tidptr, child_tidptr);&#125;#endif 可以看到，无论是 fork() 还是 vfork()，最终都会调用到 do_fork() 函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** Ok, this is the main fork-routine.** It copies the process, and if successful kick-starts* it and waits for it to finish using the VM if required.*/long do_fork(unsigned long clone_flags,unsigned long stack_start,unsigned long stack_size,int __user *parent_tidptr,int __user *child_tidptr)&#123;// 创建进程描述符指针 struct task_struct *p; int trace = 0; long nr;/** Determine whether and which event to report to ptracer. When* called from kernel_thread or CLONE_UNTRACED is explicitly* requested, no event is reported; otherwise, report if the event* for the type of forking is enabled.*/if (!(clone_flags &amp; CLONE_UNTRACED)) &#123; if (clone_flags &amp; CLONE_VFORK) trace = PTRACE_EVENT_VFORK; else if ((clone_flags &amp; CSIGNAL) != SIGCHLD) trace = PTRACE_EVENT_CLONE; else trace = PTRACE_EVENT_FORK; if (likely(!ptrace_event_enabled(current, trace))) trace = 0;&#125;// 复制进程描述符，返回值是 task_structp = copy_process(clone_flags, stack_start, stack_size,child_tidptr, NULL, trace);/** Do this prior waking up the new thread - the thread pointer* might get invalid after that point, if the thread exits quickly.*/if (!IS_ERR(p)) &#123; struct completion vfork; struct pid *pid; trace_sched_process_fork(current, p); // 得到新进程描述符的 pid pid = get_task_pid(p, PIDTYPE_PID); nr = pid_vnr(pid); if (clone_flags &amp; CLONE_PARENT_SETTID) put_user(nr, parent_tidptr); // 调用 vfork() 方法，完成相关的初始化工作 if (clone_flags &amp; CLONE_VFORK) &#123; p-&gt;vfork_done = &amp;vfork; init_completion(&amp;vfork); get_task_struct(p); &#125; // 将新进程加入到调度器中，为其分配 CPU，准备执行 wake_up_new_task(p); // fork() 完成，子进程开始运行，并让 ptrace 跟踪 /* forking complete and child started to run, tell ptracer */ if (unlikely(trace)) ptrace_event_pid(trace, pid); // 如果是 vfork()，将父进程加入等待队列，等待子进程完成 if (clone_flags &amp; CLONE_VFORK) &#123; if (!wait_for_vfork_done(p, &amp;vfork)) ptrace_event_pid(PTRACE_EVENT_VFORK_DONE, pid); &#125; put_pid(pid);&#125; else &#123; nr = PTR_ERR(p);&#125; return nr;&#125; do_fork() 首先调用 copy_process 将父进程信息复制给子进程，然后调用 vfork() 完成相关的初始化工作，接着调用 wake_up_new_task() 将进程加入调度器中，为之分配 CPU。最后，等待子进程退出。 copy_process():123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169static struct task_struct *copy_process(unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *child_tidptr, struct pid *pid, int trace)&#123;int retval;// 创建进程描述符指针struct task_struct *p;// 检查 clone flags 的合法性，比如 CLONE_NEWNS 与 CLONE_FS 是互斥的if ((clone_flags &amp; (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))return ERR_PTR(-EINVAL);if ((clone_flags &amp; (CLONE_NEWUSER|CLONE_FS)) == (CLONE_NEWUSER|CLONE_FS))return ERR_PTR(-EINVAL);/** Thread groups must share signals as well, and detached threads* can only be started up within the thread group.*/if ((clone_flags &amp; CLONE_THREAD) &amp;&amp; !(clone_flags &amp; CLONE_SIGHAND))return ERR_PTR(-EINVAL);/** Shared signal handlers imply shared VM. By way of the above,* thread groups also imply shared VM. Blocking this case allows* for various simplifications in other code.*/if ((clone_flags &amp; CLONE_SIGHAND) &amp;&amp; !(clone_flags &amp; CLONE_VM))return ERR_PTR(-EINVAL);/** Siblings of global init remain as zombies on exit since they are* not reaped by their parent (swapper). To solve this and to avoid* multi-rooted process trees, prevent global and container-inits* from creating siblings.*/// 比如CLONE_PARENT时得检查当前signal flags是否为SIGNAL_UNKILLABLE，防止kill init进程。if ((clone_flags &amp; CLONE_PARENT) &amp;&amp;current-&gt;signal-&gt;flags &amp; SIGNAL_UNKILLABLE)return ERR_PTR(-EINVAL);/** If the new process will be in a different pid or user namespace* do not allow it to share a thread group or signal handlers or* parent with the forking task.*/if (clone_flags &amp; CLONE_SIGHAND) &#123;if ((clone_flags &amp; (CLONE_NEWUSER | CLONE_NEWPID)) ||(task_active_pid_ns(current) !=current-&gt;nsproxy-&gt;pid_ns_for_children))return ERR_PTR(-EINVAL);&#125;retval = security_task_create(clone_flags);if (retval)goto fork_out;retval = -ENOMEM;// 复制当前的 task_structp = dup_task_struct(current);if (!p)goto fork_out;ftrace_graph_init_task(p);rt_mutex_init_task(p);#ifdef CONFIG_PROVE_LOCKINGDEBUG_LOCKS_WARN_ON(!p-&gt;hardirqs_enabled);DEBUG_LOCKS_WARN_ON(!p-&gt;softirqs_enabled);#endifretval = -EAGAIN;// 检查进程是否超过限制，由 OS 定义if (atomic_read(&amp;p-&gt;real_cred-&gt;user-&gt;processes) &gt;=task_rlimit(p, RLIMIT_NPROC)) &#123;if (p-&gt;real_cred-&gt;user != INIT_USER &amp;&amp;!capable(CAP_SYS_RESOURCE) &amp;&amp; !capable(CAP_SYS_ADMIN))goto bad_fork_free;&#125;current-&gt;flags &amp;= ~PF_NPROC_EXCEEDED;retval = copy_creds(p, clone_flags);if (retval &lt; 0)goto bad_fork_free;/** If multiple threads are within copy_process(), then this check* triggers too late. This doesn&apos;t hurt, the check is only there* to stop root fork bombs.*/retval = -EAGAIN;// 检查进程数是否超过 max_threads，由内存大小定义if (nr_threads &gt;= max_threads)goto bad_fork_cleanup_count;// ......// 初始化 io 计数器task_io_accounting_init(&amp;p-&gt;ioac);acct_clear_integrals(p);// 初始化 CPU 定时器posix_cpu_timers_init(p);// ......// 初始化进程数据结构，并为进程分配 CPU，进程状态设置为 TASK_RUNNING/* Perform scheduler related setup. Assign this task to a CPU. */retval = sched_fork(clone_flags, p);if (retval)goto bad_fork_cleanup_policy;retval = perf_event_init_task(p);if (retval)goto bad_fork_cleanup_policy;retval = audit_alloc(p);if (retval)goto bad_fork_cleanup_perf;/* copy all the process information */// 复制所有进程信息，包括文件系统，信号处理函数、信号、内存管理等shm_init_task(p);retval = copy_semundo(clone_flags, p);if (retval)goto bad_fork_cleanup_audit;retval = copy_files(clone_flags, p);if (retval)goto bad_fork_cleanup_semundo;retval = copy_fs(clone_flags, p);if (retval)goto bad_fork_cleanup_files;retval = copy_sighand(clone_flags, p);if (retval)goto bad_fork_cleanup_fs;retval = copy_signal(clone_flags, p);if (retval)goto bad_fork_cleanup_sighand;retval = copy_mm(clone_flags, p);if (retval)goto bad_fork_cleanup_signal;// !!! 复制 namespaceretval = copy_namespaces(clone_flags, p);if (retval)goto bad_fork_cleanup_mm;retval = copy_io(clone_flags, p);if (retval)goto bad_fork_cleanup_namespaces;// 初始化子进程内核栈retval = copy_thread(clone_flags, stack_start, stack_size, p);if (retval)goto bad_fork_cleanup_io;// 为新进程分配新的 pidif (pid != &amp;init_struct_pid) &#123;pid = alloc_pid(p-&gt;nsproxy-&gt;pid_ns_for_children);if (IS_ERR(pid)) &#123;retval = PTR_ERR(pid);goto bad_fork_cleanup_io;&#125;&#125;// ......// 返回新进程 preturn p;&#125; copy_process 主要分为三步：首先调用 dup_task_struct() 复制当前的进程描述符信息 task_struct，为新进程分配新的堆栈，第二步调用 sched_fork() 初始化进程数据结构，为其分配 CPU，把进程状态设置为 TASK_RUNNING，最后一步就是调用 copy_namespaces() 复制 namesapces。我们重点关注最后一步 copy_namespaces()：12345678910111213141516171819202122232425262728293031323334353637/** called from clone. This now handles copy for nsproxy and all* namespaces therein.*/int copy_namespaces(unsigned long flags, struct task_struct *tsk)&#123;struct nsproxy *old_ns = tsk-&gt;nsproxy;struct user_namespace *user_ns = task_cred_xxx(tsk, user_ns);struct nsproxy *new_ns;if (likely(!(flags &amp; (CLONE_NEWNS | CLONE_NEWUTS | CLONE_NEWIPC |CLONE_NEWPID | CLONE_NEWNET)))) &#123;get_nsproxy(old_ns);return 0;&#125;if (!ns_capable(user_ns, CAP_SYS_ADMIN))return -EPERM;/** CLONE_NEWIPC must detach from the undolist: after switching* to a new ipc namespace, the semaphore arrays from the old* namespace are unreachable. In clone parlance, CLONE_SYSVSEM* means share undolist with parent, so we must forbid using* it along with CLONE_NEWIPC.*/if ((flags &amp; (CLONE_NEWIPC | CLONE_SYSVSEM)) ==(CLONE_NEWIPC | CLONE_SYSVSEM)) return -EINVAL;new_ns = create_new_namespaces(flags, tsk, user_ns, tsk-&gt;fs);if (IS_ERR(new_ns))return PTR_ERR(new_ns);tsk-&gt;nsproxy = new_ns;return 0;&#125; 可见，copy_namespace() 主要基于“旧的” namespace 创建“新的” namespace，核心函数在于 create_new_namespaces：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** Create new nsproxy and all of its the associated namespaces.* Return the newly created nsproxy. Do not attach this to the task,* leave it to the caller to do proper locking and attach it to task.*/static struct nsproxy *create_new_namespaces(unsigned long flags,struct task_struct *tsk, struct user_namespace *user_ns,struct fs_struct *new_fs)&#123;struct nsproxy *new_nsp;int err;// 创建新的 nsproxynew_nsp = create_nsproxy();if (!new_nsp)return ERR_PTR(-ENOMEM);//创建 mnt namespacenew_nsp-&gt;mnt_ns = copy_mnt_ns(flags, tsk-&gt;nsproxy-&gt;mnt_ns, user_ns, new_fs);if (IS_ERR(new_nsp-&gt;mnt_ns)) &#123;err = PTR_ERR(new_nsp-&gt;mnt_ns);goto out_ns;&#125;//创建 uts namespacenew_nsp-&gt;uts_ns = copy_utsname(flags, user_ns, tsk-&gt;nsproxy-&gt;uts_ns);if (IS_ERR(new_nsp-&gt;uts_ns)) &#123;err = PTR_ERR(new_nsp-&gt;uts_ns);goto out_uts;&#125;//创建 ipc namespacenew_nsp-&gt;ipc_ns = copy_ipcs(flags, user_ns, tsk-&gt;nsproxy-&gt;ipc_ns);if (IS_ERR(new_nsp-&gt;ipc_ns)) &#123;err = PTR_ERR(new_nsp-&gt;ipc_ns);goto out_ipc;&#125;//创建 pid namespacenew_nsp-&gt;pid_ns_for_children =copy_pid_ns(flags, user_ns, tsk-&gt;nsproxy-&gt;pid_ns_for_children);if (IS_ERR(new_nsp-&gt;pid_ns_for_children)) &#123;err = PTR_ERR(new_nsp-&gt;pid_ns_for_children);goto out_pid;&#125;//创建 network namespacenew_nsp-&gt;net_ns = copy_net_ns(flags, user_ns, tsk-&gt;nsproxy-&gt;net_ns);if (IS_ERR(new_nsp-&gt;net_ns)) &#123;err = PTR_ERR(new_nsp-&gt;net_ns);goto out_net;&#125;return new_nsp;// 出错处理out_net:if (new_nsp-&gt;pid_ns_for_children)put_pid_ns(new_nsp-&gt;pid_ns_for_children);out_pid:if (new_nsp-&gt;ipc_ns)put_ipc_ns(new_nsp-&gt;ipc_ns);out_ipc:if (new_nsp-&gt;uts_ns)put_uts_ns(new_nsp-&gt;uts_ns);out_uts:if (new_nsp-&gt;mnt_ns)put_mnt_ns(new_nsp-&gt;mnt_ns);out_ns:kmem_cache_free(nsproxy_cachep, new_nsp);return ERR_PTR(err);&#125; 在create_new_namespaces()中，分别调用 create_nsproxy(), create_utsname(), create_ipcs(), create_pid_ns(), create_net_ns(), create_mnt_ns() 来创建 nsproxy 结构，uts，ipcs，pid，mnt，net。 具体的函数我们就不再分析，基本到此为止，我们从子进程创建，到子进程相关的信息的初始化，包括文件系统，CPU，内存管理等，再到各个 namespace 的创建，都走了一遍，下面附上 namespace 创建的代码流程图。 mnt namespace: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475mnt namespace:struct mnt_namespace *copy_mnt_ns(unsigned long flags, struct mnt_namespace *ns,struct user_namespace *user_ns, struct fs_struct *new_fs)&#123;struct mnt_namespace *new_ns;struct vfsmount *rootmnt = NULL, *pwdmnt = NULL;struct mount *p, *q;struct mount *old;struct mount *new;int copy_flags;BUG_ON(!ns);if (likely(!(flags &amp; CLONE_NEWNS))) &#123;get_mnt_ns(ns);return ns;&#125;old = ns-&gt;root;// 分配新的 mnt namespacenew_ns = alloc_mnt_ns(user_ns);if (IS_ERR(new_ns))return new_ns;namespace_lock();/* First pass: copy the tree topology */// 首先 copy root 路径copy_flags = CL_COPY_UNBINDABLE | CL_EXPIRE;if (user_ns != ns-&gt;user_ns)copy_flags |= CL_SHARED_TO_SLAVE | CL_UNPRIVILEGED;new = copy_tree(old, old-&gt;mnt.mnt_root, copy_flags);if (IS_ERR(new)) &#123;namespace_unlock();free_mnt_ns(new_ns);return ERR_CAST(new);&#125;new_ns-&gt;root = new;list_add_tail(&amp;new_ns-&gt;list, &amp;new-&gt;mnt_list);/** Second pass: switch the tsk-&gt;fs-&gt;* elements and mark new vfsmounts* as belonging to new namespace. We have already acquired a private* fs_struct, so tsk-&gt;fs-&gt;lock is not needed.*/// 为新进程设置 fs 信息p = old;q = new;while (p) &#123;q-&gt;mnt_ns = new_ns;if (new_fs) &#123;if (&amp;p-&gt;mnt == new_fs-&gt;root.mnt) &#123;new_fs-&gt;root.mnt = mntget(&amp;q-&gt;mnt);rootmnt = &amp;p-&gt;mnt;&#125;if (&amp;p-&gt;mnt == new_fs-&gt;pwd.mnt) &#123;new_fs-&gt;pwd.mnt = mntget(&amp;q-&gt;mnt);pwdmnt = &amp;p-&gt;mnt;&#125;&#125;p = next_mnt(p, old);q = next_mnt(q, new);if (!q)break;while (p-&gt;mnt.mnt_root != q-&gt;mnt.mnt_root)p = next_mnt(p, old);&#125;namespace_unlock();if (rootmnt)mntput(rootmnt);if (pwdmnt)mntput(pwdmnt);return new_ns;&#125; 可以看到，mount namespace 在新建时会新建一个新的 namespace，然后将父进程的 namespace 拷贝过来，并将 mount-&gt;mnt_ns 指向新的 namespace。接着设置进程的 root 路径以及当前路径到新的 namespace，然后为新进程设置新的 vfs 等。从这里就可以看出，在子进程中进行 mount 操作不会影响到父进程中的 mount 信息。 uts namespace: 12345678static inline struct uts_namespace *copy_utsname(unsigned long flags,struct user_namespace *user_ns, struct uts_namespace *old_ns)&#123;if (flags &amp; CLONE_NEWUTS)return ERR_PTR(-EINVAL);return old_ns;&#125; uts namespace 直接返回父进程 namespace 信息。 ipc namespace: 1234567struct ipc_namespace *copy_ipcs(unsigned long flags,struct user_namespace *user_ns, struct ipc_namespace *ns)&#123;if (!(flags &amp; CLONE_NEWIPC))return get_ipc_ns(ns);return create_ipc_ns(user_ns, ns);&#125; ipc namespace 如果是设置了参数 CLONE_NEWIPC，则直接返回父进程的 namespace，否则返回新创建的 namespace。 pid namespace: 1234567static inline struct pid_namespace *copy_pid_ns(unsigned long flags,struct user_namespace *user_ns, struct pid_namespace *ns)&#123;if (flags &amp; CLONE_NEWPID)ns = ERR_PTR(-EINVAL);return ns;&#125; pid namespace 直接返回父进程的 namespace。 net namespace 1234567static inline struct net *copy_net_ns(unsigned long flags,struct user_namespace *user_ns, struct net *old_net)&#123;if (flags &amp; CLONE_NEWNET)return ERR_PTR(-EINVAL);return old_net;&#125; net namespace 也是直接返回父进程的 namespace。 OK，不知不觉写了这么多，但回头去看，这更像是代码走读，分析深度不够，更详细的大家可以参照源码，源码结构还是比较清晰的。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/categories/Docker/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"容器","slug":"容器","permalink":"https://chambai.github.io/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"Namespace","slug":"Namespace","permalink":"https://chambai.github.io/tags/Namespace/"}]},{"title":"Docker 基础技术之 Linux namespace 详解","slug":"tech/Docker_基础技术之_Linux_namespace_详解","date":"2018-03-08T05:16:14.000Z","updated":"2019-04-11T14:38:24.056Z","comments":true,"path":"2018/03/08/tech/Docker_基础技术之_Linux_namespace_详解/","link":"","permalink":"https://chambai.github.io/2018/03/08/tech/Docker_基础技术之_Linux_namespace_详解/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Docker 是“新瓶装旧酒”的产物，依赖于 Linux 内核技术 chroot 、namespace 和 cgroup。本篇先来看 namespace 技术。 Docker 和虚拟机技术一样，从操作系统级上实现了资源的隔离，它本质上是宿主机上的进程（容器进程），所以资源隔离主要就是指进程资源的隔离。实现资源隔离的核心技术就是 Linux namespace。这技术和很多语言的命名空间的设计思想是一致的（如 C++ 的 namespace）。 隔离意味着可以抽象出多个轻量级的内核（容器进程），这些进程可以充分利用宿主机的资源，宿主机有的资源容器进程都可以享有，但彼此之间是隔离的，同样，不同容器进程之间使用资源也是隔离的，这样，彼此之间进行相同的操作，都不会互相干扰，安全性得到保障。 为了支持这些特性，Linux namespace 实现了 6 项资源隔离，基本上涵盖了一个小型操作系统的运行要素，包括主机名、用户权限、文件系统、网络、进程号、进程间通信。 这 6 项资源隔离分别对应 6 种系统调用，通过传入上表中的参数，调用 clone() 函数来完成。1int clone(int (*child_func)(void *), void *child_stack, int flags, void *arg); clone() 函数相信大家都不陌生了，它是 fork() 函数更通用的实现方式，通过调用 clone()，并传入需要隔离资源对应的参数，就可以建立一个容器了（隔离什么我们自己控制）。 一个容器进程也可以再 clone() 出一个容器进程，这是容器的嵌套。 如果想要查看当前进程下有哪些 namespace 隔离，可以查看文件 /proc/[pid]/ns （注：该方法仅限于 3.8 版本以后的内核）。 可以看到，每一项 namespace 都附带一个编号，这是唯一标识 namespace 的，如果两个进程指向的 namespace 编号相同，则表示它们同在该 namespace 下。同时也注意到，多了一个 cgroup，这个 namespace 是 4.6 版本的内核才支持的。Docker 目前对它的支持普及度还不高。所以我们暂时先不考虑它。 下面通过简单的代码来实现 6 种 namespace 的隔离效果，让大家有个直观的印象。 UTS namespace UTS namespace 提供了主机名和域名的隔离，这样每个容器就拥有独立的主机名和域名了，在网络上就可以被视为一个独立的节点，在容器中对 hostname 的命名不会对宿主机造成任何影响。 首先，先看总体的代码骨架：12345678910111213141516171819202122232425262728293031#define _GNU_SOURCE#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;stdio.h&gt;#include &lt;sched.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#define STACK_SIZE (1024 * 1024)static char container_stack[STACK_SIZE];char* const container_args[] = &#123; &quot;/bin/bash&quot;, NULL&#125;;// 容器进程运行的程序主函数int container_main(void *args)&#123; printf(&quot;在容器进程中！\\n&quot;); execv(container_args[0], container_args); // 执行/bin/bash return 1;&#125;int main(int args, char *argv[])&#123; printf(&quot;程序开始\\n&quot;); // clone 容器进程 int container_pid = clone(container_main, container_stack + STACK_SIZE, SIGCHLD, NULL); // 等待容器进程结束 waitpid(container_pid, NULL, 0); return 0;&#125; 该程序骨架调用 clone() 函数实现了子进程的创建工作，并定义子进程的执行函数，clone() 第二个参数指定了子进程运行的栈空间大小，第三个参数即为创建不同 namespace 隔离的关键。 对于 UTS namespace，传入 CLONE_NEWUTS，如下：1int container_pid = clone(container_main, container_stack + STACK_SIZE, SIGCHLD | CLONE_NEWUTS, NULL); 为了能够看出容器内和容器外主机名的变化，我们子进程执行函数中加入：1sethostname(&quot;container&quot;, 9); 最终运行可以看到效果如下： IPC namespace IPC namespace 实现了进程间通信的隔离，包括常见的几种进程间通信机制，如信号量，消息队列和共享内存。我们知道，要完成 IPC，需要申请一个全局唯一的标识符，即 IPC 标识符，所以 IPC 资源隔离主要完成的就是隔离 IPC 标识符。 同样，代码修改仅需要加入参数 CLONE_NEWIPC 即可，如下：1int container_pid = clone(container_main, container_stack + STACK_SIZE, SIGCHLD | CLONE_NEWUTS | CLONE_NEWIPC, NULL); 为了看出变化，首先在宿主机上建立一个消息队列： 然后运行程序，进入容器查看 IPC，没有找到原先建立的 IPC 标识，达到了 IPC 隔离。 PID namespace PID namespace 完成的是进程号的隔离，同样在 clone() 中加入 CLONE_NEWPID 参数，如：1int container_pid = clone(container_main, container_stack + STACK_SIZE, SIGCHLD | CLONE_NEWUTS | CLONE_NEWIPC | CLONE_NEWPID, NULL); 效果如下，echo $$ 输出 shell 的 PID 号，发生了变化。 但是对于 ps/top 之类命令却没有改变： 原因是 ps/top 之类的命令底层调用的是文件系统的 /proc 文件内容，由于 /proc 文件系统（procfs）还没有挂载到一个与原 /proc 不同的位置，自然在容器中显示的就是宿主机的进程。 我们可以通过在容器中重新挂载 /proc 即可实现隔离，如下： 这种方式会破坏 root namespace 中的文件系统，当退出容器时，如果 ps 会出现错误，只有再重新挂载一次 /proc 才能恢复。 一劳永逸地解决这个问题最好的方法就是用接下来介绍的 mount namespace。 mount namespace mount namespace 通过隔离文件系统的挂载点来达到对文件系统的隔离。我们依然在代码中加入 CLONE_NEWNS 参数：1int container_pid = clone(container_main, container_stack + STACK_SIZE, SIGCHLD | CLONE_NEWUTS | CLONE_NEWIPC | CLONE_NEWPID | CLONE_NEWNS, NULL); 我验证的效果，当退出容器时，还是会有 mount 错误，这没道理，经多方查阅，没有找到问题的根源（有谁知道，可以留言指出）。 Network namespace Network namespace 实现了网络资源的隔离，包括网络设备、IPv4 和 IPv6 协议栈，IP 路由表，防火墙，/proc/net 目录，/sys/class/net 目录，套接字等。 Network namespace 不同于其他 namespace 可以独立工作，要使得容器进程和宿主机或其他容器进程之间通信，需要某种“桥梁机制”来连接彼此（并没有真正的隔离），这是通过创建 veth pair （虚拟网络设备对，有两端，类似于管道，数据从一端传入能从另一端收到，反之亦然）来实现的。当建立 Network namespace 后，内核会首先建立一个 docker0 网桥，功能类似于 Bridge，用于建立各容器之间和宿主机之间的通信，具体就是分别将 veth pair 的两端分别绑定到 docker0 和新建的 namespace 中。 和其他 namespace 一样，Network namespace 的创建也是加入 CLONE_NEWNET 参数即可。我们可以简单验证下 IP 地址的情况，如下，IP 被隔离了。 User namespace User namespace 主要隔离了安全相关的标识符和属性，包括用户 ID、用户组 ID、root 目录、key 以及特殊权限。简单说，就是一个普通用户的进程通过 clone() 之后在新的 user namespace 中可以拥有不同的用户和用户组，比如可能是超级用户。 同样，可以加入 CLONE_NEWUSER 参数来创建一个 User namespace。然后再子进程执行函数中加入 getuid() 和 getpid() 得到 namespace 内部的 User ID，效果如下： 可以看到，容器内部看到的 UID 和 GID 和外部不同了，默认显示为 65534。这是因为容器找不到其真正的 UID ，所以设置上了最大的UID（其设置定义在/proc/sys/kernel/overflowuid）。另外就是用户变为了 nobody，不再是 root，达到了隔离。 总结 以上就是对 6 种 namespace 从代码上简单直观地演示其实现，当然，真正的实现比这个要复杂得多，然后这 6 种 namespace 实际上也没有完全隔离 Linux 的资源，比如 SElinux、cgroup 以及 /sys 等目录下的资源没有隔离。目前，Docker 在很多方面已经做的很好，但相比虚拟机，仍然有许多安全性问题急需解决。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/categories/Docker/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"容器","slug":"容器","permalink":"https://chambai.github.io/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"Cgroup","slug":"Cgroup","permalink":"https://chambai.github.io/tags/Cgroup/"},{"name":"Namespace","slug":"Namespace","permalink":"https://chambai.github.io/tags/Namespace/"}]},{"title":"容器生态系统","slug":"tech/容器生态系统","date":"2018-03-02T05:16:14.000Z","updated":"2019-04-11T14:38:24.058Z","comments":true,"path":"2018/03/02/tech/容器生态系统/","link":"","permalink":"https://chambai.github.io/2018/03/02/tech/容器生态系统/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 说起生态，不禁让人想起贾跃亭的乐视，想当初我多次被它的生态布局给震撼到，一度相信它将要超越百度，坐拥互联网三大江山的宝座，但没过时日，各种劲爆的新闻就把它推到了风口浪尖上，现在想想也是让人唏嘘，但不管怎么说，愿它好吧，毕竟这种敢想敢做的精神还是值得敬佩的。 回到技术这个领域，不得不说，技术更新迭代的速度快得让人应接不暇，就容器技术这个领域来说，从 Docker 面世短短的 2-3 年时间里，就衍生出多种与之相关的技术框架，由此形成了一个小小的生态系统。 一谈到容器，大家都会想到 Docker，本文也主要从 Docker 角度来讲容器生态系统。 1 容器基础技术 Docker 的本质是利用 Linux 内核的 namespace 和 cgroups 机制，构建出一个隔离的进程（容器进程）。所以，容器的基础技术主要涉及到 Linux 内核的 namespace 和 cgroups 技术。 2 容器核心技术 容器核心技术保证容器能够在主机上运行起来，包括容器规范、容器 runtime、容器管理工具、容器定义工具、Registry 和容器 OS。 容器规范旨在将多种容器（如 OpenVZ，rkt，Docker 等）融合在一起，解决各种兼容问题，为此还专门成立了一个叫 OCI（Open Container Initiative）的组织来专门制定相关的容器规范。 容器 runtime 是容器真正运行的地方，一般需要依赖内核，也有运行在专门制定的容器 OS 上，关于容器 OS，下面会做介绍。lxc 、runc 和 rkt 是目前三种主流的 runtime。 lxc 是 Linux 上老牌的容器 runtime。Docker 最初也是用 lxc 作为 runtime。runc 是 Docker 自己开发的容器 runtime，符合 oci 规范，也是现在 Docker 的默认 runtime。rkt 是 CoreOS 开发的容器 runtime，符合 oci 规范，因而能够运行 Docker 的容器。 容器管理工具是对外提供给用户的 CLI 接口，方便用户管理容器，对内与 runtime 交互。对应于不同的 runtime，分别有三种不同的管理工具：lxd、docker engine 和 rkt cli。 容器定义工具允许用户定义容器的内容和属性，如容器需要什么镜像，装载什么应用等。常用有三种工具：docker images、Dockerfile 和 ACL（App Container Image）。 docker images 是容器镜像，runtime 依据 docker images 创建容器。dockerfile 是包含若干命令的文本文件，可以通过这些命令创建出 docker images。ACI 与 docker images 类似，只不过它是由 CoreOS 开发的 rkt 容器的 images 格式。 Registry 是存放容器镜像的仓库，包括 Docker Registry、Docker Hub 和 Quay.io，以及国内的 DaoCloud.io。企业可以用 Docker Registry 构建私有的 Registry。 容器 OS 不同于 runtime，是专门制定出来运行容器的操作系统，与常规 OS 相比，容器 OS 通常体积更小，启动更快。因为是为容器定制的 OS，通常它们运行容器的效率会更高。目前已经存在不少容器 OS，CoreOS、atomic 和 ubuntu core 是其中的杰出代表。 3 容器平台技术 随着容器部署的增多，容器也逐步过渡到容器云，容器平台技术就是让容器作为集群在分布式的环境中运行，包括了容器编排引擎、容器管理平台和基于容器的 PaaS。 容器编排引擎就是管理、调度容器在集群中运行，以保障资源的合理利用。有名的三大编排引擎为 docker swarm、kubernetes 和 mesos。其中，kubernetes 这两年脱颖而出，成为其中的佼佼者。 容器管理平台是在编排引擎之上更为通用的一个平台，它抽象了编排引擎的底层实现细节，能够支持多种编排引擎，提供友好的接口给用户，极大方便了管理。Rancher 和 ContainerShip 是容器管理平台的典型代表。 基于容器的 PaaS 基于容器的 PaaS 为微服务应用开发人员和公司提供了开发、部署和管理应用的平台，使用户不必关心底层基础设施而专注于应用的开发。Deis、Flynn 和 Dokku 都是开源容器 PaaS 的代表。 4 容器支持技术 容器的出现又重新让一些古老的技术焕发第二春，如监控、网络、数据管理、日志等技术，由于容器技术的不同，需要制定相应的符合容器规范的技术框架，由此有了容器支持技术，用于支持容器提供更丰富能力的基础设施。 其中包括容器网络、服务发现、监控、数据管理、日志管理和安全性。 容器网络主要用于解决容器与容器之间，容器与其他实体之间的连通性和隔离性。包括 Docker 原生的网络解决方案 docker network，以及第三方的网络解决方案，如 flannel、weave 和 calico。 服务发现保证容器使用过程中资源动态变化的感知性，如当负载增加时，集群会自动创建新的容器；负载减小，多余的容器会被销毁。容器也会根据 host 的资源使用情况在不同 host 中迁移，容器的 IP 和端口也会随之发生变化。在这种动态环境下，就需要有一种机制来感知这种变化，服务发现就是做这样的工作。etcd、consul 和 zookeeper 是服务发现的典型解决方案。 监控室保证容器健康运行，且让用户实时了解应用运行状态的工具，除了 Docker 原生的监控工具 docker ps/top/stats 之外，也有第三方的监控方案，如 sysdig、cAdvisor/Heapster 和 Weave Scope 。 数据管理保证容器在不同的 host 之间迁移时数据的动态迁移。有名的方案是 Flocker。 日志管理为问题排查和事件管理提供了重要依据。docker logs 是 Docker 原生的日志工具。而 logspout 对日志提供了路由功能，它可以收集不同容器的日志并转发给其他工具进行后处理。 容器安全性保证容器的安全，不被攻击，OpenSCAP 能够对容器镜像进行扫描，发现潜在的漏洞。 PS：本文借鉴了知名云计算博主 CloudMan 的博文：http://www.cnblogs.com/CloudMan6/p/6706546.html，感谢 CloudMan 呈现这么好的内容。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/categories/Docker/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"容器","slug":"容器","permalink":"https://chambai.github.io/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"}]},{"title":"容器进化史","slug":"tech/容器进化史","date":"2018-02-28T05:16:14.000Z","updated":"2019-04-11T14:38:24.052Z","comments":true,"path":"2018/02/28/tech/容器进化史/","link":"","permalink":"https://chambai.github.io/2018/02/28/tech/容器进化史/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 和虚拟机一样，容器技术也是一种资源隔离的虚拟化技术。我们追溯它的历史，会发现它的技术雏形早已有之。 1 容器简史 容器概念始于 1979 年提出的 UNIX chroot，它是一个 UNIX 操作系统的系统调用，将一个进程及其子进程的根目录改变到文件系统中的一个新位置，让这些进程只能访问到这个新的位置，从而达到了进程隔离的目的。 2000 年的时候 FreeBSD 开发了一个类似于 chroot 的容器技术 Jails，这是最早期，也是功能最多的容器技术。Jails 英译过来是监狱的意思，这个“监狱”（用沙盒更为准确）包含了文件系统、用户、网络、进程等的隔离。 2001 Linux 也发布自己的容器技术 Linux VServer，2004 Solaris 也发布了 Solaris Containers，两者都将资源进行划分，形成一个个 zones，又叫做虚拟服务器。 2005 年推出 OpenVZ，它通过对 Linux 内核进行补丁来提供虚拟化的支持，每个 OpenVZ 容器完整支持了文件系统、用户及用户组、进程、网络、设备和 IPC 对象的隔离。 2007 年 Google 实现了 Control Groups( cgroups )，并加入到 Linux 内核中，这是划时代的，为后期容器的资源配额提供了技术保障。 2008 年基于 cgroups 和 linux namespace 推出了第一个最为完善的 Linux 容器 LXC。 2013 年推出到现在为止最为流行和使用最广泛的容器 Docker，相比其他早期的容器技术，Docker 引入了一整套容器管理的生态系统，包括分层的镜像模型，容器注册库，友好的 Rest API 等。 2014 年 CoreOS 也推出了一个类似于 Docker 的容器 Rocket，CoreOS 是一个更加轻量级的 Linux 操作系统，在安全性上比 Docker 更严格。 2016 年微软也在 Windows 上提供了容器的支持，Docker 可以以原生方式运行在 Windows 上，而不是需要使用 Linux 虚拟机。 基本上到这个时间节点，容器技术就已经很成熟了，再往后就是容器云的发展，由此也衍生出多种容器云的平台管理技术，其中以 kubernetes 最为出众，有了这样一些细粒度的容器集群管理技术，也为微服务的发展奠定了基石。因此，对于未来来说，应用的微服务化是一个较大的趋势。 2 为什么需要容器 其一，这是技术演进的一种创新结果，其二，这是人们追求高效生产活动的一种工具。 随着软件开发的发展，相比于早期的集中式应用部署方式，现在的应用基本都是采用分布式的部署方式，一个应用可能包含多种服务或多个模块，因此多种服务可能部署在多种环境中，如虚拟服务器、公有云、私有云等，由于多种服务之间存在一些依赖关系，所以可能存在应用在运行过程中的动态迁移问题，那这时如何保证不同服务在不同环境中都能平滑的适配，不需要根据环境的不同而去进行相应的定制，就显得尤为重要。 就像货物的运输问题一样，如何将不同的货物放在不同的运输机器上，减少因货物的不同而频繁进行货物的装载和卸载，浪费大量的人力物力。 为此人们发明了集装箱，将货物根据尺寸形状等的不同，用不同规格的集装箱装载，然后再放到运输机上运输，由于集装箱密封，只有货物到达目的地才需拆封，在运输过程能够在不同运输机上平滑过渡，避免了资源的浪费。 因此集装箱被誉为是运输业与世界贸易最重要的发明。 Docker 容器的思想就是采用集装箱思想，为应用提供了一个基于容器的标准化运输系统。Docker 可以将任何应用及其依赖打包成一个轻量级、可移植、自包含的容器。容器可以运行在几乎所有的操作系统上。这样容器就可以跑在任何环境中，因此才有了那句话： Build Once, Run Anywhere 这种集装箱的思想我们也能从 Docker 的 Logo 中看出来，这不就是一堆集装箱吗？ PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/categories/Docker/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"容器","slug":"容器","permalink":"https://chambai.github.io/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"}]},{"title":"2018 云计算领域的技术趋势预测","slug":"tech/2018_云计算领域的技术趋势预测","date":"2018-02-20T05:16:14.000Z","updated":"2019-04-11T14:38:24.082Z","comments":true,"path":"2018/02/20/tech/2018_云计算领域的技术趋势预测/","link":"","permalink":"https://chambai.github.io/2018/02/20/tech/2018_云计算领域的技术趋势预测/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 作为一个技术人，保持对技术的敏感是必要的，尤其是在互联网这个行业，昨天还觉得移动互联网挺酷炫的，今天就被人工智能这波潮流给掩盖掉了锋芒，泯然众人矣。虽然我们不一定要赶时髦，踏踏实实做好技术才是好的，但保持这样一份好奇心，也许会让我们的技术之路走得更加顺畅一点。 对于云计算这个领域，虽然早已是陈词滥调，但新瓶装旧酒，总会玩出很多新鲜的花样。作为一个没什么经验的初学者，我斗胆预测一下 2018 年云计算领域的几大技术趋势，仅供参考。 混合云 混合云其实叫嚣了很多年，但一直没有得到真正的应用，现在大部分企业和个人还是部署公有云和私有云为主，随着市场的增长和用户需求的增加，尤其是对云安全这块的需求，相信在 2018 年会有众多客户将业务迁移到混合云上。公有云市场的一些大公司，像阿里云，腾讯云会大力布局其混合云市场，而私有云市场则会更多选择与公有云大公司合作来布局自己的混合云市场，另外，像 zstack 这样的混合云开源技术框架会得到较多青睐，兴许可以成为下一个 OpenStack。 微服务 2014 年，AWS 推出了 serverless （无服务器）计算服务 Lambda，微服务便是在这样一种模式下提出的一种架构设计思想。此后几年各大互联网公司都在引入微服务的设计思想，应用在自家的业务产品中。可以说，微服务架构设计得好，不管是开发测试，还是运维管理都会大大提升效率和增强产品的可维护性和可扩展性。2018 年，微服务将会引发一波小高潮。很多大公司会开放他们的微服务设计框架，及相关的开源项目。 kubernetes( k8s ) 容器编排 容器技术现在基本上已经成为各大互联网公司的标配，随着部署的容器应用的增多，容器云的编排与管理已经成了不得不面对的问题。k8s 的强势崛起，在短短时间之内就刮起一阵旋风，令 docker 家族闻风丧胆，最终不得不缴械投降，2018 年，k8s 会得到井喷式应用。 雾计算 雾计算，或者边缘计算，在学术界已经不算什么新鲜词了，但在工业界还少有耳闻，但其实 cisco 和一些物联网公司早已开发出自己的雾计算产品，并大量应用在网络边缘的计算设备中。据我所知的，智云这家公司早已推出自己的雾计算平台，并应用在很多物联网项目中，大公司中，百度在 2018 年年初也率先推出了自己的雾计算项目「智能边缘」，旨在通过提供 “IoT Edge SDK” 组件的方式进行数据的本地处理，结合 AI 技术，为用户打造实时响应，智能推断，安全可靠的服务体验。相信在 2018 年会有更多的雾计算产品出现，我们拭目以待吧。 以上就是我对 2018 年云计算这个领域技术趋势的大致预测，预测本身就代表着不确定性，但保持对新技术的敏感性，能让我们提前做一些准备，毕竟作为技术人，终身学习是最基本的职业素养。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"01 云计算","slug":"01-云计算","permalink":"https://chambai.github.io/categories/01-云计算/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"雾计算","slug":"雾计算","permalink":"https://chambai.github.io/tags/雾计算/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://chambai.github.io/tags/Kubernetes/"},{"name":"混合云","slug":"混合云","permalink":"https://chambai.github.io/tags/混合云/"},{"name":"微服务","slug":"微服务","permalink":"https://chambai.github.io/tags/微服务/"}]},{"title":"雾计算技术架构浅析与应用概览","slug":"tech/雾计算技术架构浅析与应用概览","date":"2018-02-13T05:16:14.000Z","updated":"2019-04-11T14:38:24.053Z","comments":true,"path":"2018/02/13/tech/雾计算技术架构浅析与应用概览/","link":"","permalink":"https://chambai.github.io/2018/02/13/tech/雾计算技术架构浅析与应用概览/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 上篇文章简单回顾了 [雾计算的简史]，本篇将对雾计算的架构和相关的应用场景做一点小小的阐述。这也算是对自己近两年来的研究工作做一点总结。从科学研究的角度，我更多做的是理论性的研究工作，因此，本文也只限于从理论角度做一点记录，更多的实践工作还望跟进Cisco和相关公司的研究进展。 1. 从云计算到雾计算的转变 Cisco 对「雾计算」的定义是：将云计算资源和服务从网络的核心（network core）扩展到网络的边缘（network edge），以满足多种IoT应用服务质量（QoS）的需求，提高用户体验。 传统的云计算架构位于网络的核心，即 Internet 数据中心。用户终端和云端之间采用Client-Server的通信模式，物理距离较远，用户消息需要经过若干跳的网络传输才能达到。另外，云数据中心采用「集中式」的资源管理方式，不易够灵活且不易扩展。如下左图是一种简化的架构图。 集中式 分布式 雾计算架构位于网络的边缘。Cisco对网络边缘的定义是广义的，只要相对网络核心更接近于用户层面的，都可以称之为网络边缘，如接入网、近场的网关设备、本地设备或与设备相连的通信模块，更具体一点就是路由器、交换机、AP、服务器、PC、Mobile等等这些设备都可以构成网络边缘，而提供雾计算能力的这些设备，我们通常称之为「雾结点」。 从这个层面上看，雾计算更多看成是一种计算模式。只要能够为用户提供就近的资源和服务访问，就可以看作是雾计算。IOx是Cisco实现的雾计算架构的解决方案，开发者能够利用它开发相关的应用，并部署到网络的边缘进行管理。更多关于IOx的技术文档请访问 IOx开发者文档。相对于云计算集中式的架构，雾计算采用分布式的架构，更加接近用户，减少网络访问时延的同时，提高了资源管理的灵活性和可扩展性。如上图右图就是一种简化了的雾计算架构图。 2. 雾计算的架构 由于雾计算基础设施部署的灵活性，雾计算的架构呈现也是比较灵活的。通过查阅资料可知大致可以分为两种架构，一种是分层架构，另一种是 D2D( Device to Device )架构。 2.1 分层架构 这种架构很好理解，简单了说，就是用户层、雾计算层和云计算层构成了三层的架构图。其中，雾计算层的结构实现，要完成雾结点的物理资源（包括计算、存储、网络）的抽象和应用或服务（如各种IoT应用程序）的协调，除此之外，当然免不了要提供各种功能模块的计算平台。如下图就是一种理论上可行的雾计算架构。Cisco 的 IOx 就属于这种架构的最佳实践。 图中雾计算资源抽象层（Abstraction Layer）通过可定制的 API 和 UI 在异构的基础设施中，提供统一的资源访问、监控和管理，同时保证多租户的安全性和隐私性。服务协调层（Orchestration Service Layer）主要用于上层应用或服务的生命周期管理和协调。由于雾计算基础设施分布式的特性，所以该层需要实现很多的分布式组件来满足各种应用对资源的动态需求及管理，如分布式的数据库、各种软件中间件和策略管理组件等。详细请访问文章[1]。 2.2 D2D架构 这种架构顾名思义，就是设备到设备的通信，也叫 M2M( Machine to Machine )。云计算和雾计算的本质都是对闲置资源的充分利用，实现共享。D2D架构的特点在于充分利用自己附近的闲置资源来处理自身的应用。比如两台很近的移动设备之间通过蓝牙连接来共享资源，更如移动设备可以访问附近的基站、车辆、咖啡厅的某个服务器等等设备的闲置资源或服务。这种架构较早的实践方案是由文献[2]提出的，他们提出用「Mapreduce」和「Hadoop」这些分布式计算框架实现移动设备之间的任务计算。如下图是一种直观的D2D架构图（图片摘自文献[3]） 3. 雾计算的应用 雾计算满足低时延、动态实时、大规模分布等应用的需求。这些恰是今天多种IoT应用、AI 应用、增强现实和大数据分析应用等的基本需求。具体可以细分到诸多垂直市场，如智慧农业，智能交通，智慧城市，智慧建筑，智能医疗等等。详细内容可访问[5]。 智能交通 通过智能交通控制系统中的雾节点网络，可以分享高峰时刻的交通信息、进行本地化事故处理、重新规划交通路径。同样，人们也可以很容易从娱乐系统中获取资源，因为每个公共交通用户手机上具有雾计算应用，让用户可以共享相邻用户数据，相互提供可靠的网络连接。 对于公共交通中的无人驾驶汽车安全系统、道路监控系统、售票系统来说，可以搜集许多基于传感器和视频的数据。这些系统，理想地来说，只将一些汇总的数据上传到云端，从而不侵犯用户隐私，同时智能地保证用户带宽。云，可以提取有用的商业价值，例如如何在更长时间级别规划路径，而不是短期提供低延时保证。在边缘，可以进行实时决策，策略控制。而在云端，可以进行大数据分析。 智慧农业 对于农业来说，作用体现在肉类和乳制品，水产品，水稻，蔬菜，玉米等的种植和生产。在许多地区，农业通过合作农场形式进行优化。这些农场，已经经过技术革命，应用适量除草剂和杀虫剂，最大化利用水资源，保证产量。更进一步的说，小农场（小于2英亩），将在我们的粮食生产中扮演更重要的角色。这些小农场，也需要最大化资源使用效率。 但是，缺少可信赖或者节约的方法连接云端，无法实时高效的知道除草剂和杀虫剂的效率，动物健康，环境因素，以及水和土壤情况等等，阻碍了生产率提高。另外，农民没有专业IT知识，所以即使让农民和云基础架构连接，也不清楚他们可以如何利用这些资源。所以，本地化计算资源，对于农业来说，积极作用很大。 智慧城市 建立智慧城市一个主要障碍就是：带宽和连接的可用性。当大多数现代城市小区网络容量和峰值带宽受限，只能满足现有居民的需求。对于额外的服务，所预留的带宽很少，Fog正是可以解决这个问题。可以影响人们在城市中的交互和生活方式，帮助提高基础城市相关操作效率，例如延时，连接性，隐私，安全等等，提供高效和人性化服务。 智慧城市挑战还来自于安全，关键指标和高级分析。城市网络，可能携带敏感数据以及生命攸关的系统，例如智能运输避障应用，第一应答者通信等等，所以需要安全和信赖。视频监控高级分析，也是保证快速有效定位城市犯罪的关键。所以，智慧城市部署需要本地化。Fog架构，具有安全性，数据加密和分布式分析，在智慧城市中扮演重要角色。 智慧建筑 建筑管理自动化，是边缘智能和本地化处理的一个经典案例。商业建筑，会包含许多传感器，测量不同建筑操作参数，包括温度，湿度，门开关，出入证读取，泊车位占有率，安全，电梯和空气质量。这些传感器不断测量建筑内部数据，存储在本地，然后驱动制动器，对于建筑内条件进行优化。从传感器测得的数据后，需要进行实时的计算，从而决定暖通空调是否要运行慢点，当房间没人时关灯，感知到火情时触发火警，在起火时启动消防装置等等。Fog部署模型，可自主的进行本地控制功能操作。 另外，长期建筑遥测数据和控制动作，可以上传到云端，进行关于电、水、燃气消耗、操作效率、设备检修时间、预防性活动和其他相关操作的更大范围分析。基于这些存储的操作历史，可以训练机器学习模型，在本地“雾”基础架构中，使用“云”训练优化操作策略。 4. 总结 其实这样看下来，可以发现，雾计算也不是什么新鲜的技术，都是原有的技术随着时间推移的一种架构演进，其中体现的分布式计算的思想很早就存在了。不禁想起计算机领域的一句至理：All problems in computer science can be solved by another level of indirection（计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决） 福利： 公众号后台回复“雾计算”关键字，免费获赠雾计算资料一份。 Preference: [1] A Paradigm Shift from Cloud to Fog Computing.[2] Misco: a mapreduce framework for mobile systems.[3] To Offload or to Wait An Opportunistic Offloading Algorithm for Parallel Tasks in a Mobile Cloud.[4] IoT, from cloud to fog computing[5] OpenFog开放雾计算架构及其垂直市场应用[6] Cisco IOx in Cisco Live 2014: Showcasing“fog computing”at work[7] openfogconsortium.org[8] 机智云4.0发布 推下一代IOT雾计算概念[9] 毋庸置疑的雾计算 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"02 雾计算","slug":"02-雾计算","permalink":"https://chambai.github.io/categories/02-雾计算/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"雾计算","slug":"雾计算","permalink":"https://chambai.github.io/tags/雾计算/"},{"name":"边缘计算","slug":"边缘计算","permalink":"https://chambai.github.io/tags/边缘计算/"}]},{"title":"vhost-user 简介","slug":"tech/vhost_user_简介","date":"2018-02-06T05:16:14.000Z","updated":"2019-04-11T14:38:24.067Z","comments":true,"path":"2018/02/06/tech/vhost_user_简介/","link":"","permalink":"https://chambai.github.io/2018/02/06/tech/vhost_user_简介/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 1. 什么是 vhost-user在 vhost 的方案中，由于 vhost 实现在内核中，guest 与 vhost 的通信，相较于原生的 virtio 方式性能上有了一定程度的提升，从 guest 到 kvm.ko 的交互只有一次用户态的切换以及数据拷贝。这个方案对于不同 host 之间的通信，或者 guest 到 host nic 之间的通信是比较好的，但是对于某些用户态进程间的通信，比如数据面的通信方案，openvswitch 和与之类似的 SDN 的解决方案，guest 需要和 host 用户态的 vswitch 进行数据交换，如果采用 vhost 的方案，guest 和 host 之间又存在多次的上下文切换和数据拷贝，为了避免这种情况，业界就想出将 vhost 从内核态移到用户态。这就是 vhost-user 的实现。 2 vhost-user 的实现 vhost-user 和 vhost 的实现原理是一样，都是采用 vring 完成共享内存，eventfd 机制完成事件通知。不同在于 vhost 实现在内核中，而 vhost-user 实现在用户空间中，用于用户空间中两个进程之间的通信，其采用共享内存的通信方式。 vhost-user 基于 C/S 的模式，采用 UNIX 域套接字（UNIX domain socket）来完成进程间的事件通知和数据交互，相比 vhost 中采用 ioctl 的方式，vhost-user 采用 socket 的方式大大简化了操作。 vhost-user 基于 vring 这套通用的共享内存通信方案，只要 client 和 server 按照 vring 提供的接口实现所需功能即可，常见的实现方案是 client 实现在 guest OS 中，一般是集成在 virtio 驱动上，server 端实现在 qemu 中，也可以实现在各种数据面中，如 OVS，Snabbswitch 等虚拟交换机。 如果使用 qemu 作为 vhost-user 的 server 端实现，在启动 qemu 时，我们需要指定 -mem-path 和 -netdev 参数，如： 123$ qemu -m 1024 -mem-path /hugetlbfs,prealloc=on,share=on \\-netdev type=vhost-user,id=net0,file=/path/to/socket \\-device virtio-net-pci,netdev=net0 指定 -mem-path 意味着 qemu 会在 guest OS 的内存中创建一个文件，share=on 选项允许其他进程访问这个文件，也就意味着能访问 guest OS 内存，达到共享内存的目的。 -netdev type=vhost-user 指定通信方案，file=/path/to/socket 指定 socket 文件。 当 qemu 启动之后，首先会进行 vring 的初始化，并通过 socket 建立 C/S 的共享内存区域和事件机制，然后 client 通过 eventfd 将 virtio kick 事件通知到 server 端，server 端同样通过 eventfd 进行响应，完成整个数据交互。 3 几个例子 开源社区中实现了一个项目 Vapp，主要是用来测试 vhost-user 的 C/S 模式的，github 地址如下：https://github.com/virtualopensystems/vapp.git 使用： 1234567$ git clone https://github.com/virtualopensystems/vapp.git$ cd vapp$ make// 运行 server 端$ ./vhost -s ./vhost.sock// 运行 client 端$ ./vhost -q ./vhost.sock 通过以上步骤，就可以启动 vhost-user 的 C/S 模式。 另外还有例子就是集成在虚拟交换机 Snabbswitch 上的 vhost-user，通过以下方式获得 vhost-user 分支： 12345$ git clone -b vhostuser --recursive https://github.com/SnabbCo/snabbswitch.git$ cd snabbswitch$ make测试：$ sudo src/snabbswitch -t apps.vhost.vhost_user 还有例子就是 qemu 上的实现，这也是最原早的实现，同样通过以下方式来获得使用： 12345$ git clone -b vhost-user-v5 https://github.com/virtualopensystems/qemu.git$ mkdir qemu/obj$ cd qemu/obj/$ ../configure --target-list=x86_64-softmmu$ make -j 除此之外，还有很多的实现，如 OVS 和 DPDK 上都有实现，这实际上是集成了 vhost-user 的通用 API。 4 总结 virtio，vhost，vhost-user 是基于场景和性能而提出的三种 guest 和 host 之间的通信方案，三种方案，各有优劣。vhost-user 用在很多数据面之上的进程间通信，效率高。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"03 虚拟化","slug":"03-虚拟化","permalink":"https://chambai.github.io/categories/03-虚拟化/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"KVM","slug":"KVM","permalink":"https://chambai.github.io/tags/KVM/"},{"name":"Qemu","slug":"Qemu","permalink":"https://chambai.github.io/tags/Qemu/"},{"name":"vhost_user","slug":"vhost-user","permalink":"https://chambai.github.io/tags/vhost-user/"},{"name":"vhost","slug":"vhost","permalink":"https://chambai.github.io/tags/vhost/"},{"name":"virtio","slug":"virtio","permalink":"https://chambai.github.io/tags/virtio/"}]},{"title":"vhost 简介","slug":"tech/vhost_简介","date":"2018-01-23T05:16:14.000Z","updated":"2019-04-11T14:38:24.076Z","comments":true,"path":"2018/01/23/tech/vhost_简介/","link":"","permalink":"https://chambai.github.io/2018/01/23/tech/vhost_简介/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 1. 什么是 vhost vhost 是 virtio 的一种后端实现方案，在 virtio 简介中，我们已经提到 virtio 是一种半虚拟化的实现方案，需要虚拟机端和主机端都提供驱动才能完成通信，通常，virtio 主机端的驱动是实现在用户空间的 qemu 中，而 vhost 是实现在内核中，是内核的一个模块 vhost-net.ko。为什么要实现在内核中，有什么好处呢，请接着往下看。 2. 为什么要用 vhost 在 virtio 的机制中，guest 与 用户空间的 Hypervisor 通信，会造成多次的数据拷贝和 CPU 特权级的上下文切换。例如 guest 发包给外部网络，首先，guest 需要切换到 host kernel，然后 host kernel 会切换到 qemu 来处理 guest 的请求， Hypervisor 通过系统调用将数据包发送到外部网络后，会切换回 host kernel ， 最后再切换回 guest。这样漫长的路径无疑会带来性能上的损失。 vhost 正是在这样的背景下提出的一种改善方案，它是位于 host kernel 的一个模块，用于和 guest 直接通信，数据交换直接在 guest 和 host kernel 之间通过 virtqueue 来进行，qemu 不参与通信，但也没有完全退出舞台，它还要负责一些控制层面的事情，比如和 KVM 之间的控制指令的下发等。 3. vhost 的数据流程 下图左半部分是 vhost 负责将数据发往外部网络的过程， 右半部分是 vhost 大概的数据交互流程图。其中，qemu 还是需要负责 virtio 设备的适配模拟，负责用户空间某些管理控制事件的处理，而 vhost 实现较为纯净，以一个独立的模块完成 guest 和 host kernel 的数据交换过程。 vhost 与 virtio 前端的通信主要采用一种事件驱动 eventfd 的机制来实现，guest 通知 vhost 的事件要借助 kvm.ko 模块来完成，vhost 初始化期间，会启动一个工作线程 work 来监听 eventfd，一旦 guest 发出对 vhost 的 kick event，kvm.ko 触发 ioeventfd 通知到 vhost，vhost 通过 virtqueue 的 avail ring 获取数据，并设置 used ring。同样，从 vhost 工作线程向 guest 通信时，也采用同样的机制，只不过这种情况发的是一个回调的 call envent，kvm.ko 触发 irqfd 通知 guest。 4. 总结 vhost 与 kvm 的事件通信通过 eventfd 机制来实现，主要包括两个方向的 event，一个是 guest 到 vhost 方向的 kick event，通过 ioeventfd 实现；另一个是 vhost 到 guest 方向的 call event，通过 irqfd 实现。 代码分析整个通信的流程：http://royluo.org/2014/08/22/vhost/ PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"03 虚拟化","slug":"03-虚拟化","permalink":"https://chambai.github.io/categories/03-虚拟化/"}],"tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"KVM","slug":"KVM","permalink":"https://chambai.github.io/tags/KVM/"},{"name":"Qemu","slug":"Qemu","permalink":"https://chambai.github.io/tags/Qemu/"},{"name":"vhost","slug":"vhost","permalink":"https://chambai.github.io/tags/vhost/"},{"name":"virtio","slug":"virtio","permalink":"https://chambai.github.io/tags/virtio/"}]},{"title":"用户空间网络提升 NFV 的性能","slug":"tech/用户空间网络提升_NFV_的性能","date":"2018-01-21T05:16:14.000Z","updated":"2019-04-11T14:38:24.055Z","comments":true,"path":"2018/01/21/tech/用户空间网络提升_NFV_的性能/","link":"","permalink":"https://chambai.github.io/2018/01/21/tech/用户空间网络提升_NFV_的性能/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 12本文是一篇翻译，翻译自：https://software.intel.com/en-us/blogs/2015/06/12/user-space-networking-fuels-nfv-performance，文章有点老了，15年写的，但是文章总结了一些用户态的协议栈，很有学习参考的意义。 用户态协议栈 如今，作为一个网络空间的软件开发人员是非常激动人心的，因为工程师的角色随着这个世界的规则在逐渐发生改变。 过去这 15 年来，人们对高性能网络做了很多努力，网络模型也发生了很多改变，起初，数据包的收发都要推送到内核才能完成，现在，不用内核态的参与也可以完成。这种改变的背后主要是在解决以下的几个问题：1）用户态和内核态上下文切换的开销；2）软硬中断的开销；3）数据拷贝的开销等等。 最近，很多人在讨论 mTCP——一个实现了用户态协议栈的开源库，这种技术在很大程度上就颠覆了传统的网络模型，使得网络收发包的效率大大提升。它充分利用了 CPU 的亲和性，共享内存，批处理等技术来实现高效的 I/O 事件。与之类似的技术也相继被提出。 实验表明，mTCP 这种用户态协议栈，相较原生的内核协议栈，在处理多种流行的应用时的性能得到较大提升，如 SSLShader 提升了 33%，lighttpd 提升了 320%。 软件形态的改变离不开硬件的革新。由以前的单核系统到如今多核系统的性能扩展，直接导致了网络软件架构的改变。例如，以前内核所做的所有功能和处理，包括网络驱动程序，现在都可以被直接放到用户空间中来实现，应用程序可以直接访问底层的 NUMA 结构，利用 CPU 的亲和性，以及多核特性并行处理任务。这种设计避免了上下文之间的切换开销，可以显著降低数据传输的延迟和 CPU 使用，同时提高吞吐量和带宽。另外，提供一种运行到完成（run-to-completion）的模型能够让不同的核独立并行地完成不同的任务。 随着网络的发展，我们现在看到了大量的开源项目，都在将内核协议栈移到用户空间来做。它们的做法存在一些区别，像 mTCP，它的协议栈是从零开始开发的，而其他很多项目则是基于 FreeBSD 的来做，这主要是因为 FreeBSD 的协议栈具有 “最健壮的网络协议栈的声誉”，此外，很多存储解决方案也是采用的 FreeBSD 来作为其核心操作系统。当然，Linux 协议栈也是可以采用的。 这些用户态协议栈怎么做到绕过内核的，这就离不开 DPDK 的支持。利用 DPDK，用户态协议栈可以创建一个中断来将数据包从 NIC 的缓冲区直接映射到用户空间，然后利用协议栈的特性来管理 TCP/IP 数据包的处理和传输。 DPDK 还可以作为一些 vSwitch（虚拟交换机）的加速器，这些 vSwitch 包含 OpenFlow 协议的完整实现，以及与 OpenStack Neutron 的整合。 下面，我们收集了一些发现的开源项目，无论你决定使用一个 vSwitch 还是一个完整的网络协议栈，网络开发人员都有很多选择，可以将应用程序移到用户空间，并在多核系统上扩展性能。 DPDK-Enabled vSwitch： OVS Open vSwitch 是一个多核虚拟交换机平台，支持标准的管理接口和开放可扩展的可编程接口，支持第三方的控制接入。https://github.com/openvswitch/ovs Lagopus Lagopus 是另一个多核虚拟交换的实现，功能和 OVS 差不多，支持多种网络协议，如 Ethernet，VLAN，QinQ，MAC-in-MAC，MPLS 和 PBB，以及隧道协议，如 GRE，VxLan 和 GTP。https://github.com/lagopus/lagopus/blob/master/QUICKSTART.md Snabb Snabb 是一个简单且快速的数据包处理工具箱。https://github.com/SnabbCo/snabbswitch/blob/master/README.md xDPd xDPd 是一个多平台，多 OpenFlow 版本支持的开源 datapath，主要专注在性能和可扩展性上。https://github.com/bisdn/xdpd/blob/stable/README 从零开发的用户空间协议栈套件 mTCP mTCP 是一个针对多核系统的高可扩展性的用户空间 TCP/IP 协议栈。https://github.com/eunyoung14/mtcp/blob/master/README Mirage-Tcpip mirage-tcpip 是一个针对 MirageOS 这种 “库操作系统” 而开发的一个用户态网络协议栈，开发的语言是 OCaml。https://github.com/mirage/mirage-tcpip IwIP IwIP 针对 RAM 平台的精简版的 TCP/IP 协议栈实现。http://git.savannah.gnu.org/cgit/lwip.git/tree/README 移植版的用户空间协议栈套件 Arrakis 针对多核系统的用户空间 OS，移植于 IwIP。https://github.com/UWNetworksLab/arrakis/blob/master/README_ARRAKIS libuinet 用户空间的 TCP/IP 协议栈，移植于 FreeBSD。https://github.com/pkelsey/libuinet/blob/master/README NUSE (libos) 一个基于 Linux 的库操作系统，移植于 Linux。https://github.com/libos-nuse/net-next-nuse/wiki/Quick-Start OpenDP 一个针对 DPDK TCP/IP 协议栈的数据面，移植于 FreeBSD。https://github.com/opendp/dpdk-odp/wiki OpenOnload 一个高性能的用户态协议栈，移植于 IwIP。http://www.openonload.org/download/openonload-201205-README.txt OSv 一个针对虚拟机的开源操作系统。移植于 FreeBSD。https://github.com/cloudius-systems/osv/blob/master/README.md Sandstorm 一个针对个人服务器安全的开源网络平台，移植于 FreeBSD。https://github.com/sandstorm-io/sandstorm/blob/master/README.md 总结 1、这篇文字的亮点在于总结了当前阶段业界出现的一些用户空间协议栈，对于文章标题提到的 NFV 在文中则只字未提，但其实意思也很明了了。用户空间的协议栈是随着硬件技术的发展，以及新鲜应用场景应运而生的，换句话说，对于像 NFV 这种对性能要求比较高的场景，采用用户态的协议栈是比较合适的。 2、文中是 2015 年写的，这意味着到现在为止，肯定出现了很多比上面总结还要多的方案，其中比较出名的有 SeaStar 和 腾讯开源的 F-Stack，后面找机会再进行详述，敬请期待吧。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"NFV","slug":"NFV","permalink":"https://chambai.github.io/categories/NFV/"}],"tags":[{"name":"DPDK","slug":"DPDK","permalink":"https://chambai.github.io/tags/DPDK/"},{"name":"mTCP","slug":"mTCP","permalink":"https://chambai.github.io/tags/mTCP/"},{"name":"NFV","slug":"NFV","permalink":"https://chambai.github.io/tags/NFV/"}]},{"title":"Linux 网络体系结构全景分析","slug":"tech/Linux_网络体系结构全景分析","date":"2018-01-12T05:16:14.000Z","updated":"2019-04-11T14:38:24.061Z","comments":true,"path":"2018/01/12/tech/Linux_网络体系结构全景分析/","link":"","permalink":"https://chambai.github.io/2018/01/12/tech/Linux_网络体系结构全景分析/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Linux 是一个非常庞大的系统结构，模块众多，各个模块分工合作，共同运作着各自的任务，为 Linux 这个大家庭贡献着自己的力量。 Linux 网络子系统 其中，网络子系统是一个较为复杂的模块，如下图是 Linux 网络子系统的体系结构，自顶向下，可以分应用层、插口层（或协议无关层）、协议层和接口层（或设备驱动层），这个层级关系也分别对应着我们所熟悉的 OSI 七层模型（物理层、数据链路层、网络层、传输层、会话层、表示层和应用层）。 Linux 所有用户态的应用程序要访问链接内核都要依赖系统调用，这是内核提供给用户态的调用接口，这通常是由标准的 C 库函数来实现的。对于网络应用程序，内核提供了一套通用的 socket 系统调用的接口。 插口层，也叫协议无关层，它屏蔽了协议相关的操作，不论是什么协议（UDP，TCP），都提供一组通用的函数接口，也就是 socket 的实现。 协议层，用于实现各种具体的网络协议族，包括 TCP/IP，OSI 和 Unix 域的实现，每个协议族都包含自己的内部结构，例如，对于 TCP/IP 协议族，IP 是最底层，TCP 和 UDP 层在 IP 层的上面。 接口层，包括了通用设备接口，和网络设备通信的设备驱动程序，其中，包串口使用的 SLIP 驱动程序以及以太网使用的以太网驱动程序，以及环回口使用的都是这一层的设备。它对上提供了协议与设备驱动通信的通用接口，对下也提供了一组通用函数供底层网络设备驱动程序使用。具体的细节后面再开文章详细讲述。 以上是从分层的体系结构来看，下面从数据传输的角度来说说，一个数据包是如何依赖这些层次关系被发送/接收的。 首先，数据的发送过程，应用层组织好待发送的数据包，执行系统调用进入内核协议栈，按照层次关系分别进行包头的封装，如到达传输层，封装 TCP/UDP 的包头，进入网络层封装 IP 包头，进入接口层封装 MAC 帧，最后借助驱动将数据包从网卡发送出去。 然后，数据的接收过程正好与发包过程相反，是一个拆包的过程。接口层借助网卡 DMA 硬件中断感知数据包的到来，拆解包头，识别数据，借助软中断机制告知上层进行相应的收包处理，最终用户态执行系统调用接收数据包。 继续细化这个过程，其内部在实现上都是通过具体的数据结构来完成每一层的过渡的，譬如说，应用层和内核之间通过 struct sock 结构实现协议无关的接口调用进行交互，传输层提供 struct proto 的结构来支持多种协议，网络层通过 struct sk_buff 来传递数据，接口层定义 struct net_device 来完成和驱动程序的交互。 Linux 网络体系结构还是比较博大精深的，尤其是这套自顶向下的分层设计方式对很多技术都有借鉴意义。更具体的函数调用和数据收发过程，后面的文章再进行讲述，敬请期待。 总结 Linux 网络子系统的分层模型，数据收发过程，以及核心数据结构。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"}]},{"title":"Linux 下几种零拷贝的方法","slug":"tech/Linux_下几种零拷贝的方法","date":"2018-01-05T05:16:14.000Z","updated":"2019-04-11T14:38:24.080Z","comments":true,"path":"2018/01/05/tech/Linux_下几种零拷贝的方法/","link":"","permalink":"https://chambai.github.io/2018/01/05/tech/Linux_下几种零拷贝的方法/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 本文讲解 Linux 的零拷贝技术，我在「云计算技能图谱」中说过，云计算是一门很庞大的技术学科，融合了很多技术，Linux 算是比较基础的技术，所以，学好 Linux 对于云计算的学习会有比较大的帮助。 本文借鉴并总结了几种比较常见的 Linux 下的零拷贝技术，相关的引用链接见文后，大家如果觉得本文总结得太抽象，可以转到链接看详细解释。 为什么需要零拷贝 传统的 Linux 系统的标准 I/O 接口（read、write）是基于数据拷贝的，也就是数据都是 copy_to_user 或者 copy_from_user，这样做的好处是，通过中间缓存的机制，减少磁盘 I/O 的操作，但是坏处也很明显，大量数据的拷贝，用户态和内核态的频繁切换，会消耗大量的 CPU 资源，严重影响数据传输的性能，有数据表明，在Linux内核协议栈中，这个拷贝的耗时甚至占到了数据包整个处理流程的57.1%。 什么是零拷贝 零拷贝就是这个问题的一个解决方案，通过尽量避免拷贝操作来缓解 CPU 的压力。Linux 下常见的零拷贝技术可以分为两大类：一是针对特定场景，去掉不必要的拷贝；二是去优化整个拷贝的过程。由此看来，零拷贝并没有真正做到“0”拷贝，它更多是一种思想，很多的零拷贝技术都是基于这个思想去做的优化。 零拷贝的几种方法 原始数据拷贝操作 在介绍之前，先看看 Linux 原始的数据拷贝操作是怎样的。如下图，假如一个应用需要从某个磁盘文件中读取内容通过网络发出去，像这样： 123while((n = read(diskfd, buf, BUF_SIZE)) &gt; 0)write(sockfd, buf , n); 那么整个过程就需要经历：1）read 将数据从磁盘文件通过 DMA 等方式拷贝到内核开辟的缓冲区；2）数据从内核缓冲区复制到用户态缓冲区；3）write 将数据从用户态缓冲区复制到内核协议栈开辟的 socket 缓冲区；4）数据从 socket 缓冲区通过 DMA 拷贝到网卡上发出去。 可见，整个过程发生了至少四次数据拷贝，其中两次是 DMA 与硬件通讯来完成，CPU 不直接参与，去掉这两次，仍然有两次 CPU 数据拷贝操作。 方法一：用户态直接 I/O 这种方法可以使应用程序或者运行在用户态下的库函数直接访问硬件设备，数据直接跨过内核进行传输，内核在整个数据传输过程除了会进行必要的虚拟存储配置工作之外，不参与其他任何工作，这种方式能够直接绕过内核，极大提高了性能。 缺陷： 1）这种方法只能适用于那些不需要内核缓冲区处理的应用程序，这些应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如数据库管理系统就是一个代表。 2）这种方法直接操作磁盘 I/O，由于 CPU 和磁盘 I/O 之间的执行时间差距，会造成资源的浪费，解决这个问题需要和异步 I/O 结合使用。 方法二：mmap 这种方法，使用 mmap 来代替 read，可以减少一次拷贝操作，如下： 123buf = mmap(diskfd, len);write(sockfd, buf, len); 应用程序调用 mmap ，磁盘文件中的数据通过 DMA 拷贝到内核缓冲区，接着操作系统会将这个缓冲区与应用程序共享，这样就不用往用户空间拷贝。应用程序调用write ，操作系统直接将数据从内核缓冲区拷贝到 socket 缓冲区，最后再通过 DMA 拷贝到网卡发出去。 缺陷： 1）mmap 隐藏着一个陷阱，当 mmap 一个文件时，如果这个文件被另一个进程所截获，那么 write 系统调用会因为访问非法地址被 SIGBUS 信号终止，SIGBUS 默认会杀死进程并产生一个 coredump，如果服务器被这样终止了，那损失就可能不小了。 解决这个问题通常使用文件的租借锁：首先为文件申请一个租借锁，当其他进程想要截断这个文件时，内核会发送一个实时的 RT_SIGNAL_LEASE 信号，告诉当前进程有进程在试图破坏文件，这样 write 在被 SIGBUS 杀死之前，会被中断，返回已经写入的字节数，并设置 errno 为 success。 通常的做法是在 mmap 之前加锁，操作完之后解锁： 12345678910111213141516171819if(fcntl(diskfd, F_SETSIG, RT_SIGNAL_LEASE) == -1) &#123;perror(&quot;kernel lease set signal&quot;);return -1;&#125;/* l_type can be F_RDLCK F_WRLCK 加锁*//* l_type can be F_UNLCK 解锁*/if(fcntl(diskfd, F_SETLEASE, l_type))&#123;perror(&quot;kernel lease set type&quot;);return -1;&#125; 方法三：sendfile 从Linux 2.1版内核开始，Linux引入了sendfile，也能减少一次拷贝。 123#include&lt;sys/sendfile.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); sendfile 是只发生在内核态的数据传输接口，没有用户态的参与，自然避免了用户态数据拷贝。它指定在 in_fd 和 out_fd 之间传输数据，其中，它规定 in_fd 指向的文件必须是可以 mmap 的，out_fd 必须指向一个套接字，也就是规定数据只能从文件传输到套接字，反之则不行。sendfile 不存在像 mmap 时文件被截获的情况，它自带异常处理机制。 缺陷： 1）只能适用于那些不需要用户态处理的应用程序。 方法四：DMA 辅助的 sendfile 常规 sendfile 还有一次内核态的拷贝操作，能不能也把这次拷贝给去掉呢？ 答案就是这种 DMA 辅助的 sendfile。 这种方法借助硬件的帮助，在数据从内核缓冲区到 socket 缓冲区这一步操作上，并不是拷贝数据，而是拷贝缓冲区描述符，待完成后，DMA 引擎直接将数据从内核缓冲区拷贝到协议引擎中去，避免了最后一次拷贝。 缺陷： 1）除了3.4 中的缺陷，还需要硬件以及驱动程序支持。 2）只适用于将数据从文件拷贝到套接字上。 方法五：splice splice 去掉 sendfile 的使用范围限制，可以用于任意两个文件描述符中传输数据。 12345#define _GNU_SOURCE /* See feature_test_macros(7) */#include &lt;fcntl.h&gt;ssize_t splice(int fd_in, loff_t *off_in, int fd_out, loff_t *off_out, size_t len, unsigned int flags); 但是 splice 也有局限，它使用了 Linux 的管道缓冲机制，所以，它的两个文件描述符参数中至少有一个必须是管道设备。 splice 提供了一种流控制的机制，通过预先定义的水印（watermark）来阻塞写请求，有实验表明，利用这种方法将数据从一个磁盘传输到另外一个磁盘会增加 30%-70% 的吞吐量，CPU负责也会减少一半。 缺陷： 1）同样只适用于不需要用户态处理的程序 2）传输描述符至少有一个是管道设备。 方法六：写时复制 在某些情况下，内核缓冲区可能被多个进程所共享，如果某个进程想要这个共享区进行 write 操作，由于 write 不提供任何的锁操作，那么就会对共享区中的数据造成破坏，写时复制就是 Linux 引入来保护数据的。 写时复制，就是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么就需要将其拷贝到自己的进程地址空间中，这样做并不影响其他进程对这块数据的操作，每个进程要修改的时候才会进行拷贝，所以叫写时拷贝。这种方法在某种程度上能够降低系统开销，如果某个进程永远不会对所访问的数据进行更改，那么也就永远不需要拷贝。 缺陷： 需要 MMU 的支持，MMU 需要知道进程地址空间中哪些页面是只读的，当需要往这些页面写数据时，发出一个异常给操作系统内核，内核会分配新的存储空间来供写入的需求。 方法七：缓冲区共享 这种方法完全改写 I/O 操作，因为传统 I/O 接口都是基于数据拷贝的，要避免拷贝，就去掉原先的那套接口，重新改写，所以这种方法是比较全面的零拷贝技术，目前比较成熟的一个方案是最先在 Solaris 上实现的 fbuf （Fast Buffer，快速缓冲区）。 Fbuf 的思想是每个进程都维护着一个缓冲区池，这个缓冲区池能被同时映射到程序地址空间和内核地址空间，内核和用户共享这个缓冲区池，这样就避免了拷贝。 缺陷： 1）管理共享缓冲区池需要应用程序、网络软件、以及设备驱动程序之间的紧密合作 2）改写 API ，尚处于试验阶段。 高性能网络 I/O 框架——netmap Netmap 基于共享内存的思想，是一个高性能收发原始数据包的框架，由Luigi Rizzo 等人开发完成，其包含了内核模块以及用户态库函数。其目标是，不修改现有操作系统软件以及不需要特殊硬件支持，实现用户态和网卡之间数据包的高性能传递。 在 Netmap 框架下，内核拥有数据包池，发送环\\接收环上的数据包不需要动态申请，有数据到达网卡时，当有数据到达后，直接从数据包池中取出一个数据包，然后将数据放入此数据包中，再将数据包的描述符放入接收环中。内核中的数据包池，通过 mmap 技术映射到用户空间。用户态程序最终通过 netmap_if 获取接收发送环 netmap_ring，进行数据包的获取发送。 总结： 1、零拷贝本质上体现了一种优化的思想 2、直接 I/O，mmap，sendfile，DMA sendfile，splice，缓冲区共享，写时复制…… 参考： （1）Linux 中的零拷贝技术，第 1 部分https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/index.html（2）Linux 中的零拷贝技术，第 2 部分https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/（3）Netmap 原理http://www.tuicool.com/articles/MnIRbuU PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chambai.github.io/tags/Linux/"},{"name":"零拷贝","slug":"零拷贝","permalink":"https://chambai.github.io/tags/零拷贝/"}]},{"title":"雾计算简史","slug":"tech/雾计算简史","date":"2017-12-30T05:16:14.000Z","updated":"2019-04-11T14:38:24.062Z","comments":true,"path":"2017/12/30/tech/雾计算简史/","link":"","permalink":"https://chambai.github.io/2017/12/30/tech/雾计算简史/","excerpt":"","text":"文章首发于我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 在我看来，雾计算和云计算的本质是一样的——都是充分利用「闲置的资源」进行任务的处理。不同在于云计算利用的是网络核心的资源，而雾计算则利用网络边缘的资源。 1961 年，人工智能之父麦卡锡在一次会议上提出了「效用计算」这个概念，第一次体现了这种共享资源的思想。当时计算设备的价格非常昂贵，远非普通企业和机构所能承受，所以就想到将分散的闲置资源整合起来，共享给多个用户使用。类似的概念还有「网络计算」、「分布式计算」、「弹性计算」等，这些概念都是经由学术界提出，并逐步成为支撑工程应用发展的基础理论。 工业界虽说比学术界要落后，但工业界做着让所有人都兴奋的事——让概念标准化，真正让技术实现落地。上面这些概念让人晕乎，虽有差异，但本质一致，所以工业界就统一用「云计算」一词来囊括。 2006 年 8 月 9 日，Google 首席执行官埃里克·施密特在搜索引擎大会(SES San Jose 2006)首次提出云计算(Cloud Computing)的概念。从此云计算的发展进入了井喷时代。 2007 年初，Amazon 推出弹性计算云 EC2 服务；2007 年 11 月，IBM 发布业界首个云计算商业解决方案「蓝云」计划；2008 年 4 月，Google APP Engine 发布；2008 年 Gartner 发布报告，认为云计算代表了今后计算的方向；2009 年 1 月，阿里巴巴在南京建立首个“电子商务云计算中心”；2010 年 1 月，微软正式发布 Microsoft Azure 云平台服务；2010 年 7 月，美国国家航空航天局和包括 Rackspace、AMD、Intel、戴尔等支持厂商共同宣布开放「OpenStack」项目源代码…… 时至今日，云计算已经进入稳定发展时期，面临的是新的问题。 随着移动设备、嵌入式设备和传感设备等智能设备的不断创新和普及，进入了「万物互联网时代（IoT）」，全球的移动数据呈现出疯狂式的增长。 据 Cisco 2016 年做的一个关于移动数据预测报告显示，全球的移动数据将会在 2016 年和 2021 年之间提高 18 倍，2021 年截止将会超过 49 EB。面对大量的数据和新型的应用程序对服务质量的严苛需求，云计算的问题也凸显出来。 首先，云计算中心位于远程的 Internet，对于那些对延迟敏感的应用程序（如视频流、在线游戏等），将会带来较长的传播时延（WAN），这对于用户体验来说是无法忍受的。其次，对移动场景支持不足，特别是对于高速移动的车载网络环境，司机对于路况、交通流等的感知都必须是快速且实时的。再次，无法满足地理位置分布相关的感知环境的实时要求，如大规模的传感网络，要求传感节点定时向其他节点更新自身的信息。再有，大量的设备接入云端，网络带宽就显得捉襟见肘。最后，云计算的安全性和隐私性不容乐观，在用户和云计算中心之间需要经过多跳的网络传输，越深的网络传输，数据的完整性和机密性就越难保证。 以上问题的解决方案，自然是由学术界首先提出的。2009 年卡内基梅隆大学的沙特亚教授等人在其发表的论文[1]中提出「微云（Cloudlet）」的概念。论文指出微云是一种「和云有着同样的技术标准，但邻近用户」的新型计算模式。 这里面蕴含着几层信息。第一，能够提供和云计算一样的服务，但所提供的资源有限，不如云计算能够提供无限的资源；第二，邻近用户，意味着用户请求的响应时延大大减少；第三，雾计算基础设施以分布式的方式部署在网络的边缘，满足高速移动场景和地理位置分布的场景需求，同时，减缓了网络核心的带宽负载；第四，安全性和隐私性较云计算得到较大保障。 这是「雾计算」最初的雏形。之后，学术界又提出很多类似的解决方案，如「Fog Computing」、「Edge Computing」、「Follow me Cloud」、「Small-Cell Cloud」、「Virtual Cloud」、「FemtoCloud」等。 这些概念其实本质都是一样的，都是在讲一件事，就是将「计算去中心化」——将云计算资源和服务从网络的核心转移到网络的边缘，以此来适应今天多种 IoT 应用的需求。和云计算的提出如出一辙，只不过引导这次工业变革的对象不再是 Google，而是 Cisco。 Cisco 在 Cisco Live 2014 会议上首度提出这个概念。Cisco 强调雾计算是依托于现今无处不在的 IoT 应用产生的一种新型计算模式。 相比于云计算，雾计算是一种更加新进和广泛的计算模式，更具扩展性和可持续性。但是雾计算也不能完全取代云计算，必须依托于云计算才能更好地发挥其作用，因此它们的关系是相辅相成，相互联系的。 在会上，Cisco 同时发布了供开发者使用的开发套件 IOx。IOx 是 Cisco 对于雾计算模式的实现。它为开发者提供了一整套的开发框架（包括开发、分发、部署、监控和管理等多种组件）和计算平台，开发者能够将开发好的应用部署到网络的边界上（路由器、交换机等）进行处理。如下是 IOx 的架构图，更多信息请访问 IOx 开发者文档。 雾计算是应现今「人工智能」、「物联网」一波红海而生的技术革新。业界多家企业和组织机构都开始在布局雾计算的生态体系，除了 Cisco、华为这些通讯产商，还有很多云计算、物联网的企业也加入进来。 在中国，最早布局雾计算架构的是成立于2005 年的全球领先的物联网云服务商「智云」。他们在 2016 年初即发布了主打 IoT 雾计算的机智云 4.0，整合了雾计算、物联网大数据和机器学习应用能力，形成了一体化的解决方案。 此外，2015 年 11 月 19 日，Cisco 联合 ARM、Dell、Intel、Microsoft 和普林斯顿大学成立了「开放雾联盟（OpenFog）」，旨在制定雾计算相关的技术标准和推动行业的技术变革。 由此可见，雾计算将会成为继云计算之后的又一波技术浪潮。 PS：最近听一些朋友在谈「雾计算」，正好我研究生期间研究过一段时间这玩意，于是有一种不吐不快之感，遂拿出来跟大家分享了。如果你觉得对你有一点帮助，点赞，转发，不胜感激，或者有什么想跟我探讨的，欢迎留言。 Reference: [1] The Case for VM-Based Cloudlets in Mobile Computing[2] Fog Computing: A Taxonomy, Survey and future direction[3] Edge-centric Computing: Vision and Challenges[4] Edge-Computing: Challenges to support edge-as-a-service[5] A virtual Cloud computing provider for mobile devices[6] Femto Clouds: Leveraging mobile devices to provide Cloud service at the edge[7] Follow me Cloud: interworking federated Clouds and distributed mobile networks PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"02 雾计算","slug":"02-雾计算","permalink":"https://chambai.github.io/categories/02-雾计算/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"雾计算","slug":"雾计算","permalink":"https://chambai.github.io/tags/雾计算/"},{"name":"边缘计算","slug":"边缘计算","permalink":"https://chambai.github.io/tags/边缘计算/"}]},{"title":"OVS 总体架构、源码结构及数据流程全面解析","slug":"tech/OVS_总体架构、源码结构及数据流程全面解析","date":"2017-12-23T05:16:14.000Z","updated":"2019-04-11T14:38:24.082Z","comments":true,"path":"2017/12/23/tech/OVS_总体架构、源码结构及数据流程全面解析/","link":"","permalink":"https://chambai.github.io/2017/12/23/tech/OVS_总体架构、源码结构及数据流程全面解析/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 在前文「从 Bridge 到 OVS」中，我们已经对 OVS 进行了一番探索。本文决定从 OVS 的整体架构到各个组件都进行一个详细的介绍。 OVS 架构 OVS 是产品级的虚拟交换机，大量应用在生产环境中，支撑整个数据中心虚拟网络的运转。OVS 基于 SDN 的思想，将整个核心架构分为控制面和数据面，数据面负责数据的交换工作，控制面实现交换策略，指导数据面工作。 从整体上看，OVS 可以划分为三大块，管理面、数据面和控制面。 数据面就是以用户态的 ovs-vswitchd 和内核态的 datapath 为主的转发模块，以及与之相关联的数据库模块 ovsdb-server，控制面主要是由 ovs-ofctl 模块负责，基于 OpenFlow 协议与数据面进行交互。而管理面则是由 OVS 提供的各种工具来负责，这些工具的提供也是为了方便用户对底层各个模块的控制管理，提高用户体验。下面就对这些工具进行一个逐一的阐述。 ovs-ofctl： 这个是控制面的模块，但本质上它也是一个管理工具，主要是基于 OpenFlow 协议对 OpenFlow 交换机进行监控和管理，通过它可以显示一个 OpenFlow 交换机的当前状态，包括功能、配置和表中的项。使用时，有很多参数，我们可以通过 ovs-ofctl –help 查看。 常用命令： 12345ovs-ofctl show switch-name ：输出交换机信息，包括其流量表和端口信息。ovs-ofctl dump-ports switch-name：输出交换机的端口统计信息，包括收发包、丢包、错误包等数量。ovs-ofctl add-flow switch-name：为交换机配置流策略。 ovs-dpctl： 用来配置交换机的内核模块 datapath，它可以创建，修改和删除 datapath，一般，单个机器上的 datapath 有 256 条（0-255）。一条 datapath 对应一个虚拟网络设备。该工具还可以统计每条 datapath 上的设备通过的流量，打印流的信息等，更过参数通过 ovs-dpctl –help 查看。 常用命令： 12345ovs-dpctl show ：显示所有 datapath 的基本信息。ovs-dpctl dump-dps ：显示所有 datapath 的名字。ovs-dpctl dump-flows DP ：显示一条 datapath DP 上的流信息。 ovs-appctl： 查询和控制运行中的 OVS 守护进程，包括 ovs-switchd，datapath，OpenFlow 控制器等，兼具 ovs-ofctl、ovs-dpctl 的功能，是一个非常强大的命令。ovs-vswitchd 等进程启动之后就以一个守护进程的形式运行，为了能够很好的让用户控制这些进程，就有了这个命令。详细可以 ovs-appctl –help 查看。 ovs-vsctl： 查询和更新 ovs-vswitchd 的配置，这也是一个很强大的命令，网桥、端口、协议等相关的命令都由它来完成。此外，还负责和 ovsdb-server 相关的数据库操作。 常用命令： 123ovs-vsctl show ：显示主机上已有的网桥及端口信息。ovs-vsctl add-br br0：添加网桥 br0。 ovsdb-client： 访问 ovsdb-server 的客户端程序，通过 ovsdb-server 执行一些数据库操作。 常用命令：123ovsdb-client dump：用来查看ovsdb内容。ovsdb-client transact ：用来执行一条类 sql。 ovsdb-tool： 和 ovsdb-client 要借助 ovsdb-server 才能进行相关数据库操作不同，ovsdb-tool 可以直接操作数据库。 OVS 源码结构 OVS 源码结构中，主要包含以下几个主要的模块，数据交换逻辑在 vswitchd 和 datapath 中实现，vswitchd 是最核心的模块，OpenFlow 的相关逻辑都在 vswitchd 中实现，datapath 则不是必须的模块。ovsdb 用于存储 vswitch 本身的配置信息，如端口、拓扑、规则等。控制面部分采用的是 OVS 自家实现的 OVN，和其他控制器相比，OVN 对 OVS 和 OpenStack 有更好的兼容性和性能。 从图中可以看出 OVS 的分层结构，最上层 vswitchd 主要与 ovsdb 通信，做配置下发和更新等，中间层是 ofproto ，用于和 OpenFlow 控制器通信，并基于下层的 ofproto provider 提供的接口，完成具体的设备操作和流表操作等工作。 dpif 层实现对流表的操作。 netdev 层实现了对网络设备（如 Ethernet）的抽象，基于 netdev provider 接口实现多种不同平台的设备，如 Linux 内核的 system, tap, internal 等，dpdk 系的 vhost, vhost-user 等，以及隧道相关的 gre, vxlan 等。 数据转发流程 通过一个例子来看看 OVS 中数据包是如何进行转发的。 1）ovs 的 datapath 接收到从 ovs 连接的某个网络端口发来的数据包，从数据包中提取源/目的 IP、源/目的 MAC、端口等信息。 2）ovs 在内核态查看流表结构（通过 hash），如果命中，则快速转发。 3）如果没有命中，内核态不知道如何处置这个数据包，所以，通过 netlink upcall 机制从内核态通知用户态，发送给 ovs-vswitchd 组件处理。 4）ovs-vswitchd 查询用户态精确流表和模糊流表，如果还不命中，在 SDN 控制器接入的情况下，经过 OpenFlow 协议，通告给控制器，由控制器处理。 5）如果模糊命中， ovs-vswitchd 会同时刷新用户态精确流表和内核态精确流表，如果精确命中，则只更新内核态流表。 6）刷新后，重新把该数据包注入给内核态 datapath 模块处理。 7）datapath 重新发起选路，查询内核流表，匹配；报文转发，结束。总结 OVS 为了方便用户操作，提供了很多管理工具，我们平常在使用过程中只需记住每个工具的作用，具体的命令可以使用 -h 或 –help 查看。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"OVS","slug":"OVS","permalink":"https://chambai.github.io/categories/OVS/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"OVS","slug":"OVS","permalink":"https://chambai.github.io/tags/OVS/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"OpenFlow","slug":"OpenFlow","permalink":"https://chambai.github.io/tags/OpenFlow/"}]},{"title":"从 Bridge 到 OVS，探索虚拟交换机","slug":"tech/从_Bridge_到_OVS，探索虚拟交换机","date":"2017-12-17T05:16:14.000Z","updated":"2019-04-11T14:38:24.063Z","comments":true,"path":"2017/12/17/tech/从_Bridge_到_OVS，探索虚拟交换机/","link":"","permalink":"https://chambai.github.io/2017/12/17/tech/从_Bridge_到_OVS，探索虚拟交换机/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 和物理网络一样，虚拟网络要通信，必须借助一些交换设备来转发数据。因此，对于网络虚拟化来说，交换设备的虚拟化是很关键的一环。 上文「网络虚拟化」已经大致介绍了 Linux 内核为了满足网络虚拟化的要求，实现了一套虚拟交换设备——Bridge。本文重点介绍下 Bridge 的加强版——Open vSwitch（OVS），并从 Bridge 过渡到 OVS 的缘由讲起，让大家有个全面的认识。 借助 Linux Bridge 功能，同主机或跨主机的虚拟机之间能够轻松实现通信，也能够让虚拟机访问到外网，这就是我们所熟知的桥接模式，一般在装 VMware 虚拟机或者 VirtualBox 虚拟机的时候，都会提示我们要选择哪种模式，常用的两种模式是桥接和 NAT。 NAT 也很好理解，可以简单理解为当虚拟机启用了 NAT 模式之后，宿主机便通过 DHCP 为其生成可以访问外网的 IP，当 VM 访问外网的时候，就可以用该 IP 访问，其实就是宿主机为其做了地址转换。更详细的内容请自行搜索了解。 物理交换机有个重要的功能，就是虚拟局域网（VLAN），是对局域网（LAN）的软件化升级。一般，两台计算机通过一台交换机连接在一起就构成了一个 LAN。 一个 LAN 表示一个广播域，这意味着这个 LAN 中的任何节点发的数据包，其他节点都能收到，这有两个问题，一个是容易形成广播风暴，造成网络拥塞，另一个是广播包无法隔离，比如节点 B 不想接收节点 A 的包，但节点 A 强行要发，这就有点说不过去了。 解决这个问题的方案就是 VLAN，VLAN 能够对广播包进行有效隔离，它的做法是从软件上将交换机的端口虚拟出多个子端口，用 tag 来标记，相当于将交换机的端口划分多个 LAN，同一个 LAN 中的节点发出的数据包打上本 LAN 的 tag，这样，其他 LAN 中的节点就无法收到包，达到隔离的目的。 Bridge 本身是支持 VLAN 功能的，如下图所示，通过配置，Bridge 可以将一个物理网卡设备 eth0 划分成两个子设备 eth0.10，eth0.20，分别挂到 Bridge 虚拟出的两个 VLAN 上，VLAN id 分别为 VLAN 10 和 VLAN 20。同样，两个 VM 的虚拟网卡设备 vnet0 和 vnet 1 也分别挂到相应的 VLAN 上。这样配好的最终效果就是 VM1 不能和 VM2 通信了，达到了隔离。 Linux Bridge + VLAN 便可以构成一个和物理交换机具备相同功能的虚拟交换机了。对于网络虚拟化来说，Bridge 已经能够很好地充当交换设备的角色了。 但是为什么还有很多厂商都在做自己的虚拟交换机，比如比较流行的有 VMware virtual switch、Cisco Nexus 1000V，以及 Open vSwitch。究其原因，主要有以下几点（我们重点关注 OVS）： 1） 方便网络管理与监控。OVS 的引入，可以方便管理员对整套云环境中的网络状态和数据流量进行监控，比如可以分析网络中流淌的数据包是来自哪个 VM、哪个 OS 及哪个用户，这些都可以借助 OVS 提供的工具来达到。 2） 加速数据包的寻路与转发。相比 Bridge 单纯的基于 MAC 地址学习的转发规则，OVS 引入流缓存的机制，可以加快数据包的转发效率。 3） 基于 SDN 控制面与数据面分离的思想。上面两点其实都跟这一点有关，OVS 控制面负责流表的学习与下发，具体的转发动作则有数据面来完成。可扩展性强。 4） 隧道协议支持。Bridge 只支持 VxLAN，OVS 支持 gre/vxlan/IPsec 等。 5） 适用于 Xen、KVM、VirtualBox、VMware 等多种 Hypervisors。 …… 除此之外，OVS 还有很多高级特性，详情可以查阅官网自行了解。 下面简单看下 OVS 的整体架构，如下图所示，OVS 在 Linux 用户态和内核态都实现了相应的模块，用户态主要组件有数据库服务 ovsdb-server 和守护进程 ovs-vswitchd。内核态中实现了 datapath 模块。 其中， ovs-vswitchd 和 datapath 共同构成了 OVS 的数据面，控制面由 controller 模块来完成，controller 一般表示的是 OpenFlow 控制器，在 OVS 中，它可以借由第三方来完成，只要支持 OpenFlow 协议即可。 这里额外提一点，很多的一些产品级的虚拟交换机都是自身集成了控制器，比如 Cisco 1000V 的 Virtual Supervisor Manager(VSM)，VMware 的分布式交换机中的 vCenter，而 OVS 是把这个事交由第三方去做，这么做的意义还是比较大的，可以让自己的产品很好地融入到各种解决方案中。 OpenFlow OpenFlow 是控制面和数据面通信的一套协议，我们常常把支持 OpenFlow 协议的交换机称为 OpenFlow 交换机，控制器称为 OpenFlow 控制器，业界比较知名的 OpenFlow 控制器有 OpenDaylight、ONOS 等。 OpenFlow 是一个独立的完整的流表协议，不依赖于 OVS，OVS 只是支持 OpenFlow 协议，有了支持，就可以使用 OpenFlow 控制器来管理 OVS 中的流表。OpenFlow 不仅仅支持虚拟交换机，某些硬件交换机也支持 OpenFlow 协议。 ovs-vswitchd ovs-vswitchd 是 OVS 的核心组件，它和内核模块 datapath 共同构成了 OVS 的数据面。它使用 OpenFlow 协议与 OpenFlow 控制器通信，使用 OVSDB 协议与 ovsdb-server 通信，使用 netlink 和 datapath 内核模块通信。 ovsdb-server ovsdb-server 是 OVS 轻量级的数据库服务，用于整个 OVS 的配置信息，包括接口、交换内容、VLAN 等，ovs-vswitchd 根据这些配置信息工作。 OpenFlow 控制器 OpenFlow 控制器可以通过 OpenFlow 协议连接到任何支持 OpenFlow 的交换机，比如 OVS 。控制器通过向交换机下发流表规则来控制数据流向。 Kernel Datapath datapath 内核模块和 ovs-vswitchd 是相互协作工作的，datapath 负责具体的收发包，而 ovs-vswitchd 通过 controller 下发的流表规则指导 datapath 如何转发包。 举个例子，datapath 从主机物理网卡 NIC 或者 VM 的 虚拟网卡 vNIC 收到包，如果是第一次收到包，datapath 不知道怎么处理这个包，于是将其丢给 ovs-vswitchd ， ovs-vswitchd 决定该如何处理这个包之后又丢给 datapath，datapath 根据 ovs-vswitchd 的指示执行相应的动作，是丢弃还是从哪个口传出去。同时，ovs-vswitchd 会让 datapath 缓存好这个包的动作，下次再来就可以直接执行动作。 如果不是第一次收到包，就是按照之前缓存好的动作执行，这样极大地提高了数据处理的速度。 本文先对 OVS 有个初步印象，下文再详细介绍 OVS 的其他组件。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"OVS","slug":"OVS","permalink":"https://chambai.github.io/categories/OVS/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"OVS","slug":"OVS","permalink":"https://chambai.github.io/tags/OVS/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"Bridge","slug":"Bridge","permalink":"https://chambai.github.io/tags/Bridge/"},{"name":"VLAN","slug":"VLAN","permalink":"https://chambai.github.io/tags/VLAN/"},{"name":"OpenFlow","slug":"OpenFlow","permalink":"https://chambai.github.io/tags/OpenFlow/"}]},{"title":"一文搞懂网络虚拟化","slug":"tech/一文搞懂网络虚拟化","date":"2017-12-14T05:16:14.000Z","updated":"2019-04-17T15:21:47.552Z","comments":true,"path":"2017/12/14/tech/一文搞懂网络虚拟化/","link":"","permalink":"https://chambai.github.io/2017/12/14/tech/一文搞懂网络虚拟化/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 网络虚拟化相对计算、存储虚拟化来说是比较抽象的，以我们在学校书本上学的那点网络知识来理解网络虚拟化可能是不够的。 在我们的印象中，网络就是由各种网络设备（如交换机、路由器）相连组成的一个网状结构，世界上的任何两个人都可以通过网络建立起连接。 带着这样一种思路去理解网络虚拟化可能会感觉云里雾里——这样一个庞大的网络如何实现虚拟化？ 其实，网络虚拟化更多关注的是数据中心网络、主机网络这样比较「细粒度」的网络，所谓细粒度，是相对来说的，是深入到某一台物理主机之上的网络结构来谈的。 如果把传统的网络看作「宏观网络」的话，那网络虚拟化关注的就是「微观网络」。网络虚拟化的目的，是要节省物理主机的网卡设备资源。从资源这个角度去理解，可能会比较好理解一点。 传统网络架构 在传统网络环境中，一台物理主机包含一个或多个网卡（NIC），要实现与其他物理主机之间的通信，需要通过自身的 NIC 连接到外部的网络设施，如交换机上，如下图所示。 传统网络（图片来源于网络，侵权必删） 这种架构下，为了对应用进行隔离，往往是将一个应用部署在一台物理设备上，这样会存在两个问题，1）是某些应用大部分情况可能处于空闲状态，2）是当应用增多的时候，只能通过增加物理设备来解决扩展性问题。不管怎么样，这种架构都会对物理资源造成极大的浪费。 虚拟化网络架构 为了解决这个问题，可以借助虚拟化技术对一台物理资源进行抽象，将一张物理网卡虚拟成多张虚拟网卡（vNIC），通过虚拟机来隔离不同的应用。 这样对于上面的问题 1），可以利用虚拟化层 Hypervisor 的调度技术，将资源从空闲的应用上调度到繁忙的应用上，达到资源的合理利用；针对问题 2），可以根据物理设备的资源使用情况进行横向扩容，除非设备资源已经用尽，否则没有必要新增设备。这种架构如下所示。 虚拟化网络（图片来源于网络，侵权必删） 其中虚拟机与虚拟机之间的通信，由虚拟交换机完成，虚拟网卡和虚拟交换机之间的链路也是虚拟的链路，整个主机内部构成了一个虚拟的网络，如果虚拟机之间涉及到三层的网络包转发，则又由另外一个角色——虚拟路由器来完成。 一般，这一整套虚拟网络的模块都可以独立出去，由第三方来完成，如其中比较出名的一个解决方案就是 Open vSwitch（OVS）。 OVS 的优势在于它基于 SDN 的设计原则，方便虚拟机集群的控制与管理，另外就是它分布式的特性，可以「透明」地实现跨主机之间的虚拟机通信，如下是跨主机启用 OVS 通信的图示。 分布式虚拟交换机（图片来源于网络，侵权必删） 总结下来，网络虚拟化主要解决的是虚拟机构成的网络通信问题，完成的是各种网络设备的虚拟化，如网卡、交换设备、路由设备等。 Linux 下网络设备虚拟化的几种形式 为了完成虚拟机在同主机和跨主机之间的通信，需要借助某种“桥梁”来完成用户态到内核态（Guest 到 Host）的数据传输，这种桥梁的角色就是由虚拟的网络设备来完成，上面介绍了一个第三方的开源方案——OVS，它其实是一个融合了各种虚拟网络设备的集大成者，是一个产品级的解决方案。 但 Linux 本身由于虚拟化技术的演进，也集成了一些虚拟网络设备的解决方案，主要有以下几种： （1）TAP/TUN/VETH TAP/TUN 是 Linux 内核实现的一对虚拟网络设备，TAP 工作在二层，TUN 工作在三层。Linux 内核通过 TAP/TUN 设备向绑定该设备的用户空间程序发送数据，反之，用户空间程序也可以像操作物理网络设备那样，向 TAP/TUN 设备发送数据。 基于 TAP 驱动，即可实现虚拟机 vNIC 的功能，虚拟机的每个 vNIC 都与一个 TAP 设备相连，vNIC 之于 TAP 就如同 NIC 之于 eth。 当一个 TAP 设备被创建时，在 Linux 设备文件目录下会生成一个对应的字符设备文件，用户程序可以像打开一个普通文件一样对这个文件进行读写。 比如，当对这个 TAP 文件执行 write 操作时，相当于 TAP 设备收到了数据，并请求内核接受它，内核收到数据后将根据网络配置进行后续处理，处理过程类似于普通物理网卡从外界收到数据。当用户程序执行 read 请求时，相当于向内核查询 TAP 设备是否有数据要发送，有的话则发送，从而完成 TAP 设备的数据发送。 TUN 则属于网络中三层的概念，数据收发过程和 TAP 是类似的，只不过它要指定一段 IPv4 地址或 IPv6 地址，并描述其相关的配置信息，其数据处理过程也是类似于普通物理网卡收到三层 IP 报文数据。 VETH 设备总是成对出现，一端连着内核协议栈，另一端连着另一个设备，一个设备收到内核发送的数据后，会发送到另一个设备上去，这种设备通常用于容器中两个 namespace 之间的通信。 （2）Bridge Bridge 也是 Linux 内核实现的一个工作在二层的虚拟网络设备，但不同于 TAP/TUN 这种单端口的设备，Bridge 实现为多端口，本质上是一个虚拟交换机，具备和物理交换机类似的功能。 Bridge 可以绑定其他 Linux 网络设备作为从设备，并将这些从设备虚拟化为端口，当一个从设备被绑定到 Bridge 上时，就相当于真实网络中的交换机端口上插入了一根连有终端的网线。 如下图所示，Bridge 设备 br0 绑定了实际设备 eth0 和 虚拟设备设备 tap0/tap1，当这些从设备接收到数据时，会发送给 br0 ，br0 会根据 MAC 地址与端口的映射关系进行转发。 Bridge 与 TAP/TUN 的关系 因为 Bridge 工作在二层，所以绑定到它上面的从设备 eth0、tap0、tap1 均不需要设 IP，但是需要为 br0 设置 IP，因为对于上层路由器来说，这些设备位于同一个子网，需要一个统一的 IP 将其加入路由表中。 这里有人可能会有疑问，Bridge 不是工作在二层吗，为什么会有 IP 的说法？其实 Bridge 虽然工作在二层，但它只是 Linux 网络设备抽象的一种，能设 IP 也不足为奇。 对于实际设备 eth0 来说，本来它是有自己的 IP 的，但是绑定到 br0 之后，其 IP 就生效了，就和 br0 共享一个 IP 网段了，在设路由表的时候，就需要将 br0 设为目标网段的地址。 总结 传统网络架构到虚拟化的网络架构，可以看作是宏观网络到微观网络的过渡 TAP/TUN/VETH、Bridge 这些虚拟的网络设备是 Linux 为了实现网络虚拟化而实现的网络设备模块，很多的云开源项目的网络功能都是基于这些技术做的，比如 Neutron、Docker network 等。 OVS 是一个开源的成熟的产品级分布式虚拟交换机，基于 SDN 的思想，被大量应用在生产环境中。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"03 虚拟化","slug":"03-虚拟化","permalink":"https://chambai.github.io/categories/03-虚拟化/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"OVS","slug":"OVS","permalink":"https://chambai.github.io/tags/OVS/"},{"name":"网络","slug":"网络","permalink":"https://chambai.github.io/tags/网络/"},{"name":"Bridge","slug":"Bridge","permalink":"https://chambai.github.io/tags/Bridge/"},{"name":"tap","slug":"tap","permalink":"https://chambai.github.io/tags/tap/"},{"name":"tun","slug":"tun","permalink":"https://chambai.github.io/tags/tun/"},{"name":"veth-pair","slug":"veth-pair","permalink":"https://chambai.github.io/tags/veth-pair/"}]},{"title":"2017 年除了人工智能，这门技术也在茁壮生长","slug":"tech/2017_年除了人工智能，这门技术也在茁壮生长","date":"2017-12-10T05:16:14.000Z","updated":"2019-04-11T14:38:24.065Z","comments":true,"path":"2017/12/10/tech/2017_年除了人工智能，这门技术也在茁壮生长/","link":"","permalink":"https://chambai.github.io/2017/12/10/tech/2017_年除了人工智能，这门技术也在茁壮生长/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 没错，这个标题就是个标题党，目的就是为了让你点进来看看。 2017 年是人工智能元年，我们也能看到各大互联网公司对于人工智能的大布局。但人工智能再怎么牛逼，别忘了它的底层基础设施是什么，没错，就是云计算，少了云计算的底层支撑，人工智能也只能活在书本里。虽然说云计算经过这么多年的沉淀，技术总体上来说已经比较成熟，但有一门技术仍然呈现欣欣向荣之势，未来发展仍有无限可能。 它就是以 docker 为首的容器技术。 不知道大家关注最近这两天的 KubeCon 2017 北美峰会没有，会上提得最多的也是容器技术，其中最大的新闻莫过于 OpenStack 基金会发布了最新开源容器项目 Kata Containers。看到这个消息，我的第一反应是「为啥最近容器圈的动作这么多」。 我们把时间拉回到 11 月底的中国开源年会上，当时阿里正式开源了自家自研容器项目 Pouch。再把时间拉到差不多两个月前（10月17日）的 DockerCon EU 2017 大会上，彼时 docker 官方宣布全面支持 kubernates。类似这样大大小小的动作，在 2017 年还发生了很多，这一切的动作都在说明容器的重要性，未来的可期待指数可以说不亚于人工智能。 下面简单介绍下 Kata 和阿里的 Pouch 到底是个怎样的角色，我也仅限于网络上各种资讯的了解，信息传达难免会有失误，如果大家觉得有问题可以留言指出。 Kata Containers 是什么 Kata 官方宣称这是同时兼具容器的速度和虚拟机安全的全新容器解决方案，旨在将虚拟机的安全优势与容器的速度和可管理性统一起来，其建立在 Intel 的 Clear Containers 技术和 Hyper 的 runV 虚拟机管理程序运行时基础之上。 Kata 的特点是什么？总体来讲，Kata 解决的是容器的安全问题。众所周知，当前容器技术旨在实现在一个虚拟机之上运行多个用户的、多个应用的容器实例，不同实例之间共享同一个虚拟机操作系统内核并采用 Namespaces 来隔离，但这种方式很难保证各实例彼此之间的完全隔离，存在安全隐患。 Kata 的解决方案是意图为每个容器实例提供一个专属的、高度轻量化的虚拟机操作系统内核来解决这个问题。让某一个用户的、一个应用的一个或多个容器实例单独跑在这个专属的虚拟机内核之上，这样不同用户、不同应用之间都是使用独占的虚拟机，不会共享同一个操作系统内核，这样就确保了安全性。 另外还有一点值得注意的是，Kata 的设计初衷强调了能够无缝、便捷的与 OpenStack 和 Kubernetes 集成的能力，这为 OpenStack 、Kubernetes 和 Container 更好的融合铺平了道路。 更详细的内容可以访问： http://www/katacontainers.io/https://github.com/hyperhq/runv Pouch 是什么 相比 Kata，阿里的 Pouch 就没那么新鲜了，只不过是换了个马甲而已。 为什么这么说，因为 Pouch 并不是全新的容器解决方案，而是已经在阿里内部经过千锤百炼的老牌容器技术 t4。2011 年，Linux 内核的 namespace、cgroup 等技术开始成熟，LXC 等容器运行时技术也在同期诞生，阿里作为一家技术公司，在当时便基于 LXC 自研了自己的容器技术 t4，并以产品的形式给内部提供服务。 t4 就是 Pouch 的前身，从时间节点上看，t4 面世比 docker 要早两年，但 t4 有很多问题没有解决，譬如说没有镜像机制。2013 年，docker 横空出世，其带有镜像创新的容器技术，似一阵飓风，所到之处，国内外无不叫好，阿里也不例外，便在现有技术体系结构的基础上融入了 docker 的镜像技术，慢慢打磨，演变成今天的 Pouch。 Pouch 针对自身的业务场景对镜像的下载和分发进行了创新。由于阿里的业务体量庞大，集群规模数以万计，这就会存在一个问题就是镜像的下载和分发效率会很低，所以针对此，阿里在 Pouch 中集成了一个镜像分发工具蜻蜓（Dragonfly），蜻蜓基于智能 P2P 技术的文件分发系统，解决了大规模文件分发场景下分发耗时、成功率低、带宽浪费等难题。 Pouch 的架构主要考虑到两个方面，一方面是如何对接容器编排系统，另一方面是如何加强容器运行时，第一点让 Pouch 有了对外可扩展的能力，譬如可以原生支持 Kubernetes 等编排系统。第二点可以增加 Pouch 对虚拟机和容器的统一管理，让其适应更多的业务场景。 更详细的内容可以访问： https://github.com/alibaba/pouch 总结 从几种举动中，我们可以看出，未来容器发展具有两大重要方向，分别是容器编排技术和容器的安全加强。这些都是在寻求一种更好的、更有效率的方式来为上层的业务提供更可靠、更安全的支撑。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"01 云计算","slug":"01-云计算","permalink":"https://chambai.github.io/categories/01-云计算/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"容器","slug":"容器","permalink":"https://chambai.github.io/tags/容器/"},{"name":"Docker","slug":"Docker","permalink":"https://chambai.github.io/tags/Docker/"},{"name":"Kata","slug":"Kata","permalink":"https://chambai.github.io/tags/Kata/"},{"name":"Pouch","slug":"Pouch","permalink":"https://chambai.github.io/tags/Pouch/"}]},{"title":"I/O 虚拟化的三种形式","slug":"tech/I:O_虚拟化的三种形式","date":"2017-12-06T05:16:14.000Z","updated":"2019-04-11T14:38:24.085Z","comments":true,"path":"2017/12/06/tech/I:O_虚拟化的三种形式/","link":"","permalink":"https://chambai.github.io/2017/12/06/tech/I:O_虚拟化的三种形式/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 上文「I/O 虚拟化」简单介绍了 I/O 虚拟化的做法，本文重点关注一下三种 I/O 虚拟化的分类——全虚拟化、半虚拟化和 I/O 直通（透传）。 I/O 全虚拟化 这种方式比较好理解，简单来说，就是通过纯软件的形式来模拟虚拟机的 I/O 请求。以 qemu-kvm 来举例，内核中的 kvm 模块负责截获 I/O 请求，然后通过事件通知告知给用户空间的设备模型 qemu，qemu 负责完成本次 I/O 请求的模拟。更具体的内容可以翻阅前文。 优点： 不需要对操作系统做修改，也不需要改驱动程序，因此这种方式对于多种虚拟化技术的「可移植性」和「兼容性」比较好。 缺点： 纯软件形式模拟，自然性能不高，另外，虚拟机发出的 I/O 请求需要虚拟机和 VMM 之间的多次交互，产生大量的上下文切换，造成巨大的开销。 I/O 半虚拟化 针对 I/O 全虚拟化纯软件模拟性能不高这一点，I/O 半虚拟化前进了一步。它提供了一种机制，使得 Guest 端与 Host 端可以建立连接，直接通信，摒弃了截获模拟这种方式，从而获得较高的性能。 值得注意的有两点：1）采用 I/O 环机制，使得 Guest 端和 Host 端可以共享内存，减少了虚拟机与 VMM 之间的交互；2）采用事件和回调的机制来实现 Guest 与 Host VMM 之间的通信。这样，在进行中断处理时，就可以直接采用事件和回调机制，无需进行上下文切换，减少了开销。 要实现这种方式， Guest 端和 Host 端需要采用类似于 C/S 的通信方式建立连接，这也就意味着要修改 Guest 和 Host 端操作系统内核相应的代码，使之满足这样的要求。为了描述方便，我们统称 Guest 端为前端，Host 端为后端。 前后端通常采用的实现方式是驱动的方式，即前后端分别构建通信的驱动模块，前端实现在内核的驱动程序中，后端实现在 qemu 中，然后前后端之间采用共享内存的方式传递数据。关于这方面一个比较好的开源实现是 virtio，后面会有专门的文章来讲述之。 优点： 性能较 I/O 全虚拟化有了较大的提升 缺点： 要修改操作系统内核以及驱动程序，因此会存在移植性和适用性方面的问题，导致其使用受限。 I/O 直通或透传技术 上面两种虚拟化方式，还是从软件层面上来实现，性能自然不会太高。最好的提高性能的方式还是从硬件上来解决。如果让虚拟机独占一个物理设备，像宿主机一样使用物理设备，那无疑性能是最好的。 I/O 直通技术就是提出来完成这样一件事的。它通过硬件的辅助可以让虚拟机直接访问物理设备，而不需要通过 VMM 或被 VMM 所截获。 由于多个虚拟机直接访问物理设备，会涉及到内存的访问，而内存又是共享的，那怎么来隔离各个虚拟机对内存的访问呢，这里就要用到一门技术——IOMMU，简单说，IOMMU 就是用来隔离虚拟机对内存资源访问的。 I/O 直通技术需要硬件支持才能完成，这方面首选是 Intel 的 VT-d 技术，它通过对芯片级的改造来达到这样的要求，这种方式固然对性能有着质的提升，不需要修改操作系统，移植性也好。 但该方式也是有一定限制的，这种方式仅限于物理资源丰富的机器，因为这种方式仅仅能满足一个设备分配给一个虚拟机，一旦一个设备被虚拟机占用了，其他虚拟机时无法使用该设备的。 为了解决这个问题，使一个物理设备能被更多的虚拟机所共享。学术界和工业界都对此作了大量的改进，PCI-SIG 发布了 SR-IOV (Single Root I/O Virtualizmion) 规范，其中详细阐述了硬件供应商在多个虚拟机中如何共享单个 I/O 设备硬件。 SR-IOV标准定义了设备原生共享所需的「软硬件支持」。硬件支持包括芯片组对 SR-IOV 设备的识别，为保证对设备的安全、隔离访问还需要北桥芯片的 VT-d 支持，为保证虚拟机有独立的内存空间，CPU 要支持 IOMMU。软件方面，VMM 将驱动管理权限交给 Guest，Guest 操作系统必须支持 SR-IOV 功能。 SR-IOV 单独引入了两种软件实体功能： PF（physical function）：包含轻量级的 PCIe 功能，负责管理 SR-IOV 设备的特殊驱动，其主要功能是为 Guest 提供设备访问功能和全局贡献资源配置的功能。 VF（virtual function）：包含轻量级的 PCIe 功能。其功能包含三个方面：向虚拟机操作系统提供的接口；数据的发送、接收功能；与 PF 进行通信，完成全局相关操作。 每个 SR-IOV 设备都可有一个物理功能 PF，并且每个 PF 最多可有 64,000 个与其关联的虚拟功能 VF。 一般，Guest 通过物理功能 PF 驱动发现设备的 SR-IOV 功能后将包括发送、接收队列在内的物理资源依据 VF 数目划分成多个子集，然后 PF 驱动将这些资源子集抽象成 VF 设备，这样，VF 设备就可以通过某种通信机制分配给虚拟机了。 尽管 I/O 直通技术消除了虚拟机 I/O 中 VMM 干预引起的额外开销，但在 I/O 操作中 I/O 设备会产生大量的中断，出于安全等因素考虑，虚拟机无法直接处理中断，因此中断请求需要由 VMM 安全、隔离地路由至合适的虚拟机。所以，其实实际使用中，都是软硬件虚拟化方式结合使用的。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"03 虚拟化","slug":"03-虚拟化","permalink":"https://chambai.github.io/categories/03-虚拟化/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"KVM","slug":"KVM","permalink":"https://chambai.github.io/tags/KVM/"},{"name":"Qemu","slug":"Qemu","permalink":"https://chambai.github.io/tags/Qemu/"},{"name":"I/O","slug":"I-O","permalink":"https://chambai.github.io/tags/I-O/"},{"name":"SR-IOV","slug":"SR-IOV","permalink":"https://chambai.github.io/tags/SR-IOV/"},{"name":"IOMMU","slug":"IOMMU","permalink":"https://chambai.github.io/tags/IOMMU/"}]},{"title":"I/O 虚拟化","slug":"tech/I:O_虚拟化","date":"2017-12-02T05:16:14.000Z","updated":"2019-04-11T14:38:24.051Z","comments":true,"path":"2017/12/02/tech/I:O_虚拟化/","link":"","permalink":"https://chambai.github.io/2017/12/02/tech/I:O_虚拟化/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ I/O 虚拟化在虚拟化技术中算是比较复杂，也是最重要的一部分。从整体上看，I/O 虚拟化也包括基于软件的虚拟化和硬件辅助的虚拟化，软件虚拟化部分又可以分为全虚拟化和半虚拟化，如果根据设备类型再细分的话，又可以分为字符设备 I/O 虚拟化（键盘、鼠标、显示器）、块设备 I/O 虚拟化（磁盘、光盘）和网络设备 I/O 虚拟化（网卡）等。 我们先看下在没有虚拟机存在的情况下，I/O 设备请求是怎样的。某个应用或进程发出 I/O 请求，通过系统调用等方式进入内核，调用相应的驱动程序，请求到具体的 I/O 设备，然后再将结果返回到调用者进行回显。 那么存在虚拟机的情况下，又是怎样的呢。按理说，虚拟机是宿主机上的一个进程，应该可以以类似的 I/O 请求方式访问到宿主机上的 I/O 设备，但别忘了，虚拟机处在非 Root 的虚拟化模式下，请求无法直接下发到宿主机，必须借助于 VMM 来截获并模拟虚拟机的 I/O 请求。 至于怎么截获并模拟，每一种 VMM 的实现方案都不一样，像 qemu-kvm ，截获操作是由内核态的 kvm 来完成，模拟操作是由用户态的 qemu 来完成的，这也是 kvm 不同于其他 VMM 实现方案的地方。kvm 这样做也是为了提升性能和保持内核的纯净性，关于这块的知识不清楚的可以查阅前文。 从层次上看，虚拟机发出 I/O 请求到完成相应的 I/O 操作，中间要经过虚拟机的设备驱动，到 VMM 的设备模型，再到宿主机的设备驱动，最终才到真正的 I/O 设备。 那什么是设备模型，设备模型就是 VMM 中进行设备模拟，并处理所有设备请求和响应的逻辑模块，对于 qemu-kvm，qemu 其实就可以看做是一个设备模型。 上图显示的就是设备模型的逻辑层次关系，对于不同构造的虚拟机，其逻辑层次是类似的：VMM 截获虚拟机的 I/O 操作，将这些操作传递给设备模型进行处理，设备模型运行在一个特定的环境下，这可以是宿主机，可以是 VMM 本身，也可以是另一个虚拟机。 下图显示的就是在宿主机中设备模型的实现，也就是 qemu-kvm 的实现方案，在这个例子中，VMM 主要部分实现为内核模块，设备模型实现为一个用户态进程，当虚拟机发生 I/O 之后，VMM 作为内核模块将其截获后，会通过内核态-用户态接口传递给用户态的设备模型处理，设备模型运行与宿主机操作系统之上，可以使用相应的系统调用和所有运行时库，宿主机操作系统就是设备模型的运行环境。 所以，设备模型在这里起着一个桥梁的作用，由虚拟机设备驱动发出的 I/O 请求先通过设备模型转化为物理 I/O 设备的请求，再通过调用物理设备驱动来完成相应的 I/O 操作。反过来，设备驱动将 I/O 操作结果通过设备模型，返回给虚拟机的虚拟设备驱动程序。 上面说的这种方式是纯软件模拟的，或者说得再专业一点就是全虚拟化，全虚拟化就是 VMM 完全虚拟出一套宿主机的设备模型，宿主机有什么就虚拟出什么，这样，虚拟机发出的任何 I/O 请求都是无感知的，也是说虚拟机认为自己在“直接”使用物理的 I/O 设备，其实不是，全是虚拟出来的。 有了全虚拟化，自然就有半虚拟化，半虚拟化的提出就是解决全虚拟化的性能问题的。通过上面的分析，不难看出，这种截获再模拟的方式导致一次 I/O 请求要经过多次的内核态和用户态的切换，性能肯定不理想。半虚拟化就是尽量避免这种情况发生。 半虚拟化中，虚拟机能够感知到自己是处于虚拟化状态，虚拟机和宿主机之间通过某种机制来达成这种感知，也就是两者之间需要建立一套通信接口，虚拟机的 I/O 请求走这套接口，而不是走截获模拟那种方式，这样就可以提升性能。这套接口一个比较好的实现就是 virtio，Linux 2.6.30 版本之后就被集成到了 Linux 内核模块中。 半虚拟化虽然提升了性能，但是还是基于软件模拟的方式，性能上还是无法与直接访问物理 I/O 设备相抗衡，那能不能做到呢，答案是一定的，那就是从硬件上去入手了。 以 Intel VT-d 为首的技术就是硬件辅助的 I/O 虚拟化技术，但是业界一般不是直接使用硬件，而是配合相应的软件技术来完成，比较常用的两门技术是 PCI Pass-Through 和 SR-IOV。 本文仅是简单总结下 I/O 虚拟化的方式，分类，以及存在的技术问题。后面会针对具体的类别或问题进行展开。 PS：如果你觉得本文对你有一点帮助，点赞，转发，不胜感激。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"03 虚拟化","slug":"03-虚拟化","permalink":"https://chambai.github.io/categories/03-虚拟化/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"KVM","slug":"KVM","permalink":"https://chambai.github.io/tags/KVM/"},{"name":"Qemu","slug":"Qemu","permalink":"https://chambai.github.io/tags/Qemu/"},{"name":"I/O","slug":"I-O","permalink":"https://chambai.github.io/tags/I-O/"}]},{"title":"内存虚拟化","slug":"tech/内存虚拟化","date":"2017-11-27T05:16:14.000Z","updated":"2019-04-11T14:38:24.080Z","comments":true,"path":"2017/11/27/tech/内存虚拟化/","link":"","permalink":"https://chambai.github.io/2017/11/27/tech/内存虚拟化/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 虚拟内存 我们知道，早期的计算机内存，只有物理内存，而且空间是极其有限的，每个应用或进程在使用内存时都得小心翼翼，不能覆盖别的进程的内存区。 为了避免这些问题，就提出了虚拟内存的概念，其抽象了物理内存，相当于对物理内存进行了虚拟化，保证每个进程都被赋予一块连续的，超大的（根据系统结构来定，32 位系统寻址空间为 2^32，64 位系统为 2^64）虚拟内存空间，进程可以毫无顾忌地使用内存，不用担心申请内存会和别的进程冲突，因为底层有机制帮忙处理这种冲突，能够将虚拟地址根据一个页表映射成相应的物理地址。 这种机制正是虚拟化软件做的事，也就是 MMU 内存管理单元。 本文要说的不是这种虚拟内存，而是基于虚拟机的内存虚拟化，它们本质上是一样的，通过对虚拟内存的理解，再去理解内存虚拟化就比较容易了。 结合前面的文章，我们知道，虚拟化分为软件虚拟化和硬件虚拟化，而且遵循 intercept 和 virtualize 的规律。 内存虚拟化也分为基于软件的内存虚拟化和硬件辅助的内存虚拟化，其中，常用的基于软件的内存虚拟化技术为「影子页表」技术，硬件辅助内存虚拟化技术为 Intel 的 EPT（Extend Page Table，扩展页表）技术。 为了讲清楚这两门技术，我们从简易到复杂，循序渐进，逐步揭开其神秘面纱。 常规软件内存虚拟化 虚拟机本质上是 Host 机上的一个进程，按理说应该可以使用 Host 机的虚拟地址空间，但由于在虚拟化模式下，虚拟机处于非 Root 模式，无法直接访问 Root 模式下的 Host 机上的内存。 这个时候就需要 VMM 的介入，VMM 需要 intercept （截获）虚拟机的内存访问指令，然后 virtualize（模拟）Host 上的内存，相当于 VMM 在虚拟机的虚拟地址空间和 Host 机的虚拟地址空间中间增加了一层，即虚拟机的物理地址空间，也可以看作是 Qemu 的虚拟地址空间（稍微有点绕，但记住一点，虚拟机是由 Qemu 模拟生成的就比较清楚了）。 所以，内存软件虚拟化的目标就是要将虚拟机的虚拟地址（Guest Virtual Address, GVA）转化为 Host 的物理地址（Host Physical Address, HPA），中间要经过虚拟机的物理地址（Guest Physical Address, GPA）和 Host 虚拟地址（Host Virtual Address）的转化，即：1GVA -&gt; GPA -&gt; HVA -&gt; HPA 其中前两步由虚拟机的系统页表完成，中间两步由 VMM 定义的映射表（由数据结构 kvm_memory_slot 记录）完成，它可以将连续的虚拟机物理地址映射成非连续的 Host 机虚拟地址，后面两步则由 Host 机的系统页表完成。如下图所示。 这样做得目的有两个： 提供给虚拟机一个从零开始的连续的物理内存空间。 在各虚拟机之间有效隔离、调度以及共享内存资源。 影子页表技术 接上图，我们可以看到，传统的内存虚拟化方式，虚拟机的每次内存访问都需要 VMM 介入，并由软件进行多次地址转换，其效率是非常低的。因此才有了影子页表技术和 EPT 技术。 影子页表简化了地址转换的过程，实现了 Guest 虚拟地址空间到 Host 物理地址空间的直接映射。 要实现这样的映射，必须为 Guest 的系统页表设计一套对应的影子页表，然后将影子页表装入 Host 的 MMU 中，这样当 Guest 访问 Host 内存时，就可以根据 MMU 中的影子页表映射关系，完成 GVA 到 HPA 的直接映射。而维护这套影子页表的工作则由 VMM 来完成。 由于 Guest 中的每个进程都有自己的虚拟地址空间，这就意味着 VMM 要为 Guest 中的每个进程页表都维护一套对应的影子页表，当 Guest 进程访问内存时，才将该进程的影子页表装入 Host 的 MMU 中，完成地址转换。 我们也看到，这种方式虽然减少了地址转换的次数，但本质上还是纯软件实现的，效率还是不高，而且 VMM 承担了太多影子页表的维护工作，设计不好。 为了改善这个问题，就提出了基于硬件的内存虚拟化方式，将这些繁琐的工作都交给硬件来完成，从而大大提高了效率。 EPT 技术 这方面 Intel 和 AMD 走在了最前面，Intel 的 EPT 和 AMD 的 NPT 是硬件辅助内存虚拟化的代表，两者在原理上类似，本文重点介绍一下 EPT 技术。 如下图是 EPT 的基本原理图示，EPT 在原有 CR3 页表地址映射的基础上，引入了 EPT 页表来实现另一层映射，这样，GVA-&gt;GPA-&gt;HPA 的两次地址转换都由硬件来完成。 这里举一个小例子来说明整个地址转换的过程。假设现在 Guest 中某个进程需要访问内存，CPU 首先会访问 Guest 中的 CR3 页表来完成 GVA 到 GPA 的转换，如果 GPA 不为空，则 CPU 接着通过 EPT 页表来实现 GPA 到 HPA 的转换（实际上，CPU 会首先查看硬件 EPT TLB 或者缓存，如果没有对应的转换，才会进一步查看 EPT 页表），如果 HPA 为空呢，则 CPU 会抛出 EPT Violation 异常由 VMM 来处理。 如果 GPA 地址为空，即缺页，则 CPU 产生缺页异常，注意，这里，如果是软件实现的方式，则会产生 VM-exit，但是硬件实现方式，并不会发生 VM-exit，而是按照一般的缺页中断处理，这种情况下，也就是交给 Guest 内核的中断处理程序处理。 在中断处理程序中会产生 EXIT_REASON_EPT_VIOLATION，Guest 退出，VMM 截获到该异常后，分配物理地址并建立 GVA 到 HPA 的映射，并保存到 EPT 中，这样在下次访问的时候就可以完成从 GVA 到 HPA 的转换了。 总结 内存虚拟化经历从虚拟内存，到传统软件辅助虚拟化，影子页表，再到硬件辅助虚拟化，EPT 技术的进化，效率越来越高。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"03 虚拟化","slug":"03-虚拟化","permalink":"https://chambai.github.io/categories/03-虚拟化/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"KVM","slug":"KVM","permalink":"https://chambai.github.io/tags/KVM/"},{"name":"内存","slug":"内存","permalink":"https://chambai.github.io/tags/内存/"}]},{"title":"CPU 虚拟化","slug":"tech/CPU_虚拟化","date":"2017-11-26T05:16:14.000Z","updated":"2019-04-11T14:38:24.070Z","comments":true,"path":"2017/11/26/tech/CPU_虚拟化/","link":"","permalink":"https://chambai.github.io/2017/11/26/tech/CPU_虚拟化/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 前面「虚拟化技术总览」中从虚拟平台 VMM 的角度，将虚拟化分为 Hypervisor 模型和宿主模型，如果根据虚拟的对象（资源类型）来划分，虚拟化又可以分为计算虚拟化、存储虚拟化和网络虚拟化，再细一些，又有中断虚拟化，内存虚拟化，字符/块设备虚拟化，网络功能虚拟化等。 我会将此作为一个系列来写，本文先看 CPU 虚拟化。在这之前，我们先来笼统看下虚拟化的本质是什么，它到底是如何做到将 Host 的硬件资源虚拟化给 Guest 用，我这里用两个词来定义，intercept 和 virtualize，中文翻译成截获和模拟比较恰当一点，这两个词基本上是虚拟化的终极定义了，带着这两个词去看每一种虚拟化类型，会发现很容易理解和记忆。 CPU 软件虚拟化 基于软件的 CPU 虚拟化，故名思议，就是通过软件的形式来模拟每一条指令。通过前面的文章我们知道常用的软件虚拟化技术有两种：优先级压缩和二进制代码翻译。这两种是通用技术，可以用在所有虚拟化类型中。我们就结合 intercept 和 virtualize 来看看 CPU 软件虚拟化是怎么做的。 首先，一些必须的硬件知识要知道，X86 体系架构为了让上层的软件（操作系统、应用程序）能够访问硬件，提供了四个 CPU 特权级别，Ring 0 是最高级别，Ring 1 次之，Ring 2 更次之，Ring 3 是最低级别。 一般，操作系统由于要直接访问硬件和内存，因此它的代码需要运行在最高级别 Ring 0 上，而应用程序的代码运行在最低级别 Ring 3 上，如果要访问硬件和内存，比如设备访问，写文件等，就要执行相关的系统调用，CPU 的运行级别发生从 Ring 3 到 Ring 0 的切换，当完成之后，再切换回去，我们熟悉的用户态和内核态切换的本质就来自这里。 虚拟化的实现也是基于这个思想，VMM 本质上是个 Host OS，运行在 Ring 0 上，Guest OS 运行在 Ring 1 上，再往上是相应层次的应用程序运行在 Ring 2 和 Ring 3 上。 当 Guest OS 或上层应用在执行相关的特权指令时，就会发生越权访问，触发异常，这个时候 VMM 就截获（intercept）这个指令，然后模拟（virtualize）这个指令，返回给 Guest OS，让其以为自己的特权指令可以正常工作，继续运行。整个过程其实就是优先级压缩和二进制代码翻译的体现。 CPU 硬件虚拟化 上面的这种截获再模拟的纯软件的虚拟化方式，势必是性能非常低的。那怎么样提高性能呢，有一种改进的方式是修改 Guest OS 中关于特权指令的相关操作，将其改为一种函数调用的方式，让 VMM 直接执行，而不是截获和模拟，这样就能在一定程度上提高性能。 但这种方式并不通用，要去改 Guest OS 的代码，只能看作是一种定制。为了能够通用，又能够提高性能，就只能从硬件上去做文章了。所以，后来，以 Intel 的 VT-x 和 AMD 的 AMD-V 为主的硬件辅助的 CPU 虚拟化就被提出来（Intel VT 包括 VT-x （支持 CPU 虚拟化）、EPT（支持内存虚拟化）和 VT-d（支持 I/O 虚拟化））。 CPU 硬件辅助虚拟化在 Ring 模式的基础上引入了一种新的模式，叫 VMX 模式。它包括根操作模式（VMX Root Operation）和非根操作模式（VMX Non-Root Operation）。 这两种模式都有 Ring 0 - Ring 3 的特权级。所以，在描述某个应用程序时，除了描述其属于哪个特权级，还要指明其处于根模式还是非根模式。 引入这种模式的好处就在于，Guest OS 运行在 Ring 0 上，就意味着它的核心指令可以直接下达到硬件层去执行，而特权指令等敏感指令的执行则是由硬件辅助，直接切换到 VMM 执行，这是自动执行的，应用程序是感知不到的，性能自然就提高了。 这种切换 VT-x 定义了一套机制，称为 VM-entry 和 VM-exit。从非根模式切换到根模式，也就是从 Guest 切换到 Host VMM，称为 VM-exit，反之称为 VM-entry。 VM-exit ： 如果 Guest OS 运行过程中遇到需要 VMM 处理的事件，比如中断或缺页异常，或者主动调用 VMCALL 指令调用 VMM 服务的时候（类似于系统调用），硬件自动挂起 Guest OS，切换到根模式，VMM 开始执行。 VM-entry： VMM 通过显示调用 VMLAUNCH 或 VMRESUME 指令切换到非根模式，硬件自动加载 Guest OS 的上下文，Guest OS 开始执行。 KVM CPU 虚拟化 KVM 是一种硬件辅助的虚拟化技术，支持 Intel VT-x 和 AMD-v 技术，怎么知道 CPU 是否支持 KVM 虚拟化呢？可以通过如下命令查看：1# grep -E &apos;(vmx|svm)&apos; /proc/cpuinfo 如果输出是 vmx 或 svm，则表明当前 CPU 支持 KVM，Intel 是 vmx，AMD 是svm。 从本质上看，一个 KVM 虚拟机对应 Host 上的一个 qemu-kvm 进程，它和其他 Linux 进程一样被调度，而 qemu-kvm 进程中的一个线程就对应虚拟机的虚拟 CPU （vCPU），虚拟机中的任务线程就被 vCPU 所调度。 比如下面这个例子，Host 机有两个物理 CPU，上面起了两个虚拟机 VM1 和 VM2，VM1 有两个 vCPU，VM2 有 3 个 vCPU，VM1 和 VM2 分别有 2 个 和 3 个线程在 2 个物理 CPU 上调度。VM1 和 VM2 中又分别有 3 个任务线程在被 vCPU 调度。 所以，这里有两级的 CPU 调度，Guest OS 中的 vCPU 负责一级调度，Host VMM 负责另一级调度，即 vCPU 在物理 CPU 上的调度。 我们也可以看到，vCPU 的个数，可以超过物理 CPU 的个数，这个叫 CPU 「超配」，这正是 CPU 虚拟化的优势所在，这表明了虚拟机能够充分利用 Host 的 CPU 资源，进行相应的业务处理，运维人员也可以据此控制 CPU 资源使用，达到灵活调度。 OK，CPU 虚拟化就到这里，下篇文章将讲述内存虚拟化。觉得写得凑合可以给个赞，谢谢大家的支持。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"03 虚拟化","slug":"03-虚拟化","permalink":"https://chambai.github.io/categories/03-虚拟化/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"KVM","slug":"KVM","permalink":"https://chambai.github.io/tags/KVM/"},{"name":"CPU","slug":"CPU","permalink":"https://chambai.github.io/tags/CPU/"}]},{"title":"KVM 初探","slug":"tech/KVM_初探","date":"2017-11-20T05:16:14.000Z","updated":"2019-04-11T14:38:24.062Z","comments":true,"path":"2017/11/20/tech/KVM_初探/","link":"","permalink":"https://chambai.github.io/2017/11/20/tech/KVM_初探/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ KVM 是业界最为流行的 Hypervisor，全称是 Kernel-based Virtual Machine。它是作为 Linux kernel 中的一个内核模块而存在，模块名为 kvm.ko，也可以看作是一个进程，被内核调度并管理，从 Linux 2.6.20 版本开始被完全正式加入到内核的主干开发和正式发布代码中。 KVM 主要用于管理 CPU 和内存的虚拟化，IO 设备的虚拟化则是由 Qemu 来完成。为什么会有这样的分工，请继续往下看。 KVM 与 Qemu 的前世今生 Qemu 是一个纯软件实现的开源「模拟」软件，它能够模拟整套虚拟机的实现，包括 CPU、内存、各种 IO 设备、鼠标、键盘、USB 、网卡、声卡等等，基本上没有它不能模拟的。有人可能会比较疑惑它跟 KVM 之间到底有何关系，我们可以把它们看成是合作关系，好基友，谁都离不开彼此。 KVM 离不开 Qemu。KVM 实现初期，为了简化开发和代码重用，在 Qemu 的基础上进行了修改，主要是将比较耗性能的 CPU 虚拟化和内存虚拟化部分移到了内核中实现，保留 IO 虚拟化模块在用户空间实现。这样的做法主要是考虑到性能的原因，CPU 和 内存虚拟化是非常复杂的虚拟化模块，而且使用非常频繁，如果实现在用户空间的话，用户态和内核态的频繁切换势必会对性能造成很大的影响。那为什么要单独保留 IO 虚拟化在用户空间呢，这个也是权衡之下的结果，首先 IO 设备太多了，其次 IO 虚拟化相对其他两个模块使用不是很频繁，开销会小一些，所以，为了尽可能保持内核的纯净性，才有了这样的分配。 Qemu 离不开 KVM。上面也说了，Qemu 是一个纯软件的实现，运行在用户空间，性能非常低下，所以，从 Qemu 的角度，可以说是 Qemu 使用了 KVM 的虚拟化功能，为自身虚拟机提供加速。 早期两者还没有区分（没有同居），KVM 修改的模块叫 qemu-kvm，到 Qemu1.3 版本之后，两者就合二为一了（同居啦），如果我们在用 Qemu 创建虚拟机时，要加载 KVM 模块，需要为其指定参数 --enable-kvm。 KVM 与 Qemu 的关系（图片来源于网络，侵权必删） KVM 架构 KVM 是基于硬件虚拟化（Intel VT 或 AMD-V）实现的一套虚拟化解决方案，通过以上一个与 Qemu 关系的分析，我们基本上知道它在虚拟化领域处在一个什么样的地位。它其实只负责 CPU 和内存的虚拟化，不负责任何设备的模拟，而是提供接口给用户空间的 Qemu 来模拟。这个接口是 /dev/kvm，Qemu 通过 /dev/kvm 接口设置一个虚拟机的地址空间，然后向它提供模拟好的 I/O 设备，并将相关的设备回显操作映射到宿主机，完成整个 I/O 设备的虚拟化操作。 KVM 架构 /dev/kvm 接口是 Qemu 和 KVM 交互的“桥梁”，基本的原理是：/dev/kvm 本身是一个设备文件，这就意味着可以通过 ioctl 函数来对该文件进行控制和管理，从而可以完成用户空间与内核空间的数据交互。在 KVM 与 Qemu 的通信过程主要就是一系列针对该设备文件的 ioctl 调用。 我就拿创建虚拟机举个例子，虚拟机本质上是宿主机的一个进程，包括用户态数据结构和内核态数据结构，用户态部分由 Qemu 创建并初始化，内核态部分则由 KVM 来完成，完成后会返回一个文件句柄来代表所创建的虚拟机，针对该文件句柄的 ioctl 调用就可以对虚拟机进行相应的管理，比如建立虚拟机地址空间和宿主机地址空间的映射关系，创建多个线程（虚拟处理器，vCPU）来供虚拟机使用等，对于创建出的 vCPU，也会生成相应的文件句柄，同样，对 vCPU 的文件句柄的 ioctl 调用就可以对 vCPU 进行管理。 关于这块的具体细节，后面会有文章来专门讨论。 VMM 管理工具 —— libvirt 目前，虚拟化这个领域可以说是百花齐放，针对不同的场景提出了很多的虚拟化解决方案，KVM、Xen、VMware、VirtualBox、Hyper-V 等等，具体的这些方案有什么特点，可以看前文「虚拟化技术总览」。这么多方案势必有很多通用的模块，不同之处可能在于，与不同硬件厂商的适配上，为了支持更多厂商，以及应用更多的领域，有很多 IaaS 解决方案需要融合多种虚拟化技术。这个时候如果有一个平台类的管理工具就会非常方便，libvirt 就是这样一个工具。 libvirt 架构（图片来源于网络，侵权必删） libvirt 除了能够支持多种虚拟化方案之外，还支持 OpenVZ、LXC 等容器虚拟化系统。它提供一套完善的虚拟机管理工具，支持 GUI 和命令行的形式，如 virsh、virt-install、virt-manager。由于它的通用性和易管理，很多云计算框架平台都在底层使用 libvirt 的 API 来管理虚拟机，比如 OpenStack、OpenNebula、Eucalyptus 等。这个工具我们仅仅提一下，有兴趣的可以装个玩玩。 下面给出 KVM 和 Qemu 的 git 路径，有兴趣的可以把源码下下来研究下。1234kvm.git：git clone git://git.kernel.org/pub/scm/virt/kvm/kvm.gitqemu.git（包括了 kvm）:git clone git://git.qemu-project.org/qemu.git PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"03 虚拟化","slug":"03-虚拟化","permalink":"https://chambai.github.io/categories/03-虚拟化/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"KVM","slug":"KVM","permalink":"https://chambai.github.io/tags/KVM/"},{"name":"Qemu","slug":"Qemu","permalink":"https://chambai.github.io/tags/Qemu/"}]},{"title":"一文读懂 Qemu 模拟器","slug":"tech/一文读懂_Qemu_模拟器","date":"2017-11-19T05:16:14.000Z","updated":"2019-04-11T14:38:24.078Z","comments":true,"path":"2017/11/19/tech/一文读懂_Qemu_模拟器/","link":"","permalink":"https://chambai.github.io/2017/11/19/tech/一文读懂_Qemu_模拟器/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ Qemu 架构 Qemu 是纯软件实现的虚拟化模拟器，几乎可以模拟任何硬件设备，我们最熟悉的就是能够模拟一台能够独立运行操作系统的虚拟机，虚拟机认为自己和硬件打交道，但其实是和 Qemu 模拟出来的硬件打交道，Qemu 将这些指令转译给真正的硬件。 正因为 Qemu 是纯软件实现的，所有的指令都要经 Qemu 过一手，性能非常低，所以，在生产环境中，大多数的做法都是配合 KVM 来完成虚拟化工作，因为 KVM 是硬件辅助的虚拟化技术，主要负责 比较繁琐的 CPU 和内存虚拟化，而 Qemu 则负责 I/O 虚拟化，两者合作各自发挥自身的优势，相得益彰。 Qemu 总结结构 从本质上看，虚拟出的每个虚拟机对应 host 上的一个 Qemu 进程，而虚拟机的执行线程（如 CPU 线程、I/O 线程等）对应 Qemu 进程的一个线程。下面通过一个虚拟机启动过程看看 Qemu 是如何与 KVM 交互的。 1234567891011121314151617181920212223// 第一步，获取到 KVM 句柄kvmfd = open(&quot;/dev/kvm&quot;, O_RDWR);// 第二步，创建虚拟机，获取到虚拟机句柄。vmfd = ioctl(kvmfd, KVM_CREATE_VM, 0);// 第三步，为虚拟机映射内存，还有其他的 PCI，信号处理的初始化。ioctl(kvmfd, KVM_SET_USER_MEMORY_REGION, &amp;mem);// 第四步，将虚拟机镜像映射到内存，相当于物理机的 boot 过程，把镜像映射到内存。// 第五步，创建 vCPU，并为 vCPU 分配内存空间。ioctl(kvmfd, KVM_CREATE_VCPU, vcpuid);vcpu-&gt;kvm_run_mmap_size = ioctl(kvm-&gt;dev_fd, KVM_GET_VCPU_MMAP_SIZE, 0);// 第五步，创建 vCPU 个数的线程并运行虚拟机。ioctl(kvm-&gt;vcpus-&gt;vcpu_fd, KVM_RUN, 0);// 第六步，线程进入循环，并捕获虚拟机退出原因，做相应的处理。for (;;) &#123;ioctl(KVM_RUN)switch (exit_reason) &#123;case KVM_EXIT_IO: /* ... */case KVM_EXIT_HLT: /* ... */&#125;&#125;// 这里的退出并不一定是虚拟机关机，// 虚拟机如果遇到 I/O 操作，访问硬件设备，缺页中断等都会退出执行，// 退出执行可以理解为将 CPU 执行上下文返回到 Qemu。 Qemu 源码结构 Qemu 软件虚拟化实现的思路是采用二进制指令翻译技术，主要是提取 guest 代码，然后将其翻译成 TCG 中间代码，最后再将中间代码翻译成 host 指定架构的代码，如 x86 体系就翻译成其支持的代码形式，ARM 架构同理。 所以，从宏观上看，源码结构主要包含以下几个部分： /vl.c：最主要的模拟循环，虚拟机环境初始化，和 CPU 的执行。 /target-arch/translate.c：将 guest 代码翻译成不同架构的 TCG 操作码。 /tcg/tcg.c：主要的 TCG 代码。 /tcg/arch/tcg-target.c：将 TCG 代码转化生成主机代码。 /cpu-exec.c：主要寻找下一个二进制翻译代码块，如果没有找到就请求得到下一个代码块，并且操作生成的代码块。 其中，涉及的主要几个函数如下： 知道了这个总体的代码结构，再去具体了解每一个模块可能会相对容易一点。 Qemu 的使用 1. 源码下载 1234567centos：sudo apt-get install qemuubuntu：sudo yum install qemu -y安装包：$wget http://wiki.qemu-project.org/download/qemu-2.0.0.tar.bz2$tar xjvf qemu-2.0.0.tar.bz2Git：$git clone git://git.qemu-project.org/qemu.git 2. 编译及安装 1234$cd qemu-2.0.0 //如果使用的是git下载的源码，执行cd qemu$./configure --enable-kvm --enable-debug --enable-vnc --enable-werror --target-list=&quot;x86_64-softmmu&quot;$make -j8$sudo make install configure 脚本用于生成 Makefile，其选项可以用 ./configure –help 查看。 这里使用到的选项含义如下： –enable-kvm：编译 KVM 模块，使 Qemu 可以利用 KVM 来访问硬件提供的虚拟化服务。 –enable-vnc：启用 VNC。 –enalbe-werror：编译时，将所有的警告当作错误处理。 –target-list：选择目标机器的架构。默认是将所有的架构都编译，但为了更快的完成编译，指定需要的架构即可。 安装好之后，会生成如下应用程序： ivshmem-client/server：这是一个 guest 和 host 共享内存的应用程序，遵循 C/S 的架构。 qemu-ga：这是一个不利用网络实现 guest 和 host 之间交互的应用程序（使用 virtio-serial），运行在 guest 中。 qemu-io：这是一个执行 Qemu I/O 操作的命令行工具。 qemu-system-x86_64：Qemu 的核心应用程序，虚拟机就由它创建的。 qemu-img：创建虚拟机镜像文件的工具，下面有例子说明。 qemu-nbd：磁盘挂载工具。 下面通过创建虚拟机操作来对这些工具有个初步的认识。 3. 创建虚拟机 使用qemu-img创建虚拟机镜像 虚拟机镜像用来模拟虚拟机的硬盘，在启动虚拟机之前需要创建镜像文件。1qemu-img create -f qcow2 test-vm-1.qcow2 10G -f 选项用于指定镜像的格式，qcow2 格式是 Qemu 最常用的镜像格式，采用来写时复制技术来优化性能。test-vm-1.qcow2 是镜像文件的名字，10G是镜像文件大小。镜像文件创建完成后，可使用 qemu-system-x86 来启动x86 架构的虚拟机： 使用 qemu-system-x86 来启动 x86 架构的虚拟机1qemu-system-x86_64 test-vm-1.qcow2 因为 test-vm-1.qcow2 中并未给虚拟机安装操作系统，所以会提示 “No bootable device”，无可启动设备。 启动 VM 安装操作系统镜像1qemu-system-x86_64 -m 2048 -enable-kvm test-vm-1.qcow2 -cdrom ./Centos-Desktop-x86_64-20-1.iso -m 指定虚拟机内存大小，默认单位是 MB， -enable-kvm 使用 KVM 进行加速，-cdrom 添加 fedora 的安装镜像。可在弹出的窗口中操作虚拟机，安装操作系统，安装完成后重起虚拟机便会从硬盘 ( test-vm-1.qcow2 ) 启动。之后再启动虚拟机只需要执行：1qemu-system-x86_64 -m 2048 -enable-kvm test-vm-1.qcow2 qemu-img 支持非常多种的文件格式，可以通过 qemu-img -h 查看其中 raw 和 qcow2 是比较常用的两种，raw 是 qemu-img 命令默认的，qcow2 是 qemu 目前推荐的镜像格式，是功能最多的格式。这些知识后面会有文章来专门讲述。 这篇文章写得有点长，可能是 Qemu 唯一一篇文章，这并不是说 Qemu 不重要，而是我们平时在使用过程中主要把它当工具用，遇到不懂的查就行了，当然，如果你觉得看代码爽一点，非常鼓励，如果看了有什么心得，我们可以一起交流交流。好了，老铁们，看在我深夜一点还在写干货给你们，就给我点个赞吧。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"03 虚拟化","slug":"03-虚拟化","permalink":"https://chambai.github.io/categories/03-虚拟化/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"},{"name":"Qemu","slug":"Qemu","permalink":"https://chambai.github.io/tags/Qemu/"}]},{"title":"虚拟化技术总览","slug":"tech/虚拟化技术总览","date":"2017-11-18T05:16:14.000Z","updated":"2019-04-11T14:38:24.066Z","comments":true,"path":"2017/11/18/tech/虚拟化技术总览/","link":"","permalink":"https://chambai.github.io/2017/11/18/tech/虚拟化技术总览/","excerpt":"","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 说起虚拟化，相信大家应该都不陌生，像虚拟内存、Java 虚拟机、Android 模拟器这些都是虚拟化技术的体现，为什么这样说，这个就要回到虚拟化技术的本质上——虚拟化就是由位于下层的软件模块，根据上层的软件模块的期待，抽象（虚拟）出一个虚拟的软件或硬件模块，使上一层软件直接运行在这个与自己期待完全一致的虚拟环境上。从这个意义上来看，虚拟化既可以是软件层的抽象，又可以是硬件层的抽象。 虚拟化技术本质上是软/硬件层的抽象 所以说，像虚拟内存、Java 虚拟机、Android 模拟器这些都属于是软件虚拟化技术，而硬件虚拟化技术更多的应用就是在云计算领域。从提出至今，虚拟化技术已经出现了多种实现方式，这些不同的方式其实就是软件和硬件的不同组合。本文主要就是对这些实现方式进行一个总览，形成一个总体认识，方便后面的学习。 VMM VMM 全称是 Virtual Machine Monitor，虚拟机监控系统，也叫 Hypervisor，是虚拟化层的具体实现。主要是以软件的方式，实现一套和物理主机环境完全一样的虚拟环境，物理主机有的所有资源，包括 CPU、内存、网络 IO、设备 IO等等，它都有。这样的方式相当于 VMM 对物理主机的资源进行划分和隔离，使其可以充分利用资源供上层使用。虚拟出的资源以虚拟机的形式提供服务，一个虚拟机本质上和一台物理机没有什么区别，可以跑各种操作系统，在之上再跑各种应用。这种方式无疑是计算机历史上非常里程碑的一步，你想想，以前可能要买多台服务器才能解决的事，现在只用一台就解决了。 虚拟机通常叫做客户机（guest），物理机叫宿主机（host），VMM 处在中间层，既要负责对虚拟资源的管理，包括虚拟环境的调度，虚拟机之间的通信以及虚拟机的管理等，又要负责物理资源的管理，包括处理器、中断、内存、设备等的管理，此外，还要提供一些附加功能，包括定时器、安全机制、电源管理等。 VMM VMM 分类 VMM 根据平台类型和实现结构有两种不同的分类，按平台类型可以分为完全虚拟化和类虚拟化，完全虚拟化就是 VMM 完全模拟出一个跟物理主机完全一样的环境。但是这个是非常困难的，首先，这需要硬件的支持，而硬件在初期设计的时候，没有那么远的前瞻性，可以预想到为虚拟化提供支持，前次，指令的复杂性，即使通过模拟的方式也很难做到全部指令都模拟。所以，就需要借助其他的一些技术来辅助虚拟化。 VMM 分类 软件辅助虚拟化是通过优先级压缩（Ring Compression）和二进制代码翻译（Binary Translation）这两个技术来完成的。简单讲，RC 基于 CPU 特权级的原理，也就是 guest、VMM 和 host 分别处于不同的特权级上（这个后面讲 CPU 虚拟化的时候会详述），guest 要访问 host 就属于越级访问，会抛异常，这时 VMM 会截获这个异常，并模拟出其可能的行为，从而进行相应处理。但这个问题很明显，就是由于硬件设计的缺陷，有些指令并不能截获，从而导致“漏洞”。 BT 可以弥补这个缺陷，它通过去扫描 guest 的二进制的代码，将难以虚拟化的指令转为支持虚拟化的指令，从而可以配合 VMM 完成虚拟化功能。这两种方式都是通过「打补丁」的方式来辅助虚拟化，很难再架构上保证完整性。 所以，后期的硬件厂商就在硬件上对虚拟化提供了支持，有了硬件辅助的虚拟化。通过对硬件本身加入更多的虚拟化功能，就可以截获更多的敏感指令，填补上漏洞。在这一块，Intel 的 VT-x/d 技术和 AMD 的 AMD-V 技术是其中的代表。 而类虚拟化则是另外一种通过软件来避免漏洞的方式，就是通过修改 guest 操作系统内核代码（API 级）来避免漏洞，这种方式好处就是可以自定义内核的执行行为，某种程度上对性能进行优化。 上面这种分类仅供了解即可，重点掌握下面这种分类，就是根据 VMM 的实现结构分类，主要分类 Hypervisor 模型（1 型）和宿主模型（2 型）。 Hypervisor 模型中 VMM 既是操作系统，也是虚拟化软件，也就是集成了虚拟化功能的操作系统，对上为 guest 提供虚拟化功能，对下管理着所有物理资源，它的优点就是效率高，虚拟机的安全性只依赖于 VMM，缺点就是管理所有的物理资源，意味着 VMM 要承担很多的开发工作，特别是驱动层面的开发，我们知道硬件的 I/O 设备是很多的，这些设备都要有对应的驱动来设配才能为虚拟机提供功能。 Hypervisor 模型或 1 型模型 宿主模型剥离了管理功能和虚拟化功能，虚拟化功能只是作为内核的一个模块来加载，比如 KVM 技术就是其中的佼佼者，KVM 技术可以说是云计算最核心的技术了，后面会经常用到。一般 KVM 只负责 CPU 和内存的虚拟化，I/O 的虚拟化则由另外一个技术来完成，即 Qemu。这些技术都是后面的重点，在这里只是提一下。 宿主模型或 2 型模型 典型的虚拟化产品 VMware VMware 可以说是虚拟化的鼻祖，现在很多公司都是在模仿 VMware 的产品，相应用过 VMware 虚拟机的朋友应该不陌生了，VMware 提供了很多的虚拟化产品，从服务器到桌面都有很多应用。主要有面向企业级应用的 ESX Server，面向服务端的入门级产品 VMware Server，面向桌面的主打产品 VMware Workstation（这个相信大家经常用），面向苹果系统的桌面产品 VMware Fusion，还有提供整套虚拟应用产品的 VMware vSphere，细分的话还有 VMware vStorage（虚拟存储），VMware vNet（虚拟网络）等。 Xen Xen 是一款开源虚拟机软件，Xen 结合了 Hypervisor 模型和宿主模型，属于一种混合的虚拟化模型，基于 Xen 的虚拟化产品也有很多，比如 Ctrix、VirtualIron、RedHat 和 Novell 等都有相应的产品。这个一般是研究机构用得多一些，生产环境中大部分用的是 KVM。 KVM KVM 也是一款开源软件，于 2007 年 2 月被集成到了 Linux 2.6.20 内核中，成为了内核的一部分。KVM 采用的是基于 Intel VT 的硬件辅助虚拟化技术，以及结合 Qemu 来提供设备虚拟化，从实现上看，属于宿主模型。使用 KVM 的厂商很多啊，像我们比较熟悉 VMware Workstation 和 VirtualBox 都在使用，在此就不一一列举了。 OK，有了这些基本认识，对于学后面的高深内容可能会好理解一些，大家如果觉得写得不错，可以给我个赞，你的鼓励是我不断输出好内容的动力。现在我开始写公众号，才发现这种看上去很虚的东西其实蛮鼓励人的，我现在看到那些坚持原创的作者都会感同身受，都会忍不住想给他们赞。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"03 虚拟化","slug":"03-虚拟化","permalink":"https://chambai.github.io/categories/03-虚拟化/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"}]},{"title":"计算技能图谱","slug":"tech/云计算技能图谱","date":"2017-11-17T05:16:14.000Z","updated":"2019-04-11T14:38:24.068Z","comments":true,"path":"2017/11/17/tech/云计算技能图谱/","link":"","permalink":"https://chambai.github.io/2017/11/17/tech/云计算技能图谱/","excerpt":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 云计算领域是一个很庞大的技术领域，技术分支很多，从底层的虚拟化技术，到各种框架，再到上层各种应用服务，都涉及非常多的技能点，","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 云计算领域是一个很庞大的技术领域，技术分支很多，从底层的虚拟化技术，到各种框架，再到上层各种应用服务，都涉及非常多的技能点，按照10000小时天才理论，即使能成为某一板块的技术专家，个人觉得也很难吃透所有的东西。下面是 infoQ 整理的一份技能图谱，我重新画了图，并增删了一部分。 可以看到，里面涉及的知识点太多了，这个公众号我会重点关注基础设施的计算和网络部分，架构的 OpenStack 、Docker 部分，开发语言重点关注 C/C++、Python，其他可能也会涉及，不管怎么样，希望能坚持下去吧。 基础设施包括计算、存储、网络、安全四大板块所涉及到的基础知识，现在比较火的容器也在列，隶属于计算部分。 架构涉及很多的框架，包括分布式消息、微服务、OpenStack 生态、Docker 生态等，这些都是一个云平台为了满足高可用、高可靠、和性能不可缺少的组件。 开发涉及到流程和语言方面，其中 Python 和 Go 是云计算时代比较常用的语言工具。 平台平台部分展示的更多的是管理和维护一个云平台的工具，其中最为重要的是数据管理部分，光这个部分都可以再生出一个庞大的技能图谱——大数据开发工程师必备技能。 应用主要是基于云平台开发的前后端应用和行业相关的应用。 运维运维也可以再生一个技能图谱，这部分仅当了解。 如果有志于找这个领域的开发工作，注意是开发，可以参考下面这个建议路径： 注意，上面是应用开发工程师，当然还有很多发展路径，比如测试、产品、运维等，就开发这个路径来说，还有系统工程师，比较注重底层，OpenStack 开发工程师，主要基于 OpenStack 开发，等等。 好了，有了大概的一个方向，接下来就开干吧。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"01 云计算","slug":"01-云计算","permalink":"https://chambai.github.io/categories/01-云计算/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"技能图谱","slug":"技能图谱","permalink":"https://chambai.github.io/tags/技能图谱/"}]},{"title":"初识云计算","slug":"tech/初识云计算","date":"2017-11-16T05:16:14.000Z","updated":"2019-04-11T14:38:24.083Z","comments":true,"path":"2017/11/16/tech/初识云计算/","link":"","permalink":"https://chambai.github.io/2017/11/16/tech/初识云计算/","excerpt":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 云计算的发展历史 我们主要从用户对云计算的认知角度来谈云计算的发展史，至于它从提出到发扬光大的那些大事件，网上搜下就知道了，而且我觉得去谈那些发展事件意义也不大，","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 云计算的发展历史 我们主要从用户对云计算的认知角度来谈云计算的发展史，至于它从提出到发扬光大的那些大事件，网上搜下就知道了，而且我觉得去谈那些发展事件意义也不大，倒不如说说我们对云计算的一个认知变化过程，我觉得任何事物存在必有其可循的迹象，可能在很久以前这东西就存在了，只不过在当时的情境下不叫这个名字而已，随着技术的发展和环境的变化，自然就演变成今天的样子。 就云计算这个话题，我就拿我们个人来举个例子，假设一个开发者闭关数日，不分白天与黑夜，倾心 Coding，终于开发出一款自认为很牛逼的产品，准备上线了，但是苦于没有服务器（资源）来承载他的产品，于是他勒紧裤腰带买了一台。上线没几天，这款产品出人意料的火爆，完全超出这名开发者的预想，于是，为了支撑流量的上涨，他又买了更多的服务器，为了维护这些服务器集群，他又开始自建机房，自己部署业务系统并运维。看着眼前这小有成就的一切，这名开发者却漏出了难色，这些支离破碎的机房运维管理工作搞得人焦头烂额，都没有心思 Coding 了。这个时候他听说有一些 IDC （Internet Data Center）运营商可以帮助企业或个人托管服务器资源，于是便当机立断把自己的服务器集群转移到 IDC 托管。正当他准备撸起袖子 Coding 之时，想到要定期去采购设备，还要跟 IDC 那边交接托管的事情就头大。这时，他又听朋友说云计算可以解决他这个问题，于是他又跑到一家云计算厂商，租用了一些资源就把这一切都搞定了。忙活了一通，终于可以安心 Coding 了。^=^ 上面这个小故事是我杜撰的，或许能在一定程度上帮助你了解云计算的一个发展历史，从自建机房，到 IDC 托管，再到云计算，整体经历过这么三个阶段。当然，从技术的角度来说，云计算的思想也是早已有之，从早期的网格计算，分布式计算，再到虚拟化技术，无不跟云计算息息相关。云计算的出现，离不开人们的需求日益变化和技术人对技术的倾心专研。 云计算服务类型 最终，云计算反过来为人们提供更好的服务。从人们的需求来看，云计算总体上提供三类服务：IaaS、PaaS 和 SaaS。 关于这三类服务，我在前文中也说了一些，在这里总结一下，IaaS 主要提供的是底层的资源服务，比如服务器、存储、网络，企业或个人租用了这些资源之后，可以根据自己的需求定制自身的业务系统，如采用什么部署环境，开发环境等，这种一般比较适合于中大规模企业。 PaaS 则是在此基础上事先构建好了所有和开发、测试、运维等相关的环境，个人或企业可以专注在自身的业务逻辑上，不必去关心底层的运行环境，因为它一般能给你提供一个高可用，高可靠，可扩展的环境，这种一般适合于个人或小规模的企业。 SaaS 就更直接一些，提供的是现成的软件或应用的服务，如 email 服务等，这种比较具有普适性，不管是个人，还是任何规模的企业，都有使用现成的各类软件的需求。 图1 云服务类型 云计算的分层架构 上面科普完了，下面从技术的角度简要说说云计算的架构。任何技术，总少不了会采用分层的架构（貌似是这样的~），这也验证了某位科学先驱所说的，任何问题，都可以通过增加一个间接的中间层来解决。云计算的分层架构可以从技术和使用者，也就是租户的角度，分为两种不同的架构，如下图，左边是技术视角架构，右边租户视角架构。 图2 云计算的分层架构 从技术视角看，计算、存储、网络等底层基础设施构成硬件资源层，虚拟化层通过虚拟化技术，并根据上层应用需求分配、编排和管理着这些资源，为了让资源具备高可用、高可靠，以及可扩展等特性，增加相应的中间层来支持，最上层则提供 Web 等友好控制台给用户，以 RESTful API 的方式展示资源，提高用户体验。 而从租户视角来看，租户根据自身业务的需求，如高可用，和所属业务领域，如游戏，依据不同的业务逻辑，来申请使用资源。这种方式能够很好隔离资源的提供者和使用者，提高了灵活性，让资源能够得到最大化的利用。 本文的目的是希望对云计算形成一个总体的认识，因为我觉得学习任何知识，按照总-分-总这条路线来进行的话，对后面深入学习会有很大的帮助，但是这得花一些时间去整理、总结，才能比较好的输出，但你们很幸运，可以直接看我总结好的，为了鼓励我更好的输出给你们，动动手指给我个赞吧，另外，由于能力有限，难免会有错误，还望留言给我指出。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"01 云计算","slug":"01-云计算","permalink":"https://chambai.github.io/categories/01-云计算/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"}]},{"title":"云计算术语扫盲","slug":"tech/云计算术语扫盲","date":"2017-11-15T05:16:14.000Z","updated":"2019-04-11T14:38:24.074Z","comments":true,"path":"2017/11/15/tech/云计算术语扫盲/","link":"","permalink":"https://chambai.github.io/2017/11/15/tech/云计算术语扫盲/","excerpt":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 资源 在云计算中，资源和服务本质上是一样的，服务可能更泛一些，资源一般特指 CPU（计算）、Mem（存储）和 IO （网络）三大资源，","text":"文章首发我的公众号「Linux云计算网络」，欢迎关注，第一时间掌握技术干货！ 资源 在云计算中，资源和服务本质上是一样的，服务可能更泛一些，资源一般特指 CPU（计算）、Mem（存储）和 IO （网络）三大资源，云计算的做法就是将闲置的这些资源充分利用起来，租给用户使用。我觉得这也有点共享经济的意思，大家把自己身边闲置的资源拿出来，分享给别人使用，我为人人，人人为我。只不过云计算这种资源比较奢侈，一般人还提供不起，只有那些大企业，在满足自己业务需求之余，还空闲着很多资源，所以，与其浪费掉，还不如租给用户去使用，既避免了浪费，还能赚钱。 云部署类型 资源多了，就会有一个问题，这些资源该放在哪，以及怎么放，这就涉及到云计算资源的部署类型，根据放的地方不同，可以分为公有云、私有云和混合云。公有云就是放在一个公共的地方，这个地方有个术语叫云服务提供商，这一般都是大公司，小公司还玩不转；私有云则是放在企业内部，一般供自身业务需求；而混合云则是两者融合起来，公有云服务体量大的业务，私有云负责数据的安全。而根据怎么放，近年来已经玩出了很多新花样，譬如把和政务相关的资源放一块，形成政务云，跟金融相关的放一块又形成金融云，类似的还有视频云、音乐云、直播云等。 云服务类型 资源整合起来，就需要对外提供服务，用户那么多，可能每个用户的对服务的需求都不一样，该怎么满足用户多样的需求，是一个非常关键的问题。比如用户想要一个开发环境，想立马就上手 Coding，你就不能纯粹给他一个裸机资源，又如用户想用 email 服务，你也必须给他装好相应的软件，用户只需动动手指就可以使用。所以，根据提供的服务类型的不同，可以将云服务分为 IaaS（基础设施即服务）、PaaS（平台即服务） 和 SaaS（软件即服务）。同样，如果再细分的话，类似的还有 DaaS（数据即服务）、SDNaaS（SDN 即服务）、CaaS（容器即服务）等。 公有云 上面已经说了一些，这里严格定义一下，公有云一般为云服务器提供商所拥有和运营，包括所有硬件、软件和其他支撑性基础设施资源，通过 Internet 向用户提供其资源，用户可以通过 Web 等方式来访问这些资源。业界比较有名的公有云厂商有：Amazon AWS、Microsoft Azure、Google Cloud、阿里云、腾讯云、百度云、UCloud 等。 私有云 私有云是专供一个企业或组织使用的云计算资源，一般部署在自家数据中心上，也可以付费给第三方的提供商托管。在私有云中，通过专用网络来维护其服务和基础结构，因而安全性会比较高。业界比较有名的私有云厂商有：VMWare、Nutanix.、深信服、华为云、青云等。 混合云 混合云组合了公有云和私有云，通过技术手段支持数据和应用程序在两者之间迁移，能够为企业提供更大的灵活性和更多的部署选项。 IaaS IaaS 提供的是比较底层的云计算服务，如服务器和虚拟机、存储空间、网络和操作系统，用户可以根据自己的需求租用特定的资源即可，云服务提供商管理和维护着这些资源，用户只需要购买、安装、配置和管理所需的软件，就可以构建自己的业务系统。 PaaS PaaS 则可以按需提供开发、测试、交付和管理应用程序所需的环境，包括中间件和数据库相关的基础结构。用户可以专注在自己的业务逻辑上，无需关心环境的问题，因为一切都就绪，你就开干就行了。 SaaS SaaS 则是提供实在的软件服务，一般用户通过订阅的方式来使用软件，随时随地都可以在云上使用现成的软件，无需下载安装，也无需关心软件升级和维护问题，因为这一切在云端都已经帮你做了。 虚拟机 虚拟机是资源的的具象，资源太抽象了，虽然说包括但不限于计算、存储和网络这三大资源，但是这些资源都是统一放在一个“池子”里，如何管理这些资源，并根据用户的需求合理地进行划分，虚拟机就是一种非常好的资源管理方式，它将物理主机上的资源进行细分，一个虚拟机使用一部分，彼此之间不会影响。在外部看来，它就像是一台真实的物理主机一样，拥有和主机该有的一切配置，包括 CPU、内存和 IO，只不过这些都是通过程序虚拟出来的。 虚拟化 虚拟化就是将资源进行细分（虚拟）的一门技术，它可以虚拟计算、虚拟存储、虚拟网络，以及虚拟网络功能。它的一个宗旨就是将闲置的资源划分出来，虚构一个和真实物理环境没有差别的虚拟环境，这样，用户在使用资源的时候，就像是在使用一台真实物理机一样。常见的虚拟化技术有 KVM、Xen、Qemu 等。 PS：文章未经我允许，不得转载，否则后果自负。 –END– 欢迎扫👇的二维码关注我的微信公众号，后台回复「m」，可以获取往期所有技术博文推送，更多资料回复下列关键字获取。","categories":[{"name":"01 云计算","slug":"01-云计算","permalink":"https://chambai.github.io/categories/01-云计算/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://chambai.github.io/tags/云计算/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://chambai.github.io/tags/虚拟化/"}]},{"title":"架构小觑——来自《大型网站技术架构》","slug":"life/架构小觑——来自《大型网站技术架构》","date":"2017-05-19T16:00:00.000Z","updated":"2019-02-23T16:42:43.144Z","comments":true,"path":"2017/05/20/life/架构小觑——来自《大型网站技术架构》/","link":"","permalink":"https://chambai.github.io/2017/05/20/life/架构小觑——来自《大型网站技术架构》/","excerpt":"这本书出版比较早了，13年出的，在互联网发展超乎想象的今天，可能书中某些东西都不值一提了，但对于没有做过什么大型项目的小白来说，还是很有指导意义的，特别开阔眼界，对性能、可用性、扩展性、伸缩性、安全性等这些抽象的词会有更为具体且全面的理解。","text":"这本书出版比较早了，13年出的，在互联网发展超乎想象的今天，可能书中某些东西都不值一提了，但对于没有做过什么大型项目的小白来说，还是很有指导意义的，特别开阔眼界，对性能、可用性、扩展性、伸缩性、安全性等这些抽象的词会有更为具体且全面的理解。 书中讲述了大量的案例，有淘宝、百度、新浪、Wikipedia等网站的技术架构分析，也有多种关于提高网站性能的技术阐述，如分布式缓存Memcached，海量分布式存储系统Doris，NoSQL数据库HBase等，更有更上层的关于架构设计的价值观，以及架构师应该具备的优秀品质和努力方向。更值得庆贺的是书中几乎对每一种架构设计方案都加了图文并茂的展示，让读者能够较为准确地把握一个系统架构从无到有，从小到大的架构演化。 所以这看起来更像是展示架构设计的思想，有了指导思想，即使互联网再怎么演变，万变不离其宗，基础的东西都是不变的。这本书提出的架构模式就是架构设计永恒的元素，正如书中所说： 模式的关键在于模式的可重复性，问题与场景的可重复性带来解决方案的可重复性。 作为一个在校生，我没做过什么中大型项目，能在单机上用LAMP套件搭建一个网站已是我能够做的全部，要说架构设计也说不出什么所以然来。所以，就大致用思维导图整理了下书中的一些知识点，姑且让自己不要看了就忘了吧。 不过，今天云计算已经发展很成熟，应该不会有人在架构设计的时候不考虑用云吧，所以，将来能够亲历一个网站从小到大演化的架构师可能就不存在了。","categories":[{"name":"读书","slug":"读书","permalink":"https://chambai.github.io/categories/读书/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://chambai.github.io/tags/读书/"},{"name":"架构","slug":"架构","permalink":"https://chambai.github.io/tags/架构/"},{"name":"阿里巴巴","slug":"阿里巴巴","permalink":"https://chambai.github.io/tags/阿里巴巴/"}]},{"title":"我锤这次真的惊艳到我了！","slug":"life/我锤这次真的惊艳到我了","date":"2017-05-09T16:00:00.000Z","updated":"2019-02-21T16:21:40.199Z","comments":true,"path":"2017/05/10/life/我锤这次真的惊艳到我了/","link":"","permalink":"https://chambai.github.io/2017/05/10/life/我锤这次真的惊艳到我了/","excerpt":"不带半点的感情掺杂，作为一个理性的消费者，我仍然觉得「坚果pro」是目前为止我见过的最好的外观设计的手机，它满足了我对手机设计的所有期待：简洁，大方，硬朗，充满了质感，漂亮得不像实力派，感觉就像是为我量身定制的一样。","text":"不带半点的感情掺杂，作为一个理性的消费者，我仍然觉得「坚果pro」是目前为止我见过的最好的外观设计的手机，它满足了我对手机设计的所有期待：简洁，大方，硬朗，充满了质感，漂亮得不像实力派，感觉就像是为我量身定制的一样。 关注手机圈的朋友应该注意到这两年，手机正在从一个技术驱动的产品走向设计体验驱动的产品。很多家厂商都在逐步加入这种元素，像以前丑得一笔的华为，不管是去年推出的荣耀V9，还是今年的P10，都让我转变对它的好印象；同样还有小米，初期小米的手机也是没法看的，但凭借「性价比」还是赢得了不少鲜花和掌声，后来有所改观，但看上去还是太大众化了（应该说是小米引领的大众化）。大众化也没什么错，至少代表了主流的审美观，只是没什么特色。但作为中国手机行业的引领者，小米从来都不想让自己停留在大众化的边缘，去年底的小米MIX和今年的米6，就是对此最好的证明，特别是MIX，成为了今天各家争相模仿的对象。 老罗的锤子则显得与众不同，谁叫老罗就是个与众不同的人呢。从第一代的锤子T1，老罗的定位就是一款设计优秀，体验极致的产品，设计上拿到了设计界的奥斯卡「iF金奖」，体验上造就了风格独特的拟物化设计的「Smartisan OS」。后来推出的千元机坚果，一系列的情怀背壳和周边，引领了一波潮流，带动了多少人心中依稀尚存的理想主义情怀，直到今天仍然被很多人所津津乐道。再后来的M1，虽然设计上没有前两款惊艳，但体验上可谓上了一个里程碑，首屈一指的OneStep和Big Bang，颠覆了人机交互的模式，带给了人们更多的想象空间。再到昨晚发布的坚果pro，惊艳到我已经完全控制不住自己了，隔着电脑屏幕都像老罗一样激动不已。 发布会可以说上演一出剧情大反转的好戏。起初的剧情设置了两场戏，一场是发布会前网上流出的谍照，当时看到那些照片我失望透顶，我只说一点就是后背有圆滑的弧线，和现在市面上清一色的手机没什么两样，哦对了，有人形容“这不就是魅族吗”，自己想象吧。另外一场是发布会的前两个半小时都在讲功能，对于机身就放了几张模糊的图片，把边边角角都掩盖了。开始还以为老罗默认了网上流出的谍照就是真机的样子了，他都懒得说了，倒不如多讲点手机的设计，希望扳回一城。没想到老罗这是在憋大招，最后一个小时（没错，这场发布会破天荒开了三个半小时）开始拉上了大红屏幕，犹如一场魔术盛宴即将拉开帷幕一样，哐哐连续几张精致的手机谍照出现在屏幕上，引得台下观众哇哇大叫，声浪犹如潮水般一波接一波，我在屏幕前也是激动不已。 接着老罗也难掩内心的激动，哽咽了起来。 我希望你们记住一句话，如果有一天我们的手机卖到几百万几千万台，连傻逼都在用我们的手机，你要知道 … 其实 … 你要知道，这是为你们做的。 是啊，不管怎么样，不管哪一天锤子真的成了，连傻逼都在用，锤子的初心依然牢固地系在每一个锤友身上。 不说了，来看看这场发布会又带来哪些装逼的句子。 谈到坚果pro的设计语言，老罗简单粗暴的表示「你还要怎么样」 圆滑当道时代的锐利异类 肉感时代的纤瘦身影 大红大金时代的内敛与闷骚 全玻璃面板时代双材质的惊艳碰撞 仍然漂亮得不像实力派 改变人类行程的足迹。 最后，引用「手机中国」的一句话来总结老罗和锤科。 老罗和锤子科技早已不仅限于手机行业现象那么简单了，他可能是企图以极端审美与大众审美的对抗，甚至是理想主义与传统商业规则的对抗中最具影响力的那一个，不管成与不成，都会对中国的创业者们产生巨大的影响，当然，如果这次没成的话，额，那就再尝试抢救一下，T3加油！","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[{"name":"老罗","slug":"老罗","permalink":"https://chambai.github.io/tags/老罗/"},{"name":"锤子科技","slug":"锤子科技","permalink":"https://chambai.github.io/tags/锤子科技/"}]},{"title":"《人民的名义》好在哪","slug":"life/《人民的名义》好在哪","date":"2017-04-26T16:00:00.000Z","updated":"2019-02-21T16:07:14.574Z","comments":true,"path":"2017/04/27/life/《人民的名义》好在哪/","link":"","permalink":"https://chambai.github.io/2017/04/27/life/《人民的名义》好在哪/","excerpt":"紧跟中央反腐大潮，一众老戏骨加持，扎实的剧本，紧张的剧情，《人民的名义》猝不及防地在这个开春之际火得一塌糊涂。","text":"紧跟中央反腐大潮，一众老戏骨加持，扎实的剧本，紧张的剧情，《人民的名义》猝不及防地在这个开春之际火得一塌糊涂。 看完我迫不及待想写一篇文章来记录一下。作为一个互联网从业者，我想借自己对互联网的思考，从自己的角度来分析一下这部现象级的电视剧到底好在哪？ 紧贴时事第一点也是最重要的一点，当然就是大家众所周知的紧跟中央的反腐之风。这部剧中的人物在现实中都能看到其原型，譬如小官巨贪的“赵德汉”、出逃的“丁义珍”、公安厅长“祁同伟”等等。在人们感叹高能的时候，殊不知这是当下的现实已经到达这个程度。这是现实中实实在在发生的事，只不过作为平民百姓的我们，永远也无从感知那种官场的世界。这部剧恰好带我们体验了一把，刷新了我们对这个世界新的认知。 政治对我们来说说大也大，说小也小，大的是它有不为人知，神秘但又神圣的一面；小的是它其实关乎着我们每一个人的点滴生活。所以，这一部剧受到各个年龄层的人喜爱，大到七老八十的大爷大妈，小到刚上学的小朋友。这样一部大火的剧，除了接地气的政治表达之外，其实还有很多令人津津乐道的点。 多线叙事这种常用在电影里面的叙事技巧，用在电视剧中让人耳目一新。剧中多处使用这种技巧，将一个个迷雾在多条线中来回穿插，逐渐真相大白，可谓引人入胜。比如在讲到“祁同伟”当年为了得到后台关系，不惜违背自身意愿下跪求婚的时候，就安排了三条叙事线。第一条是当事人“祁同伟”和“高书记”说的真心话，第二条也算是当事人的“梁老师”和闺蜜“吴老师”的谈心，第三条则是旁观者的“侯亮平”和自己的老婆茶余饭后的交流。一个简单的回忆录，却用了这样的三条叙事线。在把“祁同伟”这个“于连式”的人物性格交代得更加丰满立体的同时，也吸引着观众在不同的视角中，感受人物内心那种激烈的情感冲突。可以说，这种方式调动了我很多感官的体验，欲罢不能。 当下流行元素近两年科技行业发展非常迅猛，特别是互联网行业。很多传统行业为了能够续命，都纷纷互联网化，即用互联网思维来强化自己。这部剧着眼的是当下，自然少不了当下潮流的科技元素。 黑科技剧中很多地方都体现着高科技，用当下科技界流行的术语来说就是「黑科技」。当然用黑科技来评价剧中的科技元素，有点夸大其词。因为这些科技都是有科学依据的，并不像黑科技定义的那般玄乎，不明觉厉。其中最有科技感的几个地方，一个是追踪技术的应用上。比如“丁义珍”出逃的场景，通过手机的GPS定位技术，可以清楚地追踪目标的移动。同样还有追踪“蔡成功”的司机小钱的场景，这些都能简单地通过公安部的追踪系统做到。 另外一个黑科技体现在侦查员胸前佩戴的微型摄像机上。这种摄像机携带轻便，集摄像、录音、拍照等多种功能于一体，而且具有联网功能，可以通过网络将视频实时地传输到中控系统进行处理。比如很经典的一幕是“陆亦可”她们到“高小琴”的山水庄园去调查，而“侯亮平”他们则是在检察院的中控屏幕上看现场直播，指挥着这一切。最后，“高小琴”还和“侯亮平”来了一次远程的FaceTime。诸如此类的黑科技还有很多，在此就不一一细数了。这些黑科技某种程度上 也是在向世人传话“小子，千万别犯事，我盯着你呢！”。 互联网+真没想到，这部剧会提到「互联网+」这个词。这份功得记在年轻一代的“郑乾”身上。很多人都说“郑西坡”和“郑乾”这父子俩拖慢了整部剧的节奏，毁了这部剧。其实在我看来，导演这样安排肯定是有原因的。剧中清一色都是老干部，这样飚戏免不了严肃压抑。适当加入一些年轻的元素，有助于气氛的调节，也能引起一些年轻人的共鸣。而且这对父子也挺滑稽搞笑的，想必很多人在看一些桥段时都会哈哈大笑起来吧。 最主要的是“郑乾”在一众普通传统工人中代表着年轻，新鲜。他这一代人深受互联网的影响，张口闭嘴互联网。他是网上的活跃分子，干着很多类似水军干的事情，转帖，删帖，点赞。这种事如果处理得好能得到一些好处，否则一不小心就会踏入网络犯罪的深渊。好在“郑乾”是个精明的主，智商情商都很高。所以最后才应民众的呼声挤掉他爹，当上大风厂的董事长，跟自己的员工大谈特谈互联网+。这算是一个小人物借助互联网在传统行业逆袭的故事。不难看出，导演的用意其实很深的。 网络舆情反腐是全民参与的大事。在今天这个「自媒体的时代」，现实生活中的任何一点小事在短时间之内就能让全世界的人知道。就像大风厂的拆迁事件，人心惶惶，舆论的声音短时间就传到中央领导的耳中。特别是有很多像“郑乾”一样喜欢煽风点火的人，巴不得把事情搞得越大越好。所以，在今天这个时代，不只有法律这双有形的眼睛在盯着你，更有千千万万双隐形的眼睛同样在盯着你。 授人以知识这部剧好看除了反腐高能之外，最主要的一点，我觉得是它授人以知识。暂且不说「官不聊生」、「无私者无畏」、「姓蒋还是姓汪」这些充满深厚政治意义的词。咱们就说说那些相对接地气，能够引发我们平民小百姓深思的词。这些词有些是生造的，但在当时的场景下，形容非常精准贴切。有些是已经存在的，但似乎被我们忽略了，在一部电视剧里提起，着实引人深思。 灵魂清零这个词就是一个生造的词。这是“祁同伟”自杀后，“侯亮平”向“高书记”汇报，他为什么没有杀自己的原因。原话是这样的： 我觉得，是那首儿歌起了作用，孩子们天真无邪的声音，在祁同伟阴暗的心灵，投上了一缕阳光，唤醒了他的人性，让他「灵魂清零」。 这个词用在这里就非常精准，恰如其分地说出了“祁同伟”当时灵魂受感化的心理。用我的理解，这个词的大意就是，我们每个人曾经都有让自己超脱感动的瞬间，即使是一个无恶不作的人，当他对这个世界不抱有任何想法的时候，可能唯一能想到就是曾经那个让他感动的瞬间，这足以唤起他心中的美好。 人格美容这也是一个生造词。也是在同一次汇报中，“侯亮平”评价和“高书记”有「所谓爱情」的“高小凤”，其实是经过「人格美容」的美女。“高书记”很诧异，本来是自己给学生上课的，反倒被学生上了一课。“侯亮平”解释到： 人格美容是我发明的一个新的概念，它的基本定义是，一个人的从前和现在，「可以通过简单的培训变成完全不同的两个人」。 最后一句话是我加的，剧中说到那里就跳到另一条线上叙事去了，最后也没有接着解释。但是其实这个意思已经非常明了了。 美容毕竟是美容，总有要卸妆的时候，卸了妆之后可能完全就是另外一个人。这是现在社会上很多不为人知的黑暗行径的体现，那些别有用心的人通过对一些酒店服务员或其他身份稍卑微的人员，进行一些有针对性的专业培训，然后投一些官员所好，从而将其拉下马。这种诱惑，稍有不慎，就会万劫不复。就像剧中的“高书记”一样，关关都能过，就是难过美人关。 形婚这算是一个冷知识了吧。「形婚」，顾名思义就是形式婚姻。夫妻双方只是名义上的夫妻身份，但由于彼此的利益关系而协商住在一起，其实无实质内容。剧中“高书记”和“吴老师”就是过着这样一种生活。刚开始我还有点纳闷，为什么夫妻俩一个住楼上，一个住楼下，看到后面才明白是怎么回事，同时有点让人哗然。哗然的原因在于“吴老师”的利益，这种利益最主要的是隐秘在她内心的那点卑微的现实。 精致的利己主义者这个词虽不是生造词，但是一个非常新的词。它是在2015年由北京大学中文系的钱理群教授首次提出的： 我们的一些大学，包括北京大学，正在培养一些「精致的利己主义者」，他们高智商，世俗，老到，善于表演，懂得配合，更善于利用体制达到自己的目的。这种人一旦掌握权力，比一般的贪官污吏危害更大。 在这部剧中是“侯亮平”用来形容“吴老师”的。当从“吴老师”口中说出自己甘愿形婚的目的，除了为女儿考虑之外，还有，需要“高书记”手中的权利，以及，自己作为大学教授放不下的面子。“侯亮平”听到这里，就说“吴老师”真是一个精致的利己主义者，“吴老师”似乎也不反对，只是一笑置之。 达康书记当然，让这部剧大火，还有一个更重要的原因，就是「达康书记」。一言不合就爆炸，却有几分肝胆柔肠的达康书记，在这个开春之际着实火出了天际。各种表情包满天飞，观众倒也乐此不彼。饰演达康书记的吴刚也是身价暴涨。真的要恭喜这种大器晚成的老戏骨，演得真是太特么好了。","categories":[{"name":"影评","slug":"影评","permalink":"https://chambai.github.io/categories/影评/"}],"tags":[{"name":"人民的名义","slug":"人民的名义","permalink":"https://chambai.github.io/tags/人民的名义/"}]},{"title":"我眼中的国产电影Top10","slug":"life/我眼中的国产电影Top10","date":"2017-04-24T16:00:00.000Z","updated":"2019-02-21T16:11:11.266Z","comments":true,"path":"2017/04/25/life/我眼中的国产电影Top10/","link":"","permalink":"https://chambai.github.io/2017/04/25/life/我眼中的国产电影Top10/","excerpt":"国产电影给人的感觉一直都是不温不火，特别是商业化气息浓重的今天，大多数导演拍戏都不是从本心出发，而是特意去迎合市场，迎合观众的口味。所以，这两年烂片层出不穷，值得一提的好电影屈指可数。","text":"国产电影给人的感觉一直都是不温不火，特别是商业化气息浓重的今天，大多数导演拍戏都不是从本心出发，而是特意去迎合市场，迎合观众的口味。所以，这两年烂片层出不穷，值得一提的好电影屈指可数。 在细数这份榜单之前，需要说明一点是我个人的口味偏悬疑、动作、喜剧、剧情类的电影。所以，这份榜单有我个人的偏好在里面，不尽客观。 十《杀破狼》香港黑帮之经典，快意恩仇式的暴力血腥，剧情紧凑，畅快淋漓。几场杀人戏令人头皮发麻，忌讳者慎入。我非常喜欢戏中甄子丹和吴京的那场“史无前例，后无来者”的对决戏，简直是教科书般的动作设计。作为香港动作片爱好者，这部电影不容错过。 九《新警察故事》成龙大哥有很多好电影，但我唯独喜欢这一部。直到今天，我都会时不时刷上一遍，看不过瘾。这是唯一一部集结了两位电影圈中有口皆碑拍戏从不用替身的演员的电影，大哥和谢霆锋。意义之大不用多说。另外，喜欢这种大哥带小弟的电影，近几年很多导演都会启用小鲜肉担纲主角，本来很好的剧却被尽毁。这一点，应该多学学韩国。最后，我还想说，这可能是吴彦祖的巅峰之作了吧（吴彦祖的粉丝不要打我）。 八《罗曼蒂克消亡史》中国少有的导演个人风格鲜明的电影。有人评价说程耳是中国的昆汀。暴力美学的呈现和分镜头的切换确实能看到昆汀的影子。但我觉得这部电影比昆汀式电影高明的一点是柔性感的呈现。这一点不单体现在暴力美学上，更多是人物隐忍心性的塑造，以及不疾不徐的节奏把控。这是程耳导演的第二部电影，第一部《边境风云》也很好看。 七《喜剧之王》说到十佳电影，怎么能少得了星爷呢？星爷的好电影也有好多，我最喜欢《喜剧之王》和《功夫》这两部。但要论对星爷的意义和中国电影史的影响，前者可能比后者要好过十部《美人鱼》（个人观点）。剧中很多桥段和台词在今天都还在被人们所津津乐道，特别是那句“我养你啊”，甚是带感。 六《西游记之大圣归来》国产动画电影的巅峰之作。《人民日报》甚至评价说这是中国动画电影史以来的现象级作品。你要问我为何给一部我们小时候就看得很厌烦的动画片这么高的排名，我想说任何描述这部电影的好的词语都显得太苍白了。我想上点情怀的东西: 这是压抑了500年的中国超级英雄孙悟空走向世界去惊艳四座的最佳时刻！ 五《心迷宫》中国少有的能上映而且非常好看的独立现实主义题材电影。很多人评价是中国版的11.14。风格独特让人耳目一新。影片着眼于中国农村的犯罪事实，选用的都是不知名演员，属于小成本电影。但剧本扎实，纪实的镜头和跌宕起伏的剧情形成极大反差，不可谓是一部艺术上乘之作。 四《智取威虎山》这是徐克导演试水3D电影的最佳范本。对样板戏进行了新解，融合潮流的谍战动作元素，全片高潮迭起，背景音乐燃爆，是视觉听觉的极致享受，观影过程简直不能太棒。都说《湄公河行动》刮起了主旋律之风，其实早在这部时就已开始。张涵予也由这部戏成功转型为中国的硬汉大叔“连姆·尼森”，让人好生喜爱。另外，本片的戏曲艺术也是展露无疑，特别是对暗号片段百看不厌，让人浑身起鸡皮疙瘩。英雄主义情愫的流露也不比他老美差。值得一提的是，为什么林更新这么受徐克导演青睐，这部电影也许能说明一切。 三《全民目击》中国另一位具有极强个人风格的导演非行的作品。我甚至以为他和程耳将会是未来中国电影的顶梁柱，前提是不犯什么错误。因为他们把个性追求当信仰，是不太可能出烂片的。要说《心迷宫》、《罗曼蒂克消亡史》这些电影的叙事风格在西方还能找到影子，《全民目击》完全是自成一家。这也奠定了它不可替代的地位。全片有多种叙事结构交结在一起，有线性的、倒叙插叙的，更有分层次、循环嵌套的。独特在其剪辑手法，以快进的方式回放每一帧，以弥补那种突然出现的生硬感。孰优孰劣，仁者见仁智者见智吧。但坚持这种独特性，还是值得人浓墨重彩一笔的。对了，对于其前作《守望者》，有人这么评价: 前三十分钟以为是烂片，中三十分钟以为是雷片，最后三十分钟原来是好片 二《让子弹飞》姜文导演的这部电影的艺术价值可能远比我们所能看到的要高得多。离奇荒诞却又单纯至极，奇幻冒险却又紧贴现实，全程高能热血却又幽默风趣，兼具宫崎骏的梦幻意象和久石让的柔性之美，在一个乌托邦式的世界中以卡通式的天真逻辑揭开了强烈的政治寓意。上映之初人们赞不绝口。据说姜文导演的初衷构想是把背景定在现代，但考虑到过审问题而不得已，殊不知效果奇佳。看看今天火得一塌糊涂的《人民的名义》，过审问题还是问题吗？这倒是一件令人欣慰的事。剧中演员个个都挺惊艳的，三巨头的斗智斗勇让人看得过瘾，其他配角也相当出彩。廖凡也因为这部电影慢慢成长起来，成为“长得有特点”类型演员的佼佼者；陈坤可谓让人跌破眼镜，不过身为演技派的坤哥应该没有他不能胜任的吧。“让子弹飞一会儿”！ 一《无间道》三部曲第一名当之无愧是《无间道》。经典之处不容多说。我眼中悬疑片的最高水准，至今无人可以超越。梁朝伟的演技让我第一次觉得原来真是有好演员的，真正的用眼睛都会演戏的男人！一千个人眼中有一千个哈姆雷特，真正伟大的电影就留给世人去评判，留给历史去记载吧！我就不必多说了。","categories":[{"name":"影评","slug":"影评","permalink":"https://chambai.github.io/categories/影评/"}],"tags":[{"name":"电影推荐","slug":"电影推荐","permalink":"https://chambai.github.io/tags/电影推荐/"}]},{"title":"吐血整理双罗际会9个小时的《长谈》笔记","slug":"life/双罗际会的《长谈》擦出了怎样的火花","date":"2017-04-23T16:00:00.000Z","updated":"2019-02-23T16:42:38.161Z","comments":true,"path":"2017/04/24/life/双罗际会的《长谈》擦出了怎样的火花/","link":"","permalink":"https://chambai.github.io/2017/04/24/life/双罗际会的《长谈》擦出了怎样的火花/","excerpt":"一位是当今科技圈拥有多重身份的科技新星罗永浩（老罗），一位是传媒界成功转型的创业先锋罗振宇（罗胖），当这样两位个性鲜明的中年人聚在一起时会擦出怎样的火花呢？","text":"一位是当今科技圈拥有多重身份的科技新星罗永浩（老罗），一位是传媒界成功转型的创业先锋罗振宇（罗胖），当这样两位个性鲜明的中年人聚在一起时会擦出怎样的火花呢？ 一个罗粉心中老罗的样子说起老罗，和很多人一样，我也是通过网上流出的音频知道他的。那种幽默中透露着很强煽动力的话语让我一下子就喜欢上了他。后来就在网上搜各种关于他的内容，才知道，原来老罗当时已经是小有名气的网红了。网友为其整理的老罗语录能够写成一本书！我开始看这些经典语录，也看关于他的各种演讲视频。小小的心灵犹如虔诚的禅语洗涤一般，充满了力量。就这样，我也成为了罗粉。 辍学者，新东方英语老师，老罗英语培训学校、牛博网创办者，锤子科技CEO，众多身份之后是老罗彪悍人生的真实写照。很多人对老罗还有另外的印象：好战分子。最典型的例子就是砸西门子冰箱事件，微博上经常跟别人“约架”等等。可是这不正好说明他不信邪，不妥协的求真品质。做手机之后，老罗收敛了很多，他也在发布会上不止一次提醒自己要克制。那么，除了我们众所周知的那点事之外，这次《长谈》展现了一个怎样鲜活立体的老罗呢？ 做手机是一种辜负自己天分的天才生活态度“一个英语老师如何做手机？”这是很多人疑惑的问题。老罗坦诚，要赚钱很简单。自己赚钱最快的方式是做脱口秀，签一个年约，六个月做节目六个月度假。所谓的“站着把钱赚了”。但老罗考虑更多的是做满足自己梦想和追求的事。 数码产品是爱好外人可能不知道的是，老罗选择做手机实质从心出发。作为一个热爱数码产品多年的文艺中年，老罗已经研究人机交互六年以上，工业设计领域也已研究了十年以上，市场和品牌传播能力在英语培训行业已经获得了证明。这些经历都让老罗的起步奠定了良好的基础。 所以我认为比起其他的创业公司来说，我做这个的分险是很小的，我起步就是六十分，我需要弥补我自己的那个四十分的短板。 科技行业没有百年老店谈到科技行业，老罗难掩兴奋。他觉得科技行业没有哪一家公司因为固有的优势始终保持领先，再牛的公司一百年百分之百完蛋，像牛的Google、亚马逊可能50年就都不行了。反之，他举了可口可乐这样的传统行业，只要一个成熟的职业经理人团队，不犯什么严重的错误，维持几百年都不会有问题。所以，他觉得科技行业没有百年老店，这是他特别兴奋且欣慰的一件事。 我讨厌一个领先者，由于固有的优势和资源，始终领先，这不是我希望看到的世界。 正因此，科技行业遍地充满着机会。但并不是每个人都能抓住这个机会。老罗认为：锤子科技商业上的成功是产品的成功。 科技行业小的公司打败大的公司，核心如果没太大的意外是靠产品，不是靠运气或者什么其他的莫名其妙的东西，而是看它真正比别人做得好，给别人带来好的东西所以成功。 下一代计算平台的预备选手还有一个重要的原因，老罗进入手机行业是想有资格成为下一代计算平台的预备选手。自从人类发明计算平台以来，从早些年科学家在实验室使用的大型计算机到后来的个人PC，再到如今的手机。每隔一二十年，承载不同计算平台都会诞生无数伟大的科技商业公司，如微软、苹果等等。它们分别是两个时代的计算平台霸主。在PC时代，微软打败了苹果成为霸主。但是在智能手机时代到来时，苹果却将微软远远甩在身后。背后的商业逻辑则是科技公司在面对下一代新的计算平台时是否有参赛权。 下一个平台如果没有意外一定是眼镜，VR这种眼镜，比如说12年13年，十年左右下一代平台，一个卖空调的企业可能上这个牌桌，你做电视上不了，你已经比中国最大的科技公司还大，但是这儿跟你没有关系，我的梦想是做最大的计算平台，在平台革命的时候参与或者领导一次，这是我的终极梦想。 后悔在乔布斯活着的时候没有去旧金山，谈到乔布斯时有些失落谈到“如果你可以体验另外一个人的工作和生活你会选谁？”这个问题时，老罗的答案自然是乔布斯。他为乔布斯活着的时候没去旧金山听现场特别后悔，他觉得没有去做这个事是非常不可思议的事。 向往像乔布斯一样推动世界进步的行业英雄老罗希望在历史发展的进程中，能够留下自己的足迹。像乔布斯一样，做一些cool的事。 虽然没有乔布斯，我们也会有智能手机，也会有今天的移动互联网，但是看历史发展过程当中有关一些关键性的人物出现在一个结点上，使得人类进步往前被一个人的一己之体提高了三四年，这个是科学史上屡见不鲜。我会特别向往如果你能在推动世界进步过程中，由于个人的力量导致出现一个变化使行业进程往前提个三五年，这个东西能够满足感远远超过金银财宝，这个是我们特别向往的事情。 产品型CEO老罗和锤子科技的核心创业逻辑是——一家靠产品驱动的公司。老罗认为锤子科技的核心创业逻辑和博朗电器、索尼、苹果这些公司是一样的。他们想做不一样的事。 人类电子产品的消费历史上有三个格外不一样的公司，就是博朗电器、索尼和苹果。这三家公司和同时代的所有的电子产品的公司有一个显著的不同，从用户体验角度体现出来就是产品设计得好，细节很细腻，做了一些非常优秀的让人惊喜的一些东西。从研究企业的角度来看这三家公司的共同特征就是三个公司的创始人或者创业团队兼具文科生和理科生的思维。在大概率是由理科生、科学家创办公司的科技行业，如果公司是纯技术驱动，理科生没有问题。但是如果是制造面对大众消费者的产品，这些技术驱动的公司就会欠缺审美、设计和细腻的心理学考量。而上面的这三家公司则兼具这些思维，所以他们的产品就会格外不一样。我们认为这也是我们一开始创业的逻辑。 差异化且优秀是进步的永动力不管是在做英语培训时期，还是现在做锤子手机，老罗给人的印象都是与众不同。老罗知道，人类进步的发展就是不断寻求差异化的历史。要想在竞争白热化的手机行业站稳脚跟，必须做到差异化且优秀。为此，从创业的第一天开始，老罗就努力将差异化做得更好，希望在“这儿弄出一个特别大的份额来”，这样才能对未来充满信心。 锤子手机的与众不同这给他带来了国际工业设计史上的地位：第一款中国大陆获得IF设计金奖的手机。精致硬朗的双面玻璃机身，当时来说少见的使用三明治构造的设计 ，在当时来说可谓惊艳。更为人所津津乐道的是Smartisan OS，图标采用拟物化的设计风格，在当时清一色的扁平化设计风格盛行的时候，锤子手机标新立异。这是锤子科技差异化的地方，更是它最大的核心竞争力。 锤子官网介绍上有这么一句话：锤子科技的使命是用完美主义的工匠精神，打造用户体验一流的数码消费类产品（智能手机为主），改善人们的生活质量。 15%的员工淘汰率是永葆公司青春的秘诀谈到近些天高管离职风波（有一定知名度的有CTO钱晨博士，云平台总监池建强，设计总监罗子雄），老罗似乎看得很淡。 我认识很多大企业的告诉我，我们过去常年维持在年流失率不到7%、8%，说这是很不健康的，一个正常公司如果到了六七百人的规模每年强制淘汰15%都是正常的，我们无比的得益于公司过于稳定，他说这个是不健康的，这个是业余的，要强制15%末位淘汰，虽然这样很残酷，但是这样才能保持战斗力。 标签和真相满足乔哈里窗格创办锤子科技这些年，老罗身上被贴上了很多标签：理想主义、情怀、工匠精神、天生骄傲……这些词在老罗的强大营销能力下，逐渐由陌生变成了大众热词，再由大众热词逐渐出现烂大街的厌烦感。这些词本来是很好，很正能量的词，最后却变了味。老罗也很无奈，并坦然表示： 真相、和你自己认为的，和别人认为的，这三件事，永远都是三件事。所以，从这意义上，很多东西都是我后来也就认了，没有办法就认了，但是其实跟我没有什么特别大的关系。 情怀是别人眼里的我情怀这个词是老罗在发布T1的时候不经意间提到的，然后就被外界解读为“手机是白送的，情怀就值三千块”。这给老罗造成不少尴尬，包括去找投资人和合作伙伴谈的时候，给人家“不是卖手机，是卖情怀”的先入为主的印象。 在那个发布会上，全程我就提了这么一句，结果这一句被很多偏文青的这种媒体的记者当成一个事，然后去讲，讲的话那些偏理科生就觉得很烦，你做科技企业的讲什么情怀，然后拿着个就使劲恶心我，包括我们手机上市以后，他们说你这个手机是白送的，情怀就值三千块，就用这个恶心我们，后来越传越广。 工匠精神是趋势 工匠精神，是指工匠以极致的态度对自己的产品精雕细琢，精益求精、追求更完美的精神理念。 去年还被写入政府的工作报告中。其实这个词早已有之，但真正流行起来还是靠老罗的推动。但老罗很谦虚的说“这是抬举我们了”。 我年轻的时候，1994、1995年在韩国做过差不多一年的蓝领。我在韩国打工的时候，韩国的报纸天天讲一个词叫“匠人精神”，其实就是我们讲的工匠精神。有人说是我们提倡起来的，这是抬举我们了，是因为中国制造业，还有消费水平都到了这个阶段，它是一个必然，历史的必然。 抛开金钱讲理想主义没用从2010年到2014年，老罗每年都如期给大家带来一个理想主义者的创业故事。当时对读大学的我来说，每年期待这场视听盛宴可以说胜过其他任何事。时到今日，老罗再次谈到这个话题，有了更多现实的考量。 我觉得为什么我们这个企业挣钱以后也是要始终讲理想主义，要有追求。我理解的好企业是要在金钱之上的，但不是说放弃金钱，金钱始终是一个基础，金钱之上有更高的追求，但是这只是我的意愿，如果这个企业不控股了，我讲这个有什么用。 支持者叫锤友，而非锤粉这两年随着互联网的发展，“粉丝文化”逐渐向互联网行业渗透，特别是像以雷军的小米为首的众多科技公司，都以自己独有的方式在经营着自己的粉丝。老罗作为一个自带流量和粉丝的中年网红，却比较忌讳这个词。他有自己的新意： 由于在理念上和价值观上，我本质上和他们是一类人，只是因为我由于某些特殊原因而一路走红，我充当了他们认可的价值观的执行者。所以我们不认为他们是我们的粉丝，因为一旦我们公司做了任何违背我们信任的价值观方面的事情，他们都会立刻跑掉。 谈粉丝经济进一步谈到粉丝经济，老罗的观点很犀利。这不禁让人联想到汪峰当初做耳机为什么没做起来。 我再澄清一下，粉丝经济的载体必须是一个20美元左右的东西，这个是通行全世界的东西，在粉丝身上赚钱的明星，都是卖一本书一个碟，电影票。一个偶像的脑残粉支持卖一两千块的东西，在商业上成功的例子几乎没有。 用心经营锤友对于锤友，老罗自觉有些愧疚。由于人手等原有，锤子做不到像小米那样用心经营自己的用户。但是国内外170、180个城市的锤友们都自发组织建立锤友群，老罗欣慰的同时表示感激，并让公关团队在活动的时候送一些T恤衫，海报，让这些活动更顺畅。其实，就像老罗说的，既然确定是同一类人，不管经不经营都是那些人。 罗胖这个死磕侠最后，不得不提罗胖。这两个人身上有太多的相似性，所以他们才会凑到一块。罗胖这两年动静搞得很大，先是跨界搞逻辑思维，后来又做得到，倡导知识经济。这还不够他折腾，每天早上6点准时发音频，做20年的关于时间的朋友的跨年演讲，现在又成了《奇葩说》的常驻嘉宾。真是不折腾不成魔。但我想说，时代的进步需要这样的人。","categories":[{"name":"读书","slug":"读书","permalink":"https://chambai.github.io/categories/读书/"}],"tags":[{"name":"老罗","slug":"老罗","permalink":"https://chambai.github.io/tags/老罗/"},{"name":"罗胖","slug":"罗胖","permalink":"https://chambai.github.io/tags/罗胖/"},{"name":"锤子科技","slug":"锤子科技","permalink":"https://chambai.github.io/tags/锤子科技/"}]},{"title":"在手机严重同质化的今天，小米6带来了什么惊喜","slug":"life/在手机严重同质化的今天，小米6带来了什么惊喜","date":"2017-04-20T16:00:00.000Z","updated":"2019-04-16T12:24:58.207Z","comments":true,"path":"2017/04/21/life/在手机严重同质化的今天，小米6带来了什么惊喜/","link":"","permalink":"https://chambai.github.io/2017/04/21/life/在手机严重同质化的今天，小米6带来了什么惊喜/","excerpt":"在手机严重同质化的今天，仍然还有一些厂家在不断涌入这个市场，究其原因，我想现在的手机已经不在单纯是一台手机，而是一台连接多种智能产品的连接器，在未来可能就是一台AR，一台人工智能机器终端。大家不是为了现在能够分一杯羹，而是为了将来能有自己的生存空间。","text":"在手机严重同质化的今天，仍然还有一些厂家在不断涌入这个市场，究其原因，我想现在的手机已经不在单纯是一台手机，而是一台连接多种智能产品的连接器，在未来可能就是一台AR，一台人工智能机器终端。大家不是为了现在能够分一杯羹，而是为了将来能有自己的生存空间。 关注手机圈的朋友应该会有这种感受，这几年的手机行业好似过山车，从当初的火爆，到中间有过一段低迷，再到现在又多了些生机。 其实也很好理解。刚开始，iPhone的面世重新定义了智能手机。接着移动互联网爆发，让很多人都嗅到了这股充满着无限可能的气息。谁进入得早，谁的希望就大。 所以，我们看到有从无到有的创业新生小米，有大胆转型的魅族，有疯狂扩张的巨头华为，后来更有从教育界杀出的锤子，视频网站乐视，P图软件美图等等。不惜头破血流，争相进入这个市场。 如此多厂家介入，说明技术已不是什么问题。各家的手机到后来基本都长一个样，同质化是其低迷的原因之一，还有原因就是现在手机市场趋向饱和，基本上达到人手一部的地步。 大家更多关心的不再是买哪个品牌的手机，而是换哪个品牌的手机。那些没有什么特色的手机终将会遭到淘汰。为了生存，除了在手机上加大打磨的力度之外，各家都在布局自己所谓的生态，即把手机当做是一个连接周边产品的连接器。单纯的手机角色已然没那么重要。 所以，我们也看到，近两年来各家的手机发布会都会发布很多周边的产品，关于手机的介绍显得低调很多，观众的情绪也没了之前那么高涨。 但是，今年大家的情绪好像又变得异常高涨。从去年底的小米MIX，到年初的三星S8，华为P10，都让大家看到了太多的惊艳。各家似乎都又找到新的手机设计元素。 如果说以前的手机是技术驱动的产品，那么现在的手机是设计、体验驱动的产品。这方面的追求可能永远没有边界。再加上今年是人工智能的元年，未来手机市场的发展仍然无可限量，所以现在仍有厂家进入一点也不足为奇。 今年手机市场的焕然生机，从这次米6的发布会上就能初见端倪。全程都是在讲这一款手机。好像小米已经很久没有在发布会上只发布一款产品了，让人有种久违的感觉。 雷军说这是小米做了七年的手机，可见在小米人眼中这是一部近乎完美的手机。我第一眼看到的时候，确实觉得挺惊艳的。骁龙835的首发，四曲面玻璃机身+不锈钢金属边框，双摄做平，简洁的设计，大方的配色，确实有种像雷军所说的流光溢彩，温润如玉的感觉。 回顾小米的成长史，一直都是以性价比著称。 让很多人花较少的钱就能买到一部比较不错的手机。小米也开创了很多让后来者争相模仿的先例，譬如饥饿营销，粉丝经济，小米之家等。 这让它在很多人心中占据了非常重要的地位，不管是消费者还是竞争对手，大家都非常敬重这家创业不久的企业，也常亲切称雷军为“雷布斯”。 随着竞争越来越激烈，长此以往以性价比标榜自己的小米也迎来了危机。很多人吐槽小米手机就是屌丝机，小米的产品就是屌丝产品，小米就这样被标成了屌丝品牌。 这还奇了怪了，为老百姓做好事，反到不受待见。反观那些一味就只知道抄袭打广告，性能其差，又贵得离谱的oppo,vivo确还成了宠儿，真是让人疑惑。不过这些吐槽并没有让小米忘记初心，依然秉承着做让消费者买得起的产品的原则。 另一方面，小米也在虚心接受这些吐槽声并反思。消费者开始讨厌便宜的产品，正说明人们的生活水平提高了，消费升级的时代来了。所以，之前的小米MIX和今天的米6正是对此有力的回应。 小米起初正是因为太注重性价比，所以没有太多关注设计上的事。从前几代的小米上就可以看出来，太“硬”却没有“朗”，“轻”却不够“灵”，有一种由糙老爷们工程师打磨出来的感觉。 从设计上也能打磨一款优秀的手机这一条路，在中国可能是由老罗开创的。 在锤子的发布会上，老罗提的比较多的一个词就是设计。虽然他不承认，让人感觉锤子就是一家以设计驱动的公司。小米后来的思路转变可能某种程度上也是受了老罗的启发。 我开始真正关注小米是从红米note3开始。notes3的发布会是我看的小米第一场发布会。 之所以看那场发布会，是因为那段时间可以说是“百家争鸣”，各家相继开发布会。小米作为领头羊，在那年早早就把发布会给开了（好像是米4的）。这之后竞争相当激烈，魅族，华为，锤子，乐视都发布了很有竞争力的产品。很多强劲的功能（如指纹识别，全金属）都提前发布了，而且价格都比小米有优势。 很显然，提前发布的米4就成了鸡肋（米4作为小米当年主打产品，没有那些时下流行的功能是说不过去的）。这时很多人都在关注着小米，心想也许它会再发布一款产品，果然年底就发布红米note3。 这款手机虽然说千元机，但融合了太多功能，在当时来说可谓惊艳无比。而且价格再次突破大家的认知底线。雷军可真够狠的。 那场发布会我印象非常深刻，除了上面的原因之外。最主要的一点是，这一年小米受到太多竞争对手的打击（“友商是傻x”）。在当时百家争侯，头破血流的时候，小米拿出如此有诚意的作品，可见承受不小的压力。 这也引得雷军在发布会上动情流泪，台下一众高管也是泪眼婆娑。我也流泪了，从那时开始我也成了米粉的一员。 之后，各家都在以自己的方式在这个大市场野蛮生长，小米做起了米家，华为死磕起了相机，一加在后盖上搞事情，乐视布起了生态，锤子搞起了情怀。在这个默默布局的时间里，大家已经看不到多少惊喜的东西了，很多都是料想之中的事（虽然米5主打了很多所谓的黑科技，但这些都是当年主打的功能，谈不上新鲜）。所以很多人开始唱衰手机市场，特别是看到苹果给不出惊喜的时候。 但出人意料的是，今年却焕发生机。 这意味着多年的厚积终于到了薄发的时候，同时也意味着这将要迎来一个新的时代，一个更加智能化的时代。","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[{"name":"手机","slug":"手机","permalink":"https://chambai.github.io/tags/手机/"},{"name":"小米","slug":"小米","permalink":"https://chambai.github.io/tags/小米/"}]},{"title":"《硅谷之谜》给我的启示","slug":"life/《硅谷之谜》读书笔记","date":"2017-03-20T14:44:36.000Z","updated":"2019-02-23T16:42:46.088Z","comments":true,"path":"2017/03/20/life/《硅谷之谜》读书笔记/","link":"","permalink":"https://chambai.github.io/2017/03/20/life/《硅谷之谜》读书笔记/","excerpt":"作为一个程序猿，我觉得读一些科普类的书是很有必要的，不但扩充了自己的眼界，还对这个世界更加充满了好奇。之前就拜读过吴军老师的《浪潮之巅》，第一次了解了世界知名大公司的兴衰史，读起来让人热血沸腾。当知道了曾经那些叱咤风云的大公司如今已呈衰败之势，或倒闭，或被收购，无不让人唏嘘不已。 《硅谷之谜》是吴军老师对科技，对文明深度探讨的另一大作，系列的书还有《大学之路》、《文明之光》以及今年新出的《智能时代》，《智能时代》已入手，准备之后拜读，其余两本也会跟上。现在恨不得没日没夜抱着啃，但是急不得，好东西是需要慢慢品味的。","text":"作为一个程序猿，我觉得读一些科普类的书是很有必要的，不但扩充了自己的眼界，还对这个世界更加充满了好奇。之前就拜读过吴军老师的《浪潮之巅》，第一次了解了世界知名大公司的兴衰史，读起来让人热血沸腾。当知道了曾经那些叱咤风云的大公司如今已呈衰败之势，或倒闭，或被收购，无不让人唏嘘不已。 《硅谷之谜》是吴军老师对科技，对文明深度探讨的另一大作，系列的书还有《大学之路》、《文明之光》以及今年新出的《智能时代》，《智能时代》已入手，准备之后拜读，其余两本也会跟上。现在恨不得没日没夜抱着啃，但是急不得，好东西是需要慢慢品味的。 读完之后，我大概有以下几点收获： 了解了风险投资 风险投资就是投资公司或者投资人出钱给一些有想法的年轻人去做事情，至于事情能不能做成，没有人能知道，所以，这里面就有一定的风险。就像赌博一样，存在很大的未知性，赌赢了就大家双赢，输了就大家输。一般，硅谷的风险投资采用三个原则：广种薄收、双倍砸钱和技术价值投资。广种薄收就是广撒网，什么都投，这样能在很大概率上保证有成功的；双倍砸钱则是根据项目的表现，在第二轮的时候，对那些表现好的项目投入双倍的资金；而技术价值投资则只关注技术类的项目投资，像互联网项目。 硅谷成功的原因，众说纷坛 海内外专家学者对硅谷成功的原因，都众说纷坛。但吴军老师认为这些说法彼此之间存在矛盾，容易让人产生误导。其中有：气候说、斯坦福之说、风险投资说、政府扶持说、知识产权说等。我捡两点说下自己的感受，书中的观点大大出乎了我的意料。首先是政府扶持说，在美国崇尚的是自由经济，商业上的事政府少干预，这种政策在硅谷地区贯彻得最为明显。这种情况跟中国政府完全不同。中国政府更像一个悉心照顾孩子的大家长，社会生活事无巨细都会管，而老百姓也习惯于有这样一个家长——凡是都会找政府。所以，这就在很大程度上制约了商业的发展。没有政府的干预，美国的商业行为靠那双“看不见的手”来规范，即根据市场情况动态调整，形成最优的经济发展态势。其次是知识产权说，书中将专利看做是一把双刃剑，它既能维护发明者的权益，也能阻碍科技的进步。利用专利阻碍科技进步的具体表现是：其一是一些律师公司通过低价收购一些专利，专门去纠缠那些产品可能和这些专利有关的公司，寻求高额的专利使用费；其二是一些拥有大量专利但业务发展已经开始出现停滞的大公司，通过从那些需要专利的公司收取专利费或是打官司的方式获得高额的专利费，典型的公司代表是IBM和微软。对于硅谷的大部分公司申请专利主要是处于防御的目的，这些公司不热衷于申请专利，而是把大部分精力投入在产品的创新中。所以，在很多世界专利排名的名单中，前10名都几乎看不见硅谷公司的影子。这真是一个讽刺啊。 硅谷的独特之处 包括对叛逆的支持和宽容，多元文化，拒绝平庸，对失败的宽容，工程师文化，不迷信权威，企业的扁平式管理以及的世界的情怀。其中对叛逆的支持和宽容让人不可思议，甚至颁发了禁止公司之间私下里达成相互不挖角的君子协议，一旦违背了这个协议，就要吃到政府的官司，苹果、Google、Intel和Adobe这些大公司曾经就受到重罚——罚款4.15亿美元！对于多元文化，其中有一点，就是硅谷的公司员工来自世界各地，所以他们一般都是站在世界的角度看问题，开发的产品也是世界性的产品，并没有根据哪个国家的特殊性去定制相应的产品，像苹果的产品，每个国家的人都爱不释手，还有Google的搜索产品，并没有本地化之分，同样Facebook的产品也是这样，所以，硅谷地区的公司推出的产品基本上就是全球化产品，这跟中国很多公司推行全球化的方式还是相差太多。中国的公司，像腾讯这种大公司，在推行产品的全球化时，都会刻意地去调查当地的用户习惯，然后定制化符合当地特色的产品，这无疑是非常耗资源且不一定观众就会买涨的行为，iPhone的产品就是对此最好的抨击，它没有刻意去迎合哪个国家的用户，而是站在更高的世界观格局来思考产品的形态，最终成就了人人都爱不释手的产品。 其他几个品质都非常让人受益匪浅，但作为一个程序猿，我要特别说下工程师文化，这个特点在打开我的脑洞的同时，有一种让我羞愧的感觉。吴军老师在书中根据前苏联著名物理学家朗道对物理学家的分类，对工程师也进行了相应的分类。吴军老师将工程师分为五个等级。看了之后，觉得自己连第一等级都没达到，不禁回想自己四年大学、三年研究生的生活，有点小伤感。不过还好，现在看到了这本书。 第一个等级是对工程师的基本要求，即要能够独立设计和实现一项功能，前提是没有人告诉他怎么做，如果一个程序猿做事需要产品经理或者自己的上级告诉他做什么，吴军老师认为这就是所谓的“码农”。回想我们在学校的学习，凡是涉及到一些动手实践的项目，要么是课程设计，要么是某种比赛，或者是导师接的科研项目。由于这些项目都是被动接受的，难免出现应付了事的心态，久而久之，某种程度上就会扼杀我们的好奇心和创造力。第二等级要求工程师具有产品头脑和领导才能，能在整个产品的生命周期从头到尾将一个产品负责到底。第三等级工程师可以做出行业里最好的作品。第四等级的工程师是可以给世界带来惊喜的人，和第三等级的工程师相比，多的更多是悟性、对产品的原创性，以及对世界的影响力，如Google Glass的总设计师。第五等工程师则是开创一个全新行业的人，如爱迪生、特斯拉等人。不管是哪一等级的工程师，书中强调一个共同的特点，就是好动手，即DIY（Do it yourself）。很多IT界的大佬，像Unix的发明人汤普森，每天大部分时间依然花在写程序上，太阳公司的创始人贝托谢姆，做了投资人之后依然在写代码。这真的是让人挺震撼的。 信息时代的科学基础 吴军老师分别对比了工业时代和信息时代的科学基础，认为这些科学基础让这个时代快速迭代发展的兴奋剂。工业时代依靠的是以牛顿、瓦特为代表的科学家们提出的机械论，以及由此引发的泰勒管理理论。这些思维和理论强调依赖生产资料，机械化和标准化生产产品，比如流水线生产。对于企业管理，则采用严格的树状组织结构，自上而下进行经营管理。这种思维对于指导传统行业的发展具有一定的促进作用，但对于新兴的互联网产业，或者信息时代，则无法奏效。吴军老师认为指导当今信息时代发展的科学基础是三论，即控制论、信息论和系统论。 控制论主张根据反馈来不断调整。为了完成一件事情，需要根据做事的过程中的中间结果的反馈不断调整做事的方式和方向，而不是一味按照计划，不懂得变通。就像开发一个互联网产品，不是一开始就要做大而全，而是专注基本功能，以最快的速度开发出来，并上线，得到反馈之后，在修改完善，最后呈现出一个完美的产品。 信息论包括基本信息论、香农第一定律和第二定律。基本信息论强调信息的不确定性，香农采用了热力学中熵的概念来描述信息的不确定性：在一个系统中，不确定性越多熵就越大，要消除这种不确定性，就要引入信息。比如数据挖掘，推荐系统，要想非常精确的将一个东西推荐给一个用户，就必须引入这个用户的历史轨迹数据，社交数据等等。第一定律讲的是一种编码方式，将大串的信息用尽可能少的编码来表示，以便于传输。这反映的是吉尔德定律，即最大限度地采用便宜的资源，尽可能的节省昂贵的资源来做事，就像做一个产品，用最少的人力，最少的服务器，做出一个有基本功能的版本，后面再慢慢迭代。第二定律讲的是信息的传播速率不能超过信道的容量，实质是不断扩张带宽的过程。就像人脉，就是人与人之间交往的带宽，每个人都是渴望这个带宽能够不断扩张的。 系统论强调的则是整体的性能未必能通过局部性能的优化来实现。这和机械论认为的一个产品只要把每个部分都做到最优，整体上就能达到最优的思维是截然不同的。一个典型的例子还是iPhone，纵观苹果的每一代iPhone，可以说各种绝对指标并不比竞争对手Android高，但整体上确是用户体验最优的手机，光流畅这一点就没的说。 总结：书中很多观点虽说是描述硅谷的，但对于我们的为人处世都具有很高的指导意义，特别是身为这个IT时代的一份子。但是对于这些思想，我们也要带着一定的批判观念去看，毕竟那描述的是这个世界上科技最牛逼的硅谷，这个世界也并不要求人人都需要达成那样的高度。 所谓的成功，我觉得就是让自己心安理得罢了。","categories":[{"name":"读书","slug":"读书","permalink":"https://chambai.github.io/categories/读书/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://chambai.github.io/tags/读书/"}]},{"title":"终于还是鼓起勇气看了《霸王别姬》","slug":"life/终于还是鼓起勇气看了《霸王别姬》","date":"2017-03-15T05:24:23.000Z","updated":"2019-02-21T16:11:30.199Z","comments":true,"path":"2017/03/15/life/终于还是鼓起勇气看了《霸王别姬》/","link":"","permalink":"https://chambai.github.io/2017/03/15/life/终于还是鼓起勇气看了《霸王别姬》/","excerpt":"我是一个感性胜过理性的人，虽然大学一直读的理科专业。对于那些悲情虐心的电影，我一般是没有勇气看的，因为很容易被感动，很多时候看完之后心情总是久久不能平静，很难继续做事情。但好电影还是忍不住想看，觉得不能压抑自己的情绪，看得多了，自然也就免疫了。","text":"我是一个感性胜过理性的人，虽然大学一直读的理科专业。对于那些悲情虐心的电影，我一般是没有勇气看的，因为很容易被感动，很多时候看完之后心情总是久久不能平静，很难继续做事情。但好电影还是忍不住想看，觉得不能压抑自己的情绪，看得多了，自然也就免疫了。 每个人对电影都会有一个慢慢接受的过程，有些电影碰不得就是碰不得，碰了就会有三观尽毁的强烈的不舒服的感觉。对于我来说，放在以前，同性电影是绝对不会看的，甚至连听到这个词都会觉得刺耳。但是现在，随着时代的进步，这种现象已经非常普遍，而且合法合理。我的思想自然也要随之有所进步才对。 在这个放空的周末，也在张国荣即将到来的纪念日之前用心看了这部电影。整个三小时的观影过程中，我的注意力始终都被狠狠地抓在其中，无法自拔。影片围绕着中国国粹的京剧演绎一场新时期动荡时代下的活生生的《霸王别姬》，枯燥得让人想睡觉是很多当下中国人对京剧的印象，我也是这么感觉的，但是看这部电影我丝毫没有这种感觉，反而觉得有一种沉静的美，特别是当你联系起那些京剧演员从小生活的环境，遭受的苦难，你会感觉他们的一颦一笑都充满了力量。 影片的背景定在一个动荡的大环境下，加上让人敏感的同性题材，在看之前，就知道这注定是一个悲情的电影。果然，在电影开篇就出现很虐心的画面：母亲为了能让小豆子拜师学艺，不惜以剁掉自己儿子的手指相逼，整个画面放在当今来看，都是极少会出现的血腥画面。看到这里，我就能预想到后面将会看到更为虐心的人物冲突和人性挣扎。但是剧情发展，远远超出了我的预想。在接下来的训练中，那种艰难、不堪、无助、拷打、惊叫、哭丧完全让人震惊，水生火热不足以形容这些小演员的处境。终于在某一天，大门的突然打开，让孩子们压抑已久的情绪得到爆发，也正是这个时候，残酷的现实无情的吞噬着那些弱小的心灵，直到以死来完成对自己的救赎。 不管现实是多么残酷，但也要乐观的面对，一句句“打得好”让人心疼。在那些以打为生的日子里，隐约可见的是程蝶衣和段小楼在小心翼翼地经营着彼此对对方的感情，程蝶衣在慢慢进入自己的角色，段小楼也凭借自己出色的能力逐渐成长起来，形成了名震四海的霸王与虞姬。出名给他们带来如潮水般的掌声和尊重，但也带来了很多诱惑。人性的扭曲和挣扎开始在这个时候凸显。段小楼如他扮演的霸王一样，霸气十足，唱戏生活完全无法满足他对美好生活的向往，他觉得戏就是戏，人生就是人生，两者不能混为一谈。程蝶衣正好相反，正是得益于小时候师兄的特殊照顾，他才产生对师兄的一种难以割舍的情愫，他觉得人生如戏，戏如人生，他希望和师兄像戏中的霸王和虞姬一样相伴在一起，一生只为唱戏。段小楼没有那么高的境界，也体会不到程蝶衣那微妙的情愫，他需要成家，儿孙满堂，过一个正常人该有的生活。为此不顾程蝶衣的感受，取了一个妓女。两个人的感情至此走向决裂，“你唱你的，我唱我的”，程蝶衣含泪忍痛向段小楼说出了决绝的话。此后，程蝶衣变得麻痹自己，成了袁先生的红尘知己，甚至吸起了大麻，颓败萎靡之色令人心碎。但他精妙绝伦的戏剧仍然叫人啧啧称赞，对段小楼也还留有无法割舍的感情。所以，宁愿冒着被日本人杀的风险也要毅然决然把段小楼救出来，最后反到招致段小楼吐沫星子的误会。 抗战成功后，内战期间，比日本人表现出更为无知的中国人，把程蝶衣以给日本人唱戏为由抓了起来，这个时候，作为师兄的段小楼也没有忘本，决定出手相救，但事与愿违，环境的悲哀与人心的矛盾再次把这次闹剧变成悲剧。之后新中国成立，迎来短暂的和平，但很快文化大革命的出现，瞬间把故事推向最后的高潮。人性不再扭曲，也不再挣扎，而是彻底爆发，有多恨就表现得多恨，有多丑恶就表现得多丑恶，爱不再有，灵魂已干涸，尚有一滴爱的血液都无法融入这个世界，唯有死亡才能解脱。 人生如戏，却比戏更悲凉。虞姬离霸王而去不是因为爱，而是因为没有爱。 剧中几条人物线都非常鲜活，总体看下来，两个主要人物段小楼和程蝶衣最终都因爱和恨，或是一己私立出现人性的扭曲，最终化为悲剧。反而妓女出生的菊仙一直都是站在正义的一方，不过前提是她体会不到段小楼和程蝶衣那种矛盾的心理冲突。段小楼只是把唱戏当做是自己的工作，他有情有义，有民族情怀，但当自身利益受到威胁的时候，他也可以出卖自己的灵魂，变成魔鬼。程蝶衣把唱戏当做是自己毕生追求的信仰，即使遭遇诸多不幸，他仍能在戏中找到心灵的寄托，直到唱戏的权利被别人剥夺，自己的人格被爱的人糟践，他也忍无可忍，以同样的方式完成了报复，最终以虞姬的身份完成了谢幕。 贯穿始终的京剧是剧中人物的信仰，一旦信仰出现裂痕，都让人不可避免的堕落。段小楼以斗蛐蛐来慰藉，程蝶衣以抽大麻来麻痹。当信仰的裂痕无法再填补上时，也就意味着到头了。","categories":[{"name":"影评","slug":"影评","permalink":"https://chambai.github.io/categories/影评/"}],"tags":[]},{"title":"共享经济浪潮下的另类——ofo与摩拜","slug":"life/共享经济浪潮下的另类——ofo与摩拜","date":"2017-03-05T05:24:23.000Z","updated":"2019-04-16T12:24:21.234Z","comments":true,"path":"2017/03/05/life/共享经济浪潮下的另类——ofo与摩拜/","link":"","permalink":"https://chambai.github.io/2017/03/05/life/共享经济浪潮下的另类——ofo与摩拜/","excerpt":"当下ofo和摩拜正以迅雷不及掩耳之势火遍全中国，追本溯源，这是共享经济的又一波冲击。 百度百科上对共享经济的定义是：以获取一定的报酬为目的，基于陌生人且存在物品使用权暂时转移的一种新的经济模式。其中涉及到三个关键词：获取报酬、陌生人和使用权暂时转移。简单来说，就是将个人闲置的资源共享给别人使用，然后从中抽取一定的费用作为激励。这种共享的思想古已有之。古时物质很匮乏，所有的东西都是公有的，大家互相信任，都会把自己东西无偿地共享出来作为共用，记得爷爷曾经说过，他们都是吃大锅饭长大的。随着时间的推移，人们的生活水平逐步提高，物资开始有了盈余，人与人的关系也开始渐渐变得陌生和冷漠起来。而现在呢，物资依然有盈余，很多东西开始闲置下来，造成了大量资源的浪费，这时共享经济就作为一种解决方案被推行出来，与此同时，人变得越来越开放，需求也变得更加多元化，人与人之间的关系也随着共享经济的推行而变得信任起来。这是自然，也是必然的。","text":"当下ofo和摩拜正以迅雷不及掩耳之势火遍全中国，追本溯源，这是共享经济的又一波冲击。 百度百科上对共享经济的定义是：以获取一定的报酬为目的，基于陌生人且存在物品使用权暂时转移的一种新的经济模式。其中涉及到三个关键词：获取报酬、陌生人和使用权暂时转移。简单来说，就是将个人闲置的资源共享给别人使用，然后从中抽取一定的费用作为激励。这种共享的思想古已有之。古时物质很匮乏，所有的东西都是公有的，大家互相信任，都会把自己东西无偿地共享出来作为共用，记得爷爷曾经说过，他们都是吃大锅饭长大的。随着时间的推移，人们的生活水平逐步提高，物资开始有了盈余，人与人的关系也开始渐渐变得陌生和冷漠起来。而现在呢，物资依然有盈余，很多东西开始闲置下来，造成了大量资源的浪费，这时共享经济就作为一种解决方案被推行出来，与此同时，人变得越来越开放，需求也变得更加多元化，人与人之间的关系也随着共享经济的推行而变得信任起来。这是自然，也是必然的。 其实共享经济这个术语最早在1978年由美国的两位大学教授在论文中提出的，直到2009年的共享汽车Uber和2011年的共享房屋Airbnb的出现，才空前火热起来。发展到今天，已经出现众多共享经济的产品，涵盖了人们几乎所能想到的领域。而且经过发展与创新，今天的共享经济已经有了不同程度的变种和解读，其中以ofo和摩拜为代表的共享单车就是这一形式下出现的另类产品。 之所以说另类，是因为共享单车所谓的共享只是体现在“无桩”上，即单车不用按照严格的方式停放，做到让用户随时随地骑到车。对于单车并不是人们的闲散资源，而是来源于第三方的平台，也即共享经济平台。平台通过自研自产或者合作代产的方式为用户提供单车，并实现共享。以目前市面上比较火的ofo和摩拜为代表，两者之间又有些许差别。 ofo并不能完全列入另类的行列，只是目前大家看到的现象是这样。ofo原本是北大“互联网+创新创业大赛”的比赛项目，项目的定位就是纯共享经济产品，按照创始人透露的理念是“不生产车，只连接车”，就是收集人们闲置的单车，喷漆之后进行共享。但是初期实践证明，无法行得通，进而才采用和工厂合作生产单车，但是从一些媒体报道中了解到，ofo将来还是要继续完成“只连接车”这个愿景，并且提出“1:N”的模式，即任何愿意共享单车给ofo的用户，将获得所有单车的永久免费使用权。这似乎是一个很吸引人的举措，但真要实施还需时日等待。 反观摩拜，做的成“单车分时租赁平台”，从单车的设计，到研发，再到生产投放市场完全由摩拜自己完成。所以摩拜的单车都是独一无二的专利性产品，结构上摒弃了链条传动，而采用轴传动，更加稳固和防锈；单车的锁结构内置了GPS和计算单元，可以实现单车定位和路线规划，而且增强了安全性和便利性，与APP搭配还可以完成很多大数据应用，未来市场不可估量。从这个角度看，摩拜给人一种科技感，时尚感，智能化，美得不像一辆自行车。ofo锁结构采用的是机械锁，1.0时代饱受诟病，随便都可以开锁，2.0时代虽然升级了锁，但机械所带来的难操作性考验着人们对它的耐心，所以索性很多人开了就不锁，这种现象在某些学校已经泛滥成灾了（别说大学生素质就很高）很多人都是在免费骑ofo，这样的现象持续了很长时间。我在想难道ofo的人想不到吗，如果想到了，为什么不改呢，我找不到原因。一次听到ofo创始人的一个采访解答了我的疑惑，他说技术绝不是问题，他们之所以放任不管，是因为现在正是抢占用户的时候，用户爱怎么样就怎么样，他们内心会产生一种良好的体验和依赖，其实他们早就研发好类似摩拜的智能锁，只是一直没有投入市场，就是希望再等等，在他们能够掌控的范围内。 要说这两家哪家更好用，仁者见仁智者见智，但我说下自己的感受。由于ofo主打校园，而摩拜主打城区，所以之前我一直用的是ofo，经历了从1.0到3.0，3.0变得更加小巧，轮子变成实心轮，显得有些笨重，但不得不说是越来越好骑。开锁确实很麻烦，至少得花1-2min，对于有时候赶时间确实会让人很烦躁。APP就是一个产生随机密码的工具，不想下APP，可以用ofo公众号。而摩拜定位的是智能单车，APP要复杂一些，除了上述的优点外，还可以预约车辆，方便人们找车。摩拜使用扫码开锁，确实非常方便，基本上能在5s内骑上车，内置GPS单元的智能锁可以记录人们的行驶轨迹，手拨关锁的同时就能完成费用的支付。另外傍上腾讯爸爸也许也会让它走得更远。关于费用上，都采用的是押金+车费的方式，摩拜是299元的押金，ofo对社会人士是99元，对校职工和学生免押金，计费两者差不多，摩拜1元/30min，ofo校园用户0.5元/小时，社会用户1元/小时，相比ofo要便宜些，主要也是因为摩拜成本高，但是功能多，所以总体下来差不多。关于活动上，两家为了争夺市场，也是玩起来转车时代的烧钱战略，ofo率先推出返现活动：充值最高返现100%；充20赠5块，充50赠20块。充100最高赠100块。摩拜随后也推出了充值返现的活动，充100即得210元，每一档一定要压着ofo。最后是信用体系上，摩拜有一套完整且成熟的积分制体系，能够在一定程度上制约素质差的用户滥用，而ofo目前来看还没有从技术上去解决这个问题，而是借助一些地方的监管机构来管制。但不管是哪种情况，我想说的是，人性中的恶是最难以琢磨的，就算看在共享单车为我们提供便利的面子上，行驶我们作为人该有道德责任吧。 就我的使用感受，两家都各有优劣。ofo整体骑行的舒适感是比较好的，适合学生，但机械锁，软件层面不少毛病。而摩拜智能，对于想要快速找到车并想通过路径规划节约时间的商务人士再合适不过了。如今两家在市场上竞争异常激烈，与此同时，还有更多的共享单车涌入，目前不完全统计，已经达到20-30家左右。看了一下其他一些家的APP，如小蓝单车、小鸣单车等，基本都是和摩拜一个模子。不管以后怎么演进，合并或是齐头并进，未可知，不过这场战役像极了曾经的专车之战，但不同的是，两者的产品理念有些许不同，相同的是他们都是在倡导绿色出行，解决城市最后一公里出行的问题，而这又是政府和人民都很期待的愿景，是大势所趋。所以，对于这么大的问题，我的看法是，需要竞争来维系绿色的推行，最好不要合并，但是也不要超过两家。 最后，我想说，共享单车是今天很伟大的发明，只有我们共同携手，放下心中那卑微的恶，拾起差点落下的善，才能推动这项发明欣欣向荣。","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[{"name":"共享经济","slug":"共享经济","permalink":"https://chambai.github.io/tags/共享经济/"}]},{"title":"Hexo 不同电脑/终端同步方法","slug":"tech/Hexo-不同电脑-终端同步方法","date":"2017-01-08T05:24:23.000Z","updated":"2019-02-22T15:25:56.238Z","comments":true,"path":"2017/01/08/tech/Hexo-不同电脑-终端同步方法/","link":"","permalink":"https://chambai.github.io/2017/01/08/tech/Hexo-不同电脑-终端同步方法/","excerpt":"问题描述： 在Linux系统上搭建了博客，现想在windows上写博客，如何在两个系统进行文章的同步？ 上面是在同一台电脑的不同终端上操作，同样这个问题也适用于不同电脑上，所以这个问题可以扩展成一个比较通用的问题： 不同电脑，或终端上如何同步Hexo？ Google一下，网友已经给了很好的解决方案，大体上有以下两种方案：利用分支和新建仓库。","text":"问题描述： 在Linux系统上搭建了博客，现想在windows上写博客，如何在两个系统进行文章的同步？ 上面是在同一台电脑的不同终端上操作，同样这个问题也适用于不同电脑上，所以这个问题可以扩展成一个比较通用的问题： 不同电脑，或终端上如何同步Hexo？ Google一下，网友已经给了很好的解决方案，大体上有以下两种方案：利用分支和新建仓库。1、利用分支顾名思义，就是新建一个分支来存放hexo网站的原始文件，master分支则用来存放生成的静态网页。具体操作参见以下的链接：使用hexo，如果换了电脑怎么更新博客？多设备同步hexo搭建的Github博客2、新建仓库和建分支同样道理，通过建仓库来存放hexo网站的原始文件，这种方法操作起来比1简单，不易出错，建分支万一发布的时候走神，没有切换到正确的分支，就GG了。方法参见：Hexo 换终端/换电脑小记","categories":[{"name":"05 工具","slug":"05-工具","permalink":"https://chambai.github.io/categories/05-工具/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://chambai.github.io/tags/hexo/"}]},{"title":"Git学习笔记——来自廖雪峰的博客","slug":"tech/Git学习笔记——来自廖雪峰的博客","date":"2016-12-29T07:19:18.000Z","updated":"2019-02-22T15:26:03.198Z","comments":true,"path":"2016/12/29/tech/Git学习笔记——来自廖雪峰的博客/","link":"","permalink":"https://chambai.github.io/2016/12/29/tech/Git学习笔记——来自廖雪峰的博客/","excerpt":"Git 简介Git是目前世界上最先进的开源的分布式版本控制系统。和集中式的版本控制系统，如CVS、SVN等相比，Git有几大优点：1、不像集中式版本控制系统一样，需要联网才能工作；2、安全性较高，避免了单点失效的问题，不会因为某台电脑坏了，文件就丢失了；3、具有强大的分支管理功能。 安装GitLinux：sudo apt-get install git centos: sudo yum install git-core windows: git bash 安装完成后，需要配置机器的Git仓库，即： git config --global user.name &quot;Your Name&quot; git config --global user.email &quot;email@example.com&quot;","text":"Git 简介Git是目前世界上最先进的开源的分布式版本控制系统。和集中式的版本控制系统，如CVS、SVN等相比，Git有几大优点：1、不像集中式版本控制系统一样，需要联网才能工作；2、安全性较高，避免了单点失效的问题，不会因为某台电脑坏了，文件就丢失了；3、具有强大的分支管理功能。 安装GitLinux：sudo apt-get install git centos: sudo yum install git-core windows: git bash 安装完成后，需要配置机器的Git仓库，即： git config --global user.name &quot;Your Name&quot; git config --global user.email &quot;email@example.com&quot; Git 基础特性及常用命令创建版本库（仓库，repository）mkdir learngit cd learngit 添加文件到Git仓库git init: 将当期目录变成Git可以管理的仓库 git add file git commit -m &quot;add file&quot; 补充几个概念： 工作区：如learngit 版本库：.git (包括暂存区和分支) 暂存区：git add 之后存储的位置 分支：git commit 之后存储的位置 跟踪工作区的状态git status: 可以随时掌握工作区的状态 git diff file: 如果git status告知file被修改了，该命令告知修改了什么内容 版本回退git log: 查看提交历史，显示commit id、author、date等 git log --pretty=oneline: 清爽版 回退方法两种：1、HEADHEAD表示当前版本，HEAD^上一版本，HEAD^^上上一版本，HEAD~100上第100版本。 git reset --hard HEAD^ 2、commit id git reset --hard 34343 如要重返未来的某一个版本，则只能找到commit id，通过以下命令来确定： git reflog 工作区、暂存区的文件修改、撤销修改、删除相关git diff HEAD -- readme.txt:查看工作区和版本库里面最新版本的区别 git checkout -- file：丢弃工作区的修改 git reset HEAD file: 丢弃暂存区的修改，回到工作区 如果git commit提交到版本库，参考版本回退 git rm file git commit -m &quot;remove file&quot;:将文件从版本库删除，保证本地工作区和版本库文件同步 远程仓库（Github）本地Git仓库和远程Github仓库之间的传输是通过SSH加密的，所以需要设置SSH Key： ssh-keygen -t rsa -C &quot;youremail@example.com&quot; less ~/.ssh/id_rsa.pub 注：GitHub允许你添加多个Key。假定你有若干电脑，你一会儿在公司提交，一会儿在家里提交，只要把每台电脑的Key都添加到GitHub，就可以在每台电脑上往GitHub推送了。 git remote add origin git@github.com:xxx/learngit.git:将本地参考与远程仓库进行关联 git push -u origin master:把本地仓库内容推送到远程，-u表示把本地master分支与远程master分支关联，后面如果本地做了修改，只需git push origin master推送修改即可 克隆远程仓库： git clone git@github.com:xxx/learngit.git:使用ssh协议克隆，也可以使用https，但ssh支持的原生git协议速度更快。 Git 高级特性：分支、标签创建与合并分支git checkout -b dev:创建dev分支，并切换到dev分支 相当于： git branch dev git checkout dev git branch:查看当前分支 git merge dev: 在master上合并dev分支 git branch -d dev: 删除dev分支 git log --graph: 可以查看合并分支图，常用： git log --graph --pretty=oneline --abbrev-commit 分支管理策略合并分支时一般会使用Fast Forward模式，即快进模式，将master分支直接指向dev分支，删除分支后，丢失分支信息，看不出曾经的合并历史信息，这不利于将来出错回头排查问题，所以，可以禁用Fast forward模式，通过以下方式： git merge --no-ff -m &quot;merge with no-ff&quot; dev:Git 在merge时生成一个新的commit id,从分支历史上看出分支信息 Bug 分支在dev分支上开发，突然有了bug，但是dev还没开发好，无法提交，这时，可以： git stash:把当前工作现场保存起来，等以后恢复现场后继续工作 git stash list: 查看保存的工作现场 git stash apply: 恢复工作区，但恢复后stash不删除，需要用： git stash drop:来删除 git stash pop:恢复的同时把stash内容也删了 Feature 分支开发一个新feature，最好创建一个分支；如果要丢弃一个没有被合并过的分支，可以通过： git branch -D &lt;name&gt;：强行删除 多人协作：推送分支git remote:查看远程库信息 git remote -v：显示更详细的信息 git push origin master: 推送分支到远程master分支 git push origin dev:推送分支到远程dev分支 分支推送备注 master分支是主分支，因此要时刻与远程同步； dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步； bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug； feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。 多人协作：抓取分支git checkout -b dev origin/dev：在远程的dev分支上进行开发 如果两个人对同一个dev分支，会产生冲突，此时先pull，再push。 git pull git branch --set-upstream dev origin/dev:指定本地dev分支与远程origin/dev分支的链接 如果有冲突，则先处理冲突 标签管理git tag &lt;name&gt;:用于新建一个标签，默认为HEAD，也可以指定一个commit id； git tag -a &lt;tagname&gt; -m &quot;blablabla...&quot;:可以指定标签信息； git tag -s &lt;tagname&gt; -m &quot;blablabla...&quot;:可以用PGP签名标签； git tag:可以查看所有标签。 git push origin &lt;tagname&gt;:可以推送一个本地标签； git push origin --tags:可以推送全部未推送过的本地标签； git tag -d &lt;tagname&gt;:可以删除一个本地标签； git push origin :refs/tags/&lt;tagname&gt;:可以删除一个远程标签。 更多高级特性，请前往：廖雪峰git教程","categories":[{"name":"05 工具","slug":"05-工具","permalink":"https://chambai.github.io/categories/05-工具/"}],"tags":[{"name":"git","slug":"git","permalink":"https://chambai.github.io/tags/git/"}]},{"title":"狗狗的记忆——《人狗奇缘》续","slug":"life/狗狗的记忆——《人狗奇缘》续","date":"2016-06-15T13:07:14.000Z","updated":"2019-02-21T15:56:21.781Z","comments":true,"path":"2016/06/15/life/狗狗的记忆——《人狗奇缘》续/","link":"","permalink":"https://chambai.github.io/2016/06/15/life/狗狗的记忆——《人狗奇缘》续/","excerpt":"这部电影真是太赞了，看了之后，在感动之余，勾起了我很多的回忆，突然有很多想说的话，上一篇算是一篇观后感，这一篇打算写写我与狗狗的故事。 小时候，我非常喜欢小狗，我爸妈也很喜欢，大概在上小学的时候家里就开始养狗。我记得非常清楚，那只小狗是爸妈从一个邻居家报来养的，当时邻居家的一只母狗一次性产了5只小狗，震惊了整个村子（最近听说某国的一只杜宾狗一次性产下了13只！！），我当时看到5小只乖乖地躺在一个小箩筐里，立刻就被萌化了，就喊着要一只，邻居家也很大方，就给了。","text":"这部电影真是太赞了，看了之后，在感动之余，勾起了我很多的回忆，突然有很多想说的话，上一篇算是一篇观后感，这一篇打算写写我与狗狗的故事。 小时候，我非常喜欢小狗，我爸妈也很喜欢，大概在上小学的时候家里就开始养狗。我记得非常清楚，那只小狗是爸妈从一个邻居家报来养的，当时邻居家的一只母狗一次性产了5只小狗，震惊了整个村子（最近听说某国的一只杜宾狗一次性产下了13只！！），我当时看到5小只乖乖地躺在一个小箩筐里，立刻就被萌化了，就喊着要一只，邻居家也很大方，就给了。 因为我经常待在家里的缘故，自然就多了很多与小狗相处的机会，基本上每天都会粘着它，每次吃饭都会给他好吃的，爸妈常常叮嘱我不要给它太好吃的东西，不然会把它给惯坏的，到时候它啥也不吃，专挑你碗里的吃。我肯定是不以为然，经常和它分享我的食物。一段时间之后，确实如爸妈所说的，给它盛的东西基本上不怎么吃，而是跑到我面前，眼睛直勾勾地盯着我，想让我给它好吃的，那种可爱又迫切的小眼神我怎么舍得不依着它。但是我不会给它太多，到大家都吃完了，它还饿着肚子的话就会去吃自己碗里的，吃不完就留着饿了就吃，甚至当宵夜吃。一家人休息的时候也会经常陪它玩，给它各种口令，让它跳高，蹲下，转圈等等，刚开始它还很抵抗，后来采取食物诱惑的方法才慢慢使它“屈从”。平常一家人出门，它都会跟随，但是一般如果我在家的话，它都会和我黏在一起，如果去上学，铁定用一根绳子把它栓住，不然它真的会一直跟着我。 长大一点，从小学升初中，开始到一个离家较远的县城上学，和小狗从每日一见，每周一见，到好几个月才能一见。虽然每次相见小狗都异常兴奋，活蹦乱跳，各种疯狂的动作迎接我的到来，我也常常被它逗得哈哈大笑，但于我来说，想见它的心情可能没有它想见我那么迫切，就好像过眼云烟，这个事情发生的当下，会觉得很快乐，但在之前或者之后，可能对与小狗有关的事情早已抛在九霄云外。但对小狗不同，它很小就被主人圈养，把主人当做它最好的玩伴，但主人终究要离它而去，可以想象它要承受多大心理压力，它可能要重新调整它的生活，可能要重新寻找新的玩伴，或者得过且过，做一只只会吃吃睡睡的憨狗。 你还真别说，对于一只稍微聪明的狗，它真的有可能这样，聪明的狗一般能体会到主人的情绪，非常有感情。我现在看了这部电影，然后回忆着我家狗狗以前的故事，我才发现我家的小狗真的是一只非常聪明又可爱的狗，电影里的好多场景，我都有似曾相识的感觉。可惜以前没有意识到，只是把它当做是一种普通的物种，就跟鸡鸭猫类似的，经常呼来唤去的，从来没有把它当做是自己的朋友。长时间的不见之后，它依然那么喜欢我，而我只是把它当做一个过客，一个可有可无的物种。虽然有时候会给它吃东西，但是仅此而已，已经不会花心思在它心上。在家待不了几天，就又要准备去上学，还以为它不会像以前那样跟来，但它还是跟来了，后来还是爸妈把它栓上才阻止它，我已经不记得当时的心境是怎样的，但此时心里却有一点隐隐作痛。 痛的是我对它太冷漠了，这种冷漠随着时间的流逝越来越强烈，后来升高中，小狗的年龄也在逐渐增大，激情，活泼的感觉也在慢慢减弱，整个看上去昏昏沉沉的，好几次我放假回家，它都是只与叫声来欢迎我，不再跟我接触，妈妈还开玩笑说：“你看，小狗都不记得你了”。平常和爸妈交流，他们也都会提一下狗狗，说它变得特别懒，整天就慵懒地躺在院子里，然后也经常性地不吃饭，有时候甚至好几天都不见它影子，爸妈怀疑是出去找伙伴了，还因此担心要是被别人家抓去杀了就可惜了。后来爸妈干脆就把它栓在院子里，虽然残忍，但也没办法。我当时唯一的想法就是希望爸妈不要杀它，让它慢慢老去，然后安然地死去。很高兴的是，爸妈和我的想法也是一样的。 再后来，我上了大学，我家的狗狗依然还活着，仔细算算的话，正好是10岁左右，真是生命力太顽强了，但是后面能够明显感觉到它很虚弱，走路都有些撑不开腿，在上学期间还听爸妈提过它在死亡的边缘挣扎过好几次，但最后它都能自己挺过来，真不知道是什么支撑它度过这些难关。 最后的最后，再听爸妈提起它时，它已经不在了，不是它死了，而是它不知去哪了——爸妈说有一天放开绳索，想让它活动活动，但从此就再没回来过。当听到这里的时候，我还挺难过的。不管它身处何方，我只希望它安好。 这部电影真的给我的触动还挺大的，勾起了我内心深处喜欢动物的情结，回想起来，小时候我除了养狗之外，还养过很多小鸟，其中印象最深的一只是养到最后是完全不要笼子，它非常乖，感觉也非常有感情，每天早上就像鸡叫一样叫我起床，但不幸的是在某个下雪的冬天，它耐不住寒冷飞走了，就再也没飞回来，当时还让我难过了好一阵。 虽然我喜欢动物，但是我仍然在不公平地对待动物，因为我没意识到其实动物就是我们的朋友，直到看了这部电影，才真正从内心深处感受到这一点。不管是动物，我觉得我们人类更是如此，交朋友有太多的套路，而少了一些真诚，这一点真应该像人类的好朋友——小狗学习。 看完这部电影，我突然下了一个决定，就是要研究狗。说到做到，这两天关注了很多关于狗的新闻，才发现这个世界上有那么多可爱的小狗，有种大开眼界的感觉。就像我一个朋友，他某一天偶然看到一种花非常漂亮，然后就兴起了要研究花的决心。过了一段时间问他情况，没想到他还做得风生水起，已经是几个花卉论坛的坛主，而且最近还做起了花卉摄影师。虽然我不可能像他一样，做着做着做成一份事业，但如果能发展成一个我的业余爱好，以后能收养一些狗狗，懂一些狗狗的知识，我也就满足了。","categories":[{"name":"影评","slug":"影评","permalink":"https://chambai.github.io/categories/影评/"}],"tags":[]},{"title":"被《人狗奇缘》虐死了","slug":"life/被《人狗奇缘》虐死了","date":"2016-06-12T14:44:36.000Z","updated":"2019-02-21T16:08:24.133Z","comments":true,"path":"2016/06/12/life/被《人狗奇缘》虐死了/","link":"","permalink":"https://chambai.github.io/2016/06/12/life/被《人狗奇缘》虐死了/","excerpt":"说实话，我最怕看这种虐心的电影，因为看完后，我会很难过，有时甚至会难过好几天。特别是这种跟动物有关的电影，最后的结局动物免不了一死，要么是救自己的主人而死，要么是与某种邪恶的力量抗战而死，总之，前期一定会把动物刻画得多么聪明、可爱，重点突出与主人的那种难舍难分的感情，一旦这种感情达到最高潮时，观众心里都快被融化时，剧情开始虐心了，并且层层递进，怎么虐怎么来，直至死…… 这是一部韩国电影，我发现韩国导演特别擅长拍这种煽情的电影，曾经的《野蛮女友》、《七号房的礼物》，不知融化了多少人的心。","text":"说实话，我最怕看这种虐心的电影，因为看完后，我会很难过，有时甚至会难过好几天。特别是这种跟动物有关的电影，最后的结局动物免不了一死，要么是救自己的主人而死，要么是与某种邪恶的力量抗战而死，总之，前期一定会把动物刻画得多么聪明、可爱，重点突出与主人的那种难舍难分的感情，一旦这种感情达到最高潮时，观众心里都快被融化时，剧情开始虐心了，并且层层递进，怎么虐怎么来，直至死…… 这是一部韩国电影，我发现韩国导演特别擅长拍这种煽情的电影，曾经的《野蛮女友》、《七号房的礼物》，不知融化了多少人的心。 这部电影2006年就上映了，很可惜我到现在才看。知道它是因为看了一位网友的博客，他的博客写得很好，并且经常更新，除了写技术之外，还写写自己的小生活，人情世故等，希望自己也能向他学习。 电影讲述的是两个被父母遗弃的兄妹和一条拉布拉多犬心心之间的故事。故事的开头设定的还蛮有趣的，妹妹过生日，想要一条狗，哥哥就到一家富贵人家偷了一条给她，这里留下了一个小铺垫——结尾处在心心奄奄一息之时，哥哥告诉它，其实它是偷来的。前后照应，结合演员和狗狗的演技，这一段真的很虐心。 开始时兄妹俩和心心过着相依为命的生活，妹妹很可爱，每日的生活就是在家里陪心心嬉戏打闹，而哥哥要坐班车到很远的地方去上学，剧中最唯美的几场戏之一就是妹妹和心心每天都要到班车站台去等哥哥放学，然后三个小可爱蹦蹦跳跳着回家，有时候如果碰到哥哥有事，就要等到天黑，因为妹妹怕黑，所以就依偎到心心的怀里睡觉，直到哥哥来她才敢睁开眼睛。 这样的温馨的好景不长，兄妹俩和心心一起去溜冰，正玩得起劲时，哥哥肚子疼想方便，让妹妹和心心留在原地等他回来，不料心心看到一个风筝飞进了溜冰场，好奇地走了过去，一不小心掉进了冰水里，妹妹看到了吓一跳，很担心心心出事，所以也走了过去，结果可想而知，心心挣扎出来了，而妹妹却永远沉入了水里。 哥哥因此而怪罪心心，不再理心心，甚至拳打脚踢。有一天，哥哥要去很远的地方找妈妈，心心自然是哥哥到哪跟到哪，哥哥不想见心心，对它各种怒吼，让他不要跟着自己。哥哥终于甩开心心上了一辆火车，心心硬是一路跟随火车的方向追去，中途跟丢了火车，自己又疲惫有饥饿，就到周边的人家去乞讨，又被各种嫌弃，但也有好心人，在心心表演一些可爱的动作之后，给了它一些吃的，靠着这样的聪明、坚强和要找到哥哥的执着与毅力，最后找到了哥哥。 但哥哥在被妈妈拒绝收养之后，更是痛不欲生，流落街边乞讨，最后落入一个坏家伙的手中。心心几经努力，终于见到了哥哥，但此时正是心心危难的到来，心心为救哥哥，与饥饿、病魔和坏家伙斗智斗勇……啊啊啊，已经写不下去，我快崩溃了，之前看的剧情在我的脑海中又重新演了一遍，就此打住吧。 这部电影，给了我太多感动，动物的力量是那么渺小，大自然的生命是那么脆弱，人和动物应该成为好朋友，而不是受到不公平的待遇。另外，人和动物之间的交友可以做到那么真诚纯粹，希望人与人之间也更应如此吧。 两位小演员和狗狗的表演也堪称全片的经典，看完之后，我特意去查了一下那只小狗，真名叫阿达，原来是剧组找遍了全国，面试了上万只，万里挑一才找到的。还有一个小插曲就是原本这只小狗是要被他的主人带到美国去培训成为一只搜救犬的，后来这个主人看到剧本之后，立马就改了决定要让狗狗成为一只演技犬（厉害吧，狗也能演戏）。哎，这么聪明可爱的狗狗也是没谁了，真是羡慕死了。 话说到这两位小演员，演技真是棒得没话说，特别是妹妹，简直把人萌化了，哭戏说来就来，哥哥也很出彩，悲情戏刻画得入木三分，教育妹妹有模有样，两兄妹吵架的时候是全片最温馨的。从上映到现在，正好10年，两小只现在也已经长大了，俊男萌女的既视感。 妹妹金香奇 哥哥俞承豪 后面又出了第二部，主演变成了最近大火的宋仲基，狗狗还是阿达，还有它的三个小宝宝（看到这个消息的时候，我内心是真的高兴啊！）。这一部的评分和第一部相比低了很多，加入了很多喜剧和动作元素。 但我不想看了，我希望留住现在的感动，然后希望以后能够养一只拉布拉多犬，或者做一些有益于狗狗的事情。 没错，这部电影在某种程度上改变了我。","categories":[{"name":"影评","slug":"影评","permalink":"https://chambai.github.io/categories/影评/"}],"tags":[]},{"title":"所谓情怀","slug":"life/所谓情怀","date":"2016-05-03T12:46:43.000Z","updated":"2019-02-21T16:03:50.494Z","comments":true,"path":"2016/05/03/life/所谓情怀/","link":"","permalink":"https://chambai.github.io/2016/05/03/life/所谓情怀/","excerpt":"对情怀这个词有着较深的认识是来源于老罗的情怀演讲，当听到老罗赋予这个词深刻解读的时候，我感觉自己内心某一块干涸之地突然有了生机，感觉老罗所讲的这种所谓情怀的东西正是我内心所要追求的东西。 当我把这种所谓情怀的东西向身边的朋友讲述的时候，他们都表示很不理解。一个很出现频率很高的反驳是：你现在才二十多岁，哪来的情怀？我也表示很不解：难道情怀是只能上了年纪的人才有的吗？在我看来，情怀是每个人，在每个阶段都会有的东西。","text":"对情怀这个词有着较深的认识是来源于老罗的情怀演讲，当听到老罗赋予这个词深刻解读的时候，我感觉自己内心某一块干涸之地突然有了生机，感觉老罗所讲的这种所谓情怀的东西正是我内心所要追求的东西。 当我把这种所谓情怀的东西向身边的朋友讲述的时候，他们都表示很不理解。一个很出现频率很高的反驳是：你现在才二十多岁，哪来的情怀？我也表示很不解：难道情怀是只能上了年纪的人才有的吗？在我看来，情怀是每个人，在每个阶段都会有的东西。 现在情怀这个词好像被更多地植入了浓浓的商业气息，从各大互联网公司的产品发布会就可以看出，好像不提一下情怀，都不好意思说是做产品的。 原本是专属文艺青年的一个词，现在却被披上了各种各样的外衣，甚至有人还不理解。作为一个伪文艺青年，特别想记录下自己对这个词的浅薄理解，告诉自己那些曾经引起你共鸣的东西还是值得好好保持和珍藏。 百度百科上对情怀的解释只是停留在字面层面上，比如，表示一种心情，情趣，更深一点就表示胸怀，文学情致。这种解释都太抽象，太苍白。在我看来，情怀是很宽泛的，也很简单。用现在一句比较流行的话来说，就是：生活除了眼前的苟且，还有诗和远方。 现在很多的手机品牌将科技、生活方式、艺术、美感等等融合在一起，另很多人在体验高精尖的科技产品的同时，也能够体验到由科技所带来的那一份生活的舒服与惬意。这方面的典型代表要属一加和锤子了，说真的，这两家公司的出现，改变了我对科技的认识，也从某种意义上来说改变了我的生活追求。将这种硬邦邦，冷冰冰的科技产品赋予美感，并融入家常便饭，这就是情怀。 在很多新技术层出不穷的今天，曾经那些在当时另我们震惊和感动的技术，同样也会勾起我们的美好回忆。苹果新瓶装旧酒，推出iPhone SE，在很多人吐槽苹果衰败的同时，又有多少人含着热泪，在深深地感谢库克为他们保留了曾经那个伟大的时刻、感动的瞬间。这也是情怀。 在姚明离开了NBA多年后的今天，有多少人依然还爱着火箭，即使现在的火箭千疮百孔，因为曾经那份逃学看球的情谊真的太难割舍，这也是情怀。 同样，虽然现在林书豪辗转了多个球队，曾经让他疯狂崛起，一夜爆红的尼克斯，也依然有太多的人关注。这也是情怀。 都说程序员经常都是穿个人字拖，露胳膊露腿，蓬头垢面的，其实不只程序员，我见过一些大学的老师，公司的老板也是这样的一种状态，这是他们认为的舒适的生活方式，这也是一种情怀。 更甚有些人袜子只穿花色的，裤衩只穿豹纹的，这同样的也是一种情怀。 …… 情怀可以是很高大上的，诸如信念、信仰、阳春白雪；也可以是很渺小的，下里巴人。 我想情怀更多的表达的是我们对生活方式的追求，只要自己舒服即可，不刻意，不强求，保持本真。","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[{"name":"情怀","slug":"情怀","permalink":"https://chambai.github.io/tags/情怀/"}]},{"title":"漂亮得不像实力派 坚果开箱","slug":"life/漂亮得不像实力派-坚果开箱","date":"2016-01-28T11:53:36.000Z","updated":"2019-04-16T12:25:09.893Z","comments":true,"path":"2016/01/28/life/漂亮得不像实力派-坚果开箱/","link":"","permalink":"https://chambai.github.io/2016/01/28/life/漂亮得不像实力派-坚果开箱/","excerpt":"终于拿到了机子，我迫不及待想写一篇开箱之作来记录这神圣的一刻，对一个科技爱好者来说，这是必须的。但是在写之前，我还需要口水一下。 在手机同质化的今天，要买哪一款手机我是犹豫不定的，但有一点是肯定的，就是只买千元机，因为没钱^=^。细数一下现今很火的几款千元机，红米note 2、note3、魅蓝metal、乐1s、锤子的坚果…..恩，我看得上差不多就这么多。 当然还有其他的，华为的设计我不太喜欢，所以不关注；联想的，你懂的，说得直接一点，就是很老套，虽然收购了Moto，但…希望他能做好吧；还有就是一加，一加手机可以说是我最喜欢的外观设计的手机，但是一加不做千元机，好吧。 附带说一下，类似的设计还有韩国的LG，很美，但是，我只关注国产机，恩，我就是这么爱国。","text":"终于拿到了机子，我迫不及待想写一篇开箱之作来记录这神圣的一刻，对一个科技爱好者来说，这是必须的。但是在写之前，我还需要口水一下。 在手机同质化的今天，要买哪一款手机我是犹豫不定的，但有一点是肯定的，就是只买千元机，因为没钱^=^。细数一下现今很火的几款千元机，红米note 2、note3、魅蓝metal、乐1s、锤子的坚果…..恩，我看得上差不多就这么多。 当然还有其他的，华为的设计我不太喜欢，所以不关注；联想的，你懂的，说得直接一点，就是很老套，虽然收购了Moto，但…希望他能做好吧；还有就是一加，一加手机可以说是我最喜欢的外观设计的手机，但是一加不做千元机，好吧。 附带说一下，类似的设计还有韩国的LG，很美，但是，我只关注国产机，恩，我就是这么爱国。 经过几番自我殊死搏斗之后，在红米note3和锤子的文青版坚果之间又犹豫了。不可否认的是，红米note3真是良心之作，雷军在发布会还因为这款产品而动了情，引得我这种不是米粉的人也开始圈他粉了。 要是放在几个月前，这款产品绝对配得上是旗舰机，现在手机圈该有的一些新鲜科技元素，它都具备，像全金属、全网通、指纹识别、高像素、大电池等，应有尽有，在加上全新的设计，高性价比，我甚至以为它要好过小米note。 反观坚果，也许是意识到跟红米note3相同的价格，但low了一大截，所以，忍痛降价200元，跟红米note2齐头，但即便如此，光从性能上说，坚果和红米note2仍然存在差距。但坚果以其别样的设计而别具一格，使其在千元机中显得特立独行。 说到我的购买意愿，我的心理活动是这样的：我当然希望能够体验到现今一些比较先进的科技元素，这是一个科技爱好者无不想追求的东西。 但说到我内心最想的事，就是“追求表面的美胜过它的内心”，这是装X的说法，其实就是“外貌者协会”。老罗坚持以简约美学的设计风格赋予他的每一个产品，让我感叹原来看似枯燥的科技也可以这么美！作为一个从老罗语录就开始关注老罗的人来说，可以说是看着老罗彪悍的人生一路走过来的，多少有些感概，也感受到了老罗所谓的情怀。 抛下追求科技美感这些虚的东西不说，就凭老罗语录陪伴过我多少个日日夜夜这点来说，也要支持他一把。Done！ 至于为什么买文青版（这很重要的一点，差点忘了），原因就在于我有着一颗文艺青年的心，哈哈。。。 啰嗦了这么久，总算进入正题了！ 好，现在开始，首先是开箱初始照，精致小巧的盒子设计。这是一款远洲鼠的后盖配色，在我看来，是最丑的颜色（即便如此，整体是挺漂亮的），但他们坑爹的只提供了这一款，然后我看了一下其他后盖是单独卖的，49元一片，3片99，好吧，我瞬间明白是怎么回事了。。。 拆开最外层的盒子，漂亮的机身映入眼帘。 接着是配件，only电源和数据线，没有耳机！但也不能要求那么多，毕竟已经降了200元了。 撕膜，光滑精致。 对称式设计，我比较喜欢的设计风格。 开机，大大的锤子标志映入眼帘，初看给人一种工匠的感觉。 锁屏界面，沉稳大方漂亮。UI，我最喜欢的部分，拟物化的设计风格，相比市面上清一色的扁平化设计，我更青睐于拟物化的设计。 结语：在手机同质化这么严重的今天，锤子科技能够走出自己的一条路，让人感受到科技美学的同时，更能够感受到以老罗为首的这样一批年轻的，具有工匠精神的，近乎偏执狂的科技工作者的努力，祝福老罗！","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[{"name":"老罗","slug":"老罗","permalink":"https://chambai.github.io/tags/老罗/"},{"name":"锤子科技","slug":"锤子科技","permalink":"https://chambai.github.io/tags/锤子科技/"}]},{"title":"论牙痛的日子","slug":"life/论牙痛的日子","date":"2016-01-26T13:43:44.000Z","updated":"2019-02-21T16:18:01.165Z","comments":true,"path":"2016/01/26/life/论牙痛的日子/","link":"","permalink":"https://chambai.github.io/2016/01/26/life/论牙痛的日子/","excerpt":"不久前，乐嘉因为录节目而伤了蛋蛋，没过几天就洋洋洒洒写了一篇文章来讲述自己的蛋碎的始末，其幽默诙谐、自嘲自黑的文字把他乐观的心态展露无遗。说真的，真是让人佩服得五体投地。你想想，蛋都碎了，那有多痛，不单单是身体上的痛，更是心理上的痛，但也为乐嘉老师高兴，因为他说他释然了。 这两天，我也遭受着身体上的另一种痛，就是牙痛。虽说牙痛比起蛋痛，程度要低很多，但还是真的痛——神经级别的痛。受乐嘉老师感染，我也想把这个过程写出来纪念一下。","text":"不久前，乐嘉因为录节目而伤了蛋蛋，没过几天就洋洋洒洒写了一篇文章来讲述自己的蛋碎的始末，其幽默诙谐、自嘲自黑的文字把他乐观的心态展露无遗。说真的，真是让人佩服得五体投地。你想想，蛋都碎了，那有多痛，不单单是身体上的痛，更是心理上的痛，但也为乐嘉老师高兴，因为他说他释然了。 这两天，我也遭受着身体上的另一种痛，就是牙痛。虽说牙痛比起蛋痛，程度要低很多，但还是真的痛——神经级别的痛。受乐嘉老师感染，我也想把这个过程写出来纪念一下。 从开始到现在已经有一个星期了，也就是说我痛了一个星期！不过现在总算有所好转，感谢上苍！因为整个过程只是表面上的痛，没有上升到像乐嘉老师那样心理上的痛，所以，自然也说不上乐不乐观，只能说，我该做什么还是做什么，就是不舒服，真特么不爽！ 其实我真想像乐嘉老师那样写出惊天地、泣鬼神的文字，但那是不可能的。算了，不纠结了，能写成什么算什么吧，真实的做自己吧。 这一次的痛还不是首痛，应该算是复发。这时，痛感袭来，咬着下嘴唇，我深深陷入回忆中，寻找牙痛的根源。 这要追溯到去年，差不多也是这个时候，吃饭时打了一碗莲藕骨头汤，多好的汤，可偏偏就是这玩意儿坑了我的大牙。说起来，也比较诡异，想吃点汤泡饭，就倒了一些汤在饭里……名曰骨头汤，汤里怎么能缺少骨头呢，附带着一些碎骨头也进了饭里。没错，就是碎骨头，这些小家伙虽然瘦骨嶙峋，但隐身之术和尖利程度丝毫不逊色，攻击起来让人防不胜防。这不，它们隐匿在饭团中间，攻击得我措手不及，才一下，只听一声“磕打（我打）”，我就拱手投降了。接下来我“痛不欲生”，停顿了几秒，没辙，赶紧撤，不是对手！中间我是如何度过的，已经没印象了。但可以肯定的是，干等着，托着腮，哼哼着，等着下午校医院上班。 医生大人果然不是盖的，用她手中的“武器”在我嘴中咕噜捣鼓几下，痛得我哇哇大叫。我只想说，医生，你牛逼！医生说，最好拔牙，我幼小的心灵又微微震动了一下，各种新式拔牙的手法在我脑中放映了一遍：“医生，怎么拔啊？”医生不屑的看着我，音量提高了个八度：“你说怎么拔！”我当然知道要打麻醉，但我只关心疼不疼：“会疼吗，医生？”，“打麻醉有点疼。”好吧，放心多了，但我内心始终不相信拔的时候不疼，内心怵得很。“不过你现在还不能拔，稍微好一点才可以”，哎呀，说实话，当时内心是高兴的：比起拔牙，我更希望能忍痛久一点。（现在想想，真是什么操蛋的想法，拔了就不会有今天这一出） 上面的结局是第二天就有好转，之后一天比一天好，好得很快，我都没印象是怎么好的了。因为有拔牙的感官恐惧，所以，我最终放弃了拔牙。 所以，有了今天的复发。 这次复发这么来总结：莫名其妙，缓缓驶来，翻云覆雨，不见彩虹，心安理得。 可能是传说中的后遗症，这次复发莫名其妙就发生了。事后我认真回忆之前究竟是吃了什么，亦或是又嗑到了什么，但好像都没有，我顿时陷入了福尔摩斯的推理中——唯一能说得过去的是，这两天吃肉多了，那些肉末星子尽情地在我的牙骷髅里筑巢，准备过冬，然后我以迅雷不及掩耳之势，将我偌大的指甲伸进去与它们抗争到底。恩！大概是上演了这么一出戏，老毛病复发了。 第一天，轻微的疼痛，心里默念：不管它，它会自然消去。这句话不管用在哪，我觉得都百分之百没错，貌似是心理学上的至高言论。但要真正做到，不难才怪。人的知觉很容易被一些不好的东西影响而做出你无法察觉的行动。譬如说，你的手不小心割伤了，你总会不自觉用另外的手去掐，以减少暂时的疼痛感，同样牙痛了，也会不自觉用舌头或者另外的牙抵住来缓解一下痛感。这些不自觉的动作虽然能够缓一时之痛，但其实是对肌肉、神经的二次损坏，反而延长了疼痛的时间。所以，由于痛感不断向我袭来，我总是不自觉地用舌头去舔那个角落。好了，晚上睡觉的时候，等我一切放空的时候，这些神经元开始活动了，真正的战争开始了，但今晚还能正常睡觉。 第二天，过渡的疼痛。和前一天一样，采用阿Q式的精神胜利法，想着不去惹它，肯定会过去的。但事与愿违，疼痛感总是在慢慢加重——漱完口后的绞痛，风吹哆嗦的阵痛，吃完饭后的剧痛……到此，它也不跟我较劲了，索性一直痛，已经到了完全没法忍的地步。说实话，那会儿，我最害怕的是黑夜的到来，因为我能预感到无声的黑夜会空留无眠的我在那里挣扎。but，黑夜，它终究还是到来了，我是那么措手不及。疼痛真的让我无法入眠，翻来覆去不知如何是好。时间在一点点移动，周围室友的鼾声、风声、雨声等各种声音，我一概感知不到，也无暇感知，整个人被疼痛感压迫着，瞌睡虫似乎也被这些“疼痛分子”给赶的赶，杀的杀完了。我尝试换着各种睡姿，力图能从表面上暂时抵挡一下痛感，但完全不行，越动就越痛。啊，天呐，一个晚上难道就要这样过去吗？想想都觉得是生不如死，说实话，我当时出现了这种想法。现在想想，当时真的是一个夜晚都没睡，我能感觉到，刚睡着一会，很快就疼醒。不知不觉天亮了，听说下雪了，但是不想起来，想着起来也是疼，而且冷，干脆上午就这样趟着过去吧，下午再去找医生吧。好吧，就这样轻易地说服自己，但严重的后果也接踵而至。 第三天，下午去找医生，发现医院该死的当天下午开会，不就诊，当时我的心是崩溃的。这意味着我还得痛苦一个晚上，但想到上次我就医之后的那个晚上也难受，我心里也释然了，因为我知道我还得痛苦好几个晚上。有了这样的心态，我的心情没之前那么波动了。既来之，则安之。敢作就要敢受。我只记得，当天结束，我整个人是昏沉的，因为痛得我一件事情都没法做，不仅有疼痛感，还附加了罪恶感。我试过转移注意力，但是连看一部电影都难以支撑，在加上周围人都在拼命地学习，无形的压力真的让我很沮丧。 第四天，不管怎样，都要让我见到医生大人！这一次终于能如愿了。医生照旧在我的阵痛要处刷刷捣鼓一番，痛得我求爷爷告奶奶。给医生看的时候，已经出现炎症了，本来是要拔牙的，医生说再等等，不可着急。这是要偶的命！医生又耍了几把，又是刮牙，又是注射，又是塞药，几经折腾下来，感觉更疼了。开了点消炎药，离开了医院，走在飘雨的寒风中，我疼的哼哼直叫…… 明两天都是周末，我觉得可以好好静养一下了。第五天还是痛得不行，而且比之前更加肿了，我怀疑跟医生昨天那狠下重手的那几下有关，恩，是的，就是这样的！ 第六天醒来，感觉昨晚有真正睡着过，疼痛感并没之前那么强烈了，但整个腮帮肿得不像话，风吹在上面也不堪一击，走路时，整个腮帮感觉也在随着步伐的节奏在晃动。顿时感觉，上天为什么要这么对待我，父母为什么要给我培育这样一副牙齿。 后面的几天痛感在逐渐消失，可歌可泣，恩！终于还是会结束的！到写完这篇文章的今天，已经是第九天了，仍然还是只能吃粉喝粥。哦，对了，前面花了太多篇幅描写自己的心情了，重要的进餐环节给忘了。但是这个环节怎么能忘呢？过去的这几天一直都是以各种宽粉、细粉，有时候外加一点粥为主食，一天两餐，省得不行，但真的是丝毫感觉不到饿，整个身体完全被疼痛感笼罩着，整个注意力只能放在上面，有一天甚至买了一包那种12包袋装的小面包，过了一天。这样的代价就是，整个人萎靡了不少，但这个我不在乎，主要是体重生生降了5公斤，对于一个希望增肥，长肌肉，但又怎么吃都很难肥的人来说，这对我是沉重的打击，不过无所谓，该来的总会来的。 基本上我牙痛的故事到此为止了，但还缺少一句点睛的结尾，我想大概是这样的吧： 当灾难降临到我们头上，我们什么都做不了，唯一能做的就是生活。","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[]},{"title":"盘点改变世界10大创新应用 微信居首","slug":"life/盘点改变世界10大创新应用-微信居首","date":"2015-10-30T02:45:35.000Z","updated":"2019-04-16T12:24:50.176Z","comments":true,"path":"2015/10/30/life/盘点改变世界10大创新应用-微信居首/","link":"","permalink":"https://chambai.github.io/2015/10/30/life/盘点改变世界10大创新应用-微信居首/","excerpt":"这篇文章摘自于腾讯科技的一个图文报道专题，出处是BI中文站，这种报道看一眼就过去了，将来某一天想看可能就找不到了，我觉得这个报道很有意义，所以特地在自己的博客中记录下来。 这个报道所列举的这十种应用都在一定程度上颠覆一些传统的行业，未来真是不可限量。 下面是报道的原文：美国主流网络媒体BI( Business Insider )BI 中文站日前盘点了世界上最好的100大应用，并从中挑选出改变世界的10大最具创新精神应用，它们正改变我们的沟通、旅行、学习以及做事方式。这些应用正通过软件跨越各种限制，彻底改变运输、递送、外语学习、健身等行业，并让我们与亲朋好友的联系更为紧密。","text":"这篇文章摘自于腾讯科技的一个图文报道专题，出处是BI中文站，这种报道看一眼就过去了，将来某一天想看可能就找不到了，我觉得这个报道很有意义，所以特地在自己的博客中记录下来。 这个报道所列举的这十种应用都在一定程度上颠覆一些传统的行业，未来真是不可限量。 下面是报道的原文：美国主流网络媒体BI( Business Insider )BI 中文站日前盘点了世界上最好的100大应用，并从中挑选出改变世界的10大最具创新精神应用，它们正改变我们的沟通、旅行、学习以及做事方式。这些应用正通过软件跨越各种限制，彻底改变运输、递送、外语学习、健身等行业，并让我们与亲朋好友的联系更为紧密。 01.微信 如果你生活在中国之外，可能很少有机会使用这款应用，甚至没听说过它。但是微信有6亿多用户，它是世界上最大的通信应用之一。微信成功的关键之一就是，它实际上不仅仅是一个通信应用，你可以使用它做很多事情，比如打游戏、转账汇钱、视频通话、打车、订餐、购买电影票、读新闻、预约医生等等。对于数亿中国人来说，微信是他们早上醒来后打开的第一款应用，也是晚上上床睡觉前最后浏览的应用。美国硅谷创投公司Andreessen Horowitz合伙人陈宝珠（Connie Chan）说：“微信是集所有功能于一体的绝好应用，体验一流，堪与Facebook以及其他领先通信应用相媲美。” 价格：免费 适用设备：iOS、安卓以及Windows Phone 02.Snapchat 这款应用的日活跃用户数量超过1亿人，主要用户是18岁到24岁之间的青年人，它已经成为一种文化现象。Snapchat只是一种应用，没有网络接口，它的最初创意是：一旦信息阅读后就会立即永久消失。在Snapchat25岁的首席执行官埃文·斯皮格尔(Evan Spiegel)的办公室，悬挂着苹果已故创始人史蒂夫·乔布斯（Steve Jobs）的肖像，还有他对这家初创企业的宏伟构想。但实质上，Snapchat就是即时讨论照片和表达自己的应用。但它也已经成为一款消费媒体，它的Discover部分提供许多出版商的内容，包括CNN、BuzzFeed、Mashable、《People》以及《Vice》杂志等。Snapchat的目的似乎是尽可能地挽留用户，而其这种策略看起来已经发挥作用。 价格：免费 适用设备：iOS、安卓 03.Uber 在所有新兴按需应用中，没有比Uber更能体现出“分享经济”的优势，它将使用智能手机应用打车变为一种主流趋势。只需按下手机按钮，你就可以打到出租车，在应用中输入你想去的目的地，然后利用储存在上面的信用卡付费。如果Uber的计划顺利，它最终不仅能接送乘客，还将成为我们递送包裹、杂货等任何东西的最佳助手。这款应用已经在全球58个国家和地区的300多座城市中展开业务，但只在少量城市中测试其他服务。Uber的饮食递送服务UberEATS已经在洛杉矶、纽约、多伦多推出，同时在旧金山、纽约以及芝加哥推出同城快递服务UberRUSH。价格：免费适用设备：iOS、安卓 04.Shyp Shyp主要帮你解决麻烦的邮寄业务，具有颠覆整个航运行业的潜力。使用这款移动应用，你可以为任何想要邮寄的东西拍照，Shyp快递员会上门取货，并将其送到最近的邮寄点，物品在这里打包并发送。Shyp最近已经升级，允许用户名与地址绑定。为此，当人们想要邮寄物品时，只需要输入自己的名字即可。此外，他们还提供内置包裹追踪器。通过代替你与邮局打交道，Shyp已经证明其可提供你需要的、经验丰富的快递员。如果Shyp控制物品如何运输和递送，它可能改变整个行业，就像Uber改变运输行业一样。到目前为止，Shyp仅在纽约、迈阿密、洛杉矶、芝加哥以及旧金山等城市运营，但其每月新客户都以20%速度增长。 价格：下载应用免费，除了正常邮寄费用外，需要加收5美元配送费 适用设备：iOS、安卓 05.Slack Slack可能不会真的逼死电子邮件，但它正打造新的沟通方式，即便没有电子邮件，沟通也变得更容易。如果你不知道这款应用正以怎样的速度彻底改变企业内部沟通模式，你可以将其想象成为现代版的团队网络聊天室。你可以在公共频道或私人团队中与同事沟通、共享文件等。这款应用面向那些员工经常需要内部沟通的大小企业，现在非常热门。其他应用和服务也可以直接与Slack兼容，这让其看起来就像一个“指挥中心”，能让员工各尽其责。 价格：免费 适用设备：iOS、安卓以及网络 06.Lark Lark利用人工智能与人类专家相结合的方式，帮助人们减肥和保持身体健康。这款应用可以帮助你追踪个人锻炼和饮食情况，它还有短信界面，看起来好像你正与私人健身教练进行一对一沟通。Lark的创意是让人摆脱追踪饮食和锻炼的繁复方式。只需要告诉Lark你吃过什么，它就能依据你制定的目标和过往饮食习惯为你提供营养指导。这款应用还可利用智能手机和智能手表上的传感器追踪你的健身情况。Lark已经被市场研究公司Forrester Research评选为年度最具创新精神的数字健康产品。这款应用免费使用，同时为教练团队、病人或卫生保健供应商提供企业定制版。Lark的首席执行官Julia Hu表示：“我们利用人工智能克隆世界上最好的健康专家，并让他们成为你的私人教练。” 价格：免费 适用设备：iOS、安卓 07.Duolingo Duolingo是一个“寓教于乐”的免费语言学习平台，将学习外语的过程变成如同玩游戏一样有趣。这款应用将外语学习的过程分解成不同层次，用户可以根据自身水平进行选择。每完成一个阶段的学习，用户都可以获得点数奖励。这款服务完全免费，不需要你为学习而花钱。Duolingo的目标是让你能流利地听讲其支持的13种语言之一，它甚至可在第一时间提醒你温习功课。去年，Duolingo为学校推出了自己的语言测试认证。在测试期间，监考人员可通过手机摄像头和麦克风监考，这家初创企业也正为整个班级提供学习平台。Duolingo创始人路易斯·冯·安（Luis von Ahn）表示：“当你与使用Duolingo的人谈话时，他们经常会说‘我在玩Duolingo’。如果你问人们使用Duolingo的主要原因，他们会告诉你：不是因为他们在上面能学到东西，而是因为其非常有趣。” 价格：免费 适用设备：iOS、安卓 08.Google Photos Google Photos是用于管理和储存云端照片的最好应用。它的界面超级容易理解，它有相机不具备的功能，比如面部识别、通过简单描述查找照片的能力等。现在有1亿人在使用这款应用，理由是：对于许多智能手机用户来说，当前设备储存空间太小，而Google Photos可提供廉价、灵活的存储计划，让你将照片、视频储存到其服务器上。 价格：免费 适用设备：iOS、安卓 09.Airbnb 自从有了Airbnb,我们几乎可以在世界任何地方就近找到便宜的住宿之地。只要下载这款应用，并输入你想去的地方，你就会看到世界各地的人们出租客房或整个住宅的信息，你甚至能够找到城堡、农场甚至树屋。这款应用还有搜索过滤功能，应用内通信功能可联系房主。停留在一个地方时，我们无需再承受巨大压力寻找住所。传统旅馆非常担心Airbnb的强势崛起，因为Airbnb的房租比酒店客房便宜得多，有些人甚至将自己的房子改造得让客人有宾至如归的感觉，而非仅仅是一家旅馆。 价格：免费 适用设备：iOS、安卓 10.Foursquare Foursquare堪称是“签到”服务的鼻祖，在Yelp等服务崛起之后，外界已经很少能听到它的声音了。但是Foursquare现在正经历复兴。自从其从社交网络Foursquare独立出来，成为独立应用Swarm以来，这款应用已经变得比以往更好。Foursquare不仅可从世界各地的餐厅中获得大量反馈，而且其推送通知有助于发现无比有趣的新场所。 价格：免费 适用设备：iOS、安卓 （风帆）","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[{"name":"创新","slug":"创新","permalink":"https://chambai.github.io/tags/创新/"}]},{"title":"LaTeX制作中英简历模板","slug":"tech/LaTeX制作中英简历模板","date":"2015-06-07T13:17:47.000Z","updated":"2019-02-22T15:25:48.756Z","comments":true,"path":"2015/06/07/tech/LaTeX制作中英简历模板/","link":"","permalink":"https://chambai.github.io/2015/06/07/tech/LaTeX制作中英简历模板/","excerpt":"","text":"LaTex用于写文章的快捷与方便之处已是众人周知，然而LaTeX能做的事情还有很多，制作精美的PPT(特别是学术性的PPT)，制作精美的简历，以及做出精美的图片(媲美Python的matplotlib和MATLAB)，等等。LaTeX是一种脚本语言，类似于HTML，非常容易上手。利用LaTeX和JBref的组合来写文章，能够方便科研工作者快速实现自己的需求，而不必要为一些繁琐的排版问题而伤透脑筋。为了方便研究人员，很多会议、期刊、杂志都会提供自己相应的模板，投稿者只需下载模板，往里面增加自己的内容即可。 本文提供一些利用LaTeX来制作个人简历的模板，以便日后需要。几个比较好的模板： 中文模板： 英文模板：","categories":[{"name":"05 工具","slug":"05-工具","permalink":"https://chambai.github.io/categories/05-工具/"}],"tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://chambai.github.io/tags/LaTeX/"},{"name":"简历","slug":"简历","permalink":"https://chambai.github.io/tags/简历/"}]},{"title":"LaTeX相关的知识盲点","slug":"tech/LaTeX相关的知识盲点","date":"2015-04-14T13:59:05.000Z","updated":"2019-02-22T15:25:52.636Z","comments":true,"path":"2015/04/14/tech/LaTeX相关的知识盲点/","link":"","permalink":"https://chambai.github.io/2015/04/14/tech/LaTeX相关的知识盲点/","excerpt":"LaTeX是一款高效的论文写作排版工具，除了写论文，它还有其他的一些用途，比如做ppt，写优美的简历，作优美的图画等等。相对于word+endnote的论文写作组合，LaTeX也和JabRef组成一个最佳的组合，但其好用程度比之前一个提升至少10个档次。本文总结几个我在使用的过程中遇到的盲点。 LaTeX对中文的支持要使用中文模板，则LaTeX需要安装CJK库以支持汉字，该库里面已经包含了字体格式，大小等，怎么使用，请见下面一个简单的例子：","text":"LaTeX是一款高效的论文写作排版工具，除了写论文，它还有其他的一些用途，比如做ppt，写优美的简历，作优美的图画等等。相对于word+endnote的论文写作组合，LaTeX也和JabRef组成一个最佳的组合，但其好用程度比之前一个提升至少10个档次。本文总结几个我在使用的过程中遇到的盲点。 LaTeX对中文的支持要使用中文模板，则LaTeX需要安装CJK库以支持汉字，该库里面已经包含了字体格式，大小等，怎么使用，请见下面一个简单的例子： 模板%要运行该模板，LaTex需要安装CJK库以支持汉字. %字体大小为12像素，文档类型为article %如果你要写论文，就用report代替article %所有LaTex文档开头必须使用这句话 \\documentclass[12pt]{article} %使用支持汉字的CJK包 \\usepackage{CJK} %开始CJK环境,只有在这句话之后,你才能使用汉字 %另外,如果在Linux下,请将文件的编码格式设置成GBK %否则会显示乱码 \\begin{CJK*}{GBK}{song} %这是文章的标题 \\title{LaTex 常用模板} %这是文章的作者 \\author{Kevin} %这是文章的时间 %如果没有这行将显示当前时间 %如果不想显示时间则使用 \\date{} \\date{2008/10/12} %以上部分叫做&quot;导言区&quot;,下面才开始写正文 \\begin{document} %先插入标题 \\maketitle %再插入目录 \\tableofcontents \\section{LaTex 简介} LaTex是一个宏包,目的是使作者能够利用一个 预先定义好的专业页面设置, 从而得以高质量的排版和打印他们的作品. %第二段使用黑体,上面的一个空行表示另起一段 \\CJKfamily{hei}LaTex 将空格和制表符视为相同的距离. 多个连续的空白字符 等同为一个空白字符 \\section{LaTex源文件} %在第二段我们使用隶书 \\CJKfamily{li}LaTex 源文件格式为普通的ASCII文件, 你可以使用任何文本编辑器来创建. LaTex源文件不仅包括你要排版的文本, 还包括LaTex 所能识别的,如何排版这些文本的命令. \\section{结论} %在结论部分我们使用仿宋体 \\CJKfamily{fs}LaTeX, 我看行! \\end{CJK*} \\end{document} 字体CTeX里提供了GBK编码的六种中文字体（宋体、仿宋、楷体、黑体、隶书和幼圆），如果你安装了CTeX，就可以类似下面来使用这几种字体： \\documentclass{article} \\usepackage{CJK} \\begin{document} \\begin{CJK}{GBK}{song} 这是CTeX里的宋体！ \\end{CJK} \\begin{CJK}{GBK}{fs} 这是CTeX里的仿宋体！ \\end{CJK} \\begin{CJK}{GBK}{kai} 这是CTeX里的楷体！ \\end{CJK} \\begin{CJK}{GBK}{hei} 这是CTeX里的黑体！ \\end{CJK} \\begin{CJK}{GBK}{li} 这是CTeX里的隶书！ \\end{CJK} \\begin{CJK}{GBK}{you} 这是CTeX里的幼圆体！ \\end{CJK} \\end{document} 参考文献参考文献一般显示在文章末尾，可以用数字标号或者文章年份，有的甚至用作者信息来显示，这些显示方式分别对应着不同的模板，也就是不同库，我们常用的一种方式是显示标号，几种设置方式见下文： LaTex常用宏包：","categories":[{"name":"05 工具","slug":"05-工具","permalink":"https://chambai.github.io/categories/05-工具/"}],"tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://chambai.github.io/tags/LaTeX/"}]},{"title":"十个有好python惯用法","slug":"tech/十个有好python惯用法","date":"2015-01-09T11:48:05.000Z","updated":"2019-02-23T16:45:49.379Z","comments":true,"path":"2015/01/09/tech/十个有好python惯用法/","link":"","permalink":"https://chambai.github.io/2015/01/09/tech/十个有好python惯用法/","excerpt":"1. Make a script both importable and executable(使你的脚本可输入且可执行)if __name__ == &apos;__main__&apos;: Exampledef main(): print(&apos;Doing stuff in module&apos;, __name__) if __name__ == &apos;__main__&apos;: print(&apos;Executed from the command line&apos;) main() $ python mymodule.py Executed from the command line Doing stuff in module __main__ &gt;&gt;&gt; import mymodule &gt;&gt;&gt; mymodule.main() Doing stuff in module mymodule","text":"1. Make a script both importable and executable(使你的脚本可输入且可执行)if __name__ == &apos;__main__&apos;: Exampledef main(): print(&apos;Doing stuff in module&apos;, __name__) if __name__ == &apos;__main__&apos;: print(&apos;Executed from the command line&apos;) main() $ python mymodule.py Executed from the command line Doing stuff in module __main__ &gt;&gt;&gt; import mymodule &gt;&gt;&gt; mymodule.main() Doing stuff in module mymodule 2. Test for “truthy” and “falsy” values(测试采用真假判断)if x: if not x: Example# GOOD name = &apos;Safe&apos; pets = [&apos;Dog&apos;, &apos;Cat&apos;, &apos;Hamster&apos;] owners = {&apos;Safe&apos;: &apos;Cat&apos;, &apos;George&apos;: &apos;Dog&apos;} if name and pets and owners: print(&apos;We have pets!&apos;) # NOT SO GOOD if name != &apos;&apos; and len(pets) &gt; 0 and owners != {}: print(&apos;We have pets!&apos;) 3. Use in where possible(如果有可能尽可能使用in)Contains: if x in items: Iteration: for x in items: Example (contains)# GOOD name = &apos;Safe Hammad&apos; if &apos;H&apos; in name: print(&apos;This name has an H in it!&apos;) # NOT SO GOOD name = &apos;Safe Hammad&apos; if name.find(&apos;H&apos;) != -1: print(&apos;This name has an H in it!&apos;) Example (iteration)# GOOD pets = [&apos;Dog&apos;, &apos;Cat&apos;, &apos;Hamster&apos;] for pet in pets: print(&apos;A&apos;, pet, &apos;can be very cute!&apos;) # NOT SO GOOD pets = [&apos;Dog&apos;, &apos;Cat&apos;, &apos;Hamster&apos;] i = 0 while i &lt; len(pets): print(&apos;A&apos;, pets[i], &apos;can be very cute!&apos;) i += 1 4. Swap values without temp variable(交换两个数不适用temp中间值)a, b = b, a Example# GOOD a, b = 5, 6 print(a, b) # 5, 6 a, b = b, a print(a, b) # 6, 5 # NOT SO GOOD a, b = 5, 6 print(a, b) # 5, 6 temp = a a = b b = temp print(a, b) # 6, 5 5. Build strings using sequence(使用序列的方式来得到字符串)&apos;&apos;.join(some_strings) Example# GOOD chars = [&apos;S&apos;, &apos;a&apos;, &apos;f&apos;, &apos;e&apos;] name = &apos;&apos;.join(chars) print(name) # Safe # NOT SO GOOD chars = [&apos;S&apos;, &apos;a&apos;, &apos;f&apos;, &apos;e&apos;] name = &apos;&apos; for char in chars: name += char print(name) # Safe 6. EAFP is preferable to LBYL(大概意思是说使用专业的容错机制)“It&apos;s Easier to Ask for Forgiveness than Permission.” “Look Before You Leap” try: v. if ...: except: Example# GOOD d = {&apos;x&apos;: &apos;5&apos;} try: value = int(d[&apos;x&apos;]) except (KeyError, TypeError, ValueError): value = None # NOT SO GOOD d = {&apos;x&apos;: &apos;5&apos;} if &apos;x&apos; in d and \\ isinstance(d[&apos;x&apos;], str) and \\ d[&apos;x&apos;].isdigit(): value = int(d[&apos;x&apos;]) else: value = None 7. Enumerate(常用该函数，得到(index, value))for i, item in enumerate(items): Example# GOOD names = [&apos;Safe&apos;, &apos;George&apos;, &apos;Mildred&apos;] for i, name in enumerate(names): print(i, name) # 0 Safe, 1 George etc. # NOT SO GOOD names = [&apos;Safe&apos;, &apos;George&apos;, &apos;Mildred&apos;] count = 0 for name in names: print(i, name) # 0 Safe, 1 George etc. count += 1 8. Build lists using list comprehensions(使用列表合成新的列表)[i * 3 for i in data if i &gt; 10] Example# GOOD data = [7, 20, 3, 15, 11] result = [i * 3 for i in data if i &gt; 10] print(result) # [60, 45, 33] # NOT SO GOOD (MOST OF THE TIME) data = [7, 20, 3, 15, 11] result = [] for i in data: if i &gt; 10: result.append(i * 3) print(result) # [60, 45, 33] 9. Create dict from keys and values using zip(尽可能使用zip()函数创建字典)d = dict(zip(keys, values)) Example# GOOD keys = [&apos;Safe&apos;, &apos;Bob&apos;, &apos;Thomas&apos;] values = [&apos;Hammad&apos;, &apos;Builder&apos;, &apos;Engine&apos;] d = dict(zip(keys, values)) print(d) # {&apos;Bob&apos;: &apos;Builder&apos;, &apos;Safe&apos;: &apos;Hammad&apos;, &apos;Thomas&apos;: &apos;Engine&apos;} # NOT SO GOOD keys = [&apos;Safe&apos;, &apos;Bob&apos;, &apos;Thomas&apos;] values = [&apos;Hammad&apos;, &apos;Builder&apos;, &apos;Engine&apos;] d = {} for i, key in enumerate(keys): d[keys] = values[i] print(d) # {&apos;Bob&apos;: &apos;Builder&apos;, &apos;Safe&apos;: &apos;Hammad&apos;, &apos;Thomas&apos;: &apos;Engine&apos;} 10. And the rest … !● while True: break # This will spark discussion!!! ● Generators and generator expressions. ● Avoid from module import * Prefer: import numpy as np; import pandas as pd ● Use _ for “throwaway” variables e.g.: for k, _ in [(&apos;a&apos;, 1), (&apos;b&apos;, 2), (&apos;c&apos;, 3)] ● dict.get() and dict.setdefault() ● collections.defaultdict ● Sort lists using l.sort(key=key_func)","categories":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/tags/Python/"}]},{"title":"Python查缺补漏","slug":"tech/python查缺补漏","date":"2015-01-07T02:22:14.000Z","updated":"2019-02-23T16:51:02.043Z","comments":true,"path":"2015/01/07/tech/python查缺补漏/","link":"","permalink":"https://chambai.github.io/2015/01/07/tech/python查缺补漏/","excerpt":"python语法非常灵活，其宗旨在与指导程序员快速开发，所以，只有想不到，没有它做不到的。最近偶然看见博客园一位大神Vamei的博客，当时就感觉相见他的博客恨晚，因为他的文字幽默，流畅，有深度，从设计的角度剖析技术，把死板板的技术写得非常有文艺范。做一个科技的文艺范是我读大学以来明确自己的一个终极目标，看到Vamei的博文，我瞬间感觉到这就是我想要的状态，一个科技的文艺范。Vamei是一个非常努力的人，兴趣跟我惊人的相似，他是大神，读书无数，而我现在屌丝，所以，必须向他看齐，并超越。他写了诸多教程，精辟流畅，比太多所谓的教程个人感觉要好几十倍。以前就学过python，但都是浅于表面，没有深度。现在看过Vamei写的教程，觉得有些知识点自己还是很模糊。所以，决心还是把那些知识点记录下来，免得以后又要重新回过头再查阅，浪费时间。站在巨人的肩膀上学习，不过我会从自己的角度剖析这些知识点，加深印象。 1、print 很灵活，打印多个对象没问题&gt;&gt;&gt; a = 1.4 &gt;&gt;&gt; print a, type(a) 1.4 &lt;type &apos;float&apos;&gt;","text":"python语法非常灵活，其宗旨在与指导程序员快速开发，所以，只有想不到，没有它做不到的。最近偶然看见博客园一位大神Vamei的博客，当时就感觉相见他的博客恨晚，因为他的文字幽默，流畅，有深度，从设计的角度剖析技术，把死板板的技术写得非常有文艺范。做一个科技的文艺范是我读大学以来明确自己的一个终极目标，看到Vamei的博文，我瞬间感觉到这就是我想要的状态，一个科技的文艺范。Vamei是一个非常努力的人，兴趣跟我惊人的相似，他是大神，读书无数，而我现在屌丝，所以，必须向他看齐，并超越。他写了诸多教程，精辟流畅，比太多所谓的教程个人感觉要好几十倍。以前就学过python，但都是浅于表面，没有深度。现在看过Vamei写的教程，觉得有些知识点自己还是很模糊。所以，决心还是把那些知识点记录下来，免得以后又要重新回过头再查阅，浪费时间。站在巨人的肩膀上学习，不过我会从自己的角度剖析这些知识点，加深印象。 1、print 很灵活，打印多个对象没问题&gt;&gt;&gt; a = 1.4 &gt;&gt;&gt; print a, type(a) 1.4 &lt;type &apos;float&apos;&gt; 2、序列分为两种：tuple和list它们所存的对象灵活，如： s1 = (1, 2.3, &apos;love&apos;, true) s2 = [false, 3.4, &apos;you&apos;] tuple所存的各个对象可变，而list不可变。 字符串是一种tuple。对象的引用方式非常灵活，记住这一种方式——切片：基本样式：[下限：上限：步长] 3、运算符数学：+ - * \\判断：== &lt; &gt; &lt;= &gt;= != in(表某个对象在某个序列中)逻辑：and or not 4、字典：由键和值组成键和值可以是任意对象，且一一对应。词典中的对象没有顺序，所以不能通过下标来引用词典中的对象。与可变对象列表不同，词典中的对象无重复。 &gt;&gt;&gt; c = {&apos;h&apos;:1, &apos;y&apos;:2, &apos;ki&apos;:4.5} &gt;&gt;&gt; c[&apos;h&apos;] = 1 &gt;&gt;&gt; c {&apos;y&apos;: 2, &apos;h&apos;: 1, &apos;ki&apos;: 4.5} 5、文件对象创建文件对象：f = open(文件名，模式(常用 ‘w’、’r’))文件对象的方法： flist = f.read(N) #读取N bytes的数据 flist = f.readline() #读取一行 flist = f.readlines() #读取所有行 6、模块的导入python之所以被称为胶水语言，就是因为模块化的设计机制，可以导入用其他语言写的模块到python运行环境中，当然这种情况使用的比较少，大多是一些大型的应用程序才会应用到。关于模块，更多的是python自身的模块导入。 import a as b # 引入模块a，并将模块a重命名为b from a import function1 # 从模块a中引入function1对象。调用a中对象时，我们不用再说明模块，即直接使用function1，而不是a.function1。 from a import * # 从模块a中引入所有对象。调用a中对象时，我们不用再说明模块，即直接使用对象，而不是a.对象。 7、参数传递在python中，除了和其他语言共有的几种参数传递（如关键字参数、默认参数等）之外，还多了一种新的方式，这种方式来源于python中视一切皆为对象的特性。有时我们想要传递多个对象，为了减少代码的重复率，增强灵活性，就需要将多个对象合并成一个对象，比如，可以是序列，可以是字典等结构。这个合并参数的过程，换个说法就是对参数打包，即包裹参数传递。 这里要注意，规定如果传递的是元组，则函数的参数需要加*，如果传递的是字典，则加**。和包裹对应的解包裹，并不是包裹的反义，而是两个相互独立的过程，包裹对应定义参数时，而解包裹对应调用函数时。如下： # -*-coding:utf-8 -*- #包裹传递 def func(*args): # 对象是元组 print type(args) print args func(1,2,3) b = (1,2,3) func(b) def func1(**args): # 对象是字典 print type(args) print args func1(d=1, e=2) #解包裹 def func2(a,b,c): print a, b, c args = (1,2,3) func2(*args) dic = {&apos;a&apos;:1, &apos;b&apos;:2, &apos;c&apos;:3} func2(**dic) 8、实用的循环设计range()： for i in range(n)enumerate(): for (index, value) in enumerate(n) 得到(下标，值)的元组zip():对于多个等长的序列，如果在每次循环时都要取每个序列中的一个，则用zip快速方便。 ta = [1,2,3] tb = [9,8,7] tc = [&apos;a&apos;,&apos;b&apos;,&apos;c&apos;] for (a,b,c) in zip(ta,tb,tc): print(a,b,c) 9、函数对象python中一切皆可以看成是对象，函数有时候也看成是对象进行相应的操作，比如将函数作为参数传递给另一个函数。其中，有三个函数被定义成全局函数来使用，map()、filter()、reduce()。map、reduce功能有些类似大数据计算中用的map_reduce。这三个函数就接受一个函数对象作为参数。我们为了方便，常常用lambda函数来生成函数对象。lambda函数是一个匿名函数，如果有时候纠结与不知道为函数取什么名字，同时函数需要实现的功能又比较简单时，用lambda函数是最合适的。下面的例子举一反三。 filter(lambda x: x % 2 == 0, [1,2,3,4,5]) #过滤列表中\\2不为0的数 map(lambda x: x + 2, [1,2,3,4,5]) #列表中每一项分别加2 reduce(lambda x, y: x + y, [1,2,3,4,5]) #列表中两项相加和再和第三项相加，依次下去。 10、python中不支持的类型char和byte，可以用长度为1的字符串来表示指针：python中有个类似指针的东西，就是对象的身份标识id()，其实在python中一切皆为指针。int short 和long，python中有标准整形Integer，当需要长整型时，python会自动返回长整型，非常灵活。float和double，python中float实际上就是双精度浮点型，没有单精度浮点型。当需要更高的精度时，可以使用python中的十进制浮点型类型Decimal，这是一个外部模块，拥有任意的精度，足够用户任意精度的要求使用了。","categories":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/tags/Python/"}]},{"title":"Python的设计哲学","slug":"tech/python设计哲学","date":"2015-01-05T16:00:00.000Z","updated":"2019-02-23T16:45:27.210Z","comments":true,"path":"2015/01/06/tech/python设计哲学/","link":"","permalink":"https://chambai.github.io/2015/01/06/tech/python设计哲学/","excerpt":"我始终相信任何事物（包括抽象的和具象的）的诞生都是有一定的原因的，在讯息快速更新迭代的今天，我们在接受新事物的同时，不当当要知道该事物是什么，而且有必要知道该事物的起源是什么，这样有助于我们应对这种变化，拥抱变化。","text":"我始终相信任何事物（包括抽象的和具象的）的诞生都是有一定的原因的，在讯息快速更新迭代的今天，我们在接受新事物的同时，不当当要知道该事物是什么，而且有必要知道该事物的起源是什么，这样有助于我们应对这种变化，拥抱变化。 扒一扒python的使用现状我们都知道几个比较大的项目，如Google engine的很大部分代码，YouTube以及国内的豆瓣等，都是使用的python。python从1991年正式发布，到至今已经和我同岁了，在这段时间里，已经发生了太多的变化，特别是科技的变化，科技的变化永远都是要比其他的领域来得要快。同样，对于语言的发展来说，同样也是发生着翻天覆地的变化，因为语言是构成科技的重要元素之一，科技的发展离不开语言的发展变迁。python经过这几年的时间，也日趋成熟，其优雅简洁，便于快速开发的优点，逐渐成为各大IT公司和科研机构所青睐的语言。我们来扒一扒两个主流的编程语言社区对现今流行的编程语言的使用情况的一个调查结果。一个是TIOBE，该社区的调查主要是基于Internet上有经验的程序员、课程和第三方厂商对各类语言的使用情况，然后使用搜索引擎技术来进行计算得出；另外一个是CodeForge，不同于TIOBE，该社区的调查则是来源于五万六千多名软件工程师的问卷调查。下面是TIOBE的调查结果。 下面是CodeForge的调查结果。 可见，python对于业界来说，并不是特别主流的语言，更主流还要属C、C++、java这些老牌语言，因为学习这些语言便于理解计算机底层的执行流程，所以这些语言基本上都是每个学计算的人的入门语言。而对于python而言，其优点在于简洁高效，可以让开发者不必过多的关注底层的执行机制，而专注在更高层的框架设计上。所以，python相对于这些老牌语言，使用率不高也是可以理解，但是当要做一些更高端的操作，如科学计算，使用python将会大大减少开发时间，提高开发效率。因此，这些榜单只能反映某个编程语言的热门程度，并不能说明一门编程语言的好与不好，或者一门语言所编写的代码量的多少。 python的起源新事物的出现离不开旧有事物的缺陷，python的设计灵感来源自然少不了旧有的语言缺陷。python是由一位荷兰的数学兼计算机专家Guido Van Rossum于1989年底发明的。当时老爷子在一家IT公司工作，他在这家公司参与设计了一种用于教学的语言，称为ABC语言。这种语言语法非常接近于自然语言，几乎和自然语言同等，不同之处也许只有那些标号等细小的点。但是由于这种语言一个不开放（也许比较臃肿），另外一个对机器性能要求极高。这对于当时的几KB RAM的机器配置来说，想要完成一些基本任务都是很难的。为了满足现有硬件的性能要求，只能从语言本身去做优化，才能满足更多的需求。之后，Guido就继承了ABC语言简洁之道，开发了python，为了继续优化性能，Guido也借鉴了shell的设计思想，并去除了ABC语言所特有的语法臃肿的特性，加入C、C++等这些常用语言语法简洁的特性。可以说，python集百家之长，完成了华丽的崛起。 正因为此，python也被称为胶水语言（Glue Language），它能够将用其他语言写成的模块（尤其是C\\C++）很轻松的粘合在一起。常见的一种应用情形是，使用python快速生成程序的框架，然后对其中要求特别高的部分，用更合适的语言写，比如3D游戏中的图形渲染模块，对性能要求极高，就可以用C++重写，还有Google Engine也是这样做的。至于为什么Guido会取名python，据称是因为Monty Python’s Flying Circus(蒙提*派森飞行马戏团)这个剧，Guido是这个剧的狂热粉丝，名字里面就有一个Python字样，又叫做大蟒蛇，所以才会有了python的logo是一条可爱的蟒蛇。后来据说是1989年的圣诞，这个剧停播，Guido为了打发圣诞假期，才动手写的python，听起来好传奇，牛人就是这样，没有做不到，只有想不到。 设计宗旨python的设计哲学总结为六个字，就是：优雅、明确、简单。为了能够让广大python爱好者全面了解python的设计思想，python社区的人每天都在源源不断的贡献自己的智慧和精力。其中有一位叫Peter的开发者用及其精辟的话整理总结了python的特性，并将之加入到python的模块中，成为了一个小彩蛋。想见这个彩蛋，只需在shell下import this即可。 &gt;&gt;&gt; import this The Zen of Python, by Tim Peters Beautiful is better than ugly. 优美胜于丑陋 Explicit is better than implicit. 明确胜于晦涩 Simple is better than complex. 简单胜于复杂 Complex is better than complicated. 复杂胜于凌乱 Flat is better than nested. 扁平胜于嵌套 Sparse is better than dense. 稀疏胜于稠密 Readability counts. 可读性需要考虑 Special cases aren&apos;t special enough to break the rules. 即使情况特殊，也不应打破规则 Although practicality beats purity. 尽管使用胜于纯净 Errors should never pass silently. 错误不应该悄无声息的忽略 Unless explicitly silenced. 除非特意这么做 In the face of ambiguity, refuse the temptation to guess. 面对混淆是，拒绝猜测（深入搞明白问题） There should be one-- and preferably only one --obvious way to do it. 总有一个，且仅有一个，明显的方法来处理问题 Although that way may not be obvious at first unless you&apos;re Dutch. Now is better than never. 现在开始胜过永远不开始 Although never is often better than *right* now. 尽管永远不开始经常比仓促立即开始好 If the implementation is hard to explain, it&apos;s a bad idea. 如果程序的实现很难解释，那么它不是一个很好的实现 If the implementation is easy to explain, it may be a good idea. 反之 Namespaces are one honking great idea -- let&apos;s do more of those! 命名空间是个绝好的注意，让我们多利用它 这就是python的设计之禅，python社区的这群人都是非常幽默的，将python的设计思想放在解释器中，让人怎么也想不到，这还真是一番人生哲学啊。短短的几行字，借用一个网友说的，每个点都千锤百炼；每一点都直指人内心的感觉；既有指导大是大非的一年，又有指导细节操作的原则；既有谆谆教诲的推荐，也有声色俱厉的禁止。看N遍，每一遍都会让人深思，这就是哲学。","categories":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/tags/Python/"}]},{"title":"俗和雅仅有一步之遥","slug":"life/俗雅共赏","date":"2015-01-04T16:00:00.000Z","updated":"2019-02-21T16:10:11.145Z","comments":true,"path":"2015/01/05/life/俗雅共赏/","link":"","permalink":"https://chambai.github.io/2015/01/05/life/俗雅共赏/","excerpt":"很早以前就看了一步之遥的预告片，华丽的场面、紧凑的节奏和强大的演员阵容，无论是谁看过之后都会觉得赞不绝口，加之姜文导演高超的拍摄技能和影响力，以及之前多部极力较好的好口碑电影（特别是让子弹飞，不得不承认，这是我觉得最好看的两部华语电影之一，另外一部是无间道），让这部电影在上映前的很长一段时间里就集聚了众多的粉丝，对我来说，这是我年度最具期待的电影，也许正是因为期待太高了，正好顺应了那句话，期待太高的东西，最后失望也是最大的。","text":"很早以前就看了一步之遥的预告片，华丽的场面、紧凑的节奏和强大的演员阵容，无论是谁看过之后都会觉得赞不绝口，加之姜文导演高超的拍摄技能和影响力，以及之前多部极力较好的好口碑电影（特别是让子弹飞，不得不承认，这是我觉得最好看的两部华语电影之一，另外一部是无间道），让这部电影在上映前的很长一段时间里就集聚了众多的粉丝，对我来说，这是我年度最具期待的电影，也许正是因为期待太高了，正好顺应了那句话，期待太高的东西，最后失望也是最大的。 12.18号这天，电影如期上映，之前还出现过一些小插曲，让观众以为会推后上映，不过最终姜文导演还是没有辜负大家的期盼，在这一天和观众见面。在去电影院之前，就看到网上一帮看过首映的网友对这部电影评论两极化，但更多看到的是差评。多数人反映的是看不懂，台词冗长，剧情凌乱，镜头之间的切换有些不自然，更像是几个场景堆砌起来的，有些观众甚至在电影放映的中途离场。很不幸让我看到这些评论，这对于一个期待值极高，怀着无比憧憬的心的人来说，难免感到些许失望。就是这样怀着一颗怀疑的心走进电影院，观众之多让我有点意外，但也在意料之中。 开篇第一场戏是一场对话戏，这样的开篇也是挺有新意的，但不好就在于台词太多，让人有些抓不住重点，如果是要反映语言的幽默性，大可不必这样，而且人物的出场让人感觉有些突兀，比如葛优先出现了手，然后莫名其妙闪现了一下人，这样的处理是否妥当，仁者见仁，智者见智吧。之后出现了七八十年代的黑白电影的场景，这不禁让人想起了卓别林电影里面的场景，作为一部在上映之初就被视为充满现代主义情怀的大片，出现这样黑白交替的场景，不免让人有些失望，让人感觉姜导演是在很自恋的秀他拍出的大场面，但是又有点不敢很高调展示的意思，个人这样的场面跟剧情毫无关系，可有可无，有了反而让人觉得非常不适应。 除此之外，整部电影中的多个场景拍摄都让人觉得莫名其妙，如果说姜导演在掌握主旋律的同时不忘加入一些搞笑的情愫也暂且可以理解，但这样的处理除了让电影时长变长之外，也会让观众看得很乏味，觉得这样得搞笑情节简直就是有辱主基调，等看完整部电影之外，观众所谓的看不懂可能就来源于这些不伦不类的情节。以我之见，这部电影还是有可观之处，毕竟是花费了姜导演四年的时间，画面的唯美，歌舞的展现，人物的刻画等都有一些出彩的地方。但是，感觉姜导演想要的太多了，既想表现出大片的感觉，又要迎合观众而放弃电影本身最主要剧情发展，这也许像很多电影评论者所说的之前的几部好口碑电影让姜文的自信心极度膨胀以达到自恋自负到让人无法忍受的地步，最终才催生出这样一部自恋的“个人英雄主义情怀”电影。 观众的眼睛是雪亮的，希望票房的失利能让姜导演意识到一些问题，然后及时改正，争取后面能拍出类似之前或者超越之前的好口碑电影，毕竟姜文是中国的这一批导演中少有的有才华的导演，我对他期望值仍然还是很高的。","categories":[{"name":"影评","slug":"影评","permalink":"https://chambai.github.io/categories/影评/"}],"tags":[]},{"title":"一款值得信赖的编辑器——Sublime Text","slug":"tech/Sublime Text","date":"2014-12-24T16:00:00.000Z","updated":"2019-02-22T15:25:40.001Z","comments":true,"path":"2014/12/25/tech/Sublime Text/","link":"","permalink":"https://chambai.github.io/2014/12/25/tech/Sublime Text/","excerpt":"","text":"无意中遇到这款编辑器，欲罢不能，先在这里简单记录下，以后在用的过程中在进一步体验。详见：将sublime Text搭建成一个好用的IDESublime Text 2 - 性感无比的代码编辑器用户手册知乎讨论","categories":[{"name":"05 工具","slug":"05-工具","permalink":"https://chambai.github.io/categories/05-工具/"}],"tags":[{"name":"Sublime Text","slug":"Sublime-Text","permalink":"https://chambai.github.io/tags/Sublime-Text/"}]},{"title":"推荐系统学习知识点整理","slug":"tech/推荐系统","date":"2014-12-16T16:00:00.000Z","updated":"2019-02-21T15:42:08.681Z","comments":true,"path":"2014/12/17/tech/推荐系统/","link":"","permalink":"https://chambai.github.io/2014/12/17/tech/推荐系统/","excerpt":"本文由知乎如何学习推荐系统？一文整理而来，如有雷同，纯属正常。^.^推荐系统一直是我最感兴趣的技术，但是苦于课题组不做这块的东西，所以只能借助于课余时间去学习。我觉得兴趣的东西还是不能丢，趁现在还是学生时代，抓紧时间多学些东西，让自己的兴趣尽可能地放大，说白了，就是做自己喜欢做的事，不让将来有后悔的念头。关于如何学习，对于初学者，肯定只能站在巨人的肩膀上才能有所突破，本文就简单地对巨人的工作做一点整理，希望对今后的学习有所帮助。 前言推荐系统不算是一个独立的学科，它与机器学习，数据挖掘有天然密不可分的关系。所以，想要学习好这门技术，就要多有所涉略。 技术博客1、探索推荐引擎内部的秘密:对现有的推荐系统技术进行了综述性描述，如下：","text":"本文由知乎如何学习推荐系统？一文整理而来，如有雷同，纯属正常。^.^推荐系统一直是我最感兴趣的技术，但是苦于课题组不做这块的东西，所以只能借助于课余时间去学习。我觉得兴趣的东西还是不能丢，趁现在还是学生时代，抓紧时间多学些东西，让自己的兴趣尽可能地放大，说白了，就是做自己喜欢做的事，不让将来有后悔的念头。关于如何学习，对于初学者，肯定只能站在巨人的肩膀上才能有所突破，本文就简单地对巨人的工作做一点整理，希望对今后的学习有所帮助。 前言推荐系统不算是一个独立的学科，它与机器学习，数据挖掘有天然密不可分的关系。所以，想要学习好这门技术，就要多有所涉略。 技术博客1、探索推荐引擎内部的秘密:对现有的推荐系统技术进行了综述性描述，如下：2、推荐系统经典论文文献及业界应用:百度技术专家的技术博客。里面有很多参考资料。3、个性化推荐技术漫谈：对个性化推荐技术的基本原理进行简要介绍，提出了作者对优秀的个性化推荐的多角度认识。 阅读最新Paper1、几个重要会议：recsys,SIGIR,KDD,WSDM,WWW,ICDM…2、 Recommendation Engines Seminar Paper, Thomas Hess, 2009: 推荐引擎的总结性文章，Thomas 给出推荐引擎的模型，各种推荐机制的工作原理，并分析了推荐引擎面临的众多问题。3、其余更细致的内容参考本文：推荐系统经典论文文献及业界应用，资料非常齐全。 相关书籍1、项亮《推荐系统实践》2、Shapira B. Recommender systems handbook[M]. Springer, 2011. 推荐系统可做枕头，也应该放在枕边的书籍，看了半本多。如果将该书及其中的参考文献都看完并理解，那恭喜你，你已经对这个领域有深入理解了。3、Jannach D, Zanker M, Felfernig A, et al. Recommender systems: an introduction[M]. Cambridge University Press, 2010. 可以认为是2010年前推荐系统论文的综述集合。4、Celma O. Music recommendation and discovery[M]. Springer, 2010. 主要内容集中在音乐推荐，领域非常专注于音乐推荐，包括选取的特征，评测时如何考虑音乐因素。 相关视频1、Stanford-&gt;机器学习 相关系统1、Amazon：推荐技术的先驱，Amazon 在 B2C 领域的推荐技术值得大家参考。2、豆瓣:作为国内社交网络的先驱，豆瓣在推荐技术上也处于领先的位置，同时对于不同内容的推荐策略有深入的研究。3、淘宝推荐系统4、当当网搜索和推荐 庄洪波5、盛大只能对剑系统的开发与应用6、一个入门级的电影推荐系统 推荐系统工具1、Mahout：基于hadoop的机器学习，数据挖掘，推荐系统开源工具。2、scikit-learn：基于python的机器学习，数据挖掘库，方便好用，适合数据量较小的调研任务，不过，一切不支持大数据的机器学习算法，（一定程度上）都是耍流氓。。。。3、weka：经典得不能再经典的数据挖掘工具，java版本4、R：R语言5、Cluto：聚类工具，集成了较多聚类算法及相似度度量方法；单机，数据量受限6、RapidMiner：没用过，但据说使用量非常大7、svdfeature: 上交Apex开发的svd工具集，代码质量不错，而且附带（MovieLen数据集）示例，直接下载各MovieLens数据集就能实验效果8、LibFM:Rendle S. Factorization machines with libFM[J]. ACM Transactions on 经典推荐算法大赛数据1、netflix大赛数据：netflix大赛数据，想尝试各种算法效果，可以用该数据做实验；netflix已经不再发布数据，如有需要可从该链接下载。2、Movielen数据集 相关参考资料1、Google Recommender System Group：推荐系统的 Google 讨论组，有很多关于推荐引擎的有趣讨论。2、Recommender System Algorithms：关于推荐引擎算法的资源。3、Design of Recommender System：关于推荐引擎的设计方法的介绍。4、How to build a recommender system：这个演示给出了如何构建一个推荐引擎，并结合例子详细介绍了基于协同过滤的推荐策略。5、协同过滤技术的实现 后序其余关于数据挖掘和机器学习的资料请参见推荐系统经典论文文献及业界应用一文。不管怎么说，最终想要在这方面取得点成果，最重要的是动手实践，实际参加开发一个推荐系统就好了，而这正是我想做的事，也是我的一点小小的理想吧。 附：资料大合集（哇塞，有福了！）呵呵哈哈论坛","categories":[],"tags":[{"name":"推荐系统","slug":"推荐系统","permalink":"https://chambai.github.io/tags/推荐系统/"}]},{"title":"程序员必须知道的10个算法和数据结构？（转自伯乐在线）","slug":"tech/程序员必知算法与数据结构","date":"2014-11-24T16:00:00.000Z","updated":"2019-02-22T15:26:43.979Z","comments":true,"path":"2014/11/25/tech/程序员必知算法与数据结构/","link":"","permalink":"https://chambai.github.io/2014/11/25/tech/程序员必知算法与数据结构/","excerpt":"Arjun Nayini的推荐算法 1、图搜索 （广度优先、深度优先）深度优先特别重要 2、排序 3、动态规划 4、匹配算法和网络流算法 5、正则表达式和字符串匹配","text":"Arjun Nayini的推荐算法 1、图搜索 （广度优先、深度优先）深度优先特别重要 2、排序 3、动态规划 4、匹配算法和网络流算法 5、正则表达式和字符串匹配 数据结构 1、图（树尤其重要） 2、Map 3、栈/队列 5、Tries | 字典树 额外推荐 贪婪算法 概率方法 近似算法 Ken George的推荐算法 三路划分-快速排序 合并排序（更具扩展性，复杂度类似快速排序） DF/BF搜索（要知道使用场景） Prim/Kruskal(最小生成树) Dijkstra(最短路径算法) 数据结构 HashMap（真的要知道所有的哈希结构） 图和树（红黑树很好学） 堆（优先级队列） 栈/队列 Tries | 字典树 A*和遗传算法也很有趣","categories":[{"name":"04 算法","slug":"04-算法","permalink":"https://chambai.github.io/categories/04-算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://chambai.github.io/tags/数据结构/"},{"name":"算法","slug":"算法","permalink":"https://chambai.github.io/tags/算法/"}]},{"title":"Python Django第一步","slug":"tech/Python Django第一步","date":"2014-10-26T16:00:00.000Z","updated":"2019-02-23T16:49:09.317Z","comments":true,"path":"2014/10/27/tech/Python Django第一步/","link":"","permalink":"https://chambai.github.io/2014/10/27/tech/Python Django第一步/","excerpt":"几经深思和犹豫之后，终于下定了决心要学Django，这是一个如何规划效用成本的问题，有得必有吧，但这是理想的东西，即使是蜗牛的速度，不管什么时候都应该去尝试一下。 在正式入门之前，首先要解决的就是开发环境部署的问题，我选择的是Linux，原因是Django依附于多个相关的python库，在windows上安装着实不方便，而在Linux上就显得格外简单，一行sudo apt-get install XXX的命令就可以搞定。本文主要记录我在安装Django的过程中所遇到的一些问题。","text":"几经深思和犹豫之后，终于下定了决心要学Django，这是一个如何规划效用成本的问题，有得必有吧，但这是理想的东西，即使是蜗牛的速度，不管什么时候都应该去尝试一下。 在正式入门之前，首先要解决的就是开发环境部署的问题，我选择的是Linux，原因是Django依附于多个相关的python库，在windows上安装着实不方便，而在Linux上就显得格外简单，一行sudo apt-get install XXX的命令就可以搞定。本文主要记录我在安装Django的过程中所遇到的一些问题。 安装Django首先在python django下载Django，完了之后执行以下命令安装： 1、tar xzvf Django-\\*.tar.gz 2、cd Django-\\* 3、sudo python setup.py install 这时会提示no module named steuptools，这说明在安装Django需要先安装setuptools库，打开setuptools的python官网看看setuptools该如何安装，如下：除了这种安装方法之外，也可以直接下载setuptools软件包后安装：(1)下载setuptools包 # wget http://pypi.python.org/packages/source/s/ setuptools/setuptools-2.0.tar.gz (2)解压setuptools包 # tar zxvf setuptools-2.0.tar.gz # cd setuptools-2.0 (3)编译setuptools # python setup.py build (4)开始执行setuptools安装 # python setup.py install 除此之外，还有一种安装方法是使用pip，pip是什么，打开pip的python官网，我们看到，pip是’A tool for installing and managing Python packages’，也就是说pip是python的软件安装工具，下面是pip的使用方法：安装包： pip install SomePackage 查看安装包时安装了哪些文件： pip show --files SomePackage 查看哪些包有更新： pip show --files SomePackage 更新一个软件： pip install --upgrade SomePackage 卸载软件： pip uninstall SomePackage 但是用pip，首先得安装，同样的方法，在上面的pip python首页下载pip 包(pip-1.4.1.tar.gz)，使用 “ tar -xvf pip-1.4.1.tar.gz” 解压，cd 进文件夹，使用 “python setup.py install” 命令安装软件。（如果你不想使用pip安装软件包，也可以用此方法下载、解压后使用 “python setup.py install”安装！安装完pip之后，就可以用pip直接安装setuptools了，如下命令： sudo pip install steuptools 安装完setuptools之后在重新运行sudo python setup.py install，等待其执行完之后，Django 就安装完成了。接下来，我们进入python的交互命令行，测试一下Django是否安装成功，如果出现以下代码，则表示安装成功： &gt;&gt;&gt; import django &gt;&gt;&gt; django.VERSION (1, 7, 1, &apos;final&apos;, 0) 安装数据库django只要求python正确安装后就可以跑起来了。 不过，如果想开发一个数据库驱动的web站点时，你应当需要配置一个数据库服务器。如果你只想玩一下，可以不配置数据库，直接跳到 开始一个project 部分去，不过你要注意本书的例子都是假设你配置好了一个正常工作的数据库。Django支持四种数据库： PostgreSQL (http://www.postgresql.org/) SQLite 3 (http://www.sqlite.org/) MySQL (http://www.mysql.com/) Oracle (http://www.oracle.com/) 大部分情况下，这四种数据库都会和Django框架很好的工作。 （一个值得注意的例外是Django的可选GIS支持，它为PostgreSQL提供了强大的功能。）如果你不准备使用一些老旧系统，而且可以自由的选择数据库后端，我们推荐你使用PostgreSQL，它在成本、特性、速度和稳定性方面都做的比较平衡。 如果只是玩一下，不想安装数据库服务，那么可以考虑使用SQLite。 如果你用python2.5或更高版本的话，SQLite是唯一一个被支持的且不需要以上安装步骤的数据库。 它仅对你的文件系统中的单一文件读写数据，并且Python2.5和以后版本内建了对它的支持。 开始一个项目如果安装好了python，django和（可选的）数据库及相关库，你就可以通过创建一个project，迈出开发django应用的第一步。 首先得为项目新建一个工作区，如/home/username/django/djcode，进入该目录，运行命令: 1django-admin.py startproject mysite 则会在当前目录下创建一个目录mysite。如果没有对django-admin.py该命令的环境进行配置，则会报错。所以，首先得对django的环境进行配置，如何在linux下配置环境变量，网上相关的配置方法有好几种，我们选择最简单的一种，即修改用户目录下的.bashrc文件，利用命令$gedit ~/.bashrc打开.bashrc，转到最后，添加如下的命令： # set Django export PATH=$PATH:/home/bycer/Django/Django-1.7.1/django/bin 此时，重启终端，再次进入项目目录，重新运行：django-admin.py startproject mysite,就可以生成项目文件。其中包含几个文件： \\_\\_init__.py manage.py settings.py urls.py wsgi.py 运行开发服务器django开发服务器是可用在开发期间的，一个内建的，轻量级的web服务。无需进行产品级的web服务器（如Apache）的配置工作，开发服务器会监视代码并自动加载它。进入mysite，运行以下命令： python manage.py runserver 将会看到： Validating models... 0 errors found. Django version 1.0, using settings &apos;mysite.settings&apos; Development server is running at http://127.0.0.1:8000/ Quit the server with CONTROL-C. 此时在浏览器中访问http://127.0.0.1:8000/就可以看到django的欢迎界面了。此时就说明一个简单的基于Django的web应用成功部署完成。","categories":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/tags/Python/"},{"name":"Django","slug":"Django","permalink":"https://chambai.github.io/tags/Django/"}]},{"title":"上传代码到GitHub的初尝试","slug":"tech/上传代码到GitHub","date":"2014-10-01T16:00:00.000Z","updated":"2019-02-22T15:26:13.067Z","comments":true,"path":"2014/10/02/tech/上传代码到GitHub/","link":"","permalink":"https://chambai.github.io/2014/10/02/tech/上传代码到GitHub/","excerpt":"","text":"Github是Git旗下的分布式版本管理系统的库，主要用于代码的托管、展示和分享，方便程序员合作开发，所以，Github相当于一个远程的仓库或者是托管代码的云服务器，也可以把其看成是分享和展示代码的网站。这个库早早就听说过，但是一直没有使用，现在随着写的代码越来越多，而且越来越大，代码的管理和维护成为了不得不面对的问题，但作为一个IT爱好者或是即将的IT从业者（我不想用程序员这个词，总感觉这个职业处在压迫之中），不应该把精力放在后期频繁而琐碎的代码维护上，而应该专注于前期的代码开发上。所以，Github这个工具非常合适。但是其入门并不是那么傻瓜式的，因为它依托于Git，需要借助于Git的各种命令来实现代码上传与托管，网上各种入门级的教程，眼花缭乱，与其看别人的，不如自己写一篇，也供以后自己的查阅，若是能够帮助到一两个网友，也不枉费我的辛苦。 提交代码的方式通过看网友的教程，可以大致分为三种方式，因为代码的提交都是要通过本地客户端来完成，所以这三种方式都是依据不同的客户端来分的：1、使用msysgit客户端，关于如何使用msysgit上传代码，请参见这篇博文：初识Github2、直接使用Github的客户端，对应不同的OS，有不同的版本，如windows平台就有Github for Windows，其为windows用户提供了一个基本的图形前端去处理大部分常用版本控制任务，可以创建版本库，向本地版本库提交补丁，在本地和远程版本库之间同步。使用Github提交代码，参见这篇：从不会到会用Github3、使用Git客户端，配有Git bash和Git GUI,本文采用这种方法。 上传自己的项目到Github主要遵循以下两个原则： 将Github上新建的库clone到本地修改或更新之后上传到Github 基于以上两个原则，按照以下几步进行操作：1、在Github上建立项目登录Github之后，找到并点击按钮“New Repository”，即可新建一个项目，记住项目地址，以便后面使用。（PS：项目地址在Code一栏处HTTPS的地方，复制即可）。如果说不是第一次上传代码或Git已经配置过，请跳转到第4步。2、配置Git以及上传代码初次使用Git需要对其进行配置，主要就是让Git记录你Github上的账号名邮件地址，输入如下两行即可： git config --global user.name(&quot;your real name&quot;) git config --global user.email (&quot;you@email.address&quot;) 3、认证Github这一步比较麻烦，需要利用Git生成一个SSH密钥，并提交该密钥到Github上。具体生成密钥和提交密钥的步骤请见在GitHub上分享和展示你的代码4、上传代码到Github秉承下载又上传的原则，刚开始新建的库需要先克隆到本地，然后在上传，所以，首先，通过Git Bash进入需要保存项目的地方，命令的操作和Linux相似。然后执行下面克隆命令操作： git clone https://github.com/XXX/XXX.git 上面的地址就是前面所记录的地址。如果说该库在本地已存在，就不用克隆，直接上传文件即可。下面就是上传操作： a、git add . //该操作是上传当前目录下的全部文件，如果只上传单个文件，则如：git add test.md b、git commit -am &apos;commit&apos; //提交，让上条增加文件命令生效，同时显示代码文件的说明，即代码提交到Github上的提示说明，说明该代码是干嘛的。 c、git remote add origin https://github.com/XXX/XXX.git //向本地仓库中添加远程仓库地址，远程仓库地址别名为origin，如果出现下面的错误：fatal: remote origin already exists则执行如下语句：git remote rm origin d、git pull origin master //将origin所代表的远程仓库地址里的Master主干下载到本地仓库，即上传之前先进行一次同步 e、git push -u origin master //将本地仓库上传到origin所代表的远程仓库的master分支上到此，就可以到Github页面上看，就会看到本地的代码文件已经同步到远程仓库中，这里，只要记住一点：先把远程服务器Github上面的文件先pull下来，在push上去关于Github的操作还有很多，在这里，我们只做简单代码上传和托管操作，我觉得只用记住这几条命令即可，后期在做进一步深入的时候，可以在继续学习。mark~~","categories":[{"name":"05 工具","slug":"05-工具","permalink":"https://chambai.github.io/categories/05-工具/"}],"tags":[{"name":"git","slug":"git","permalink":"https://chambai.github.io/tags/git/"},{"name":"github","slug":"github","permalink":"https://chambai.github.io/tags/github/"}]},{"title":"Git的学习资源","slug":"tech/github","date":"2014-09-30T16:00:00.000Z","updated":"2019-02-22T15:25:59.768Z","comments":true,"path":"2014/10/01/tech/github/","link":"","permalink":"https://chambai.github.io/2014/10/01/tech/github/","excerpt":"","text":"最近看到一个工具，用于托管代码的仓库，Github，其相当于为本机客户端提供了一个远程管理代码的云端服务器，本机的代码可以克隆到云端，也可以从云端同步到客户端，对于程序员来说是一个非常强大的工具，这样程序员就可以不用担心代码的累积给自己造成的困扰，可以安心专注于算法，程序的设计上，而不用为其他的一些琐事儿烦恼，如后期的代码整理，查询和修改。Github是Git下面的一个子项目，Git是一款自由和开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目，类似的系统，我们可能比较熟悉的是像微软的CVS、SVN等这些免费的版本控制系统，但是这些系统是集中式的，不但速度慢，而且必须联网才能使用。由于Git是基于Linux社区建立起来的一个系统，所以其拥有开源和分布式等的优点，现在已经成为业界最为流行的分布式版本控制系统。写这篇文章只是作为简单的了解，并列举网上几个入门级的资料，方便自己以后进行更为深入的学习。见下面： 廖雪峰的官方网站从不会到会使用Github需要几步？如何高效利用Github史上最全github使用方法：github入门到精通","categories":[{"name":"05 工具","slug":"05-工具","permalink":"https://chambai.github.io/categories/05-工具/"}],"tags":[{"name":"git","slug":"git","permalink":"https://chambai.github.io/tags/git/"},{"name":"github","slug":"github","permalink":"https://chambai.github.io/tags/github/"}]},{"title":"About Time ——让时间定格于当下","slug":"life/About Time","date":"2014-09-29T16:00:00.000Z","updated":"2019-02-21T16:13:58.689Z","comments":true,"path":"2014/09/30/life/About Time/","link":"","permalink":"https://chambai.github.io/2014/09/30/life/About Time/","excerpt":"无意中看到了《About Time》(中文翻译为《时空恋旅人》)这部影片，感触颇深，特以记之作为留恋。","text":"无意中看到了《About Time》(中文翻译为《时空恋旅人》)这部影片，感触颇深，特以记之作为留恋。 影片讲述的是一个颇具哲学性的问题——假如你的生活只剩下最后一天，你该如何度过，其实很简单，和自己的家人，亲人，朋友在一起，开开心心地度过即可，而不是想着去追求多么高大上的生活，坐拥多少金银珠宝，享受着多少山珍海味，因为到最后一刻，人一定是只会和自己至亲至敬的人在一块。 剧情结构非常新颖，巧妙，以反时空穿梭作为主线引导，讲述男主人公家族遗传有时空穿梭回以前的时光的超能力，使其能够回到自己觉得不喜欢的过去的某个时刻，然后重新作出改变，使那一天过得充实，不留任何的遗憾，然后再重新回到现在，接着过接下来的生活，男主人公也是因此而追到了自己心仪的女友，并与其结婚、生子，平凡而快乐地过着自己的生活。 影片用时空穿梭为引线，也是隐喻着要告诫所有人要充实地、开开心心地过每一天的生活，不要日后回忆起来留下诸多的遗憾。 这部影片给我的感触特别深，其实在以前我就多次想过这样的问题，每天的生活我该如何度过才会觉得充实，有意义。 这样想，我就会逼着自己去做一些事，即使这些事让自己很痛苦，但是想想自己的环境、责任和理想，就会有一种莫名的力量强迫自己做下去。但是现在想想，我真的一点都不怎么开心，甚至感觉很压抑，我一直压抑自己的内心的那股激情，想着规规矩矩，踏踏实实，每天强迫自己去有意义的过每一天的生活，说白了，就是不敢去做自己想做的事。 好久以前，就想着要追一个女朋友，要学摄影，要炼肌肉，要学视频制作，可是到现在，一样都没有。现在看来，我发觉自己错了一半，不完全是错的，只是没有平衡好充实和开心的关系，过得充实的生活并不一定就开心，但开心并不一定充实。 我对充实和开心的定义是比较狭隘的，在我的眼中，充实的生活可能就是不断地从书本上学到知识，而开心的生活则是做自己喜欢做的事，而不是被现实所逼，强迫自己做不喜欢的事。举一个例子，比如一个喜欢历史的人，入学时不小心被调剂到数学系，这个人的生活该如何开心起来呢？在以前，我会觉得这个人要么只能选择痛苦地强迫自己过充实的生活，要么做自己喜欢的事，开心地过每一天，这样他可能受到来自多方的责备，但是从他本身自私的说，他是开心的。 但是现在，看了这部影片，我对充实和开心有了比较广义的理解，能不能开心的过活，完全在于自己肯不肯去做，每个人为了生计，为了适应，为了家庭，为了理想，不可能没有痛苦，不可能不劳其皮肤，饿其筋骨。只要规划好时间，珍惜身边的一草一木，一张张可爱的脸蛋，开心和幸福就会不经意经造反。 影片中有一句台词说得特别好，在纷繁的世界中，人们在很多次面对人和事的时候，都会因为紧张和担心，而错过一些美好的瞬间，因此造成事情的失败，而当第二次再做的时候，就会有非常好的效果，可是影片的主人公有第二次的机会，现实中的我们呢，没有！所以，过好当下的每一分每一秒，让时光定格每一秒，让每一秒都能成为最美好的回忆。所以，不存在什么充实与不充实，痛苦与痛苦，珍惜好每一粒尘埃就是开心的。 这部影片真的有一种让我超凡脱俗的感觉，希望自己能够做到，我相信一定能够做到的。哦，对了，补充一下，这部影片是看谢霆锋的节目，他推荐的，谢霆锋是近几年在我的心中慢慢树立起来的偶像，从他开了自己的公司，然后英语的励志演讲，在到做美食节目，不能说这里面没有他星二代的功劳，但是能像成龙大哥一样拍戏不用替身，真的让我肃然起敬。","categories":[{"name":"影评","slug":"影评","permalink":"https://chambai.github.io/categories/影评/"}],"tags":[]},{"title":"matplotlib初探","slug":"tech/matplotlib初探","date":"2014-09-24T16:00:00.000Z","updated":"2019-02-23T16:47:37.551Z","comments":true,"path":"2014/09/25/tech/matplotlib初探/","link":"","permalink":"https://chambai.github.io/2014/09/25/tech/matplotlib初探/","excerpt":"前言最近摸索了Python的画图库Matplotlib，其画的图要多炫丽有多炫丽，要多优雅有多优雅，真的有被震撼到，最近项目要求需要画图，考虑到matlab虽然博大精深，但却不易上手，貌似网上最近也在盛传“是否matplotlib能取代matlab”的诸多言论，对于一个旁观者和门外汉，我不做评论，我只有一个理念：什么好学用什么。另外，对于语言的学习和掌握，我现在有一个特别明晰的目标，就是以后以Python为主轴，C\\C++作为辅助，算法为核心来展开。 半年前就接触Python，但期间由于没有一个特定的目标，东捡一点西捡一点，到头来总是在重复同样的事情。现在觉得需要什么学什么，带有目标地去学习才能提高效率，也才能记忆犹新，废话不多说，本文就简单的说说matplotlib。由于刚入门，也没有什么心得，仅仅是看了matplotlib tutorial的一点笔记记录。由于手册是英文版，所以，本文算是对原文的翻译，但我会完全脱离原文的思路，用自己的思路来写，外加自己的一些引申的东西。在进入主题之前，先看下这个知乎大牛关于如何在论文中画出漂亮的插图的探讨，先目睹一下matplotlib所体现出炫丽与优雅。","text":"前言最近摸索了Python的画图库Matplotlib，其画的图要多炫丽有多炫丽，要多优雅有多优雅，真的有被震撼到，最近项目要求需要画图，考虑到matlab虽然博大精深，但却不易上手，貌似网上最近也在盛传“是否matplotlib能取代matlab”的诸多言论，对于一个旁观者和门外汉，我不做评论，我只有一个理念：什么好学用什么。另外，对于语言的学习和掌握，我现在有一个特别明晰的目标，就是以后以Python为主轴，C\\C++作为辅助，算法为核心来展开。 半年前就接触Python，但期间由于没有一个特定的目标，东捡一点西捡一点，到头来总是在重复同样的事情。现在觉得需要什么学什么，带有目标地去学习才能提高效率，也才能记忆犹新，废话不多说，本文就简单的说说matplotlib。由于刚入门，也没有什么心得，仅仅是看了matplotlib tutorial的一点笔记记录。由于手册是英文版，所以，本文算是对原文的翻译，但我会完全脱离原文的思路，用自己的思路来写，外加自己的一些引申的东西。在进入主题之前，先看下这个知乎大牛关于如何在论文中画出漂亮的插图的探讨，先目睹一下matplotlib所体现出炫丽与优雅。 Introduction先来看看matplotlib的Wikipedia介绍，懒得翻译了。 matplotlib is a plotting library for the Python programming language and its NumPy numerical mathematics extension. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like wxPython, Qt, or GTK+. There is also a procedural pylab interface based on a state machine (like OpenGL), designed to closely resemble that of MATLAB. SciPy makes use of matplotlib. matplotlib 一个用来画2D图形的Python库(package)，它同时支持交互式和非交互式的画图方式，能够把画出的图形保存为PNG，PS等多种格式，可以使用多种窗口的工具包，如GTK+，wxWidgets,Qt等，并且可以画出多种类型的图形，如线、条形图、饼状图、柱状图等，主要用于科学计算领域，像常见的gnuplot和MATLAB一样，它是由John Hunter开发的，他说过一句非常经典的话：Matplotlib tries to make easy things easy and hard things possible. 可见，matplotlib是多么令人心动不已。 matplotlib非常的灵活和友善，提供多种画图的方式，在《Matplotlib for python developers》中总结了三种使用matplotlib画图的方式： pyplot: matplotlib.pyplot提供类似于MATLAB的命令集合，使其表现得像MATLAB。 pylab:结合了matplotlib.pyplot和Numpy的功能，既可以画图，又可以做科学计算，说白了，它就是一个使matplotlib表现得像MATLAB的一个接口，但是John不推荐使用这种方式，原因就是它的封装性覆盖了matplotlib的一些基本的东西，不适合开发者学习，往往造成知其然而不知其所以然的状态。 Object-oriented way（OO）：面向对象方法，以python的方式使用，更加的pythonic，这种方法对于开发者来说可以完全控制matplotlib的执行过程，是最好的，但同时也是最复杂的。 下面分别以同一个画图例子来说明这三种方式：pyplot: import matplotlib.pyplot as plt import numpy as np x = np.arange(0, 10, 0.1) y = np.random.randn(len(x)) plt.plot(x, y) plt.title(&apos;random numbers&apos;) plt.show() 得到如下的图示： pylab: from pylab import * x = arange(0, 10, 0.1) y = randn(len(x)) plot(x, y) title(&apos;random numbers&apos;) show() Object-oriented way（OO） import matplotlib.pyplot as plt import numpy as np x = np.arange(0, 10, 0.1) y = np.random.randn(len(x)) fig = plt.figure() ax = fig.add_subplot(111) l, = plt.plot(x, y) t = ax.set_title(&apos;random numbers&apos;) plt.show() 可以看到，面向对象的方式和pyplot需要导入同样的库，才能做相应的操作，在所有代码中，pylab最简单，pyplot其次，OO最复杂，几乎和画图有关的所有元素都由用户自己定义，所以，这种方式更加能够剖析matplotlib的运行机理。因为我们写代码的目标是解决问题，解决问题讲究的是结果和效率，所以，我觉得用pylab是比较清爽的，但每个人都有自己不同的要求，如果一个程序2/3的代码量是依托于Plot，那么用OO的方式是比较合适的，如果只当它是个工具，就应该用最简单的。下面通过一个例子由浅入深地再来matplotlib的美妙之处，这个例子前面说过是翻译，可以找到前面的链接进入原版。 这个例子是显示一个cos(x)和sin(x)，由浅入深，层层递进。我们使用pylab来操作。 第一步：Using default使用Plot的默认参数，包括figure size, dpi, line width, color, style, axes, axis, grid properties text and ront properties and so on.代码如下： from pylab import * X = np.linspace(-np.pi, np.pi, 256, endpoint = True) C, S = np.cos(X), np.sin(X) plot(X, C) plot(X, S) show() 第二步：Instantiating defaults自己定制一个图示，所有参数都自己定制，关于参数的详细定制请见：Customizing matplotlib # Import everything from matplotlib (numpy is accessible via &apos;np&apos; alias) from pylab import * # Create a new figure of size 8x6 points, using 80 dots per inch figure(figsize=(8,6), dpi=80) # Create a new subplot from a grid of 1x1 subplot(1,1,1) X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) # Plot cosine using blue color with a continuous line of width 1 (pixels) plot(X, C, color=&quot;blue&quot;, linewidth=1.0, linestyle=&quot;-&quot;) # Plot sine using green color with a continuous line of width 1 (pixels) plot(X, S, color=&quot;green&quot;, linewidth=1.0, linestyle=&quot;-&quot;) # Set x limits xlim(-4.0,4.0) # Set x ticks xticks(np.linspace(-4,4,9,endpoint=True)) # Set y limits ylim(-1.0,1.0) # Set y ticks yticks(np.linspace(-1,1,5,endpoint=True)) # Save figure using 72 dots per inch # savefig(&quot;exercice_2.png&quot;,dpi=72) # Show result on screen show() 最后一步保存图示，所用的像素值和上面显示的像素值不一样，需要自己设置。 第三步：Changing colors and line widths... figure(figsize=(10,6), dpi=80) plot(X, C, color=&quot;blue&quot;, linewidth=2.5, linestyle=&quot;-&quot;) plot(X, S, color=&quot;red&quot;, linewidth=2.5, linestyle=&quot;-&quot;) ... 第四步：Setting limits上图中的图示感觉太紧凑了，通过对x,y轴设置，可以预留出一些空间，使之看起来清晰一些，如下： ... xlim(X.min()*1.1, X.max()*1.1) ylim(C.min()*1.1, C.max()*1.1) ... 但是，一个更鲁棒性的版本，我们应该这样写： xmin ,xmax = X.min(), X.max() ymin, ymax = Y.min(), Y.max() dx = (xmax - xmin) * 0.2 dy = (ymax - ymin) * 0.2 xlim(xmin - dx, xmax + dx) ylim(ymin - dy, ymax + dy) 第五步：Setting ticks我们需要将步长设成[+/-pi, +/-pi/2]之间的值，那么需要这样做： ... xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi]) yticks([-1, 0, +1]) ... 第六步：Setting ticks labels上图中已经非常接近了，但还需要将3.142表示成π的形式，这样做： ... xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r&apos;$-\\pi$&apos;, r&apos;$-\\pi/2$&apos;, r&apos;$0$&apos;, r&apos;$+\\pi/2$&apos;, r&apos;$+\\pi$&apos;]) yticks([-1, 0, +1], [r&apos;$-1$&apos;, r&apos;$0$&apos;, r&apos;$+1$&apos;]) ... 第七步：Moving spines这一步需要去掉边框，即形成x,y轴，形成一个坐标系，边框在这里定义成spines,我们把上、右边框移去，左边框右移，下边框上移，即可得到最终的图形。 ... ax = gca() ax.spines[&apos;right&apos;].set_color(&apos;none&apos;) ax.spines[&apos;top&apos;].set_color(&apos;none&apos;) ax.xaxis.set_ticks_position(&apos;bottom&apos;) ax.spines[&apos;bottom&apos;].set_position((&apos;data&apos;,0)) ax.yaxis.set_ticks_position(&apos;left&apos;) ax.spines[&apos;left&apos;].set_position((&apos;data&apos;,0)) ... 第八步：adding legend为图示增加一个图例，我们选择左上角的位置，如下： ... plot(X, C, color=&quot;blue&quot;, linewidth=2.5, linestyle=&quot;-&quot;, label=&quot;cosine&quot;) plot(X, S, color=&quot;red&quot;, linewidth=2.5, linestyle=&quot;-&quot;, label=&quot;sine&quot;) legend(loc=&apos;upper left&apos;) ... 第九步：Annotate some points比如我要在图中注释2/3pi,该怎么做呢？ t = 2*np.pi/3 plot([t,t],[0,np.cos(t)], color =&apos;blue&apos;, linewidth=2.5, linestyle=&quot;--&quot;) scatter([t,],[np.cos(t),], 50, color =&apos;blue&apos;) annotate(r&apos;$\\sin(\\frac{2\\pi}{3})=\\frac{\\sqrt{3}}{2}$&apos;, xy=(t, np.sin(t)), xycoords=&apos;data&apos;, xytext=(+10, +30), textcoords=&apos;offset points&apos;, fontsize=16, arrowprops=dict(arrowstyle=&quot;-&gt;&quot;, connectionstyle=&quot;arc3,rad=.2&quot;)) plot([t,t],[0,np.sin(t)], color =&apos;red&apos;, linewidth=2.5, linestyle=&quot;--&quot;) scatter([t,],[np.sin(t),], 50, color =&apos;red&apos;) annotate(r&apos;$\\cos(\\frac{2\\pi}{3})=-\\frac{1}{2}$&apos;, xy=(t, np.cos(t)), xycoords=&apos;data&apos;, xytext=(-90, -50), textcoords=&apos;offset points&apos;, fontsize=16, arrowprops=dict(arrowstyle=&quot;-&gt;&quot;, connectionstyle=&quot;arc3,rad=.2&quot;)) ... 第十步：魔鬼在于细节从上幅图中可以看出，整个图示已经够美观了，但是仔细一看，却发现线压字了，所以我们需要把字凸显出来，让线隐没下去。希望我们在这方面能够向处女座的人多学学。^_^ ... for label in ax.get_xticklabels() + ax.get_yticklabels(): label.set_fontsize(16) label.set_bbox(dict(facecolor=&apos;white&apos;, edgecolor=&apos;None&apos;, alpha=0.65 )) ... OK，到这里为止，10步就把一个图完完整整表现出来了，原作者写这个入门手册也就是为了抛砖引玉，后面怎么举一反三就靠自己了，更多的图例可以看原手册，这里不做过多描述。另外，matplotlib gallery有很多精美的图示，点开就可以看见源码，我们以后如果遇到相关图示，可以做一个简单的参考。还有邮件列表，user mailing。下面看看画图中常用的线的风格、标志符号和颜色值的表示。line style or marker: color标准的颜色值共有8种，如下： 但是指定颜色值的方式很灵活，《matplotlib for Python developer》中给出了四种方式： 用全名，如‘yellow’或缩写（缩写只有上表中的8种） 十六进制表示，如紫色用#800080表示，更全的信息详见十六进制颜色码 RGB或RGBA元组，如(1,0,1,1)，关于如何转换RGB颜色，我还没搞懂，如有知晓，请告知。 灰度值表示，如’0.7’，只针对某一种颜色进行变换。 OK，就记录到这里，更详尽的还请见matplotlib tutorial。此处有一个非常全的视频讲Numpy和matplotlib &gt;&gt;&gt;&gt; introductory tutorial on Numpy and matplotlib 参考：matplotlibmatplotlib for Python developer","categories":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/tags/Python/"},{"name":"matplotlib","slug":"matplotlib","permalink":"https://chambai.github.io/tags/matplotlib/"}]},{"title":"Numpy——强大的科学计算器","slug":"tech/Numpy科学计算器","date":"2014-09-23T16:00:00.000Z","updated":"2019-02-23T16:47:59.005Z","comments":true,"path":"2014/09/24/tech/Numpy科学计算器/","link":"","permalink":"https://chambai.github.io/2014/09/24/tech/Numpy科学计算器/","excerpt":"简单概念Numpy 是Python中用于科学计算的一个基本的包(Package)，下面来看看Numpy的官方定义：NumPy is the fundamental package for scientific computing with Python. It contains among other things: a powerful N-dimensional array object sophisticated (broadcasting) functions tools for integrating C/C++ and Fortran code useful linear algebra, Fourier transform, and random number capabilities 简单的理解Numpy就是：其为数值定义了特定的结构和规则，方便对不同的数值，甚至复杂的数值进行运算（这里说的数值是广义上的），如多维数组结构等。","text":"简单概念Numpy 是Python中用于科学计算的一个基本的包(Package)，下面来看看Numpy的官方定义：NumPy is the fundamental package for scientific computing with Python. It contains among other things: a powerful N-dimensional array object sophisticated (broadcasting) functions tools for integrating C/C++ and Fortran code useful linear algebra, Fourier transform, and random number capabilities 简单的理解Numpy就是：其为数值定义了特定的结构和规则，方便对不同的数值，甚至复杂的数值进行运算（这里说的数值是广义上的），如多维数组结构等。 Numpy提供了两种基本的对象：ndarray(N-dimensional array object)和ufunc(universal function object)。ndarray是存储单一数据类型的多维数组，而ufunc则是能够对数组进行处理的函数。 在Python的标准库，已经有相应的结构来处理数组值的计算，如list，array，那么为什么还需要Numpy？原因就是：1）、list中可以存放任何对象，因此list中所保存的是对象的指针，这样为了保存一个简单的[1,2,3]，需要3个指针和三个整数对象，对于数值计算这种结构显然是比较浪费内存和CPU计算时间的。2）、array模块直接保存数值，和C语言的一维数数组比较类似，但其不支持多维数组，也没有各种运算函数，因此不适合做数值计算。3）、Numpy定义的运算函数ufunc可以在数组和矩阵之间互相转换，可以做到和matlab一般计算游刃有余。 标准的Python库没有Numpy，需要额外安装，这里推荐一个Python shell：ipython，其整合了多个库，不用额外去安装，具体都有些什么库，可以看看知乎的一个回答：Python 常用的标准库以及第三方库有哪些？，一般我们常用的两个库是Numpy和matplotlib，在我的眼中，这两个加起来就是matlab。另外在推荐一个方便进行调试的IDE：JetBrains开发的Pycharm，个人感觉非常nice。 基本语法Numpy的主要对象是同构的多维数组（homogeneous multidimensional array），每个元素用序号进行标记，在Numpy中，维叫做轴，维中的行列值对应轴中叫做rank，如一个二维数组：[[1,0,1], [0,1,2]]有两个轴，第一个轴的rank是2，第二轴的rank是3。（和矩阵对应，Numpy提供了数组和矩阵之间的转化方式） Numpy中的数组类型叫做ndarray，也可以看成是array，只是环境不同，叫法不一样而已，它和Python标准库中的array不一样，array.array只处理一维的数组和少量的函数，而Numpy.array提供多维数组运算，同时还提供多种函数进行数组相关的数值计算，如下：ndarry.ndim:数组轴(维)的数量，如二维数组就为2ndarray.shape:数组的维，如3行2列就为（3,2）ndarray.size:数组中总的元素个数ndarray.dtype:数组中元素的类型ndarray.itemsize:数组中元素的字节类型，如int类型就为4ndarray.data:数组的缓存，一般是用不到的 由于用的不多，且时间有限，尚无法总结出其主要的操作，我们知道它是干什么用的就可以了，以后如果用到，直接查看其用户手册Numpy tutorial即可。这里有一个学习的网址：Numpy introduction","categories":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://chambai.github.io/tags/Numpy/"}]},{"title":"JabRef、Pycharm显示乱码的解决方法（大同小异）","slug":"tech/几个文件显示乱码的解决方法（大同小异）","date":"2014-09-22T16:00:00.000Z","updated":"2019-02-22T15:26:17.017Z","comments":true,"path":"2014/09/23/tech/几个文件显示乱码的解决方法（大同小异）/","link":"","permalink":"https://chambai.github.io/2014/09/23/tech/几个文件显示乱码的解决方法（大同小异）/","excerpt":"","text":"JabRef：一款和CTex配套使用的文献管理软件，就像Endnote和Word配套一样，在写Abstract或review时，其默认只能输入英文，输入中文则乱码，解决办法：first set Options||Preferences||General&gt;&gt;Default Encoding as UTF8then set Options||Preferences||Appearance&gt;&gt;Set table font as simsun (or any other Chinese fonts) 效果非常好。如果还有问题，可将Entry Preview里改为 Pycharm：一款方便调试，并集成了多个库的Python IDE，个人感觉非常好用，如C\\C++的VS和Codeblock，java的eclipse，安装默认不支持中文编码，在注释的时候出现乱码，解决办法：File-settings-file and code templates-python script中改成：# -- coding: utf-8 --然后File-settings-file encoding改成UTF-8编码 设置字体大小，行号File-&gt;Settings-&gt;Editor-&gt;Colors &amp; Font -&gt; Font File-&gt;Settings-&gt;Editor-&gt;Apperance -&gt; 选上Show line numbers 总结：一般这种编码乱码问题，都是由于编码不支持造成的，找到相关地方进行修改就可以了，一般都会在Setting里面。关于中英文编码问题，详见这篇文章，写得非常nice。字符编码","categories":[{"name":"05 工具","slug":"05-工具","permalink":"https://chambai.github.io/categories/05-工具/"}],"tags":[{"name":"乱码","slug":"乱码","permalink":"https://chambai.github.io/tags/乱码/"}]},{"title":"让自己快乐的九种途径","slug":"life/让自己快乐的九种途径","date":"2014-09-22T16:00:00.000Z","updated":"2019-02-21T16:21:00.675Z","comments":true,"path":"2014/09/23/life/让自己快乐的九种途径/","link":"","permalink":"https://chambai.github.io/2014/09/23/life/让自己快乐的九种途径/","excerpt":"","text":"1、放弃完美，多一分轻松2、面对现实，多一分从容3、欣赏自己，多一分自信4、善于取舍，多一分捷径5、远离奢华，多一分平和6、积极进取，多一分成功7、善待他人，多一分爱心8、学会转弯，多一分领悟9、把握尺度，多一分淡定","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[]},{"title":"Python编码中从容易出错的两个小问题中看其编码规范","slug":"tech/Python编码中两个容易出错的两个小问题看其编码规范","date":"2014-09-20T16:00:00.000Z","updated":"2019-02-23T16:50:23.772Z","comments":true,"path":"2014/09/21/tech/Python编码中两个容易出错的两个小问题看其编码规范/","link":"","permalink":"https://chambai.github.io/2014/09/21/tech/Python编码中两个容易出错的两个小问题看其编码规范/","excerpt":"最近在写Python的一些小程序，由于没有系统地学习过Python的语法及编码风格，在编码规范上栽了几个跟头。先看看我遇到的这两个问题，接着引出Python的编码规范。 缩进问题缩进是Python中最重要的，也是最容易出错的细节，这个对于每个初学者都要牢记于心并养成习惯，我的问题出在，从一个文本文档拷贝一段代码到一个IDE的时候，出现了如下的两个错误。 IndentationError: unindent does not match any outer indentation level IndentationError:expected an indented block","text":"最近在写Python的一些小程序，由于没有系统地学习过Python的语法及编码风格，在编码规范上栽了几个跟头。先看看我遇到的这两个问题，接着引出Python的编码规范。 缩进问题缩进是Python中最重要的，也是最容易出错的细节，这个对于每个初学者都要牢记于心并养成习惯，我的问题出在，从一个文本文档拷贝一段代码到一个IDE的时候，出现了如下的两个错误。 IndentationError: unindent does not match any outer indentation level IndentationError:expected an indented block 这两个问题就是提醒你要缩进，但是我明明缩进了，为什么还不行，原因就是拷贝的代码的缩进是用空格，缩进不统一（用肉眼完全看不出来），另外一个就是IDE它本身加了一些功能让你方便写代码，像自动缩进，换行等，拷贝的代码本身也拷贝了文件的格式，所以拷贝过来的代码IDE不能识别，不知道为什么不能识别，按理说删除空格换成Tab就应该可以了，但是不管怎么弄都不行，后来就只得重新编写代码才解决这个问题。 Python库import的导入顺序有讲究库的导入有两种方式：1）并排导入： import module1,module2,module3....... 2）顺序导入： import module1 import module2 : import moduleN 显然第二种看着要清爽，但是由于Python库众多，什么库应该先导入，就非常有讲究。我的第二个问题就是这个。先来看看一个小例子： 这上面导入的两个库的顺序不一样，完全出现不同的结果，可以看到，正确的版本是先导入第三方的库，在导入标准库，但是。。。但是Python的官方编码规范中要求的顺序是： python 标准库模块 python 第三方模块 应用程序自定义模块 这就让人很匪夷所思了，这里先mark一下，以后遇到在进一步补上，但是我决定以后的做法是，用谁，谁最后导入，这里可能存在着覆盖的问题。 好了，上面是我遇到的两个小问题，希望自己牢记，不要再犯同样的错误。关于Python的编码规范，更多的详见Google的官方的风格指南:其中，我挑几点记录一下： 1、不要在行尾加分号2、一行太长，不要加\\换行，这和C++这些不同，Python用()支持直接换行，如： foo = long_function_name( var_one, var_two, var_three, var_four) 3、括号内不要有空格，如： Yes: spam(ham[1], {eggs: 2}, []) No： spam( ham[ 1 ], { eggs: 2 }, [ ] ) 4、一般’=’或比较符号（’&lt;’’=’’&gt;’）两边我们都会加空格，但这里特别注意一下：当’=’用于指示关键字参数或默认参数值时, 不要在其两侧使用空格，如： Yes: def complex(real, imag=0.0): return magic(r=real, i=imag) No: def complex(real, imag = 0.0): return magic(r = real, i = imag) 5、一般在C、C++程序中我们都会这样写，看着舒服极了： foo = 1000 # comment long_name = 2 # comment that should not be aligned dictionary = { &quot;foo&quot; : 1, &quot;long_name&quot;: 2, } 但最好别这样写，这样写就行： foo = 1000 # comment long_name = 2 # comment that should not be aligned dictionary = { &quot;foo&quot;: 1, &quot;long_name&quot;: 2, } 6、大部分.py文件不必以#!作为文件的开始. 根据 PEP-394 , 程序的main文件应该以 #!/usr/bin/python2或者 #!/usr/bin/python3开始. (#!)叫做Shebang(也叫Hashbang),一般在科学计算中，类Unix操作系统的程序载入器会分析Shebang后的内容，将这些内容作为解释器指令，并调用该指令, 并将载有Shebang的文件路径作为该解释器的参数. 例如, 以指令#!/bin/sh开头的文件在执行时会实际调用/bin/sh程序.) (#!)先用于帮助内核找到Python解释器, 但是在导入模块时, 将会被忽略. 因此只有被直接执行的文件中才有必要加入#!. 7、使用文档字符串对模块、函数或方法进行注释，并在必要时增加行内注释，这一条决定着编写大型模块程序时，不会被搞得晕头转向，也不会让别人看自己程序时摸不清头脑。具体怎么做见下面这个模板即可。 def fetch_bigtable_rows(big_table, keys, other_silly_variable=None): &quot;&quot;&quot;Fetches rows from a Bigtable. Retrieves rows pertaining to the given keys from the Table instance represented by big_table. Silly things may happen if other_silly_variable is not None. Args: big_table: An open Bigtable Table instance. keys: A sequence of strings representing the key of each table row to fetch. other_silly_variable: Another optional variable, that has a much longer name than the other args, and which does nothing. Returns: A dict mapping keys to the corresponding table row data fetched. Each row is represented as a tuple of strings. For example: {&apos;Serak&apos;: (&apos;Rigel VII&apos;, &apos;Preparer&apos;), &apos;Zim&apos;: (&apos;Irk&apos;, &apos;Invader&apos;), &apos;Lrrr&apos;: (&apos;Omicron Persei 8&apos;, &apos;Emperor&apos;)} If a key from the keys argument is missing from the dictionary, then that row was not found in the table. Raises: IOError: An error occurred accessing the bigtable.Table object. &quot;&quot;&quot; pass 8、如果一个类不继承自其他类，就应该显示地从object继承，嵌套类也一样，继承自 object 是为了使属性(properties)正常工作, 并且这样可以保护你的代码, 使其不受Python 3000的一个特殊的潜在不兼容性影响. 这样做也定义了一些特殊的方法, 这些方法实现了对象的默认语义, 包括 __new__, __init__, __delattr__, __getattribute__, __setattr__, __hash__, __repr__, and __str__ .如： class SampleClass(object): pass class OuterClass(object): class InnerClass(object): pass class ChildClass(ParentClass): &quot;&quot;&quot;Explicitly inherits from another class already.&quot;&quot;&quot; 9、命名，这个应该是比较重要，好的命名在代码编写过程中，或是在后期调试，维护的过程中都会给人特别舒服的感觉。Tip： module_name, package_name, ClassName, method_name, ExceptionName, function_name, GLOBAL_VAR_NAME, instance_var_name, function_parameter_name, local_var_name 应该避免的名称 单字符名称, 除了计数器和迭代器. 包/模块名中的连字符(-) 双下划线开头并结尾的名称(Python保留, 例如__init__) 命名约定 所谓”内部(Internal)”表示仅模块内可用, 或者, 在类内是保护或私有的. 用单下划线(_)开头表示模块变量或函数是protected的(使用import * from时不会包含). 用双下划线(__)开头的实例变量或方法表示类内私有. 将相关的类和顶级函数放在同一个模块里. 不像Java, 没必要限制一个类一个模块. 对类名使用大写字母开头的单词(如CapWords, 即Pascal风格), 但是模块名应该用小写加下划线的方式(如lower_with_under.py). 尽管已经有很多现存的模块使用类似于CapWords.py这样的命名, 但现在已经不鼓励这样做, 因为如果模块名碰巧和类名一致, 这会让人困扰. Python 之父Guido推荐的规范 10、即使是一个打算被用作脚本的文件, 也应该是可导入的. 并且简单的导入不应该导致这个脚本的主功能(main functionality)被执行, 这是一种副作用. 主功能应该放在一个main()函数中. 在Python中, pydoc以及单元测试要求模块必须是可导入的. 你的代码应该在执行主程序前总是检查 if __name__ == ‘__main__‘ , 这样当模块被导入时主程序就不会被执行.如： def main(): ... if __name__ == &apos;__main__&apos;: main()","categories":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/tags/Python/"}]},{"title":"Python入门笔记","slug":"tech/Python入门笔记","date":"2014-09-19T16:00:00.000Z","updated":"2019-02-23T16:51:20.554Z","comments":true,"path":"2014/09/20/tech/Python入门笔记/","link":"","permalink":"https://chambai.github.io/2014/09/20/tech/Python入门笔记/","excerpt":"特殊符号的打印方法 打印单引号：print (“‘’”)打印双引号：print (‘“”‘)打印换行符：print (‘\\n’)打印反斜杠：print (‘\\‘) 总结：一般情况下单引号和双引号的作用都是相同的.","text":"特殊符号的打印方法 打印单引号：print (“‘’”)打印双引号：print (‘“”‘)打印换行符：print (‘\\n’)打印反斜杠：print (‘\\‘) 总结：一般情况下单引号和双引号的作用都是相同的. Python支持复数的运算:其支持两种表示方法：1、a = 1 + 5j2、a = complex(1, 5) 复数也支持数学运算：a = 2 + 3jb = 4 + 3ja + b = 6 + 6j 函数 id 以值或变量为参数，返回值是一整数，表示值或变量的唯一标识符，每个值或变量在内存中都有唯一的id值，其与在内存中的位置有关。e.g: id(123) = 11602164 Python 允许定义单行的小函数，如lambda函数，叫做匿名函数labmda 参数：表达式g = labmda x, y : x + yg(3,4) = 7(labmda x,y = 0,z=0:x+y+z)(3,5,6) = 14关于匿名函数，这里有一篇比较好的文章：http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868198760391f49337a8bd847978adea85f0a535591000匿名函数也是一个函数对象，可以将其赋给一个变量，也可以作为函数的返回值。 Python对大小写比较敏感如果字符串里面有很多字符都需要转义，就需要加很多\\，为了简化，Python还允许用r’’表示’’内部的字符串默认不转义 Python的字符编码：这里有一篇比较优秀的文章：http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001386819196283586a37629844456ca7e5a7faa9b94ee8000 由于Python源代码也是一个文本文件，所以，当你的源代码中包含中文的时候，在保存源代码时，就需要务必指定保存为UTF-8编码。当Python解释器读取源代码时，为了让它按UTF-8编码读取，我们通常在文件开头写上这两行： #!/usr/bin/env python # -*- coding: utf-8 -*- 要定义一个只有1个元素的tuple，如果你这么定义：t = (1) 定义的不是tuple，是1这个数！这是因为括号()既可以表示tuple，又可以表示数学公式中的小括号，这就产生了歧义，因此，Python规定，这种情况下，按小括号进行计算，计算结果自然是1。 所以，只有1个元素的tuple定义时必须加一个逗号,，来消除歧义：t = (1,) 从raw_input()读取的内容永远以字符串的形式返回。 set和dict的唯一区别仅在于没有存储对应的value，但是，set的原理和dict一样，所以，同样不可以放入可变对象，因为无法判断两个可变对象是否相等，也就无法保证set内部“不会有重复元素”。 在函数调用中，如果参数不对，会抛出”TypeError”的错误，但如果参数类型不对，则不会进行任何操作，所以，需要人为的对可能发生的错误进行处理，使用内置函数isinstance可以解决。如：对参数类型做检查，只允许整数和浮点数类型的参数。数据类型检查可以用内置函数isinstance实现： def my_abs(x): if not isinstance(x, (int, float)): raise TypeError(&apos;bad operand type&apos;) if x &gt;= 0: return x else: return -x 函数可以同时返回多个值，但其实就是一个tuple。 Python中的参数组合：在Python中定义函数，可以用必选参数、默认参数、可变参数和关键字参数，这4种参数都可以一起使用，或者只用其中某些，但是请注意，参数定义的顺序必须是：必选参数、默认参数、可变参数和关键字参数。 Python中的高阶函数：能够接受函数作为参数的函数，还可以把函数作为结果值返回，函数式编程就是指这种高度抽象的编程范式。","categories":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://chambai.github.io/tags/Python/"}]},{"title":"Markdown入门语法汇总","slug":"tech/Markdown入门语法汇总","date":"2014-09-17T16:00:00.000Z","updated":"2019-02-22T15:25:44.593Z","comments":true,"path":"2014/09/18/tech/Markdown入门语法汇总/","link":"","permalink":"https://chambai.github.io/2014/09/18/tech/Markdown入门语法汇总/","excerpt":"","text":"单个回车视为空格 连续回车 才能分段 行尾加两个空格即可段内换行。 斜体 粗体 代码行的开头空4个空格，表示程序代码，例如： C#： public class Blog { public int Id { get; set; } public string Subject { get; set; } } Python： keywords = [&quot;dsaa&quot;,&quot;Asd&quot;,&quot;sadc&quot;,&quot;Gdfd&quot;,&quot;gdfdd&quot;,&quot;gaf&quot;,&quot;gabdddddd&quot;,&quot;eg&quot;] print dict([(i[0],list(i[1])) for i in groupby(sorted(keywords),lambda x:x[0].lower())]) 表示引用文字内容,比如引用他人的文章。 显示大标题（=） 显示小标题（-）- 分割线（—） 这是无序列表 这是无序列表 两个列表之间不能相邻，否则会解释为嵌套的列表 1、这是有序列表项目2、这是有序列表项目 下面是嵌套的列表 外层列表项目 内层列表项目 内层列表项目 外层列表项目 直接把一个URL显示为超级链接： 可以这样：Markdown 图像和连接非常相似，区别在开头加一个惊叹号： 新增1、使用 `代码` 表示行内代码块。示例： 让我们聊聊 html。 2、在段落中填写 [TOC] 以显示全文内容的目录结构。更多详情请看作业部落的markdown语法手册","categories":[{"name":"05 工具","slug":"05-工具","permalink":"https://chambai.github.io/categories/05-工具/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://chambai.github.io/tags/Markdown/"}]},{"title":"电影情怀","slug":"life/电影情怀","date":"2014-03-01T16:08:24.000Z","updated":"2019-02-21T16:09:34.827Z","comments":true,"path":"2014/03/02/life/电影情怀/","link":"","permalink":"https://chambai.github.io/2014/03/02/life/电影情怀/","excerpt":"我是一个电影迷，一直都想把自己心里对电影的情怀给描述出来，每次看完一部好电影，这种想法就越强烈，但是每次又不敢下手，怕时机不对，地点不对，没有灵感，亵渎了自己对这种情怀最美好的描述。所以，每次都是默默地在心里打腹稿，希望用最直白的语言表达出我内心对自己喜欢的东西最深刻的理解，但是这东西往往事与愿违，语言的东西还是让它自然地就出来甚好！","text":"我是一个电影迷，一直都想把自己心里对电影的情怀给描述出来，每次看完一部好电影，这种想法就越强烈，但是每次又不敢下手，怕时机不对，地点不对，没有灵感，亵渎了自己对这种情怀最美好的描述。所以，每次都是默默地在心里打腹稿，希望用最直白的语言表达出我内心对自己喜欢的东西最深刻的理解，但是这东西往往事与愿违，语言的东西还是让它自然地就出来甚好！ 今天实验室集体看电影，看的是《机械战警》，实在忍不住，终于下定决心要写这篇文章。 先说说看过《机械战警》后的简单感受，这是一部好莱坞对英雄主义题材电影的又一次淋漓尽致的展现，不单单是欧美人，好像全世界的人都非常喜欢这种英雄主义题材的电影，感觉看到电影里的英雄，就看到了希望一样。从无所不能的蜘蛛侠、蝙蝠侠、超人到深入人心的绿巨人、绿灯侠、雷神，再到用科技元素武装的超级战警美国队长、X战警、钢铁侠等等，还有很多充满正义的超级英雄的每一次出现，都会让我们非常期待。现如今，拍续集似乎已经不能吊足观众的胃口，观众也会出现审美疲劳，观众喜欢新鲜感，所以，《机械战警》呼之欲出。可以说这是一部应观众口味应运而生但又不乏商业气息的英雄主义题材的豪华巨制。 由于我看的是巨幕+3D，所以，其震撼场面不用多说，剧情思路隐约感到和《阿凡达》有些类似，就是通过科学家的努力人工造出一个无所不能的人，只不过这部电影为剧情的发展留下了一点小小的台阶下，由于人工造出的机器人完全靠program控制，虽然在program中加入了人工智能的机理，但始终不能完成灵敏的操作，总是显得很笨拙，就像电脑永远不能取代人脑一样，这种机器人只能完成program规定的动作。同时，这种机器人也是当下科学家研究的机器人雏形，这方面，美国和日本最为成功。但是，电影就是电影，只有想不到，没有做不到的事。如果将人的大脑和机器的身体结合，岂不是很完美，但又有谁愿意去贡献出自己的大脑，这不是拿人的生命在开玩笑嘛。很有趣，这就是电影中的台阶，同时也是高潮的开始，男主角因为在和恐怖分子斗智斗勇的过程中，被暗算炸掉了下半身，这才成为了机械战警。剧情基本上还可以，但让我印象深刻的是这部电影所流露出来的科技元素，几乎每个镜头，无处不在，还有其呈现的军事装备，台词中所揭示的每种装备中具体的精细的数字，都在向全世界的人昭告：“look，My strong”。尤其是最后一句话升华了电影的主题：American will always be the greatest country in the world！这是在向全世界的人宣告，同时也是在向所有试图攻击美国人民的恐怖分子say impossible。 这里我要说，很多欧美国家的电影，也包括日本、韩国等亚洲国家，说白了，几乎所有的资本主义国家所拍的凡是涉及到商业，科幻，悬疑等类型电影，基本上1/3的镜头是在体现其科技力量，其余才是剧情、人文、情感、动作等辅助的要素。每一部商业电影的上映都会让人对电影里面的科技元素惊叹，我觉得，这是让全世界的人能在第一时间内知道这个国家到底在这一段时间内有多少长进的最好的方式。所以，对于资本主义国家来说，这是很容易的，他们甚至可以将总统带进电影里，以此来直击政府的最高层所存在的腐败、贪污、犯罪等现象。这种电影往往是很有效果的，能达到一举两得的效果，既能放映社会的阴暗面，提醒政府自重，又能吸引观众的眼球。 在这方面，亚洲方面，个人感觉，韩国和日本的电影业体现得比较多，韩国电影总喜欢在电影中穿插很多喜剧的元素，即使是一部沉重压抑的黑色电影，里面都会刻画一些极具喜感的角色，这可能也是他名族的特性，总感觉韩国人说话表情，肢体语言都很丰富，无形之中就能体现喜感。对比下来，我认为韩国电影拍得最成功的还要属它的灾难片。以前我从来不看韩日电影，大约是从去年才开始看，那段时间在百无聊赖之中实在找不到什么好电影看，在豆瓣上搜排名较高的电影，出现了一部《海云台》，看过之后感动得一塌糊涂，剧情、人物刻画、人性、情感都表现得淋漓尽致。从那之后，我几乎把韩国从08年以后所有的灾难电影都看过一遍，慢慢地在我的观念为韩国电影贴上了“灾难”的标签，仅限于灾难片，其他类型电影看得不多，我也没有评价的资格，但是从韩国的obba电视剧来看，其他类型好不到哪里去。有个人说的挺对的，他所看韩国和台湾电视剧，是一次降智商的行为。每个人都有每个人的评价标准，太多的人就是喜欢obba高于一切。 当然，提起灾难片，不得不提的是日本，日本也拍过一些灾难片，他们就处在灾难的起源，自然电影刻画上也不会太差，但个人认为比起韩国所拍的还稍微逊色了一些。我为日本电影所贴的标签是“悬疑”、“恐怖”、“动漫”，在这方面，别的国家真的应该向日本取经，即使是美国。不过，我只对日本的悬疑片感兴趣，看的也不多，曾经看过一部特别有印象，主要是他涉及到了自己的专业的东西—大数据，可能这也是全世界第一部表现大数据的强大功能的电影，它将全国人的DNA提取出来组成一个DNA库，一次来进行案件的侦查，准确率几乎100%，不过这也是虚构的，不可尽信。 相反，我们自己的国家，由于言论自由的限制，这方面就心有力而力不足了。看看现在中国电影的市场，普遍充斥着刺激荷尔蒙的东西，这好像是从一部勾起多少少年少女青春期回忆的《青春期》开始，慢慢地开始增多，这一块的电影投放可以说是屡试不爽。对于所谓的科技电影，真的是不敢恭维，曾经有一部在看完预告片后，感觉很惊奇：中国也能拍出如此宏大场面的电影？到看到真面目之后，彻底给雷倒了，这部电影叫做《富春山居图》，该怎么评判，相信大家心照不宣。以前感觉中国的电影还不错，不管是文艺片，动作片，多多少少都能展现这个时代的一些东西。现在的话，就只能呵呵了。在此，推荐三部我自认为是我看过的最好看的华语电影，《无间道3部》，谍战片的最高境界；《让子弹飞》，宏伟壮阔，发人深省；《全民目击》，紧贴当下，悬疑片中的文艺片，拍摄手法巧妙至极。 似乎千言万语都道不尽我对电影的感受，其实我们每个人都是演员，都在扮演着自己，有的人演得好，就能进入角色，从而找到自己，有的人永远徘徊在边缘，进入不了自己的角色，所以很难有出色的表演，祝每一个身边的人都能演好自己，也祝愿我自己。","categories":[{"name":"影评","slug":"影评","permalink":"https://chambai.github.io/categories/影评/"}],"tags":[]},{"title":"从扶摔倒之人看看客的心态","slug":"life/从扶摔倒之人看看客的心态","date":"2014-02-27T15:57:52.000Z","updated":"2019-02-21T15:57:20.031Z","comments":true,"path":"2014/02/27/life/从扶摔倒之人看看客的心态/","link":"","permalink":"https://chambai.github.io/2014/02/27/life/从扶摔倒之人看看客的心态/","excerpt":"中国人喜欢当看客似乎已经成为一种定律。国外媒体曾经有过一则报道，说对比的是中国人与外国人在对待摔倒的人的一种心态，外国人看到之后面露焦急，急忙上前去将之扶起，而中国人则赶紧拿起手机发微博，这种场景不限于路人摔倒，包括打架等各种吸引眼球的事。","text":"中国人喜欢当看客似乎已经成为一种定律。国外媒体曾经有过一则报道，说对比的是中国人与外国人在对待摔倒的人的一种心态，外国人看到之后面露焦急，急忙上前去将之扶起，而中国人则赶紧拿起手机发微博，这种场景不限于路人摔倒，包括打架等各种吸引眼球的事。 以前就是纯粹的当看客，现在的话可以利用科技将这种羞耻的事公之于大庭广众之下，还得意地为自己拍下如此的场景而在后面附上几个笑脸。 究其原因，我个人认为，主要有两点。一是中国人保守的性格特征决定的，这全世界的人众所周知。因为保守，所以谨慎，因为谨慎，所以喜欢从众，喜欢静观其变；因为谨慎，所以很容易受社会上的一些流言蜚语和不良行为的影响而失去最初的本心，例如扶老人反到被讹诈。 二是中国人普遍知识文化水平和道德情操不高，这是真话，但我说这话并不代表我不爱自己的祖国，我非常地爱。我有自己的一些歪理，貌似听自己的父母说过，我也没查证过，在80年以前，读玩完中专和技校就包分工作，所以很多人最本能的需求就是希望自己能有一技之长，至少读完中专之后生活就不用愁，以后也就很少有时间去读书充实自己，赚钱成了第一需求，整天奔波应酬，加上随着社会经济的进步也就慢慢起来，自然可以对一些冷暖之事置之不理。中国是人口大国，现在的人群中，多半是这样的人，城市里可能选择的机会还多一些，但农村基本上现在的80后，都会不约而同的选择出外打工，或在家务农。另外一方面，即使是有很多人选择有理想有抱负，继续往下读，但是中国的应试教育注定可以培养出高分的人才，即使能培养出高能的人才，也培养不出高德的人才，很多大学生不知道农村长什么样的比比皆是，而且在我经历的9年义务教育中，没有从教科书中学到什么让我感动的事，有的只是一本冠冕堂皇的思想道德，那些令我动容的事都是自己课外看书和经历中听到感受到的。所以真正让自己成长的东西需要自己亲自去体验去感受。所以，因为文化水平低，道德文化差，所以普遍不自信，因为不自信，所以好面子，因为好面子，所以喜欢当看客。 综上两点，可以看出中国人喜欢当看客的心态。 就在写这篇文章前，我看到一条新闻，说是一名IBM的员工在地铁晕倒，根据录像显示当时有向路人求救，但没有人救助，过了40分钟左右，地铁管理人员看见了才急忙上前去看，可惜已经不省人事。 看到这里，我真的心好痛，在责怪这些冷血动物的同时，我在想，如果是我，我会救吗？在想的时候，我脑子里想了很多，包括面子，路人的眼光，以及救了之后怎么送医院等等这些毫无相干的事。所以，这就证明我不会救。很多事情我们看着别人做很恶心，其实换个角度想想，我们又何尝不是在恶心自己。所以，只有保持最初的本心，对任何事情保有自己的判断力，努力提高自己，也许才有可能成为那个愿意伸出援助之手的人。 哎，我不想成为这样袖手旁观充当看客的人，我希望能遇见一件这样的事，让我看清自己。","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/tags/杂谈/"}]},{"title":"第一次住青年旅舍","slug":"life/第一次住青年旅舍","date":"2014-02-17T07:32:00.000Z","updated":"2019-02-21T15:57:45.005Z","comments":true,"path":"2014/02/17/life/第一次住青年旅舍/","link":"","permalink":"https://chambai.github.io/2014/02/17/life/第一次住青年旅舍/","excerpt":"离开了家，和姐姐交心了一晚，第二天姐姐送我到车站，既幸运又悲剧，幸运的是最后一辆车还有最后一个座位，悲剧的是这个座位在上车的楼梯口，座位小而且上下人我都要让，不过还好，我可以将车前方的风景一览无遗。和姐姐道别之后，带着些许不舍向昆明进发，沿途我拍下了不少奇形怪状的路边石壁和青葱翠绿的稻田景色。设想，如果自己坐在一个舒服的位置，就不会有此雅致去观光留念，也许只会仰头大睡，睡起来可能一阵精神萎靡，殊不知错过大好的沿途风景，这可能会产生不同的两种生活状态，这就是人生，可能在不经意经就错过了最美好的东西！","text":"离开了家，和姐姐交心了一晚，第二天姐姐送我到车站，既幸运又悲剧，幸运的是最后一辆车还有最后一个座位，悲剧的是这个座位在上车的楼梯口，座位小而且上下人我都要让，不过还好，我可以将车前方的风景一览无遗。和姐姐道别之后，带着些许不舍向昆明进发，沿途我拍下了不少奇形怪状的路边石壁和青葱翠绿的稻田景色。设想，如果自己坐在一个舒服的位置，就不会有此雅致去观光留念，也许只会仰头大睡，睡起来可能一阵精神萎靡，殊不知错过大好的沿途风景，这可能会产生不同的两种生活状态，这就是人生，可能在不经意经就错过了最美好的东西！ 到达昆明，需要住一晚明早再出发，所以选择住处是我第一紧急的事。拖着个大箱子，满面灰尘扑扑，一看就是个充充的过客，几个拿着上面写着什么招待所的广告牌子的大妈蜂拥而上，有的甚至吆喝“找小姐吗”。如果不是一个人出门在外，亲身体验，真还不知道这社会百态尽出。在汽车站旁边住不是明智之举，一是贵，二是乱，我急忙打开百度地图找寻周边适合的宾馆，不得不说，百度地图已经做成一个生活服务平台了，而不仅仅是简单的地图。 一个地方吸引了我的注意，昆明青年旅舍，临近云南大学和昆理工，周围还是旅游景点：翠湖公园，一看费用，45！我顿时眼前一亮，在一看下面第一个评论：环境清幽，有咖啡屋和健身房，虽然较远，但我一点没犹豫，坐上公交车就奔往该地。每次都是充充的路过，这次终于有机会去走一走。 这地方远离闹区，通过各种渠道，着实让我找了一番。终于到达门口，正对翠湖公园大门的一条清幽小道上，心里暗爽。外层房屋用古朴的林木搭建，有种返璞归真的感觉。门也是木制，设有门铃，大有古代客栈之意。一进门是个休息区，里层上楼是住处和休闲场所，不时有人上下楼和闲谈，清一色是青年，有的和我一样是学生。老板一男一女，女的年纪稍大，在一旁负责咨询和指挥，男的在电脑旁不停地在登记，一看就是被雇来操作软件的。 通过咨询，我才知道青年旅舍是什么，我也知道它为什么便宜的原因，心里顿时不爽。原因就是几个人同时住一间房，有男女混住，每个人配一把钥匙来保管物品。由于第一次遇到几个陌生人同住一间房的情况，我不放心自己的物品，来这的原因就是希望到云大和昆工走一遭，人一走物品怎么办，我总担心这个问题。不过，既来之，则安之，附近也找不到什么适合的，我倒是想探探这的究竟。 办好手续之后，上楼推开门一看，是一个休闲室，有台球桌，餐厅，咖啡屋，聊天室，总之，满足大多青年旅客的需求。让我好奇的是，为什么有好多的老外？带着好奇，穿过各种门，又上了一楼，达到我的房间，里面没人，是一个8人间，卫生还挺干净。二话没说，我立刻拿出手机，继续看百度地图上关于这家旅舍的后面的评论，哈哈，我笑了，后面有评论已经把这里的情况都说清楚了，有郁闷的，也有满意的。我想，如果我看了后面的评论，还会不会来，我又会不会后悔！我在通过百度，顿时没有了任何担心，原来青年旅舍是一个产业，专门为青年旅游者和驴友们提供的一个环境，是一个口碑很好的产业，由英国发源，全世界数不胜数，亚洲属日本较多，中国如此大国，应该算少的。所以，外国人常来这些地方一点就不觉得奇怪。来这的人一般都是觉悟和境界非常高的人，他们喜欢穷游，喜欢冒险，喜欢交朋友，一般同游者不会超过三人，因为人越多他们能交到的朋友就越少，通常他们在一个地方会选择住上一段时间，把这个地方该玩的地方都玩尽了，在转移到另外一个地方，所以对于他们来说，选择住宾馆等这些地方是不划算的。反观我，一个去读书的过客，误打误撞，住了一个还不错的地方。 抓紧时间，收拾好东西后，按照计划，我先到云大走了一遭，随手拍了几张照，还没摸清楚云大的概貌和有名的景点，天空就变微黄了，为了避免夜黑风高迷路，我赶紧按原路返回。可惜没有时间去昆工，只能等下次了，不知道这个下次又要等到什么时候。回来去了翠湖公园，翠湖公园的夜景好美！秉承了很多旅游景点被商业化的特点，公园的道路两旁布满了各种琳琅满目的饰品和小吃摊，烧烤的浓烟滚滚，路面环境也不怎么理想，唯独水中央的亭子在余晖的照耀下显得格外清幽，波光粼粼的水花在亭子倒影的陪衬下显得格外清澈，也许这就是翠湖能够让游客被各种各样的饰品吸引的同时能够驻足一望的理由。 不知不觉，已经快10点，在这种黑灯瞎火的地方，对于一个没有什么方位感的我来说差点迷路，还有翠湖周围有一些标志性的建筑，我才得以“脱身”。来到旅舍，稍许有些饥饿，可是这的东西太贵了，又没有其他办法，只敢点一碗杂酱面，可是坑爹要14元，有点奢侈。旁边各式各样的老外，有闲聊的，有打台球的，有玩手机的，等等，此外，还有一个超萌的白人长卷发小萝莉，可爱至极无法言表。总之，这个地方很清净，人们都懂得求同存异，互相尊重！ 来到房间，我略有紧张，打开门，一个高大白净的欧洲小伙抱以微笑并亲切地说了两个字：“你好”！顿时心里温暖，我也以微笑应答你好。另外还有三个老外也对我同样的动作，由于英语和胆量的关系不好跟人家怎么寒暄，问好之后，我默默地走开。里面有个中国人，一询问才知道他是广州的，一个人来这边旅游。他跟我说，他已经在这里一天了，经常一个人旅游，并且每次都是住这种地方，他说能交到很多的朋友，我跟他说我是要去上大学，误打误撞进了这家旅舍，他笑着说这种地方全国很多，专供驴友们住的……后来稍微唠嗑了几句，他就被他的小伙伴吆喝出去了，我一个人只好上床睡觉，明天还要早起去坐火车。 整个夜晚是一个很让人郁闷的夜晚。晚上3,4点钟还有人来回，中途来了好几次，来一次就要醒一次，总的睡眠时间我估计不超过2个小时，第二天一早我就卷铺盖走人了。 总之，这是一次收获颇多的住宿，虽然有过不爽，但这也是正常而且值得的，以后呢，这样的地方对于我们来说适合和自己的女朋友一起共住。","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://chambai.github.io/categories/杂谈/"}],"tags":[]}]}