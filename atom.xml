<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>猿大白</title>
  
  <subtitle>Linux|云计算|网络|编程|Go|C/C++</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://ctimbai.github.io/"/>
  <updated>2019-04-17T16:27:15.308Z</updated>
  <id>https://ctimbai.github.io/</id>
  
  <author>
    <name>bike</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Docker 网络模型之 macvlan 详解</title>
    <link href="https://ctimbai.github.io/2019/04/14/tech/docker-macvlan/"/>
    <id>https://ctimbai.github.io/2019/04/14/tech/docker-macvlan/</id>
    <published>2019-04-14T05:16:14.000Z</published>
    <updated>2019-04-17T16:27:15.308Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>上一篇文章我们详细介绍了 macvlan 这种技术，<a href="http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;mid=2247485246&amp;idx=1&amp;sn=c42a3618c357ebf5f6b7b7ce78ae568f&amp;chksm=ea743386dd03ba90ad65940321385f68f9315fec16d82a08efa12c18501d8cadf95cf9e614a2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">macvlan 详解</a>，由于它高效易配置的特性，被用在了 Docker 的网络方案设计中，这篇文章就来说说这个。</p><a id="more"></a><h2 id="01macvlan-用于-Docker-网络"><a href="#01macvlan-用于-Docker-网络" class="headerlink" title="01macvlan 用于 Docker 网络"></a>01macvlan 用于 Docker 网络</h2><p>在 Docker 中，macvlan 是众多 Docker 网络模型中的一种，并且是一种跨主机的网络模型，作为一种驱动（driver）启用（-d 参数指定），Docker macvlan 只支持 bridge 模式。</p><p>关于 Docker 的众多跨主机网络模型的科普，参照我之前写的一篇文章：<a href="http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;mid=2247484056&amp;idx=1&amp;sn=d67971f00e5a19ea0cb880f84122bc59&amp;chksm=ea743620dd03bf363d5b38be69412e19c8ae6395f5310b189a44ce4078fae354d1fa0c786889&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">容器网络之多主机网络</a>。</p><p>下面我们做两个实验，分别验证相同 macvlan 网络和不同 macvlan 网络的连通性。</p><h3 id="1-1-相同-macvlan-网络之间的通信"><a href="#1-1-相同-macvlan-网络之间的通信" class="headerlink" title="1.1 相同 macvlan 网络之间的通信"></a>1.1 相同 macvlan 网络之间的通信</h3><p>首先准备两个主机节点的 Docker 环境，搭建如下拓扑图示：</p><p><img src="/images/virt/dockermacvlan1.png" alt="dockermacvlan1"></p><p>1 首先使用 <code>docker network create</code> 分别在两台主机上创建两个 macvlan 网络：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># docker network create -d macvlan --subnet=172.16.10.0/24 --gateway=172.16.10.1 -o parent=enp0s8 mac1</span></span><br></pre></td></tr></table></figure><p>这条命令中，</p><ul><li><code>-d</code> 指定 Docker 网络 driver</li><li><code>--subnet</code> 指定 macvlan 网络所在的网络</li><li><code>--gateway</code> 指定网关</li><li><code>-o parent</code> 指定用来分配 macvlan 网络的物理网卡</li></ul><p>之后可以看到当前主机的网络环境，其中出现了 macvlan 网络：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># docker network ls</span></span><br><span class="line">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class="line">128956db798a        bridge              bridge              <span class="built_in">local</span></span><br><span class="line">19fb1af129e6        host                host                <span class="built_in">local</span></span><br><span class="line">2509b3717813        mac1                macvlan             <span class="built_in">local</span></span><br><span class="line">d5b0798e725e        none                null                <span class="built_in">local</span></span><br></pre></td></tr></table></figure><p>2 在 host1 运行容器 c1，并指定使用 macvlan 网络：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># docker run -itd --name c1 --ip=172.16.10.2 --network mac1 busybox</span></span><br></pre></td></tr></table></figure><p>这条命令中，</p><ul><li><code>--ip</code> 指定容器 c1 使用的 IP，这样做的目的是防止自动分配，造成 IP 冲突</li><li><code>--network</code> 指定 macvlan 网络</li></ul><p>同样在 host2 中运行容器 c2：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># docker run -itd --name c2 --ip=172.16.10.3 --network mac1 busybox</span></span><br></pre></td></tr></table></figure><p>3 在 host1 c1 中 ping host2 c2：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># docker exec c1 ping -c 2 172.16.10.3</span></span><br><span class="line">PING 172.16.10.3 (172.16.10.3): 56 data bytes</span><br><span class="line">64 bytes from 172.16.10.3: seq=0 ttl=64 time=0.641 ms</span><br><span class="line">64 bytes from 172.16.10.3: seq=1 ttl=64 time=0.393 ms</span><br><span class="line"></span><br><span class="line">--- 172.16.10.3 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 packets received, 0% packet loss</span><br><span class="line"></span><br><span class="line">round-trip min/avg/max = 0.393/0.517/0.641 ms</span><br></pre></td></tr></table></figure><blockquote><p>注意：以上的实验都需要物理网卡 enp0s8 开启混杂模式，不然会 ping 不通。</p></blockquote><h3 id="1-2-不同-macvlan-网络之间的通信"><a href="#1-2-不同-macvlan-网络之间的通信" class="headerlink" title="1.2 不同 macvlan 网络之间的通信"></a>1.2 不同 macvlan 网络之间的通信</h3><p>接下来，我们来看看不同 macvlan 网络之间的连通性，搭建以下的拓扑环境：</p><p><img src="/images/virt/dockermacvlan2.jpeg" alt="dockermacvlan2"></p><p>由于 macvlan 网络会独占物理网卡，也就是说一张物理网卡只能创建一个 macvlan 网络，如果我们想创建多个 macvlan 网络就得用多张网卡，但主机的物理网卡是有限的，怎么办呢？</p><p>好在 macvlan 网络也是支持 VLAN 子接口的，所以，我们可以通过 VLAN 技术将一个网口划分出多个子网口，这样就可以基于子网口来创建 macvlan 网络了，下面是具体的创建过程。</p><p>1 首先分别在两台主机上将物理网口 enp0s8 创建出两个 VLAN 子接口。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 vconfig 命令在 eth0 配置两个 VLAN</span></span><br><span class="line">root@ubuntu:~<span class="comment"># vconfig add enp0s8 100</span></span><br><span class="line">root@ubuntu:~<span class="comment"># vconfig add enp0s8 200</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 VLAN 的 REORDER_HDR 参数，默认就行了</span></span><br><span class="line">root@ubuntu:~<span class="comment"># vconfig set_flag enp0s8.100 1 1</span></span><br><span class="line">root@ubuntu:~<span class="comment"># vconfig set_flag enp0s8.200 1 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用接口</span></span><br><span class="line">root@ubuntu:~<span class="comment"># ifconfig enp0s8.100 up</span></span><br><span class="line">root@ubuntu:~<span class="comment"># ifconfig enp0s8.200 up</span></span><br></pre></td></tr></table></figure><p>2 分别在 host1 和 host2 上基于两个 VLAN 子接口创建 2 个 macvlan 网络，mac10 和 mac20。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># docker network create -d macvlan --subnet=172.16.10.0/24 --gateway=172.16.10.1 -o parent=enp0s8.100 mac10</span></span><br><span class="line">root@ubuntu:~<span class="comment"># docker network create -d macvlan --subnet=172.16.20.0/24 --gateway=172.16.20.1 -o parent=enp0s8.200 mac20</span></span><br></pre></td></tr></table></figure><p>3 分别在 host1 和 host2 上运行容器，并指定不同的 macvlan 网络。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># host1</span></span><br><span class="line">root@ubuntu:~<span class="comment"># docker run -itd --name d1 --ip=172.16.10.10 --network mac10 busybox</span></span><br><span class="line">root@ubuntu:~<span class="comment"># docker run -itd --name d2 --ip=172.16.20.10 --network mac20 busybox</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># host2 </span></span><br><span class="line">root@ubuntu:~<span class="comment"># docker run -itd --name d3 --ip=172.16.10.11 --network mac10 busybox</span></span><br><span class="line">root@ubuntu:~<span class="comment"># docker run -itd --name d4 --ip=172.16.20.11 --network mac20 busybox</span></span><br></pre></td></tr></table></figure><p>通过验证，d1 和 d3，d2 和 d4 在同一 macvlan 网络下，互相可以 ping 通，d1 和 d2，d1 和 d4 在不同的 macvlan 网络下，互相 ping 不通。</p><p>这个原因也很明确，不同 macvlan 网络处于不同的网络，而且通过 VLAN 隔离，自然 ping 不了。</p><p>但这也只是在二层上通不了，通过三层的路由是可以通的，我们这就来验证下。</p><p>重新找一台主机 host3，通过打开 <code>ip_forward</code> 把它改造成一台路由器（至于为什么可以这样，可以参考我之前的一篇文章xxx），用来打通两个 macvlan 网络，大概的图示如下所示：</p><p><img src="/images/virt/dockermacvlan3.jpeg" alt="dockermacvlan3"></p><p>1 首先对 host3 执行 <code>sysctl -w net.ipv4.ip_forward=1</code> 打开路由开关。</p><p>2 然后创建两个 VLAN 子接口，一个作为 macvlan 网络 mac10 的网关，一个作为 mac20 的网关。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vconfig add enp0s8 100</span></span><br><span class="line">[root@localhost ~]<span class="comment"># vconfig add enp0s8 200</span></span><br><span class="line">[root@localhost ~]<span class="comment"># vconfig set_flag enp0s8.100 1 1</span></span><br><span class="line">[root@localhost ~]<span class="comment"># vconfig set_flag enp0s8.200 1 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对 vlan 子接口配置网关 IP 并启用</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ifconfig enp0s8.100 172.16.10.1 netmask 255.255.255.0 up</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ifconfig enp0s8.200 172.16.20.1 netmask 255.255.255.0 up</span></span><br></pre></td></tr></table></figure><p>3 这样之后再从 d1 ping d2 和 d4，就可以 ping 通了。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># docker exec d1 ping -c 2 172.16.20.10</span></span><br><span class="line">PING 172.16.20.10 (172.16.20.10): 56 data bytes</span><br><span class="line">64 bytes from 172.16.20.10: seq=0 ttl=63 time=0.661 ms</span><br><span class="line">64 bytes from 172.16.20.10: seq=1 ttl=63 time=0.717 ms</span><br><span class="line"></span><br><span class="line">--- 172.16.20.10 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 packets received, 0% packet loss</span><br><span class="line">round-trip min/avg/max = 0.661/0.689/0.717 ms</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># docker exec d1 ping -c 2 172.16.20.11</span></span><br><span class="line">PING 172.16.20.11 (172.16.20.11): 56 data bytes</span><br><span class="line">64 bytes from 172.16.20.11: seq=0 ttl=63 time=0.548 ms</span><br><span class="line">64 bytes from 172.16.20.11: seq=1 ttl=63 time=0.529 ms</span><br><span class="line"></span><br><span class="line">--- 172.16.20.11 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 packets received, 0% packet loss</span><br><span class="line">round-trip min/avg/max = 0.529/0.538/0.548 ms</span><br></pre></td></tr></table></figure><p>PS：可能有些系统做了安全限制，可能 ping 不通，这时候可以添加以下 iptables 规则，目的是让系统能够转发不通 VLAN 的数据包。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">iptables -t nat -A POSTROUTING -o enp0s8.100 -j MASQUERADE</span><br><span class="line"></span><br><span class="line">iptables -t nat -A POSTROUTING -oenp0s8.200 -j MASQUERADE</span><br><span class="line"></span><br><span class="line">iptables -A FORWARD -i enp0s8.100 -o enp0s8.200 -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br><span class="line"></span><br><span class="line">iptables -A FORWARD -i enp0s8.200 -o enp0s8.100 -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">iptables -A FORWARD -i enp0s8.100 -o enp0s8.200 -j ACCEPT</span><br><span class="line"></span><br><span class="line">iptables -A FORWARD -i enp0s8.200 -o enp0s8.100 -j ACCEPT</span><br></pre></td></tr></table></figure><p>为什么配置 VLAN 子接口，配上 IP 就可以通了，我们可以看下路由表就知道了。</p><p>首先看容器 d1 的路由：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># docker exec d1 ip route</span></span><br><span class="line">default via 172.16.10.1 dev eth0 </span><br><span class="line">172.16.10.0/24 dev eth0 scope link  src 172.16.10.10</span><br></pre></td></tr></table></figure><p>我们在创建容器的时候指定了网关 <code>172.16.10.1</code>，所以数据包自然会被路由到 host3 的接口。再来看下 host3 的路由：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># ip route</span></span><br><span class="line">default via 192.168.108.1 dev enp0s3 proto dhcp metric 100 </span><br><span class="line">172.16.10.0/24 dev enp0s8.100 proto kernel scope link src 172.16.10.1 </span><br><span class="line">172.16.20.0/24 dev enp0s8.200 proto kernel scope link src 172.16.20.1 </span><br><span class="line">192.168.56.0/24 dev enp0s8 proto kernel scope link src 192.168.56.122 metric 101 </span><br><span class="line">192.168.108.0/24 dev enp0s3 proto kernel scope link src 192.168.108.2 metric 100</span><br></pre></td></tr></table></figure><p>可以看到，去往 <code>172.16.10.0/24</code> 网段的数据包会从 enp0s8.100 出去，同理 <code>172.16.20.0/24</code> 网段也是，再加上 host3 的 <code>ip_forward</code> 打开，这就打通了两个 macvlan 网络之间的通路。</p><h2 id="02-总结"><a href="#02-总结" class="headerlink" title="02 总结"></a>02 总结</h2><p>在 Docker 中，macvlan 只支持 bridge 模式。</p><p>相同 macvlan 可以通信，不同 macvlan 二层无法通信，可以借助三层路由完成通信。</p><p><strong>参考：</strong></p><p><a href="https://www.cnblogs.com/CloudMan6/p/7400580.html" target="_blank" rel="noopener">https://www.cnblogs.com/CloudMan6/p/7400580.html</a></p><p><a href="https://blog.csdn.net/dog250/article/details/45788279" target="_blank" rel="noopener">https://blog.csdn.net/dog250/article/details/45788279</a></p><p><a href="https://www.hi-linux.com/posts/40904.html" target="_blank" rel="noopener">https://www.hi-linux.com/posts/40904.html</a></p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可免费领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上一篇文章我们详细介绍了 macvlan 这种技术，&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;amp;mid=2247485246&amp;amp;idx=1&amp;amp;sn=c42a3618c357ebf5f6b7b7ce78ae568f&amp;amp;chksm=ea743386dd03ba90ad65940321385f68f9315fec16d82a08efa12c18501d8cadf95cf9e614a2&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;macvlan 详解&lt;/a&gt;，由于它高效易配置的特性，被用在了 Docker 的网络方案设计中，这篇文章就来说说这个。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Docker" scheme="https://ctimbai.github.io/tags/Docker/"/>
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="macvlan" scheme="https://ctimbai.github.io/tags/macvlan/"/>
    
  </entry>
  
  <entry>
    <title>Linux网络命令必知必会之 tcpdump</title>
    <link href="https://ctimbai.github.io/2019/04/11/tech/linux%E7%BD%91%E7%BB%9C%E5%91%BD%E4%BB%A4%E4%B9%8Btcpdump/"/>
    <id>https://ctimbai.github.io/2019/04/11/tech/linux网络命令之tcpdump/</id>
    <published>2019-04-11T05:16:14.000Z</published>
    <updated>2019-04-17T16:25:12.055Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><h2 id="01-简介"><a href="#01-简介" class="headerlink" title="01 简介"></a>01 简介</h2><p><strong>tcpdump</strong> 是一款 Linux 平台的抓包工具。它可以抓取涵盖整个 TCP/IP 协议族的数据包，支持针对网络层、协议、主机、端口的过滤，并提供 and、or、not 等逻辑语句来过滤无用的信息。</p><p>tcpdump 是一个非常复杂的工具，掌握它的方方面面实属不易，也不推荐，能够用它来解决日常工作问题才是关系。</p><a id="more"></a><h2 id="02-tcpdump-命令选项"><a href="#02-tcpdump-命令选项" class="headerlink" title="02 tcpdump 命令选项"></a>02 tcpdump 命令选项</h2><p>tcpdump 有很多命令选项，想了解所有选项可以 Linux 命令行输入 <code>tcpdump -h</code>，<code>man tcpdump</code> 查看每个选项的意思。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@by ~]# tcpdump -h</span><br><span class="line">tcpdump version 4.9.2</span><br><span class="line">libpcap version 1.5.3</span><br><span class="line">OpenSSL 1.0.2k-fips  26 Jan 2017</span><br><span class="line">Usage: tcpdump [-aAbdDefhHIJKlLnNOpqStuUvxX#] [ -B size ] [ -c count ]</span><br><span class="line">[ -C file_size ] [ -E algo:secret ] [ -F file ] [ -G seconds ]</span><br><span class="line">[ -i interface ] [ -j tstamptype ] [ -M secret ] [ --number ]</span><br><span class="line">[ -Q|-P in|out|inout ]</span><br><span class="line">[ -r file ] [ -s snaplen ] [ --time-stamp-precision precision ]</span><br><span class="line">[ --immediate-mode ] [ -T type ] [ --version ] [ -V file ]</span><br><span class="line">[ -w file ] [ -W filecount ] [ -y datalinktype ] [ -z postrotate-command ]</span><br><span class="line">[ -Z user ] [ expression ]</span><br></pre></td></tr></table></figure><p>下面列举一些常用选项：</p><ul><li>-A 只使用 ASCII 打印报文的全部数据，不要和 <code>-X</code> 一起使用，获取 http 可以用 <code>tcpdump -nSA port 80</code></li><li>-b 在数据链路层上选择协议，包括 ip, arp, rarp, ipx 等</li><li>-c 指定要抓取包的数量</li><li>-D 列出操作系统所有可以用于抓包的接口</li><li>-i 指定监听的网卡，<code>-i any</code> 显示所有网卡</li><li>-n 表示不解析主机名，直接用 IP 显示，默认是用 hostname 显示</li><li>-nn 表示不解析主机名和端口，直接用端口号显示，默认显示是端口号对应的服务名</li><li>-p 关闭接口的混杂模式</li><li>-P 指定抓取的包是流入的包还是流出的，可以指定参数 in, out, inout 等，默认是 inout</li><li>-q 快速打印输出，即只输出少量的协议相关信息</li><li>-s len 设置要抓取数据包长度为 len，默认只会截取前 96bytes 的内容，<code>-s 0</code> 的话，会截取全部内容。</li><li>-S 将 TCP 的序列号以绝对值形式输出，而不是相对值</li><li>-t 不要打印时间戳</li><li>-vv 输出详细信息（比如 tos、ttl、checksum等）</li><li>-X 同时用 hex 和 ascii 显示报文内容</li><li>-XX 同 -X，但同时显示以太网头部</li></ul><h2 id="03-过滤器"><a href="#03-过滤器" class="headerlink" title="03 过滤器"></a>03 过滤器</h2><p>网络报文是很多的，很多时候我们在主机上抓包，会抓到很多我们并不关心的无用包，然后要从这些包里面去找我们需要的信息，无疑是一件费时费力的事情，tcpdump 提供了灵活的语法可以精确获取我们关心的数据，这些语法说得专业点就是过滤器。</p><p>过滤器简单可分为三类：协议（proto）、传输方向（dir）和类型（type）。</p><p>一般的<strong>表达式格式</strong>为：</p><p><img src="/images/net/tcpdump.png" alt="tcpdump"></p><p><a href="https://www.cnblogs.com/f-ck-need-u/p/7064286.html?tdsourcetag=s_pctim_aiomsg" target="_blank" rel="noopener">图片来自</a></p><ul><li>关于 proto：可选有 ip, arp, rarp, tcp, udp, icmp, ether 等，默认是所有协议的包</li><li>关于 dir：可选有 src, dst, src or dst, src and dst，默认为 src or dst</li><li>关于 type：可选有 host, net, port, portrange（端口范围，比如 21-42），默认为 host</li></ul><h2 id="04-常用操作"><a href="#04-常用操作" class="headerlink" title="04 常用操作"></a>04 常用操作</h2><p>测试环境 IP：172.18.82.173</p><h3 id="4-1-抓取某主机的数据包"><a href="#4-1-抓取某主机的数据包" class="headerlink" title="4.1 抓取某主机的数据包"></a>4.1 抓取某主机的数据包</h3><p>抓取主机 172.18.82.173 上所有收到（DST_IP）和发出（SRC_IP）的所有数据包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump host 172.18.82.173</span><br></pre></td></tr></table></figure><p>抓取经过指定网口 interface ，并且 DST_IP 或 SRC_IP 是 172.18.82.173 的数据包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 host 172.18.82.173</span><br></pre></td></tr></table></figure><p>筛选 SRC_IP，抓取经过 interface 且从 172.18.82.173 发出的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 src host 172.18.82.173</span><br></pre></td></tr></table></figure><p>筛选 DST_IP，抓取经过 interface 且发送到 172.18.82.173 的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 dst host 172.18.82.173</span><br></pre></td></tr></table></figure><p>抓取主机 200.200.200.1 和主机 200.200.200.2 或 200.200.200.3 通信的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump host 200.200.200.1 and \(200.200.200.2 or 200.200.200.3\)</span><br></pre></td></tr></table></figure><p>抓取主机 200.200.200.1 和除了主机 200.200.200.2 之外所有主机通信的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump ip host 200.200.200.1 and ! 200.200.200.2</span><br></pre></td></tr></table></figure><h3 id="4-2-抓取某端口的数据包"><a href="#4-2-抓取某端口的数据包" class="headerlink" title="4.2 抓取某端口的数据包"></a>4.2 抓取某端口的数据包</h3><p>抓取所有端口，显示 IP 地址</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -nS</span><br></pre></td></tr></table></figure><p>抓取某端口上的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump port 22</span><br></pre></td></tr></table></figure><p>抓取经过指定 interface，并且 DST_PORT 或 SRC_PORT 是 22 的数据包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 port 22</span><br></pre></td></tr></table></figure><p>筛选 SRC_PORT</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 src port 22</span><br></pre></td></tr></table></figure><p>筛选 DST_PORT</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 dst port 22</span><br></pre></td></tr></table></figure><p>比如希望查看发送到 host 172.18.82.173 的网口 eth0 的 22 号端口的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@by ~]# tcpdump -i eth0 -nnt dst host 172.18.82.173 and port 22 -c 1 -vv</span><br><span class="line">tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">IP (tos 0x14, ttl 114, id 27674, offset 0, flags [DF], proto TCP (6), length 40)</span><br><span class="line">    113.98.59.61.51830 &gt; 172.18.82.173.22: Flags [.], cksum 0x7fe3 (correct), seq 19775964, ack 1564316089, win 2053, length 0</span><br></pre></td></tr></table></figure><h3 id="4-3-抓取某网络（网段）的数据包"><a href="#4-3-抓取某网络（网段）的数据包" class="headerlink" title="4.3 抓取某网络（网段）的数据包"></a>4.3 抓取某网络（网段）的数据包</h3><p>抓取经过指定 interface，并且 DST_NET 或 SRC_NET 是 172.18.82 的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 net 172.18.82</span><br></pre></td></tr></table></figure><p>筛选 SRC_NET</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 src net 172.18.82</span><br></pre></td></tr></table></figure><p>筛选 DST_NET</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 dst net 172.18.82</span><br></pre></td></tr></table></figure><h3 id="4-4-抓取某协议的数据包"><a href="#4-4-抓取某协议的数据包" class="headerlink" title="4.4 抓取某协议的数据包"></a>4.4 抓取某协议的数据包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 icmp</span><br><span class="line">tcpdump -i eth0 ip</span><br><span class="line">tcpdump -i eth0 tcp</span><br><span class="line">tcpdump -i eth0 udp</span><br><span class="line">tcpdump -i eth0 arp</span><br></pre></td></tr></table></figure><h3 id="4-5-复杂的逻辑表达式抓取过滤条件"><a href="#4-5-复杂的逻辑表达式抓取过滤条件" class="headerlink" title="4.5 复杂的逻辑表达式抓取过滤条件"></a>4.5 复杂的逻辑表达式抓取过滤条件</h3><p>抓取经过 interface eth0 发送到 host 200.200.200.1 或 200.200.200.2 的 TCP 协议 22 号端口的数据包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 -nntvv -c 10 &apos;((tcp) and (port 22) and ((dst host 200.200.200.1) or (dst host 200.200.200.2)))&apos;</span><br></pre></td></tr></table></figure><p>PS：对于复杂的过滤器表达式，为了逻辑清晰，可以使用 <code>()</code>，不过默认情况下，tcpdump 会将 <code>()</code> 当做特殊字符，所以必须使用 <code>&#39;&#39;</code> 来消除歧义。</p><p>抓取经过 interface eth0， DST_MAC 或 SRC_MAC 地址是 00:16:3e:12:16:e7 的 ICMP 数据包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 &apos;((icmp) and ((ether host 00:16:3e:12:16:e7)))&apos; -nnvv</span><br></pre></td></tr></table></figure><p>抓取经过 interface eth0，目标网络是 172.18 但目标主机又不是 172.18.82.173 的 TCP 且非 22 号端口号的数据包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 -nntvv &apos;((dst net 172.18) and (not dst host 172.18.82.173) and (tcp) and (not port 22))&apos;</span><br></pre></td></tr></table></figure><p>抓取流入 interface eth0，host 为 172.18.82.173 且协议为 ICMP 的数据包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 -nntvv -P in host 172.18.82.173 and icmp</span><br></pre></td></tr></table></figure><p>抓取流出 interface eth0，host 为 172.18.82.173 且协议为 ICMP 的数据包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 -nntvv -P out host 172.18.82.173 and icmp</span><br></pre></td></tr></table></figure><h2 id="05-与-wireshark、Snort-等工具的结合"><a href="#05-与-wireshark、Snort-等工具的结合" class="headerlink" title="05 与 wireshark、Snort 等工具的结合"></a>05 与 wireshark、Snort 等工具的结合</h2><p>tcpdump 抓包的时候，默认是打印到屏幕输出，如果是抓取包少还好，如果包很多，很多行数据，刷刷刷从眼前一闪而过，根本来不及看清内容。不过，tcpdump 提供了将抓取的数据保存到文件的功能，查看文件就方便分析多了，而且还能与其他图形工具一起配合分析，比如 wireshark、Snort 等。</p><ul><li>-w 选项表示把数据报文输出到文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -w capture_file.pcap port 80 # 把所有 80 端口的数据导出到文件</span><br></pre></td></tr></table></figure><ul><li>-r 选项表示读取文件里的数据报文，显示到屏幕上</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -nXr capture_file.pcap host host1</span><br></pre></td></tr></table></figure><p>PS：<code>.pcap</code> 格式的文件需要用 wireshark、Snort 等工具查看，使用 <code>vim</code> 或 <code>cat</code> 会出现乱码。</p><h2 id="06-tcpdump-的输出格式"><a href="#06-tcpdump-的输出格式" class="headerlink" title="06 tcpdump 的输出格式"></a>06 tcpdump 的输出格式</h2><p>tcpdump 的输出格式总体上为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">系统时间 源主机.端口 &gt; 目标主机.端口 数据包参数</span><br></pre></td></tr></table></figure><p>比如下面的例子，显示了 TCP 的三次握手过程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">21:27:06.995846 IP (tos 0x0, ttl 64, id 45646, offset 0, flags [DF], proto TCP (6), length 64)</span><br><span class="line">    192.168.1.106.56166 &gt; 124.192.132.54.80: Flags [S], cksum 0xa730 (correct), seq 992042666, win 65535, options [mss 1460,nop,wscale 4,nop,nop,TS val 663433143 ecr 0,sackOK,eol], length 0</span><br><span class="line"></span><br><span class="line">21:27:07.030487 IP (tos 0x0, ttl 51, id 0, offset 0, flags [DF], proto TCP (6), length 44)</span><br><span class="line">    124.192.132.54.80 &gt; 192.168.1.106.56166: Flags [S.], cksum 0xedc0 (correct), seq 2147006684, ack 992042667, win 14600, options [mss 1440], length 0</span><br><span class="line"></span><br><span class="line">21:27:07.030527 IP (tos 0x0, ttl 64, id 59119, offset 0, flags [DF], proto TCP (6), length 40)</span><br><span class="line">    192.168.1.106.56166 &gt; 124.192.132.54.80: Flags [.], cksum 0x3e72 (correct), ack 2147006685, win 65535, length 0</span><br></pre></td></tr></table></figure><p>第一条是 <code>SYN</code> 报文，通过 <code>Flags[S]</code> 看出。第二条是 <code>[S.]</code>，表示 <code>SYN-ACK</code> 报文。常见的 TCP 报文的 Flags 如下：</p><ul><li><code>[S]</code>： SYN（开始连接）</li><li><code>[.]</code>: 没有 Flag</li><li><code>[P]</code>: PSH（推送数据）</li><li><code>[F]</code>: FIN （结束连接）</li><li><code>[R]</code>: RST（重置连接）</li></ul><h2 id="06-总结"><a href="#06-总结" class="headerlink" title="06 总结"></a>06 总结</h2><p>本文可以当字典查阅，记住一些常用的 tcpdump 抓包案例，其他的用到再通过 <code>man tcpdump</code> 辅助编写。和 wireshark 等图形化工具配合使用，能更加深理解。</p><p><strong>参考：</strong></p><p><a href="https://blog.csdn.net/Jmilk/article/details/86618205?tdsourcetag=s_pctim_aiomsg" target="_blank" rel="noopener">https://blog.csdn.net/Jmilk/article/details/86618205?tdsourcetag=s_pctim_aiomsg</a></p><p><a href="https://www.cnblogs.com/f-ck-need-u/p/7064286.html?tdsourcetag=s_pctim_aiomsg" target="_blank" rel="noopener">https://www.cnblogs.com/f-ck-need-u/p/7064286.html?tdsourcetag=s_pctim_aiomsg</a></p><p><a href="https://danielmiessler.com/study/tcpdump/" target="_blank" rel="noopener">https://danielmiessler.com/study/tcpdump/</a></p><p><a href="http://bencane.com/2014/10/13/quick-and-practical-reference-for-tcpdump/" target="_blank" rel="noopener">http://bencane.com/2014/10/13/quick-and-practical-reference-for-tcpdump/</a></p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可免费领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;01-简介&quot;&gt;&lt;a href=&quot;#01-简介&quot; class=&quot;headerlink&quot; title=&quot;01 简介&quot;&gt;&lt;/a&gt;01 简介&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;tcpdump&lt;/strong&gt; 是一款 Linux 平台的抓包工具。它可以抓取涵盖整个 TCP/IP 协议族的数据包，支持针对网络层、协议、主机、端口的过滤，并提供 and、or、not 等逻辑语句来过滤无用的信息。&lt;/p&gt;
&lt;p&gt;tcpdump 是一个非常复杂的工具，掌握它的方方面面实属不易，也不推荐，能够用它来解决日常工作问题才是关系。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="tcpdump" scheme="https://ctimbai.github.io/tags/tcpdump/"/>
    
  </entry>
  
  <entry>
    <title>Linux云网络基础之网卡虚拟化技术 macvlan 详解</title>
    <link href="https://ctimbai.github.io/2019/04/01/tech/linux-macvlan/"/>
    <id>https://ctimbai.github.io/2019/04/01/tech/linux-macvlan/</id>
    <published>2019-04-01T05:16:14.000Z</published>
    <updated>2019-04-17T16:28:17.590Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><h2 id="01-macvlan-简介"><a href="#01-macvlan-简介" class="headerlink" title="01 macvlan 简介"></a>01 macvlan 简介</h2><p>前面的文章讲过了几种 Linux 虚拟网络设备：tap/tun、veth-pair、bridge，它们本质上是 Linux 系统 提供的网络虚拟化解决方案，今天要讲的 macvlan 也是其中的一种，准确说这是一种网卡虚拟化的解决方案。因为 macvlan 这种技术能将 <strong>一块物理网卡虚拟成多块虚拟网卡</strong> ，相当于物理网卡施展了 多重影分身之术 ，由一个变多个。</p><p><img src="/images/virt/macvlanmulti.jpeg" alt="macvlanmulti"></p><a id="more"></a><h2 id="02-macvlan-的工作原理"><a href="#02-macvlan-的工作原理" class="headerlink" title="02 macvlan 的工作原理"></a>02 macvlan 的工作原理</h2><p>macvlan 是 Linux kernel 支持的新特性，支持的版本有 v3.9-3.19 和 4.0+，比较稳定的版本推荐 4.0+。它一般是以内核模块的形式存在，我们可以通过以下方法判断当前系统是否支持：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># modprobe macvlan</span></span><br><span class="line"><span class="comment"># lsmod | grep macvlan</span></span><br><span class="line">macvlan                24576  0</span><br></pre></td></tr></table></figure><p>如果第一个命令报错，或者第二个命令没有返回，说明当前系统不支持 macvlan，需要升级内核。</p><p>macvlan 这种技术听起来有点像 VLAN，但它们的实现机制是完全不一样的。macvlan 子接口和原来的主接口是完全独立的，可以单独配置 MAC 地址和 IP 地址，而 VLAN 子接口和主接口共用相同的 MAC 地址。VLAN 用来划分广播域，而 macvlan 共享同一个广播域。</p><p>通过不同的子接口，macvlan 也能做到流量的隔离。macvlan 会根据收到包的目的 MAC 地址判断这个包需要交给哪个虚拟网卡，虚拟网卡再把包交给上层的协议栈处理。</p><p><img src="/images/virt/macvlanflow.png" alt="macvlanflow"></p><h2 id="03-四种模式"><a href="#03-四种模式" class="headerlink" title="03 四种模式"></a>03 四种模式</h2><p>根据 macvlan 子接口之间的通信模式，macvlan 有四种网络模式：</p><ul><li>private 模式</li><li>vepa(virtual ethernet port aggregator) 模式</li><li>bridge 模式</li><li>passthru 模式</li></ul><p>默认使用的是 vepa 模式。</p><h3 id="3-1-private"><a href="#3-1-private" class="headerlink" title="3.1 private"></a>3.1 private</h3><p>这种模式下，同一主接口下的子接口之间彼此隔离，不能通信。即使从外部的物理交换机导流，也会被无情地丢掉。</p><p><img src="/images/virt/private.png" alt="linux-macvlan-private-mode"></p><h3 id="3-2-vepa"><a href="#3-2-vepa" class="headerlink" title="3.2 vepa"></a>3.2 vepa</h3><p>这种模式下，子接口之间的通信流量需要导到外部支持 <code>802.1Qbg/VPEA</code> 功能的交换机上（可以是物理的或者虚拟的），经由外部交换机转发，再绕回来。</p><p>注：<code>802.1Qbg/VPEA</code> 功能简单说就是交换机要支持 <code>发夹（hairpin）</code> 功能，也就是数据包从一个接口上收上来之后还能再扔回去。</p><p><img src="/images/virt/vepa.png" alt="linux-macvlan-802.1qbg-vepa-mode"></p><h3 id="3-3-bridge"><a href="#3-3-bridge" class="headerlink" title="3.3 bridge"></a>3.3 bridge</h3><p>这种模式下，模拟的是 Linux bridge 的功能，但比 bridge 要好的一点是每个接口的 MAC 地址是已知的，不用学习。所以，这种模式下，子接口之间就是直接可以通信的。</p><p><img src="/images/virt/bridge.png" alt="linux-macvlan-bridge-mode"></p><h3 id="3-4-passthru"><a href="#3-4-passthru" class="headerlink" title="3.4 passthru"></a>3.4 passthru</h3><p>这种模式，只允许单个子接口连接主接口，且必须设置成混杂模式，一般用于子接口桥接和创建 VLAN 子接口的场景。</p><p><img src="/images/virt/passthru.png" alt="linux-macvlan-passthru-mode"></p><h3 id="3-5-mactap"><a href="#3-5-mactap" class="headerlink" title="3.5 mactap"></a>3.5 mactap</h3><p>和 macvlan 相似的技术还有一种是 mactap。和 macvlan 不同的是，mactap 收到包之后不是交给协议栈，而是交给一个 tapX 文件，然后通过这个文件，完成和用户态的直接通信。</p><p><img src="/images/virt/mactap.png" alt="mactap"></p><h2 id="04-实践"><a href="#04-实践" class="headerlink" title="04 实践"></a>04 实践</h2><p>在 Linux 系统下，创建 macvlan 的命令形式如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip link add link DEVICE name NAME <span class="built_in">type</span> &#123; macvlan | macvtap &#125; mode &#123; private | vepa | bridge |</span><br><span class="line">              passthru  [ nopromisc ] &#125;</span><br></pre></td></tr></table></figure><p>通常，单独使用 macvlan 毫无意义，一般都是结合 VM 和容器来构建网络。下面我们就简单使用 namespace 来看看 Linux 是怎么使用 macvlan 的。</p><p>实验拓扑如下：</p><p><img src="/images/virt/macvlan.png" alt="macvlan.png"></p><p>在我的系统中，以接口 <code>enp0s8</code> 为例创建两个 macvlan 子接口（使用 bridge 模式），配置 IP 并将其挂到两个 namespace 中，测试连通性。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建两个 macvlan 子接口</span></span><br><span class="line">ip link add link enp0s8 dev mac1 <span class="built_in">type</span> macvlan mode bridge</span><br><span class="line">ip link add link enp0s8 dev mac2 <span class="built_in">type</span> macvlan mode bridge</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建两个 namespace</span></span><br><span class="line">ip netns add ns1</span><br><span class="line">ip netns add ns2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将两个子接口分别挂到两个 namespace 中</span></span><br><span class="line">ip link <span class="built_in">set</span> mac1 netns ns1</span><br><span class="line">ip link <span class="built_in">set</span> mac2 netns ns2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 IP 并启用</span></span><br><span class="line">ip netns <span class="built_in">exec</span> ns1 ip a a 192.168.56.122/24 dev mac1</span><br><span class="line">ip netns <span class="built_in">exec</span> ns1 ip l s mac1 up</span><br><span class="line"></span><br><span class="line">ip netns <span class="built_in">exec</span> ns1 ip a a 192.168.56.123/24 dev mac2</span><br><span class="line">ip netns <span class="built_in">exec</span> ns2 ip l s mac2 up</span><br></pre></td></tr></table></figure><p>注：<code>enp0s8</code> 的 IP 是 <code>192.168.56.110/24</code>，配置的子接口 IP 也必须是同一网段的。</p><p>完了两个子接口 ping 一下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~<span class="comment"># ip netns exec ns1 ip a show mac1</span></span><br><span class="line">9: mac1@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/ether 2e:6e:d9:08:c5:05 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 192.168.56.122/24 scope global mac1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::2c6e:d9ff:fe08:c505/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">root@ubuntu:~<span class="comment"># ip netns exec ns1 ping 192.168.56.123</span></span><br><span class="line">PING 192.168.56.123 (192.168.56.123) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.56.123: icmp_seq=1 ttl=64 time=0.052 ms</span><br><span class="line">64 bytes from 192.168.56.123: icmp_seq=2 ttl=64 time=0.028 ms</span><br><span class="line">^C</span><br><span class="line">--- 192.168.56.123 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 1000ms</span><br><span class="line">rtt min/avg/max/mdev = 0.028/0.040/0.052/0.012 ms</span><br></pre></td></tr></table></figure><p>可以看到，能够 ping 通，如果把上面的 mode 换成其他模式就行不通了，这个就留给大家去实验了（默认是 vepa 模式）。</p><p>另外，在 docker 中，macvlan 是一种较为重要的跨主机网络模型，这块的内容就留作下篇文章再做讲解了。</p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可免费领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;01-macvlan-简介&quot;&gt;&lt;a href=&quot;#01-macvlan-简介&quot; class=&quot;headerlink&quot; title=&quot;01 macvlan 简介&quot;&gt;&lt;/a&gt;01 macvlan 简介&lt;/h2&gt;&lt;p&gt;前面的文章讲过了几种 Linux 虚拟网络设备：tap/tun、veth-pair、bridge，它们本质上是 Linux 系统 提供的网络虚拟化解决方案，今天要讲的 macvlan 也是其中的一种，准确说这是一种网卡虚拟化的解决方案。因为 macvlan 这种技术能将 &lt;strong&gt;一块物理网卡虚拟成多块虚拟网卡&lt;/strong&gt; ，相当于物理网卡施展了 多重影分身之术 ，由一个变多个。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/virt/macvlanmulti.jpeg&quot; alt=&quot;macvlanmulti&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="macvlan" scheme="https://ctimbai.github.io/tags/macvlan/"/>
    
  </entry>
  
  <entry>
    <title>一文带你全面了解虚拟机的四种网络模型</title>
    <link href="https://ctimbai.github.io/2019/03/25/tech/%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%9B%9B%E7%A7%8D%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"/>
    <id>https://ctimbai.github.io/2019/03/25/tech/虚拟机的四种网络模型/</id>
    <published>2019-03-25T05:16:14.000Z</published>
    <updated>2019-04-17T16:28:11.146Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><h2 id="01-从物理网络到虚拟网络"><a href="#01-从物理网络到虚拟网络" class="headerlink" title="01 从物理网络到虚拟网络"></a>01 从物理网络到虚拟网络</h2><p>著名的「六度分隔定理」说到，世界上任何两个互不相识的人，只需要最多六个人就能够建立起联系。这个定理成立的前提就是依托于庞大的网络结构。</p><p>在虚拟化技术没出现之前，构成网络的元素都是实体的物理设备，比如交换机、路由器、网线等等，人们想要构建一个小型的局域网自己玩玩，都要买各种设备，成本高还不灵活。虚拟化技术普及之后，云计算开始大行其道，我们在自己的单机上就可以建各种虚拟机，想怎么玩就怎么玩。</p><a id="more"></a><p>随之而来的就是网络变得更复杂了，由以前看得见摸得着的物理网络一下变成玄乎的虚拟网络了，好不容易建了几台虚拟机，发现网络不通，或者网络通了，但并不知道是怎么通的，这难言的苦水哽在喉咙实在令人不适。</p><p>这篇文章就来说说虚拟机世界里的几种网络模型，我们主要以 <code>VirtualBox</code> 和 <code>VMware Workstation</code> 这两款目前最主流的桌面虚拟化软件作为例子。</p><p>总的来说，目前有四种常见的网络模型：</p><ul><li>桥接（Bridge Adapter）</li><li>NAT</li><li>主机（Host-only Adapter）</li><li>内部网络（Internal）</li></ul><p>这也是 <code>VirtualBox</code> 支持的四种模型，对于 <code>VMware</code>，则只有前三种。</p><p>下图显示了 <code>VirtualBox</code> 支持的几种网络模型：</p><p><img src="/images/virt/virtualboxnet.png" alt="virtualboxnet"></p><h2 id="02-桥接（Bridge-Adapter）"><a href="#02-桥接（Bridge-Adapter）" class="headerlink" title="02 桥接（Bridge Adapter）"></a>02 桥接（Bridge Adapter）</h2><p>虚拟机桥接网络模型就是使用虚拟交换机（Linux Bridge），将虚拟机和物理机连接起来，它们处于同一个网段，IP 地址是一样的。如下图所示：</p><p><img src="/images/virt/bridgenet.png" alt=""></p><p>在这种网络模型下，虚拟机和物理机都处在一个二层网络里面，所以有：</p><ul><li>虚拟机之间彼此互通</li><li>虚拟机与主机彼此可以互通</li><li>只要物理机可以上网，那么虚拟机也可以。我们来验证下：</li></ul><p><img src="/images/virt/bridgetointernet.jpeg" alt="bridgetointernet"></p><p>桥接网络的好处是简单方便，但也有一个很明显的问题，就是一旦虚拟机太多，广播就会很严重。所以，桥接网络一般也只适用于桌面虚拟机或者小规模网络这种简单的形式。</p><h2 id="03-NAT"><a href="#03-NAT" class="headerlink" title="03 NAT"></a>03 NAT</h2><p>另一种模型是 NAT，即网络地址转换（Network Address Translatation）。这种模型严格来讲，又可以分为 <code>NAT</code> 和 <code>NAT 网络</code>两种，我们看上面的图 1 也可以看到。</p><p>根据 NAT 的原理，虚拟机所在的网络和物理机所在的网络不在同一个网段，虚拟机要访问物理所在网络必须经过一个地址转换的过程，也就是说在虚拟机网络内部需要内置一个虚拟的 NAT 设备来做这件事。</p><p>但其中 <code>NAT</code> 和 <code>NAT 网络</code> 两者还有些许的不同：</p><ul><li><code>NAT</code>：主机上的虚拟机之间是互相隔离的，彼此不能通信（它们有独立的网络栈，独立的虚拟 NAT 设备）</li><li><code>NAT 网络</code>：虚拟机之间共享虚拟 NAT 设备，彼此互通。</li></ul><p>如下图，展示了两者细微的差别：</p><p><img src="/images/virt/natnet.jpeg" alt="natnet"></p><p>PS：NAT 网络模式中一般还会内置一个虚拟的 DHCP 服务器来进行 IP 地址的管理。</p><p>下面我们通过实验来验证一下两种模式的区别，首先是 <code>NAT</code> 模式：</p><p>访问外网没问题：</p><p><img src="/images/virt/nattointernet.png" alt="nattointernet"></p><p>访问其他虚拟机：</p><p><img src="/images/virt/nattovm.png" alt="nattovm"></p><p>可以看到，两个虚拟机由于有隔离的网络栈，所以它们的 IP 地址并不在一个网段，所以 ping 不通。</p><p>再来看 <code>NAT 网络</code>，访问外网同样没问题，我们来看下 VM 之间的互通：</p><p><img src="/images/virt/natnettovm.jpeg" alt="natnettovm"></p><p>可以看到，差别体现出来了，<code>NAT 网络</code> 虚拟机之间共享网络栈，它们的 IP 地址处于同一个网段，所以彼此是互通的。</p><p>总结一下，以上两种 NAT 模式，如果不做其他配置，那么有：</p><ul><li>虚拟机可以访问主机，反之不行</li><li>如果主机可以上外网，那么虚拟机也可以</li><li>对于 <code>NAT</code>，同主机上的虚拟机之间不能互通</li><li>对于 <code>NAT 网络</code>，虚拟机之间可以互通</li></ul><p>PS：如果做了 <strong>端口映射</strong> 配置，那么主机也可以访问虚拟机。</p><h2 id="04-主机网络（Host-only-Adapter）"><a href="#04-主机网络（Host-only-Adapter）" class="headerlink" title="04 主机网络（Host-only Adapter）"></a>04 主机网络（Host-only Adapter）</h2><p>主机网络顾名思义，就是只限于主机内部访问的网络，虚拟机之间彼此互通，虚拟机与主机之间彼此互通。但是默认情况下虚拟机不能访问外网（注意：这里说的是默认情况下，如果稍作配置，也是可以的）。</p><p>主机网络看似简单，其实它的网络模型是相对比较复杂的，可以说前面几种模式实现的功能，在这种模式下，都可以通过虚拟机和网卡的配置来实现，这得益于它特殊的网络模型。</p><p>主机网络模型会在主机中模拟出一块虚拟网卡供虚拟机使用，所有虚拟机都连接到这块网卡上，这块网卡默认会使用网段 <code>192.168.56.x</code>（在主机的网络配置界面可以看到这块网卡），如下是基本的拓扑图示：</p><p><img src="/images/virt/host-onlynet.png" alt="host-onlynet"></p><p>默认情况下，虚拟机之间可以互通，虚拟机只能和主机上的虚拟网卡互通，不能和不同网段的网卡互通，更不能访问外网，如果想做到这样，那么需要如图中 <strong>红虚线</strong> 所示，将物理网卡和虚拟网卡桥接或共享。在主机上做如下设置即可：</p><p><img src="/images/virt/hostonlyshare.png" alt="hostonlyshare"></p><p>通过以上配置，我们来验证一下，虚拟机可以访问主机物理网卡和外网了：</p><p><img src="/images/virt/hostonlytointernet.jpeg" alt="hostonlytointernet"></p><h2 id="05-内部网络（internal）"><a href="#05-内部网络（internal）" class="headerlink" title="05 内部网络（internal）"></a>05 内部网络（internal）</h2><p>最后一种网络模型是内部网络，这种模型是相对最简单的一种，虚拟机与外部环境完全断开，只允许虚拟机之间互相访问，这种模型一般不怎么用，所以在 <code>VMware</code> 虚拟机中是没有这种网络模式的。这里我们就不多说了。</p><h2 id="06-总结"><a href="#06-总结" class="headerlink" title="06 总结"></a>06 总结</h2><p>虚拟机的四种网络模型：桥接、NAT、主机和内网模型。</p><p>下面以一张表来描述它们之间的通信行为：</p><table><thead><tr><th style="text-align:center">Model</th><th style="text-align:center">VM -&gt; host</th><th style="text-align:center">host -&gt; VM</th><th style="text-align:center">VM <-> VM</-></th><th style="text-align:center">VM -&gt; Internet</th><th style="text-align:center">Internet -&gt; VM</th></tr></thead><tbody><tr><td style="text-align:center">Bridged</td><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td></tr><tr><td style="text-align:center">NAT</td><td style="text-align:center">+</td><td style="text-align:center">Port Forwarding</td><td style="text-align:center">-</td><td style="text-align:center">+</td><td style="text-align:center">Port Forwarding</td></tr><tr><td style="text-align:center">NAT Network</td><td style="text-align:center">+</td><td style="text-align:center">Port Forwarding</td><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">Port Forwarding</td></tr><tr><td style="text-align:center">Host-only</td><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">Internal</td><td style="text-align:center">-</td><td style="text-align:center">-</td><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr></tbody></table><p><strong>参考：</strong> </p><p><a href="https://technology.amis.nl/2018/07/27/virtualbox-networking-explained/#prettyPhoto" target="_blank" rel="noopener">https://technology.amis.nl/2018/07/27/virtualbox-networking-explained/#prettyPhoto</a></p><p><a href="https://blog.csdn.net/niqinwen/article/details/11761487" target="_blank" rel="noopener">https://blog.csdn.net/niqinwen/article/details/11761487</a></p><p><a href="https://www.jianshu.com/p/5b8da7a1ad63" target="_blank" rel="noopener">https://www.jianshu.com/p/5b8da7a1ad63</a></p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可免费领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;01-从物理网络到虚拟网络&quot;&gt;&lt;a href=&quot;#01-从物理网络到虚拟网络&quot; class=&quot;headerlink&quot; title=&quot;01 从物理网络到虚拟网络&quot;&gt;&lt;/a&gt;01 从物理网络到虚拟网络&lt;/h2&gt;&lt;p&gt;著名的「六度分隔定理」说到，世界上任何两个互不相识的人，只需要最多六个人就能够建立起联系。这个定理成立的前提就是依托于庞大的网络结构。&lt;/p&gt;
&lt;p&gt;在虚拟化技术没出现之前，构成网络的元素都是实体的物理设备，比如交换机、路由器、网线等等，人们想要构建一个小型的局域网自己玩玩，都要买各种设备，成本高还不灵活。虚拟化技术普及之后，云计算开始大行其道，我们在自己的单机上就可以建各种虚拟机，想怎么玩就怎么玩。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Bridge" scheme="https://ctimbai.github.io/tags/Bridge/"/>
    
      <category term="NAT" scheme="https://ctimbai.github.io/tags/NAT/"/>
    
  </entry>
  
  <entry>
    <title>Linux云网络基础之 IP 隧道详解</title>
    <link href="https://ctimbai.github.io/2019/03/18/tech/ip%E9%9A%A7%E9%81%93/"/>
    <id>https://ctimbai.github.io/2019/03/18/tech/ip隧道/</id>
    <published>2019-03-18T05:16:14.000Z</published>
    <updated>2019-04-17T16:28:04.651Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>通过之前的文章<a href="http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;mid=2247484961&amp;idx=1&amp;sn=f26d7994f57abbf5de2007a2f451d9f5&amp;chksm=ea743299dd03bb8f6ac063c1cb00d5a592094c7778ab0a5baf37b7469fa3eb018101ef34551f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">tap/tun 详解</a>，我们知道 tun 是一个网络层的设备，也被叫做点对点设备，之所以叫这个名字，是因为 tun 常常被用来做隧道通信（tunnel）。</p><a id="more"></a><h2 id="IP-隧道"><a href="#IP-隧道" class="headerlink" title="IP 隧道"></a>IP 隧道</h2><p>Linux 原生支持多种三层隧道，其底层实现原理都是基于 tun 设备。我们可以通过命令 <code>ip tunnel help</code> 查看 IP 隧道的相关操作。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># ip tunnel help</span></span><br><span class="line">Usage: ip tunnel &#123; add | change | del | show | prl | 6rd &#125; [ NAME ]</span><br><span class="line">          [ mode &#123; ipip | gre | sit | isatap | vti &#125; ] [ remote ADDR ] [ <span class="built_in">local</span> ADDR ]</span><br><span class="line">          [ [i|o]seq ] [ [i|o]key KEY ] [ [i|o]csum ]</span><br><span class="line">          [ prl-default ADDR ] [ prl-nodefault ADDR ] [ prl-delete ADDR ]</span><br><span class="line">          [ 6rd-prefix ADDR ] [ 6rd-relay_prefix ADDR ] [ 6rd-reset ]</span><br><span class="line">          [ ttl TTL ] [ tos TOS ] [ [no]pmtudisc ] [ dev PHYS_DEV ]</span><br><span class="line"></span><br><span class="line">Where: NAME := STRING</span><br><span class="line">       ADDR := &#123; IP_ADDRESS | any &#125;</span><br><span class="line">       TOS  := &#123; STRING | 00..ff | inherit | inherit/STRING | inherit/00..ff &#125;</span><br><span class="line">       TTL  := &#123; 1..255 | inherit &#125;</span><br><span class="line">       KEY  := &#123; DOTTED_QUAD | NUMBER &#125;</span><br></pre></td></tr></table></figure><p>可以看到，Linux 原生一共支持 5 种 IP 隧道。</p><ul><li><code>ipip</code>：即 <code>IPv4 in IPv4</code>，在 IPv4 报文的基础上再封装一个 IPv4 报文。</li><li><code>gre</code>：即通用路由封装（<code>Generic Routing Encapsulation</code>），定义了在任意一种网络层协议上封装其他任意一种网络层协议的机制，IPv4 和 IPv6 都适用。</li><li><code>sit</code>：和 <code>ipip</code> 类似，不同的是 <code>sit</code> 是用 IPv4 报文封装 IPv6 报文，即 <code>IPv6 over IPv4</code>。</li><li><code>isatap</code>：即站内自动隧道寻址协议（<code>Intra-Site Automatic Tunnel Addressing Protocol</code>），和 <code>sit</code> 类似，也是用于 IPv6 的隧道封装。</li><li><code>vti</code>：即虚拟隧道接口（<code>Virtual Tunnel Interface</code>），是 cisco 提出的一种 <code>IPsec</code> 隧道技术。</li></ul><h2 id="实践-IPIP-隧道"><a href="#实践-IPIP-隧道" class="headerlink" title="实践 IPIP 隧道"></a>实践 IPIP 隧道</h2><p>我们下面以 <code>ipip</code> 作为例子，来实践下 Linux 的隧道通信。本文以前文的 Linux 路由机制作为基础，不清楚 Linux 路由的可以先翻看下那篇文章再来看。</p><p>实践之前，需要知道的是，<code>ipip</code> 需要内核模块 <code>ipip.ko</code> 的支持，通过 <code>lsmod | grep ipip</code> 查看内核是否加载，若没有则用 <code>modprobe ipip</code> 先加载，正常加载应该显示：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@by ~]<span class="comment"># modprobe ipip</span></span><br><span class="line">[root@by ~]<span class="comment"># lsmod | grep ipip</span></span><br><span class="line">ipip                   13465  0</span><br><span class="line">tunnel4                13252  1 ipip</span><br><span class="line">ip_tunnel              25163  1 ipip</span><br></pre></td></tr></table></figure><p>加载 <code>ipip</code> 模块后，就可以创建隧道了，方法是先创建一个 tun 设备，然后将该 tun 设备绑定为一个 <code>ipip</code> 隧道即可。</p><p>我们的实验拓扑如下：</p><p><img src="/images/virt/ipiptunnel.jpeg" alt="ipiptunnel.png"></p><p>首先参照路由那篇文章，保证 v1 和 v2 能够通信，这里就不再赘述了。</p><p>然后创建 tun 设备，并设置为 <code>ipip</code> 隧道。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1) 在 ns1 上创建 tun1 和 ipip tunnel</span></span><br><span class="line">ip netns <span class="built_in">exec</span> ns1 ip tunnel add tun1 mode ipip remote 10.10.20.2 <span class="built_in">local</span> 10.10.10.2</span><br><span class="line"></span><br><span class="line">ip netns <span class="built_in">exec</span> ns1 ip l s tun1 up</span><br><span class="line">ip netns <span class="built_in">exec</span> ns1 ip a a 10.10.100.10 peer 10.10.200.10 dev tun1</span><br></pre></td></tr></table></figure><p>上面的命令是在 NS1 上创建 tun 设备 tun1，并设置隧道模式为 <code>ipip</code>，然后还需要设置隧道端点，用 <code>remote</code> 和 <code>local</code> 表示，这是 <strong>隧道外层 IP</strong>，对应的还有 <strong>隧道内层 IP</strong>，用 <code>ip addr xx peer xx</code> 配置。大体的示意图如下所示。</p><p><img src="/images/virt/ipipformat.jpeg" alt="ipipformat.png"></p><p>同理，我们也在 NS2 上做如上配置。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1) 在 ns2 上创建 tun2 和 ipip tunnel</span></span><br><span class="line">ip netns <span class="built_in">exec</span> ns2 ip tunnel add tun2 mode ipip remote 10.10.10.2 <span class="built_in">local</span> 10.10.20.2</span><br><span class="line"></span><br><span class="line">ip netns <span class="built_in">exec</span> ns2 ip l s tun2 up</span><br><span class="line">ip netns <span class="built_in">exec</span> ns2 ip a a 10.10.200.10 peer 10.10.100.10 dev tun2</span><br></pre></td></tr></table></figure><p>当做完上述配置，两个 tun 设备端点就可以互通了，如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@by ~]<span class="comment"># ip netns exec ns1 ping 10.10.200.10 -c 4</span></span><br><span class="line">PING 10.10.200.10 (10.10.200.10) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.10.200.10: icmp_seq=1 ttl=64 time=0.090 ms</span><br><span class="line">64 bytes from 10.10.200.10: icmp_seq=2 ttl=64 time=0.148 ms</span><br><span class="line">64 bytes from 10.10.200.10: icmp_seq=3 ttl=64 time=0.112 ms</span><br><span class="line">64 bytes from 10.10.200.10: icmp_seq=4 ttl=64 time=0.110 ms</span><br><span class="line"></span><br><span class="line">--- 10.10.200.10 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3000ms</span><br><span class="line">rtt min/avg/max/mdev = 0.090/0.115/0.148/0.020 ms</span><br></pre></td></tr></table></figure><p>我们试着来分析下上述这个过程。</p><p>1、首先 ping 命令构建一个 ICMP 请求包，ICMP 包封装在 IP 包中，源目的 IP 地址分别为 <code>tun1(10.10.100.10)</code> 和 <code>tun2(10.10.200.10)</code> 的地址。</p><p>2、由于 tun1 和 tun2 不在同一网段，所以会查路由表，当通过 <code>ip tunnel</code> 命令建立 <code>ipip</code> 隧道之后，会自动生成一条路由，如下，表明去往目的地 <code>10.10.200.10</code> 的路由直接从 tun1 出去。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@by ~]<span class="comment"># ip netns exec ns1 route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">10.10.10.0      0.0.0.0         255.255.255.0   U     0      0        0 v1</span><br><span class="line">10.10.20.0      10.10.10.1      255.255.255.0   UG    0      0        0 v1</span><br><span class="line">10.10.200.10    0.0.0.0         255.255.255.255 UH    0      0        0 tun1</span><br></pre></td></tr></table></figure><p>3、由于配置了隧道端点，数据包出了 tun1，到达 v1，根据 <code>ipip</code> 隧道的配置，会封装上一层新的 IP 报头，源目的 IP 地址分别为 <code>v1(10.10.10.2)</code> 和 <code>v2(10.10.20.2)</code>。</p><p>4、v1 和 v2 同样不在一个网段，同样查路由表，发现去往 <code>10.10.20.0</code> 网段可以从 <code>10.10.10.1</code> 网关发出。</p><p>5、Linux 打开了 <code>ip_forward</code>，相当于一台路由器，<code>10.10.10.0</code> 和 <code>10.10.20.0</code> 是两条直连路由，所以直接查表转发，从 NS1 过渡到 NS2。</p><p>6、数据包到达 NS2 的 v2，解封装数据包，发现内层 IP 报文的目的 IP 地址是 <code>10.10.200.10</code>，这正是自己配置的 <code>ipip</code> 隧道的 tun2 地址，于是就将报文交给 tun2 设备。至此，tun1 的 ping 请求包就成功到达 tun2。</p><p>7、由于 ICMP 报文的传输特性，有去必有回，所以 NS2 上会构造 ICMP 响应包，并根据以上相同步骤封装和解封装数据包，直至到达 tun1，整个 ping 过程完成。</p><p>以上便是大体的 <code>ipip</code> 隧道通信过程，下面我们可以再抓包进一步验证。</p><p>如下是通过 wireshark 抓取的 v1 口的包：</p><p><img src="/images/virt/ipippcap.jpeg" alt="ipippcap.png"></p><p>可以看到，有两层 IP 报文头，外层使用的 <code>ipip</code> 协议构成隧道的端点，内层是正常的通信报文，封装了 ICMP 报文作为 payload。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>现在的 Linux 内核原生支持 5 种隧道协议，它们底层实现都是采用 tun 虚拟设备。</p><p>我们熟知的各种 VPN 软件，其底层实现都离不开这 5 种隧道协议。</p><p>我们可以把上面的 <code>ipip</code> 改成其他隧道模式，其他不变，同样可以完成不同隧道的实验。</p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可免费领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;通过之前的文章&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;amp;mid=2247484961&amp;amp;idx=1&amp;amp;sn=f26d7994f57abbf5de2007a2f451d9f5&amp;amp;chksm=ea743299dd03bb8f6ac063c1cb00d5a592094c7778ab0a5baf37b7469fa3eb018101ef34551f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;tap/tun 详解&lt;/a&gt;，我们知道 tun 是一个网络层的设备，也被叫做点对点设备，之所以叫这个名字，是因为 tun 常常被用来做隧道通信（tunnel）。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="tunnel" scheme="https://ctimbai.github.io/tags/tunnel/"/>
    
      <category term="ipip" scheme="https://ctimbai.github.io/tags/ipip/"/>
    
  </entry>
  
  <entry>
    <title>Linux云网络基础之 Linux 虚拟路由</title>
    <link href="https://ctimbai.github.io/2019/03/14/tech/Linux%E8%B7%AF%E7%94%B1%E5%8A%9F%E8%83%BD/"/>
    <id>https://ctimbai.github.io/2019/03/14/tech/Linux路由功能/</id>
    <published>2019-03-14T05:16:14.000Z</published>
    <updated>2019-04-17T16:27:49.634Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>之前文章有读者留言：</p><p><img src="/images/virt/vrouterqa.jpeg" alt="vrouterqa.png"></p><p>我的回答基本上是一句废话，因为只要你知道点网络的基础知识，肯定知道这种情况要走三层路由。</p><p>但知道归知道，不实践永远不知道自己是不是真的知道（有点绕），我相信那位读者也是希望我能讲讲这其中具体是怎么路由的，今天这篇文章就来说说这个。</p><a id="more"></a><h2 id="Linux-本身就是一台路由器"><a href="#Linux-本身就是一台路由器" class="headerlink" title="Linux 本身就是一台路由器"></a>Linux 本身就是一台路由器</h2><p>前面的文章我们学习了多种虚拟的网络设备，包括网卡、交换机等，也了解了怎么用工具来操作这些设备，那么，回到今天的主题，路由器有没有对应的虚拟设备，能不能也用相关工具来操作呢，这个答案如果要深究的话，也是有的，比如 OpenStack 的 DVR、一些开源的虚拟路由器实现等等。</p><p>不过我们不做那么深究的讨论，简化问题，Linux 系统实际上没有实现相关的虚拟路由器设备，自然也没有工具可以操作路由器，因为 <strong>Linux 本身就是一台路由器</strong>。</p><p>Linux 提供一个开关来操作路由功能，就是 <code>/proc/sys/net/ipv4/ip_forward</code>，默认这个开关是关的，打开只需：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure><p>但这种打开方式只是临时的，如果要一劳永逸，可以修改配置文件 <code>/etc/sysctl.conf</code>，添加或修改项 <code>net.ipv4.ip_forward</code> 为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure><p>即可。</p><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>为了降低大家实践的难度，我们就不创建虚拟机了，直接使用 namespace，一条 <code>ip</code> 命令就可以搞定所有的操作。</p><p>我们按照下面的图示进行操作（NS1 和 NS2 分布在不同网段）：</p><p><img src="/images/virt/vrouter.jpeg" alt=""></p><p>创建两个 namespace：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip netns add ns1</span><br><span class="line">ip netns add ns2</span><br></pre></td></tr></table></figure><p>创建两对 veth-pair，一端分别挂在两个 namespace 中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ip link add v1 type veth peer name v1_r</span><br><span class="line">ip link add v2 type veth peer name v2_r</span><br><span class="line"></span><br><span class="line">ip link set v1 netns ns1</span><br><span class="line">ip link set v2 netns ns2</span><br></pre></td></tr></table></figure><p>分别给两对 veth-pair 端点配上 IP 并启用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ip a a 10.10.10.1/24 dev v1_r</span><br><span class="line">ip l s v1_r up</span><br><span class="line">ip a a 10.10.20.1/24 dev v2_r</span><br><span class="line">ip l s v2_r up</span><br><span class="line"></span><br><span class="line">ip netns exec ns1 ip a a 10.10.10.2/24 dev v1</span><br><span class="line">ip netns exec ns1 ip l s v1 up</span><br><span class="line">ip netns exec ns2 ip a a 10.10.20.2/24 dev v2</span><br><span class="line">ip netns exec ns2 ip l s v2 up</span><br></pre></td></tr></table></figure><p>验证一下： v1 ping v2，结果不通。</p><p>看下 <code>ip_forward</code> 的值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@by ~]# cat /proc/sys/net/ipv4/ip_forward</span><br><span class="line">0</span><br></pre></td></tr></table></figure><p>没开路由怎么通，改为 1 再试，还是不通。</p><p>看下 ns1 的路由表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@by ~]# ip netns exec ns1 route -n</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">10.10.10.0      0.0.0.0         255.255.255.0   U     0      0        0 v1</span><br></pre></td></tr></table></figure><p>只有一条直连路由，没有去往 <code>10.10.20.0/24</code> 网段的路由，怎么通？那就给它配一条：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@by ~]# ip netns exec ns1 route add -net 10.10.20.0 netmask 255.255.255.0 gw 10.10.10.1</span><br><span class="line"></span><br><span class="line">[root@by ~]# ip netns exec ns1 route -n</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">10.10.10.0      0.0.0.0         255.255.255.0   U     0      0        0 v1</span><br><span class="line">10.10.20.0      10.10.10.1      255.255.255.0   UG    0      0        0 v1</span><br></pre></td></tr></table></figure><p>同理也给 ns2 配上去往 <code>10.10.10.0/24</code> 网段的路由。</p><p>最后再 ping，成功了！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@by ~]# ip netns exec ns1 ping 10.10.20.2</span><br><span class="line">PING 10.10.20.2 (10.10.20.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.10.20.2: icmp_seq=1 ttl=63 time=0.071 ms</span><br><span class="line">64 bytes from 10.10.20.2: icmp_seq=2 ttl=63 time=0.070 ms</span><br><span class="line">^C</span><br><span class="line">--- 10.10.20.2 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 1000ms</span><br><span class="line">rtt min/avg/max/mdev = 0.070/0.070/0.071/0.008 ms</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Linux 本身是一台路由器。</p><p>上面的实验使用 namespace 效果和使用虚拟机是一样的，关键是知道有这个功能，知道怎么用就差不多了。</p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可免费领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;之前文章有读者留言：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/virt/vrouterqa.jpeg&quot; alt=&quot;vrouterqa.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;我的回答基本上是一句废话，因为只要你知道点网络的基础知识，肯定知道这种情况要走三层路由。&lt;/p&gt;
&lt;p&gt;但知道归知道，不实践永远不知道自己是不是真的知道（有点绕），我相信那位读者也是希望我能讲讲这其中具体是怎么路由的，今天这篇文章就来说说这个。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="vrouter" scheme="https://ctimbai.github.io/tags/vrouter/"/>
    
  </entry>
  
  <entry>
    <title>Linux云网络基础之虚拟网络设备 Bridge 详解</title>
    <link href="https://ctimbai.github.io/2019/03/10/tech/bridge%E8%AF%A6%E8%A7%A3/"/>
    <id>https://ctimbai.github.io/2019/03/10/tech/bridge详解/</id>
    <published>2019-03-10T05:16:14.000Z</published>
    <updated>2019-04-17T16:29:02.752Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>前面几篇文章介绍了 tap/tun、veth-pair，今天这篇来看看 Bridge。</p><h2 id="Bridge-是什么"><a href="#Bridge-是什么" class="headerlink" title="Bridge 是什么"></a>Bridge 是什么</h2><p>同 tap/tun、veth-pair 一样，Bridge 也是一种虚拟网络设备，所以具备虚拟网络设备的所有特性，比如可以配置 IP、MAC 等。</p><p>除此之外，Bridge 还是一个交换机，具有交换机所有的功能。</p><a id="more"></a><p>对于普通的网络设备，就像一个管道，只有两端，数据从一端进，从另一端出。而 Bridge 有多个端口，数据可以从多个端口进，从多个端口出。</p><p>Bridge 的这个特性让它可以接入其他的网络设备，比如物理设备、虚拟设备、VLAN 设备等。Bridge 通常充当主设备，其他设备为从设备，这样的效果就等同于物理交换机的端口连接了一根网线。比如下面这幅图通过 Bridge 连接两个 VM 的 tap 虚拟网卡和物理网卡 eth0。</p><p><img src="/images/virt/vmbrtap.png" alt="vmbrtap"></p><h2 id="VM-同主机通信"><a href="#VM-同主机通信" class="headerlink" title="VM 同主机通信"></a>VM 同主机通信</h2><p>以这个图来简单说明下，借助 Bridge 来完成同主机两台 VM 的之间的通信流程。</p><p>首先准备一个 centos 或 ubuntu 虚拟机，然后创建一个 bridge：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip link add br0 type bridge</span><br><span class="line">ip link set br0 up</span><br></pre></td></tr></table></figure><p>然后通过 <code>virt-manager</code> 创建两个 kvm 虚拟机：kvm1 和 kvm2（前提得支持嵌套虚拟化），将它们的 vNIC 挂到 br0 上，如下图：</p><p><img src="/images/virt/kvm1br0.jpeg" alt="kvm1br0.png"></p><p>kvm 虚机会使用 tap 设备作为它的虚拟网卡，我们验证下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># ps -ef | grep kvm1</span><br><span class="line">libvirt+      3549     1  87 ?        00:22:09 qemu-system-x86_64 -enable-kvm -name kvm1 ... -netdev tap,fd=26,id=hostnet0,vhost=on,vhostfd=28 ...</span><br></pre></td></tr></table></figure><p>可以看到，其中网络部分参数，<code>-netdev tap,fd=26</code> 表示的就是连接主机上的 tap 设备。</p><p>创建的 fd=26 为读写 <code>/dev/net/tun</code> 的文件描述符。</p><p>使用 <code>lsof -p 3549</code> 验证下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># lsof -p 3549</span><br><span class="line">COMMAND    PID USER   FD      TYPE             DEVICE    SIZE/OFF     NODE NAME</span><br><span class="line">...</span><br><span class="line">qemu-system 3549  libvirt-qemu   26u      CHR             10,200         0t107    135 /dev/net/tun</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可以看到，PID 为 3549 的进程打开了文件 <code>/dev/net/tun</code>，分配的文件描述符 fd 为 26。</p><p>因此，我们可以得出以下结论：在 kvm 虚机启动时，会向内核注册 tap 虚拟网卡，同时打开设备文件 <code>/dev/net/tun</code>，拿到文件描述符 fd，然后将 fd 和 tap 关联，tap 就成了一端连接着用户空间的 qemu-kvm，一端连着主机上的 bridge 的端口，促使两者完成通信。</p><p>下面分别给两虚机配上 IP：<code>10.1.1.2/24</code> 和 <code>10.1.1.3/24</code>，ping 一下：</p><p><img src="/images/virt/kvmping.png" alt="kvmping.png"></p><p>在 bridge 上抓个包看看：</p><p><img src="/images/virt/tcpdumpbro.jpeg" alt="tcpdumpbro.png"></p><p>可以看到，br0 上抓到 ping 的 ICMP echo 包和 ARP 包。</p><h2 id="Bridge-常用使用场景"><a href="#Bridge-常用使用场景" class="headerlink" title="Bridge 常用使用场景"></a>Bridge 常用使用场景</h2><p>Bridge 设备通常就是结合 tap/tun、veth-pair 设备用于虚拟机、容器网络里面。这两种网络，在数据传输流程上还有些许不同，我们简单来看下：</p><p>首先是虚拟机网络，虚拟机一般通过 tap/tun 设备将虚拟机网卡同宿主机里的 Bridge 连接起来，完成同主机和跨主机的通信。如下图所示：</p><p><img src="/images/virt/vmnet.jpeg" alt="vmnet.png"></p><p>【图片来源于网络，侵权必删】</p><p>虚拟机发出的数据包通过 tap 设备先到达 br0，然后经过 eth0 发送到物理网络中，数据包不需要经过主机的的协议栈，效率是比较高的。</p><p>其次是容器网络（容器网络有多种引申的形式，这里我们只说 Bridge 网络），容器网络和虚拟机网络类似，不过一般是使用 veth-pair 来连接容器和主机，因为在主机看来，容器就是一个个被隔离的 namespace，用 veth-pair 更有优势。如下图所示：</p><p><img src="/images/virt/dockernet.jpeg" alt="dockernet.png"></p><p>【图片来源于网络，侵权必删】</p><p>容器的 Bridge 网络通常配置成内网形式，要出外网需要走 NAT，所以它的数据传输不像虚拟机的桥接形式可以直接跨过协议栈，而是必须经过协议栈，通过 NAT 和 ip_forward 功能从物理网卡转发出去，因此，从性能上看，Bridge 网络虚拟机要优于容器。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Linux Bridge 是虚拟交换机，功能和物理交换机一样，用于连接虚拟机和容器。</p><p>虚拟机网络和容器网络的区别。</p><p>Bridge 是偏低级的工具，更高级的工具是 Open vSwitch，这个工具后面再详说。</p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可免费领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面几篇文章介绍了 tap/tun、veth-pair，今天这篇来看看 Bridge。&lt;/p&gt;
&lt;h2 id=&quot;Bridge-是什么&quot;&gt;&lt;a href=&quot;#Bridge-是什么&quot; class=&quot;headerlink&quot; title=&quot;Bridge 是什么&quot;&gt;&lt;/a&gt;Bridge 是什么&lt;/h2&gt;&lt;p&gt;同 tap/tun、veth-pair 一样，Bridge 也是一种虚拟网络设备，所以具备虚拟网络设备的所有特性，比如可以配置 IP、MAC 等。&lt;/p&gt;
&lt;p&gt;除此之外，Bridge 还是一个交换机，具有交换机所有的功能。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Bridge" scheme="https://ctimbai.github.io/tags/Bridge/"/>
    
  </entry>
  
  <entry>
    <title>一文总结虚拟网络设备 eth, tap/tun, veth-pair</title>
    <link href="https://ctimbai.github.io/2019/03/08/tech/eth-taptun-vethpair%E6%80%BB%E7%BB%93/"/>
    <id>https://ctimbai.github.io/2019/03/08/tech/eth-taptun-vethpair总结/</id>
    <published>2019-03-08T05:16:14.000Z</published>
    <updated>2019-04-17T16:28:53.057Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><blockquote><p>本文翻译自：<a href="http://t.cn/EIdjMTc" target="_blank" rel="noopener">http://t.cn/EIdjMTc</a></p></blockquote><p>Linux 虚拟网络的背后都是由一个个的虚拟设备构成的。虚拟化技术没出现之前，计算机网络系统都只包含物理的网卡设备，通过网卡适配器，线缆介质，连接外部网络，构成庞大的 Internet。</p><p><img src="/images/net/virtual-device-physical-2.png" alt="virtual-device-physical-2.png"></p><a id="more"></a><p>然而，随着虚拟化技术的出现，网络也随之被虚拟化，相较于单一的物理网络，虚拟网络变得非常复杂，在一个主机系统里面，需要实现诸如交换、路由、隧道、隔离、聚合等多种网络功能。</p><p>而实现这些功能的基本元素就是虚拟的网络设备，比如 tap、tun 和 veth-pair。</p><h2 id="tap-tun"><a href="#tap-tun" class="headerlink" title="tap/tun"></a>tap/tun</h2><p>tap/tun 提供了一台主机内用户空间的数据传输机制。它虚拟了一套网络接口，这套接口和物理的接口无任何区别，可以配置 IP，可以路由流量，不同的是，它的流量只在主机内流通。</p><p>tap/tun 有些许的不同，tun 只操作三层的 IP 包，而 tap 操作二层的以太网帧。</p><p><img src="/images/net/virtual-device-tuntap-4.png" alt="virtual-device-tuntap-4.png"></p><h2 id="veth-pair"><a href="#veth-pair" class="headerlink" title="veth-pair"></a>veth-pair</h2><p>veth-pair 是成对出现的一种虚拟网络设备，一端连接着协议栈，一端连接着彼此，数据从一端出，从另一端进。</p><p>它的这个特性常常用来连接不同的虚拟网络组件，构建大规模的虚拟网络拓扑，比如连接 Linux Bridge、OVS、LXC 容器等。</p><p>一个很常见的案例就是它被用于 OpenStack Neutron，构建非常复杂的网络形态。</p><p><img src="/images/net/virtual-device-veth-1.png" alt="virtual-device-veth-1.png"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后，总结一下，我们提到几种网络设备，eth0、tap、tun、veth-pair，这些都构成了如今云网络必不可少的元素。</p><p><img src="/images/net/virtual-devices-all-4.png" alt="virtual-devices-all-4.png"></p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可免费领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;本文翻译自：&lt;a href=&quot;http://t.cn/EIdjMTc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://t.cn/EIdjMTc&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Linux 虚拟网络的背后都是由一个个的虚拟设备构成的。虚拟化技术没出现之前，计算机网络系统都只包含物理的网卡设备，通过网卡适配器，线缆介质，连接外部网络，构成庞大的 Internet。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/net/virtual-device-physical-2.png&quot; alt=&quot;virtual-device-physical-2.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="tap" scheme="https://ctimbai.github.io/tags/tap/"/>
    
      <category term="tun" scheme="https://ctimbai.github.io/tags/tun/"/>
    
      <category term="veth-pair" scheme="https://ctimbai.github.io/tags/veth-pair/"/>
    
  </entry>
  
  <entry>
    <title>Linux云网络基础之虚拟网络设备 veth-pair 详解</title>
    <link href="https://ctimbai.github.io/2019/03/03/tech/veth-pair%E8%AF%A6%E8%A7%A3/"/>
    <id>https://ctimbai.github.io/2019/03/03/tech/veth-pair详解/</id>
    <published>2019-03-03T05:16:14.000Z</published>
    <updated>2019-04-19T05:23:25.682Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>前面这篇文章介绍了 tap/tun 设备之后，大家应该对虚拟网络设备有了一定的了解，本文来看另外一种虚拟网络设备 veth-pair。</p><h2 id="01-veth-pair-是什么"><a href="#01-veth-pair-是什么" class="headerlink" title="01 veth-pair 是什么"></a>01 veth-pair 是什么</h2><p>顾名思义，veth-pair 就是一对的虚拟设备接口，和 tap/tun 设备不同的是，它都是成对出现的。一端连着协议栈，一端彼此相连着。如下图所示：</p><p><img src="/images/net/veth.png" alt="veth"></p><a id="more"></a><p>正因为有这个特性，它常常充当着一个桥梁，连接着各种虚拟网络设备，典型的例子像“两个 namespace 之间的连接”，“Bridge、OVS 之间的连接”，“Docker 容器之间的连接” 等等，以此构建出非常复杂的虚拟网络结构，比如 OpenStack Neutron。</p><h2 id="02-veth-pair-的连通性"><a href="#02-veth-pair-的连通性" class="headerlink" title="02 veth-pair 的连通性"></a>02 veth-pair 的连通性</h2><p>我们给上图中的 veth0 和 veth1 分别配上 IP：10.1.1.2 和 10.1.1.3，然后从 veth0 ping 一下 veth1。理论上它们处于同网段，是能 ping 通的，但结果却是 ping 不通。</p><p>抓个包看看，<code>tcpdump -nnt -i veth0</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~# tcpdump -nnt -i veth0</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on veth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">ARP, Request who-has 10.1.1.3 tell 10.1.1.2, length 28</span><br><span class="line">ARP, Request who-has 10.1.1.3 tell 10.1.1.2, length 28</span><br></pre></td></tr></table></figure><p>可以看到，由于 veth0 和 veth1 处于同一个网段，且是第一次连接，所以会事先发 ARP 包，但 veth1 并没有响应 ARP 包。</p><p>经查阅，这是由于我使用的 Ubuntu 系统内核中一些 ARP 相关的默认配置限制所导致的，需要修改一下配置项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt; /proc/sys/net/ipv4/conf/veth1/accept_local</span><br><span class="line">echo 1 &gt; /proc/sys/net/ipv4/conf/veth0/accept_local</span><br><span class="line">echo 0 &gt; /proc/sys/net/ipv4/conf/all/rp_filter</span><br><span class="line">echo 0 &gt; /proc/sys/net/ipv4/conf/veth0/rp_filter</span><br><span class="line">echo 0 &gt; /proc/sys/net/ipv4/conf/veth1/rp_filter</span><br></pre></td></tr></table></figure><p>完了再 ping 就行了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~# ping -I veth0 10.1.1.3 -c 2</span><br><span class="line">PING 10.1.1.3 (10.1.1.3) from 10.1.1.2 veth0: 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.047 ms</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.064 ms</span><br><span class="line"></span><br><span class="line">--- 10.1.1.3 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 3008ms</span><br><span class="line">rtt min/avg/max/mdev = 0.047/0.072/0.113/0.025 ms</span><br></pre></td></tr></table></figure><p>我们对这个通信过程比较感兴趣，可以抓包看看。</p><p>对于 veth0 口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~# tcpdump -nnt -i veth0</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on veth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">ARP, Request who-has 10.1.1.3 tell 10.1.1.2, length 28</span><br><span class="line">ARP, Reply 10.1.1.3 is-at 5a:07:76:8e:fb:cd, length 28</span><br><span class="line">IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 1, length 64</span><br><span class="line">IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 2, length 64</span><br><span class="line">IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 3, length 64</span><br><span class="line">IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2244, seq 1, length 64</span><br></pre></td></tr></table></figure><p>对于 veth1 口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~# tcpdump -nnt -i veth1</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">ARP, Request who-has 10.1.1.3 tell 10.1.1.2, length 28</span><br><span class="line">ARP, Reply 10.1.1.3 is-at 5a:07:76:8e:fb:cd, length 28</span><br><span class="line">IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 1, length 64</span><br><span class="line">IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 2, length 64</span><br><span class="line">IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2189, seq 3, length 64</span><br><span class="line">IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 2244, seq 1, length 64</span><br></pre></td></tr></table></figure><p>奇怪，我们并没有看到 ICMP 的 <code>echo reply</code> 包，那它是怎么 ping 通的？</p><p>其实这里 <code>echo reply</code> 走的是 localback 口，不信抓个包看看：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~# tcpdump -nnt -i lo</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on lo, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 2244, seq 1, length 64</span><br><span class="line">IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 2244, seq 2, length 64</span><br><span class="line">IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 2244, seq 3, length 64</span><br><span class="line">IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 2244, seq 4, length 64</span><br></pre></td></tr></table></figure><p>为什么？</p><p>我们看下整个通信流程就明白了。</p><ol><li>首先 ping 程序构造 ICMP <code>echo request</code>，通过 socket 发给协议栈。</li><li>由于 ping 指定了走 veth0 口，如果是第一次，则需要发 ARP 请求，否则协议栈直接将数据包交给 veth0。</li><li>由于 veth0 连着 veth1，所以 ICMP request 直接发给 veth1。</li><li>veth1 收到请求后，交给另一端的协议栈。</li><li>协议栈看本地有 10.1.1.3 这个 IP，于是构造 ICMP reply 包，查看路由表，发现回给 10.1.1.0 网段的数据包应该走 localback 口，于是将 reply 包交给 lo 口（会优先查看路由表的 0 号表，<code>ip route show table 0</code> 查看）。</li><li>lo 收到协议栈的 reply 包后，啥都没干，转手又回给协议栈。</li><li>协议栈收到 reply 包之后，发现有 socket 在等待包，于是将包给 socket。</li><li>等待在用户态的 ping 程序发现 socket 返回，于是就收到 ICMP 的 reply 包。</li></ol><p>整个过程如下图所示：</p><p><img src="/images/virt/pingveth.jpeg" alt="pingveth"></p><h2 id="03-两个-namespace-之间的连通性"><a href="#03-两个-namespace-之间的连通性" class="headerlink" title="03 两个 namespace 之间的连通性"></a>03 两个 namespace 之间的连通性</h2><p>namespace 是 Linux 2.6.x 内核版本之后支持的特性，主要用于资源的隔离。有了 namespace，一个 Linux 系统就可以抽象出多个网络子系统，各子系统间都有自己的网络设备，协议栈等，彼此之间互不影响。</p><p>如果各个 namespace 之间需要通信，怎么办呢，答案就是用 veth-pair 来做桥梁。</p><p>根据连接的方式和规模，可以分为“直接相连”，“通过 Bridge 相连” 和 “通过 OVS 相连”。</p><h3 id="3-1-直接相连"><a href="#3-1-直接相连" class="headerlink" title="3.1 直接相连"></a>3.1 直接相连</h3><p>直接相连是最简单的方式，如下图，一对 veth-pair 直接将两个 namespace 连接在一起。</p><p><img src="/images/virt/linuxswitch-veth.png" alt="linuxswitch-veth"></p><p>给 veth-pair 配置 IP，测试连通性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 创建 namespace</span><br><span class="line">ip netns a ns1</span><br><span class="line">ip netns a ns2</span><br><span class="line"></span><br><span class="line"># 创建一对 veth-pair veth0 veth1</span><br><span class="line">ip l a veth0 type veth peer name veth1</span><br><span class="line"></span><br><span class="line"># 将 veth0 veth1 分别加入两个 ns</span><br><span class="line">ip l s veth0 netns ns1</span><br><span class="line">ip l s veth1 netns ns2</span><br><span class="line"></span><br><span class="line"># 给两个 veth0 veth1 配上 IP 并启用</span><br><span class="line">ip netns exec ns1 ip a a 10.1.1.2/24 dev veth0</span><br><span class="line">ip netns exec ns1 ip l s veth0 up</span><br><span class="line">ip netns exec ns2 ip a a 10.1.1.3/24 dev veth1</span><br><span class="line">ip netns exec ns2 ip l s veth1 up</span><br><span class="line"></span><br><span class="line"># 从 veth0 ping veth1</span><br><span class="line">[root@localhost ~]# ip netns exec ns1 ping 10.1.1.3</span><br><span class="line">PING 10.1.1.3 (10.1.1.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.073 ms</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.068 ms</span><br><span class="line"></span><br><span class="line">--- 10.1.1.3 ping statistics ---</span><br><span class="line">15 packets transmitted, 15 received, 0% packet loss, time 14000ms</span><br><span class="line">rtt min/avg/max/mdev = 0.068/0.084/0.201/0.032 ms</span><br></pre></td></tr></table></figure><h3 id="3-2-通过-Bridge-相连"><a href="#3-2-通过-Bridge-相连" class="headerlink" title="3.2 通过 Bridge 相连"></a>3.2 通过 Bridge 相连</h3><p>Linux Bridge 相当于一台交换机，可以中转两个 namespace 的流量，我们看看 veth-pair 在其中扮演什么角色。</p><p>如下图，两对 veth-pair 分别将两个 namespace 连到 Bridge 上。</p><p><img src="/images/virt/linuxswitch-ovs-veth.png" alt="linuxswitch-ovs-veth"></p><p>同样给 veth-pair 配置 IP，测试其连通性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># 首先创建 bridge br0</span><br><span class="line">ip l a br0 type bridge</span><br><span class="line">ip l s br0 up </span><br><span class="line"></span><br><span class="line"># 然后创建两对 veth-pair</span><br><span class="line">ip l a veth0 type veth peer name br-veth0</span><br><span class="line">ip l a veth1 type veth peer name br-veth1</span><br><span class="line"></span><br><span class="line"># 分别将两对 veth-pair 加入两个 ns 和 br0</span><br><span class="line">ip l s veth0 netns ns1</span><br><span class="line">ip l s br-veth0 master br0</span><br><span class="line">ip l s br-veth0 up</span><br><span class="line"></span><br><span class="line">ip l s veth1 netns ns2</span><br><span class="line">ip l s br-veth1 master br0</span><br><span class="line">ip l s br-veth1 up</span><br><span class="line"></span><br><span class="line"># 给两个 ns 中的 veth 配置 IP 并启用</span><br><span class="line">ip netns exec ns1 ip a a 10.1.1.2/24 dev veth0</span><br><span class="line">ip netns exec ns1 ip l s veth0 up</span><br><span class="line"></span><br><span class="line">ip netns exec ns2 ip a a 10.1.1.3/24 dev veth1</span><br><span class="line">ip netns exec ns2 ip l s veth1 up</span><br><span class="line"></span><br><span class="line"># veth0 ping veth1</span><br><span class="line">[root@localhost ~]# ip netns exec ns1 ping 10.1.1.3</span><br><span class="line">PING 10.1.1.3 (10.1.1.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.060 ms</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.105 ms</span><br><span class="line"></span><br><span class="line">--- 10.1.1.3 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 999ms</span><br><span class="line">rtt min/avg/max/mdev = 0.060/0.082/0.105/0.024 ms</span><br></pre></td></tr></table></figure><h3 id="3-3-通过-OVS-相连"><a href="#3-3-通过-OVS-相连" class="headerlink" title="3.3 通过 OVS 相连"></a>3.3 通过 OVS 相连</h3><p>OVS 是第三方开源的 Bridge，功能比 Linux Bridge 要更强大，对于同样的实验，我们用 OVS 来看看是什么效果。</p><p>如下图所示：</p><p><img src="/images/virt/linuxswitch-ovs.png" alt="linuxswitch-ovs"></p><p>同样测试两个 namespace 之间的连通性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 用 ovs 提供的命令创建一个 ovs bridge</span><br><span class="line">ovs-vsctl add-br ovs-br</span><br><span class="line"></span><br><span class="line"># 创建两对 veth-pair</span><br><span class="line">ip l a veth0 type veth peer name ovs-veth0</span><br><span class="line">ip l a veth1 type veth peer name ovs-veth1</span><br><span class="line"></span><br><span class="line"># 将 veth-pair 两端分别加入到 ns 和 ovs bridge 中</span><br><span class="line">ip l s veth0 netns ns1</span><br><span class="line">ovs-vsctl add-port ovs-br ovs-veth0</span><br><span class="line">ip l s ovs-veth0 up</span><br><span class="line"></span><br><span class="line">ip l s veth1 netns ns2</span><br><span class="line">ovs-vsctl add-port ovs-br ovs-veth1</span><br><span class="line">ip l s ovs-veth1 up</span><br><span class="line"></span><br><span class="line"># 给 ns 中的 veth 配置 IP 并启用</span><br><span class="line">ip netns exec ns1 ip a a 10.1.1.2/24 dev veth0</span><br><span class="line">ip netns exec ns1 ip l s veth0 up</span><br><span class="line"></span><br><span class="line">ip netns exec ns2 ip a a 10.1.1.3/24 dev veth1</span><br><span class="line">ip netns exec ns2 ip l s veth1 up</span><br><span class="line"></span><br><span class="line"># veth0 ping veth1</span><br><span class="line">[root@localhost ~]# ip netns exec ns1 ping 10.1.1.3</span><br><span class="line">PING 10.1.1.3 (10.1.1.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.311 ms</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.087 ms</span><br><span class="line">^C</span><br><span class="line">--- 10.1.1.3 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 999ms</span><br><span class="line">rtt min/avg/max/mdev = 0.087/0.199/0.311/0.112 ms</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>veth-pair 在虚拟网络中充当着桥梁的角色，连接多种网络设备构成复杂的网络。</p><p>veth-pair 的三个经典实验，直接相连、通过 Bridge 相连和通过 OVS 相连。</p><p><strong>参考：</strong></p><p><a href="http://www.opencloudblog.com/?p=66" target="_blank" rel="noopener">http://www.opencloudblog.com/?p=66</a></p><p><a href="https://segmentfault.com/a/1190000009251098" target="_blank" rel="noopener">https://segmentfault.com/a/1190000009251098</a></p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可免费领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面这篇文章介绍了 tap/tun 设备之后，大家应该对虚拟网络设备有了一定的了解，本文来看另外一种虚拟网络设备 veth-pair。&lt;/p&gt;
&lt;h2 id=&quot;01-veth-pair-是什么&quot;&gt;&lt;a href=&quot;#01-veth-pair-是什么&quot; class=&quot;headerlink&quot; title=&quot;01 veth-pair 是什么&quot;&gt;&lt;/a&gt;01 veth-pair 是什么&lt;/h2&gt;&lt;p&gt;顾名思义，veth-pair 就是一对的虚拟设备接口，和 tap/tun 设备不同的是，它都是成对出现的。一端连着协议栈，一端彼此相连着。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/net/veth.png&quot; alt=&quot;veth&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="veth-pair" scheme="https://ctimbai.github.io/tags/veth-pair/"/>
    
  </entry>
  
  <entry>
    <title>如何用 tap/tun 设备编写一个 ICMP 程序</title>
    <link href="https://ctimbai.github.io/2019/03/01/tech/%E5%9F%BA%E4%BA%8Etaptun%E5%86%99%E4%B8%80%E4%B8%AAICMP%E7%A8%8B%E5%BA%8F/"/>
    <id>https://ctimbai.github.io/2019/03/01/tech/基于taptun写一个ICMP程序/</id>
    <published>2019-03-01T05:16:14.000Z</published>
    <updated>2019-04-17T16:28:29.467Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>前面两篇文章已经介绍过 tap/tun 的<a href="http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;mid=2247484961&amp;idx=1&amp;sn=f26d7994f57abbf5de2007a2f451d9f5&amp;chksm=ea743299dd03bb8f6ac063c1cb00d5a592094c7778ab0a5baf37b7469fa3eb018101ef34551f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">原理</a>和<a href="http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;mid=2247484976&amp;idx=1&amp;sn=a3c5112bea36c8a543660c7ac1497b36&amp;chksm=ea743288dd03bb9e15e7971894c80151e504ad5912d660204d6a3ea140cb3e6f55af245d50f2&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">配置工具</a>。这篇文章通过一个编程示例来深入了解 tap/tun 的程序结构。</p><a id="more"></a><h2 id="01-准备工作"><a href="#01-准备工作" class="headerlink" title="01 准备工作"></a>01 准备工作</h2><p>首先通过 <code>modinfo tun</code> 查看系统内核是否支持 tap/tun 设备驱动。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@by ~]# modinfo tun</span><br><span class="line">filename:       /lib/modules/3.10.0-862.14.4.el7.x86_64/kernel/drivers/net/tun.ko.xz</span><br><span class="line">alias:          devname:net/tun</span><br><span class="line">alias:          char-major-10-200</span><br><span class="line">license:        GPL</span><br><span class="line">author:         (C) 1999-2004 Max Krasnyansky &lt;maxk@qualcomm.com&gt;</span><br><span class="line">description:    Universal TUN/TAP device driver</span><br><span class="line">retpoline:      Y</span><br><span class="line">rhelversion:    7.5</span><br><span class="line">srcversion:     50878D5D5A0138445B25AA8</span><br><span class="line">depends:</span><br><span class="line">intree:         Y</span><br><span class="line">vermagic:       3.10.0-862.14.4.el7.x86_64 SMP mod_unload modversions</span><br><span class="line">signer:         CentOS Linux kernel signing key</span><br><span class="line">sig_key:        E4:A1:B6:8F:46:8A:CA:5C:22:84:50:53:18:FD:9D:AD:72:4B:13:03</span><br><span class="line">sig_hashalgo:   sha256</span><br></pre></td></tr></table></figure><p>在 linux 2.4 及之后的内核版本中，tun/tap 驱动是默认编译进内核中的。</p><p>如果你的系统不支持，请先选择手动编译内核或者升级内核。编译时开启下面的选项即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Device Drivers =&gt; Network device support =&gt; Universal TUN/TAP device driver support</span><br></pre></td></tr></table></figure><p>tap/tun 也支持编译成模块，如果编译成模块，需要手动加载它：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# modprobe tun</span><br><span class="line">[root@localhost ~]# lsmod | grep tun</span><br><span class="line">tun                    31665  0</span><br></pre></td></tr></table></figure><p>关于以上的详细步骤，网上有很多教程，这里就不再赘述了。</p><p><a href="https://blog.csdn.net/lishuhuakai/article/details/70305543" target="_blank" rel="noopener">https://blog.csdn.net/lishuhuakai/article/details/70305543</a></p><p>上面只是加载了 tap/tun 模块，要完成 tap/tun 的编码，还需要有设备文件，运行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mknod /dev/net/tun c 10 200 # c表示为字符设备，10和200分别是主设备号和次设备号</span><br></pre></td></tr></table></figure><p>这样在 <code>/dev/net</code> 下就创建了一个名为 tun 的文件。</p><h2 id="02-编程示例"><a href="#02-编程示例" class="headerlink" title="02 编程示例"></a>02 编程示例</h2><h3 id="2-1-启动设备"><a href="#2-1-启动设备" class="headerlink" title="2.1 启动设备"></a>2.1 启动设备</h3><p>使用 tap/tun 设备，需要先进行一些初始化工作，如下代码所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">tun_alloc</span><span class="params">(<span class="keyword">char</span> *dev, <span class="keyword">int</span> flags)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    assert(dev != <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ifreq</span> <span class="title">ifr</span>;</span></span><br><span class="line">    <span class="keyword">int</span> fd, err;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span> *clonedev = <span class="string">"/dev/net/tun"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ((fd = open(clonedev, O_RDWR)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> fd;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">memset</span>(&amp;ifr, <span class="number">0</span>, <span class="keyword">sizeof</span>(ifr));</span><br><span class="line">    ifr.ifr_flags = flags;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (*dev != <span class="string">'\0'</span>) &#123;</span><br><span class="line">        <span class="built_in">strncpy</span>(ifr.ifr_name, dev, IFNAMSIZ);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> ((err = ioctl(fd, TUNSETIFF, (<span class="keyword">void</span> *) &amp;ifr)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        close(fd);</span><br><span class="line">        <span class="keyword">return</span> err;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 一旦设备开启成功，系统会给设备分配一个名称，对于tun设备，一般为tunX，X为从0开始的编号；</span></span><br><span class="line">    <span class="comment">// 对于tap设备，一般为tapX</span></span><br><span class="line">    <span class="built_in">strcpy</span>(dev, ifr.ifr_name);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fd;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先打开字符设备文件 <code>/dev/net/tun</code>，然后用 <code>ioctl</code> 注册设备的工作模式，是 tap 还是 tun。这个模式由结构体 <code>struct ifreq</code> 的属性 <code>ifr_flags</code> 来定义，它有以下表示：</p><ul><li>IFF_TUN: 表示创建一个 tun 设备。</li><li>IFF_TAP: 表示创建一个 tap 设备。</li><li>IFF_NO_PI: 表示不包含包头信息，默认的，每个数据包传到用户空间时，都会包含一个附加的包头来保存包信息，这个表示不加包头。</li><li>IFF_ONE_QUEUE：表示采用单一队列模式。</li></ul><p>还是有一个属性是 <code>ifr_name</code>，表示设备的名字，它可以由用户自己指定，也可以由系统自动分配，比如 <code>tapX</code>、<code>tunX</code>，X 从 0 开始编号。</p><p><code>ioctl</code> 完了之后，文件描述符 fd 就和设备建立起了关联，之后就可以根据 fd 进行 read 和 write 操作了。</p><h3 id="2-2-写一个-ICMP-的调用函数"><a href="#2-2-写一个-ICMP-的调用函数" class="headerlink" title="2.2 写一个 ICMP 的调用函数"></a>2.2 写一个 ICMP 的调用函数</h3><p>为了测试上面的程序，我们写一个简单的 ICMP echo 程序。我们会使用 tun 设备，然后给 <code>tunX</code> 接口发送一个 ping 包，程序简单响应这个包，完成 ICMP 的 request 和 reply 的功能。</p><p>如下代码所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tun_fd, nread;</span><br><span class="line">    <span class="keyword">char</span> buffer[<span class="number">4096</span>];</span><br><span class="line">    <span class="keyword">char</span> tun_name[IFNAMSIZ];</span><br><span class="line"></span><br><span class="line">    tun_name[<span class="number">0</span>] = <span class="string">'\0'</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Flags: IFF_TUN   - TUN device (no Ethernet headers)</span></span><br><span class="line"><span class="comment">     *        IFF_TAP   - TAP device</span></span><br><span class="line"><span class="comment">     *        IFF_NO_PI - Do not provide packet information</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    tun_fd = tun_alloc(tun_name, IFF_TUN | IFF_NO_PI);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tun_fd &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">"Allocating interface"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Open tun/tap device: %s for reading...\n"</span>, tun_name);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">char</span> ip[<span class="number">4</span>];</span><br><span class="line">        <span class="comment">// 收包</span></span><br><span class="line">        nread = read(tun_fd, buffer, <span class="keyword">sizeof</span>(buffer));</span><br><span class="line">        <span class="keyword">if</span> (nread &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            perror(<span class="string">"Reading from interface"</span>);</span><br><span class="line">            close(tun_fd);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Read %d bytes from tun/tap device\n"</span>, nread);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 简单对收到的包调换一下顺序</span></span><br><span class="line">        <span class="built_in">memcpy</span>(ip, &amp;buffer[<span class="number">12</span>], <span class="number">4</span>);</span><br><span class="line">        <span class="built_in">memcpy</span>(&amp;buffer[<span class="number">12</span>], &amp;buffer[<span class="number">16</span>], <span class="number">4</span>);</span><br><span class="line">        <span class="built_in">memcpy</span>(&amp;buffer[<span class="number">16</span>], ip, <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">        buffer[<span class="number">20</span>] = <span class="number">0</span>;</span><br><span class="line">        *((<span class="keyword">unsigned</span> <span class="keyword">short</span> *)&amp;buffer[<span class="number">22</span>]) += <span class="number">8</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 发包</span></span><br><span class="line">        nread = write(tun_fd, buffer, nread);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Write %d bytes to tun/tap device, that's %s\n"</span>, nread, buffer);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面测试一下。</p><h3 id="2-3-给-tap-tun-设备配置-IP-地址"><a href="#2-3-给-tap-tun-设备配置-IP-地址" class="headerlink" title="2.3 给 tap/tun 设备配置 IP 地址"></a>2.3 给 tap/tun 设备配置 IP 地址</h3><p>编译：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost coding]# gcc -o taptun taptun.c</span><br><span class="line">[root@localhost coding]# ./taptun</span><br><span class="line">Open tun/tap device: tun0 for reading...</span><br></pre></td></tr></table></figure><p>开另一个终端，查看生成了 <code>tun0</code> 接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost coding]# ip a</span><br><span class="line">6: tun0: &lt;POINTOPOINT,MULTICAST,NOARP&gt; mtu 1500 qdisc noop state DOWN qlen 500</span><br><span class="line">    link/none</span><br></pre></td></tr></table></figure><p>给 <code>tun0</code> 接口配置 IP 并启用，比如 <code>10.1.1.2/24</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ip a a 10.1.1.2/24 dev tun0</span><br><span class="line">[root@localhost ~]# ip l s tun0 up</span><br></pre></td></tr></table></figure><p>再开一个终端，用 <code>tcpdump</code> 抓 <code>tun0</code> 的包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# tcpdump -nnt -i tun0</span><br></pre></td></tr></table></figure><p>然后在第二个终端 <code>ping</code> 一下 <code>10.1.1.0/24</code> 网段的 IP，比如 <code>10.1.1.3</code>，看到：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ping -c 4 10.1.1.3</span><br><span class="line">PING 10.1.1.3 (10.1.1.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=1 ttl=64 time=0.133 ms</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=2 ttl=64 time=0.188 ms</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=3 ttl=64 time=0.092 ms</span><br><span class="line">64 bytes from 10.1.1.3: icmp_seq=4 ttl=64 time=0.110 ms</span><br><span class="line"></span><br><span class="line">--- 10.1.1.3 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3290ms</span><br><span class="line">rtt min/avg/max/mdev = 0.092/0.130/0.188/0.038 ms</span><br></pre></td></tr></table></figure><p>由于 <code>tun0</code> 接口建好之后，会生成一条到本网段 <code>10.1.1.0/24</code> 的默认路由，根据默认路由，数据包会走 <code>tun0</code> 口，所以能 ping 通，可以用 <code>route -n</code> 查看。</p><p>再看 tcpdump 抓包终端，成功显示 ICMP 的 request 包和 reply 包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# tcpdump -nnt -i tun0</span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on tun0, link-type RAW (Raw IP), capture size 262144 bytes</span><br><span class="line">IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 3250, seq 1, length 64</span><br><span class="line">IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 3250, seq 1, length 64</span><br><span class="line">IP 10.1.1.2 &gt; 10.1.1.3: ICMP echo request, id 3250, seq 2, length 64</span><br><span class="line">IP 10.1.1.3 &gt; 10.1.1.2: ICMP echo reply, id 3250, seq 2, length 64</span><br></pre></td></tr></table></figure><p>再看程序 <code>taptun.c</code> 的输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost coding]# ./taptun</span><br><span class="line">Open tun/tap device: tun0 for reading...</span><br><span class="line">Read 48 bytes from tun/tap device</span><br><span class="line">Write 48 bytes to tun/tap device</span><br><span class="line">Read 48 bytes from tun/tap device</span><br><span class="line">Write 48 bytes to tun/tap device</span><br></pre></td></tr></table></figure><p>ok，以上便验证了程序的正确性。</p><h2 id="03-总结"><a href="#03-总结" class="headerlink" title="03 总结"></a>03 总结</h2><p>通过这个小例子，让我们知道了基于 tap/tun 编程的流程，对 tap/tun 又加深了一层理解。</p><p>使用 tap/tun 设备需要包含头文件 <code>#include &lt;linux/if_tun.h&gt;</code>，以下是完整代码。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/******************************************************************************</span></span><br><span class="line"><span class="comment"> *File Name: taptun.c</span></span><br><span class="line"><span class="comment"> *Author: 公众号: Linux云计算网络</span></span><br><span class="line"><span class="comment"> *Created Time: 2019年02月23日 星期六 21时28分24秒</span></span><br><span class="line"><span class="comment"> *****************************************************************************/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;assert.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;net/if.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/ioctl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/stat.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/if_tun.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">tun_alloc</span><span class="params">(<span class="keyword">char</span> *dev, <span class="keyword">int</span> flags)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    assert(dev != <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ifreq</span> <span class="title">ifr</span>;</span></span><br><span class="line">    <span class="keyword">int</span> fd, err;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span> *clonedev = <span class="string">"/dev/net/tun"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ((fd = open(clonedev, O_RDWR)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> fd;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">memset</span>(&amp;ifr, <span class="number">0</span>, <span class="keyword">sizeof</span>(ifr));</span><br><span class="line">    ifr.ifr_flags = flags;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (*dev != <span class="string">'\0'</span>) &#123;</span><br><span class="line">        <span class="built_in">strncpy</span>(ifr.ifr_name, dev, IFNAMSIZ);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> ((err = ioctl(fd, TUNSETIFF, (<span class="keyword">void</span> *) &amp;ifr)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        close(fd);</span><br><span class="line">        <span class="keyword">return</span> err;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 一旦设备开启成功，系统会给设备分配一个名称，对于tun设备，一般为tunX，X为从0开始的编号；</span></span><br><span class="line">    <span class="comment">// 对于tap设备，一般为tapX</span></span><br><span class="line">    <span class="built_in">strcpy</span>(dev, ifr.ifr_name);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fd;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> tun_fd, nread;</span><br><span class="line">    <span class="keyword">char</span> buffer[<span class="number">4096</span>];</span><br><span class="line">    <span class="keyword">char</span> tun_name[IFNAMSIZ];</span><br><span class="line"></span><br><span class="line">    tun_name[<span class="number">0</span>] = <span class="string">'\0'</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Flags: IFF_TUN   - TUN device (no Ethernet headers)</span></span><br><span class="line"><span class="comment">     *        IFF_TAP   - TAP device</span></span><br><span class="line"><span class="comment">     *        IFF_NO_PI - Do not provide packet information</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    tun_fd = tun_alloc(tun_name, IFF_TUN | IFF_NO_PI);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tun_fd &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">"Allocating interface"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Open tun/tap device: %s for reading...\n"</span>, tun_name);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">char</span> ip[<span class="number">4</span>];</span><br><span class="line">        <span class="comment">// 收包</span></span><br><span class="line">        nread = read(tun_fd, buffer, <span class="keyword">sizeof</span>(buffer));</span><br><span class="line">        <span class="keyword">if</span> (nread &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            perror(<span class="string">"Reading from interface"</span>);</span><br><span class="line">            close(tun_fd);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Read %d bytes from tun/tap device\n"</span>, nread);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 简单对收到的包调换一下顺序</span></span><br><span class="line">        <span class="built_in">memcpy</span>(ip, &amp;buffer[<span class="number">12</span>], <span class="number">4</span>);</span><br><span class="line">        <span class="built_in">memcpy</span>(&amp;buffer[<span class="number">12</span>], &amp;buffer[<span class="number">16</span>], <span class="number">4</span>);</span><br><span class="line">        <span class="built_in">memcpy</span>(&amp;buffer[<span class="number">16</span>], ip, <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">        buffer[<span class="number">20</span>] = <span class="number">0</span>;</span><br><span class="line">        *((<span class="keyword">unsigned</span> <span class="keyword">short</span> *)&amp;buffer[<span class="number">22</span>]) += <span class="number">8</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 发包</span></span><br><span class="line">        nread = write(tun_fd, buffer, nread);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Write %d bytes to tun/tap device, that's %s\n"</span>, nread, buffer);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可免费领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面两篇文章已经介绍过 tap/tun 的&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;amp;mid=2247484961&amp;amp;idx=1&amp;amp;sn=f26d7994f57abbf5de2007a2f451d9f5&amp;amp;chksm=ea743299dd03bb8f6ac063c1cb00d5a592094c7778ab0a5baf37b7469fa3eb018101ef34551f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原理&lt;/a&gt;和&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;amp;mid=2247484976&amp;amp;idx=1&amp;amp;sn=a3c5112bea36c8a543660c7ac1497b36&amp;amp;chksm=ea743288dd03bb9e15e7971894c80151e504ad5912d660204d6a3ea140cb3e6f55af245d50f2&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;配置工具&lt;/a&gt;。这篇文章通过一个编程示例来深入了解 tap/tun 的程序结构。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="tap" scheme="https://ctimbai.github.io/tags/tap/"/>
    
      <category term="tun" scheme="https://ctimbai.github.io/tags/tun/"/>
    
      <category term="ICMP" scheme="https://ctimbai.github.io/tags/ICMP/"/>
    
  </entry>
  
  <entry>
    <title>Linux网络命令必知必会之创建 tap/tun 设备</title>
    <link href="https://ctimbai.github.io/2019/02/28/tech/%E5%88%9B%E5%BB%BAtaptun%E8%AE%BE%E5%A4%87/"/>
    <id>https://ctimbai.github.io/2019/02/28/tech/创建taptun设备/</id>
    <published>2019-02-28T05:16:14.000Z</published>
    <updated>2019-04-17T16:28:37.658Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>在<a href="http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;mid=2247484961&amp;idx=1&amp;sn=f26d7994f57abbf5de2007a2f451d9f5&amp;chksm=ea743299dd03bb8f6ac063c1cb00d5a592094c7778ab0a5baf37b7469fa3eb018101ef34551f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">这篇文章</a>中，我们已经介绍了 tap/tun 的基本原理，本文将介绍如何使用工具 <code>tunctl</code>和 <code>ip tuntap</code> 来创建并使用 tap/tun 设备。</p><a id="more"></a><h2 id="tunctl"><a href="#tunctl" class="headerlink" title="tunctl"></a>tunctl</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>首先在 <code>centos</code> 的环境中安装 <code>tunctl</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim /etc/yum.repos.d/nux-misc.repo</span><br><span class="line"></span><br><span class="line">[nux-misc]</span><br><span class="line">name=Nux Misc</span><br><span class="line">baseurl=http://li.nux.ro/download/nux/misc/el7/x86_64/</span><br><span class="line">enabled=0</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro</span><br></pre></td></tr></table></figure><p><code>ubuntu</code> 是 <code>apt-get install uml-utilities</code>。</p><p><code>man tunctl</code> 查看 <code>tunctl</code> 手册，用法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Synopsis</span><br><span class="line">tunctl [ OPTIONS ] [ -u owner ] [-g group] [ -t device-name ]</span><br></pre></td></tr></table></figure><ul><li>-u 参数指定用户名，表明这个接口只受该用户控制，这个接口发生的事不会影响到系统的接口。</li><li>-g 指定一组用户</li><li>-t 指定要创建的 tap/tun 设备名。</li></ul><p><code>[OPTIONS]</code> 部分：</p><ul><li>-b 简单打印创建的接口名字</li><li>-n 创建 tun 设备</li><li>-p 创建 tap 设备，默认创建该设备</li><li>-f tun-clone-device 指定 tun 设备对应的文件名，默认是 <code>/dev/net/tun</code>，有些系统是 <code>/dev/misc/net/tun</code>。</li><li>-d interfacename 删除指定接口</li></ul><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p><strong>常见用法：</strong></p><p>默认创建 tap 接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tunctl</span><br></pre></td></tr></table></figure><p>以上等价于 <code>tunctl -p</code></p><p>为用户 <code>user</code> 创建一个 tap 接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># tunctl -u user</span><br></pre></td></tr></table></figure><p>创建 tun 接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tunctl -n</span><br></pre></td></tr></table></figure><p>为接口配置 IP 并启用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># ifconfig tap0 192.168.0.254 up</span><br></pre></td></tr></table></figure><p>为接口添加路由：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># route add -host 192.168.0.1 dev tap0</span><br></pre></td></tr></table></figure><p>删除接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># tunctl -d tap0</span><br></pre></td></tr></table></figure><h2 id="ip-tuntap"><a href="#ip-tuntap" class="headerlink" title="ip tuntap"></a>ip tuntap</h2><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p>命令行输入 <code>ip help</code> 查看 <code>ip</code> 命令是否支持 <code>tuntap</code> 工具，支持的话就会显示 <code>tuntap</code> 选项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ip help</span><br><span class="line">Usage: ip [ OPTIONS ] OBJECT &#123; COMMAND | help &#125;</span><br><span class="line">       ip [ -force ] -batch filename</span><br><span class="line">where  OBJECT := &#123; link | addr | addrlabel | route | rule | neigh | ntable |</span><br><span class="line">                   tunnel | tuntap | maddr | mroute | mrule | monitor | xfrm |</span><br><span class="line">                   netns | l2tp | tcp_metrics | token &#125;</span><br></pre></td></tr></table></figure><p>不支持就请升级或下载最新的 <code>iproute2</code> 工具包，或者使用上面介绍的 <code>tunctl</code> 工具。</p><h3 id="使用-1"><a href="#使用-1" class="headerlink" title="使用"></a>使用</h3><p>输入 <code>ip tuntap help</code> 查看详细使用命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ip tuntap help</span><br><span class="line">Usage: ip tuntap &#123; add | del &#125; [ dev PHYS_DEV ]</span><br><span class="line">          [ mode &#123; tun | tap &#125; ] [ user USER ] [ group GROUP ]</span><br><span class="line">          [ one_queue ] [ pi ] [ vnet_hdr ] [ multi_queue ]</span><br><span class="line"></span><br><span class="line">Where: USER  := &#123; STRING | NUMBER &#125;</span><br><span class="line">       GROUP := &#123; STRING | NUMBER &#125;</span><br></pre></td></tr></table></figure><p><strong>常见用法：</strong></p><p>创建 tap/tun 设备：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip tuntap add dev tap0 mod tap # 创建 tap </span><br><span class="line">ip tuntap add dev tun0 mod tun # 创建 tun</span><br></pre></td></tr></table></figure><p>删除 tap/tun 设备：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip tuntap del dev tap0 mod tap # 删除 tap </span><br><span class="line">ip tuntap del dev tun0 mod tun # 删除 tun</span><br></pre></td></tr></table></figure><p>PS: <code>user</code> 和 <code>group</code> 参数和 <code>tunctl</code> 的 -u、 -g 参数是一样的。</p><p>以上两个工具，我们更推荐使用 <code>ip tuntap</code>，一个是因为 <code>iproute2</code> 更全更新，已经逐步在替代老旧的一些工具，另一个是因为 <code>tunctl</code> 在某些 <code>Debian</code> 类的系统上支持不全。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>tunctl</code> 和 <code>ip tuntap</code> 的常见使用方式。</p><p>更推荐使用 <code>ip tuntap</code> 工具。</p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有大量书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;amp;mid=2247484961&amp;amp;idx=1&amp;amp;sn=f26d7994f57abbf5de2007a2f451d9f5&amp;amp;chksm=ea743299dd03bb8f6ac063c1cb00d5a592094c7778ab0a5baf37b7469fa3eb018101ef34551f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这篇文章&lt;/a&gt;中，我们已经介绍了 tap/tun 的基本原理，本文将介绍如何使用工具 &lt;code&gt;tunctl&lt;/code&gt;和 &lt;code&gt;ip tuntap&lt;/code&gt; 来创建并使用 tap/tun 设备。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="tap" scheme="https://ctimbai.github.io/tags/tap/"/>
    
      <category term="tun" scheme="https://ctimbai.github.io/tags/tun/"/>
    
  </entry>
  
  <entry>
    <title>Linux云网络基础之虚拟网络设备 tap/tun 详解</title>
    <link href="https://ctimbai.github.io/2019/02/26/tech/taptun%E8%AF%A6%E8%A7%A3/"/>
    <id>https://ctimbai.github.io/2019/02/26/tech/taptun详解/</id>
    <published>2019-02-26T05:16:14.000Z</published>
    <updated>2019-04-17T16:28:43.347Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>在云计算时代，虚拟机和容器已经成为标配。它们背后的网络管理都离不开一样东西，就是虚拟网络设备，或者叫虚拟网卡，tap/tun 就是在云计算时代非常重要的虚拟网络网卡。</p><h2 id="tap-tun-是什么"><a href="#tap-tun-是什么" class="headerlink" title="tap/tun 是什么"></a>tap/tun 是什么</h2><p>tap/tun 是 Linux 内核 2.4.x 版本之后实现的虚拟网络设备，不同于物理网卡靠硬件网路板卡实现，tap/tun 虚拟网卡完全由软件来实现，功能和硬件实现完全没有差别，它们都属于网络设备，都可以配置 IP，都归 Linux 网络设备管理模块统一管理。</p><a id="more"></a><p>作为网络设备，tap/tun 也需要配套相应的驱动程序才能工作。tap/tun 驱动程序包括两个部分，一个是字符设备驱动，一个是网卡驱动。这两部分驱动程序分工不太一样，字符驱动负责数据包在内核空间和用户空间的传送，网卡驱动负责数据包在 TCP/IP 网络协议栈上的传输和处理。</p><h2 id="用户空间与内核空间的数据传输"><a href="#用户空间与内核空间的数据传输" class="headerlink" title="用户空间与内核空间的数据传输"></a>用户空间与内核空间的数据传输</h2><p>在 Linux 中，用户空间和内核空间的数据传输有多种方式，字符设备就是其中的一种。tap/tun 通过驱动程序和一个与之关联的字符设备，来实现用户空间和内核空间的通信接口。</p><p>在 Linux 内核 2.6.x 之后的版本中，tap/tun 对应的字符设备文件分别为：</p><ul><li>tap：/dev/tap0</li><li>tun：/dev/net/tun</li></ul><p>设备文件即充当了用户空间和内核空间通信的接口。当应用程序打开设备文件时，驱动程序就会创建并注册相应的虚拟设备接口，一般以 <code>tunX</code> 或 <code>tapX</code> 命名。当应用程序关闭文件时，驱动也会自动删除 <code>tunX</code> 和 <code>tapX</code> 设备，还会删除已经建立起来的路由等信息。</p><p>tap/tun 设备文件就像一个管道，一端连接着用户空间，一端连接着内核空间。当用户程序向文件 <code>/dev/net/tun</code> 或 <code>/dev/tap0</code> 写数据时，内核就可以从对应的 <code>tunX</code> 或 <code>tapX</code> 接口读到数据，反之，内核可以通过相反的方式向用户程序发送数据。</p><p><img src="/images/virt/tapwriteread.png" alt="tapwriteread.png"></p><h2 id="tap-tun-和网络协议栈的数据传输"><a href="#tap-tun-和网络协议栈的数据传输" class="headerlink" title="tap/tun 和网络协议栈的数据传输"></a>tap/tun 和网络协议栈的数据传输</h2><p>tap/tun 通过实现相应的网卡驱动程序来和网络协议栈通信。一般的流程和物理网卡和协议栈的交互流程是一样的，不同的是物理网卡一端是连接物理网络，而 tap/tun 虚拟网卡一般连接到用户空间。</p><p>如下图的示意图，我们有两个应用程序 A、B，物理网卡 <code>eth0</code> 和虚拟网卡 <code>tun0</code> 分别配置 IP：<code>10.1.1.11</code> 和 <code>192.168.1.11</code>，程序 A 希望构造数据包发往 <code>192.168.1.0/24</code> 网段的主机 <code>192.168.1.1</code>。</p><p><img src="/images/virt/taptun.png" alt="taptun"></p><p>基于上图，我们看看数据包的流程：</p><ol><li>应用程序 A 构造数据包，目的 IP 是 <code>192.168.1.1</code>，通过 <code>socket A</code> 将这个数据包发给协议栈。</li><li>协议栈根据数据包的目的 IP 地址，匹配路由规则，发现要从 <code>tun0</code> 出去。</li><li><code>tun0</code> 发现自己的另一端被应用程序 B 打开了，于是将数据发给程序 B.</li><li>程序 B 收到数据后，做一些跟业务相关的操作，然后构造一个新的数据包，源 IP 是 <code>eth0</code> 的 IP，目的 IP 是 <code>10.1.1.0/24</code> 的网关 <code>10.1.1.1</code>，封装原来的数据的数据包，重新发给协议栈。</li><li>协议栈再根据本地路由，将这个数据包从 <code>eth0</code> 发出。</li></ol><p>后续步骤，当 <code>10.1.1.1</code> 收到数据包后，会进行解封装，读取里面的原始数据包，继而转发给本地的主机 <code>192.168.1.1</code>。当接收回包时，也遵循同样的流程。</p><p>在这个流程中，应用程序 B 的作用其实是利用 <code>tun0</code> 对数据包做了一层隧道封装。其实 <code>tun</code> 设备的最大用途就是用于隧道通信的。</p><h2 id="tap-tun-的区别"><a href="#tap-tun-的区别" class="headerlink" title="tap/tun 的区别"></a>tap/tun 的区别</h2><p>看到这里，你可能还不大明白 tap/tun 的区别。<br>tap 和 tun 虽然都是虚拟网络设备，但它们的工作层次还不太一样。</p><ul><li>tap 是一个二层设备（或者以太网设备），只能处理二层的以太网帧；</li><li>tun 是一个点对点的三层设备（或网络层设备），只能处理三层的 IP 数据包。</li></ul><h2 id="tap-tun-的应用"><a href="#tap-tun-的应用" class="headerlink" title="tap/tun 的应用"></a>tap/tun 的应用</h2><p>从上面的数据流程中可以看到，<code>tun</code> 设备充当了一层隧道，所以，tap/tun 最常见的应用也就是用于隧道通信，比如 VPN，包括 tunnel 和应用层的 IPsec 等，其中比较有名的两个开源项目是 <a href="http://openvpn.sourceforge.net" target="_blank" rel="noopener">openvpn</a> 和 <a href="http://vtun.sourceforge.net" target="_blank" rel="noopener">VTun</a>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>tun/tap 虚拟网卡，对应于物理网卡，如 eth0。</p><p>tun/tap 驱动包括字符设备驱动和网卡驱动。</p><p>tun/tap 常用于隧道通信。</p><p><strong>参考：</strong></p><p><a href="https://opengers.github.io/openstack/openstack-base-virtual-network-devices-tuntap-veth/" target="_blank" rel="noopener">https://opengers.github.io/openstack/openstack-base-virtual-network-devices-tuntap-veth/</a></p><p><a href="https://segmentfault.com/a/1190000009249039" target="_blank" rel="noopener">https://segmentfault.com/a/1190000009249039</a></p><p><a href="https://mirrors.edge.kernel.org/pub/linux/kernel/people/marcelo/linux-2.4/Documentation/networking/tuntap.txt" target="_blank" rel="noopener">https://mirrors.edge.kernel.org/pub/linux/kernel/people/marcelo/linux-2.4/Documentation/networking/tuntap.txt</a></p><p><a href="https://zh.wikipedia.org/wiki/TUN%E4%B8%8ETAP" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/TUN%E4%B8%8ETAP</a></p><p><a href="http://blog.chinaunix.net/uid-317451-id-92474.html" target="_blank" rel="noopener">http://blog.chinaunix.net/uid-317451-id-92474.html</a></p><p><a href="https://blog.csdn.net/bytxl/article/details/26586109" target="_blank" rel="noopener">https://blog.csdn.net/bytxl/article/details/26586109</a></p><p><a href="https://blog.csdn.net/u013982161/article/details/51816162" target="_blank" rel="noopener">https://blog.csdn.net/u013982161/article/details/51816162</a></p><p><a href="https://www.cnblogs.com/yml435/p/5917628.html" target="_blank" rel="noopener">https://www.cnblogs.com/yml435/p/5917628.html</a></p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有大量书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在云计算时代，虚拟机和容器已经成为标配。它们背后的网络管理都离不开一样东西，就是虚拟网络设备，或者叫虚拟网卡，tap/tun 就是在云计算时代非常重要的虚拟网络网卡。&lt;/p&gt;
&lt;h2 id=&quot;tap-tun-是什么&quot;&gt;&lt;a href=&quot;#tap-tun-是什么&quot; class=&quot;headerlink&quot; title=&quot;tap/tun 是什么&quot;&gt;&lt;/a&gt;tap/tun 是什么&lt;/h2&gt;&lt;p&gt;tap/tun 是 Linux 内核 2.4.x 版本之后实现的虚拟网络设备，不同于物理网卡靠硬件网路板卡实现，tap/tun 虚拟网卡完全由软件来实现，功能和硬件实现完全没有差别，它们都属于网络设备，都可以配置 IP，都归 Linux 网络设备管理模块统一管理。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="tap" scheme="https://ctimbai.github.io/tags/tap/"/>
    
      <category term="tun" scheme="https://ctimbai.github.io/tags/tun/"/>
    
  </entry>
  
  <entry>
    <title>一文搞懂 network namespace</title>
    <link href="https://ctimbai.github.io/2019/01/10/tech/%E6%A8%A1%E6%9D%BF/"/>
    <id>https://ctimbai.github.io/2019/01/10/tech/模板/</id>
    <published>2019-01-10T05:16:14.000Z</published>
    <updated>2019-04-17T16:23:08.944Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有 <strong>10T</strong> 书籍和视频资源，后台回复<strong>「1024」</strong>即可免费领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可免费领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有 &lt;strong&gt;10T&lt;/strong&gt; 书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong
      
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="Namespace" scheme="https://ctimbai.github.io/tags/Namespace/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>一文搞懂 network namespace</title>
    <link href="https://ctimbai.github.io/2019/01/10/tech/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82network_namespace/"/>
    <id>https://ctimbai.github.io/2019/01/10/tech/一文搞懂network_namespace/</id>
    <published>2019-01-10T05:16:14.000Z</published>
    <updated>2019-04-17T16:28:58.098Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，专注于干货分享，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>本文通过 IP 命令操作来简单介绍 network namespace 的基本概念和用法。</p><p>深入了解可以看看我之前写的两篇文章 <a href="http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;mid=2247483982&amp;idx=1&amp;sn=35e2aac1f4c164c8afa79aa91707c90d&amp;chksm=ea7436f6dd03bfe036ccc8293aaf25d0c042f21afac5277bf04a32af36643a2780c980e53d09&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Docker 基础技术之 Linux namespace 详解</a> 和 <a href="http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;mid=2247483993&amp;idx=1&amp;sn=906551e374c0d8d40db00cbde934e624&amp;chksm=ea7436e1dd03bff724d7ee03267115b2ecf54bd146fa3f826b69e918b5a2455d1562d085ab62&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">Docker 基础技术之 Linux namespace 源码分析</a>。</p><p>和 network namespace 相关的操作的子命令是 <code>ip netns</code> 。</p><a id="more"></a><h2 id="1-ip-netns-add-xx-创建一个-namespace"><a href="#1-ip-netns-add-xx-创建一个-namespace" class="headerlink" title="1. ip netns add  xx 创建一个 namespace"></a>1. ip netns add  xx 创建一个 namespace</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># ip netns add net1</span><br><span class="line"># ip netns ls</span><br><span class="line">net1</span><br></pre></td></tr></table></figure><h2 id="2-ip-netns-exec-xx-yy-在新-namespace-xx-中执行-yy-命令"><a href="#2-ip-netns-exec-xx-yy-在新-namespace-xx-中执行-yy-命令" class="headerlink" title="2. ip netns exec xx yy 在新 namespace xx 中执行 yy 命令"></a>2. ip netns exec xx yy 在新 namespace xx 中执行 yy 命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># ip netns exec net1 ip addr </span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line"># ip netns exec net1 bash // 在 net1 中打开一个shell终端</span><br><span class="line"># ip addr // 在net1中的shell终端</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line"># exit // 退出net1</span><br></pre></td></tr></table></figure><p>上面 bash 不好区分是当前是在哪个 shell，可以采用下面的方法解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># ip netns exec net1 /bin/bash --rcfile &lt;(echo &quot;PS1=\&quot;namespace net1&gt; \&quot;&quot;)</span><br><span class="line">namespace net1&gt; ping www.baidu.com</span><br></pre></td></tr></table></figure><p>每个 namespace 在创建的时候会自动创建一个回环接口 <code>lo</code> ，默认不启用，可以通过 <code>ip link set lo up</code> 启用。</p><h2 id="3-network-namespace-之间的通信"><a href="#3-network-namespace-之间的通信" class="headerlink" title="3. network namespace 之间的通信"></a>3. network namespace 之间的通信</h2><p>新创建的 namespace 默认不能和主机网络，以及其他 namespace 通信。</p><p>可以使用 Linux 提供的 <code>veth pair</code> 来完成通信。下面显示两个 namespace 之间通信的网络拓扑：</p><p><img src="/images/virt/netns.png" alt=""></p><h3 id="3-1-ip-link-add-type-veth-创建-veth-pair"><a href="#3-1-ip-link-add-type-veth-创建-veth-pair" class="headerlink" title="3.1 ip link add type veth 创建 veth pair"></a>3.1 ip link add type veth 创建 veth pair</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># ip link add type veth</span><br><span class="line"># ip link</span><br><span class="line">3: veth0@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000</span><br><span class="line">    link/ether 1a:53:39:5a:26:12 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">4: veth1@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000</span><br><span class="line">    link/ether 46:df:46:1f:bf:d6 brd ff:ff:ff:ff:ff:ff</span><br></pre></td></tr></table></figure><p>使用命令 <code>ip link add xxx type veth peer name yyy</code> 指定 veth pair 的名字。</p><h3 id="3-2-ip-link-set-xx-netns-yy-将-veth-xx-加入到-namespace-yy-中"><a href="#3-2-ip-link-set-xx-netns-yy-将-veth-xx-加入到-namespace-yy-中" class="headerlink" title="3.2 ip link set xx netns yy 将 veth xx 加入到 namespace yy 中"></a>3.2 ip link set xx netns yy 将 veth xx 加入到 namespace yy 中</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># ip link set veth0 netns net0</span><br><span class="line"># ip link set veth1 netns net1</span><br><span class="line">#</span><br><span class="line"># ip netns exec net0 ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">10: veth0@if11: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ether 1a:53:39:5a:26:12 brd ff:ff:ff:ff:ff:ff link-netnsid 1</span><br></pre></td></tr></table></figure><h3 id="3-3-给-veth-pair-配上-ip-地址"><a href="#3-3-给-veth-pair-配上-ip-地址" class="headerlink" title="3.3 给 veth pair 配上 ip 地址"></a>3.3 给 veth pair 配上 ip 地址</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># ip netns exec net0 ip link set veth0 up</span><br><span class="line"># ip netns exec net0 ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">10: veth0@if11: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state LOWERLAYERDOWN group default qlen 1000</span><br><span class="line">    link/ether 1a:53:39:5a:26:12 brd ff:ff:ff:ff:ff:ff link-netnsid 1</span><br><span class="line"># ip netns exec net0 ip addr add 10.1.1.1/24 dev veth0</span><br><span class="line"># ip netns exec net0 ip route</span><br><span class="line">10.1.1.0/24 dev veth0  proto kernel  scope link  src 10.1.1.1 linkdown</span><br><span class="line">#</span><br><span class="line"># ip netns exec net1 ip link set veth1 up</span><br><span class="line"># ip netns exec net1 ip addr add 10.1.1.2/24 dev veth1</span><br></pre></td></tr></table></figure><p>可以看到，在配完 ip 之后，还自动生成了对应的路由表信息。</p><h3 id="3-4-ping-测试两个-namespace-的连通性"><a href="#3-4-ping-测试两个-namespace-的连通性" class="headerlink" title="3.4. ping 测试两个 namespace 的连通性"></a>3.4. ping 测试两个 namespace 的连通性</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># ip netns exec net0 ping 10.1.1.2</span><br><span class="line">PING 10.1.1.2 (10.1.1.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.1.1.2: icmp_seq=1 ttl=64 time=0.069 ms</span><br><span class="line">64 bytes from 10.1.1.2: icmp_seq=2 ttl=64 time=0.054 ms</span><br><span class="line">64 bytes from 10.1.1.2: icmp_seq=3 ttl=64 time=0.053 ms</span><br><span class="line">64 bytes from 10.1.1.2: icmp_seq=4 ttl=64 time=0.053 ms</span><br></pre></td></tr></table></figure><p>Done!</p><h2 id="4-多个不同-namespace-之间的通信"><a href="#4-多个不同-namespace-之间的通信" class="headerlink" title="4. 多个不同 namespace 之间的通信"></a>4. 多个不同 namespace 之间的通信</h2><p>2 个 namespace 之间通信可以借助 <code>veth pair</code> ，多个 namespace 之间的通信则可以使用 bridge 来转接，不然每两个 namespace 都去配 <code>veth pair</code> 将会是一件麻烦的事。下面就看看如何使用 bridge 来转接。</p><p>拓扑图如下：</p><p><img src="/images/virt/bridgens.png" alt=""></p><h3 id="4-1-使用-ip-link-和-brctl-创建-bridge"><a href="#4-1-使用-ip-link-和-brctl-创建-bridge" class="headerlink" title="4.1 使用 ip link 和 brctl 创建 bridge"></a>4.1 使用 ip link 和 brctl 创建 bridge</h3><p>通常 Linux 中和 bridge 有关的操作是使用命令 <code>brctl</code> (<code>yum install -y bridge-utils</code> ) 。但为了前后照应，这里都用 ip 相关的命令来操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 建立一个 bridge</span><br><span class="line"># ip link add br0 type bridge</span><br><span class="line"># ip link set dev br0 up</span><br><span class="line">9: br0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/ether 42:55:ed:eb:a0:07 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet6 fe80::4055:edff:feeb:a007/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><h3 id="4-2-创建-veth-pair"><a href="#4-2-创建-veth-pair" class="headerlink" title="4.2 创建 veth pair"></a>4.2 创建 veth pair</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//（1）创建 3 个 veth pair</span><br><span class="line"># ip link add type veth</span><br><span class="line"># ip link add type veth</span><br><span class="line"># ip link add type veth</span><br></pre></td></tr></table></figure><h3 id="4-3-将-veth-pair-的一头挂到-namespace-中，一头挂到-bridge-上，并设-IP-地址"><a href="#4-3-将-veth-pair-的一头挂到-namespace-中，一头挂到-bridge-上，并设-IP-地址" class="headerlink" title="4.3 将 veth pair 的一头挂到 namespace 中，一头挂到 bridge 上，并设 IP 地址"></a>4.3 将 veth pair 的一头挂到 namespace 中，一头挂到 bridge 上，并设 IP 地址</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">// （1）配置第 1 个 net0</span><br><span class="line"># ip link set dev veth1 netns net0</span><br><span class="line"># ip netns exec net0 ip link set dev veth1 name eth0</span><br><span class="line"># ip netns exec net0 ip addr add 10.0.1.1/24 dev eth0</span><br><span class="line"># ip netns exec net0 ip link set dev eth0 up</span><br><span class="line">#</span><br><span class="line"># ip link set dev veth0 master br0</span><br><span class="line"># ip link set dev veth0 up</span><br><span class="line"></span><br><span class="line">// （2）配置第 2 个 net1</span><br><span class="line"># ip link set dev veth3 netns net1</span><br><span class="line"># ip netns exec net1 ip link set dev veth3 name eth0</span><br><span class="line"># ip netns exec net1 ip addr add 10.0.1.2/24 dev eth0</span><br><span class="line"># ip netns exec net1 ip link set dev eth0 up</span><br><span class="line">#</span><br><span class="line"># ip link set dev veth2 master br0</span><br><span class="line"># ip link set dev veth2 up</span><br><span class="line"></span><br><span class="line">// （3）配置第 3 个 net2</span><br><span class="line"># ip link set dev veth5 netns net2</span><br><span class="line"># ip netns exec net2 ip link set dev veth5 name eth0</span><br><span class="line"># ip netns exec net2 ip addr add 10.0.1.3/24 dev eth0</span><br><span class="line"># ip netns exec net2 ip link set dev eth0 up</span><br><span class="line"># </span><br><span class="line"># ip link set dev veth4 master br0</span><br><span class="line"># ip link set dev veth4 up</span><br></pre></td></tr></table></figure><p>这样之后，竟然通不了，经查阅 <a href="https://segmentfault.com/q/1010000010011053/a-1020000010025650" target="_blank" rel="noopener">参见</a> ，是因为</p><blockquote><p>原因是因为系统为bridge开启了iptables功能，导致所有经过br0的数据包都要受iptables里面规则的限制，而docker为了安全性，将iptables里面filter表的FORWARD链的默认策略设置成了drop，于是所有不符合docker规则的数据包都不会被forward，导致你这种情况ping不通。</p><p>解决办法有两个，二选一：</p><ol><li>关闭系统bridge的iptables功能，这样数据包转发就不受iptables影响了：echo 0 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables</li><li>为br0添加一条iptables规则，让经过br0的包能被forward：iptables -A FORWARD -i br0 -j ACCEPT</li></ol><p>第一种方法不确定会不会影响docker，建议用第二种方法。</p></blockquote><p>我采用以下方法解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -A FORWARD -i br0 -j ACCEPT</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># ip netns exec net0 ping -c 2 10.0.1.2</span><br><span class="line">PING 10.0.1.2 (10.0.1.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.0.1.2: icmp_seq=1 ttl=64 time=0.071 ms</span><br><span class="line">64 bytes from 10.0.1.2: icmp_seq=2 ttl=64 time=0.072 ms</span><br><span class="line"></span><br><span class="line">--- 10.0.1.2 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 999ms</span><br><span class="line">rtt min/avg/max/mdev = 0.071/0.071/0.072/0.008 ms</span><br><span class="line"></span><br><span class="line"># ip netns exec net0 ping -c 2 10.0.1.3</span><br><span class="line">PING 10.0.1.3 (10.0.1.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.0.1.3: icmp_seq=1 ttl=64 time=0.071 ms</span><br><span class="line">64 bytes from 10.0.1.3: icmp_seq=2 ttl=64 time=0.087 ms</span><br><span class="line"></span><br><span class="line">--- 10.0.1.3 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 1000ms</span><br><span class="line">rtt min/avg/max/mdev = 0.071/0.079/0.087/0.008 ms</span><br></pre></td></tr></table></figure><p>Done!</p><h2 id="5-Bridge-之间的同住机通信"><a href="#5-Bridge-之间的同住机通信" class="headerlink" title="5. Bridge 之间的同住机通信"></a>5. Bridge 之间的同住机通信</h2><p>以上所说的是一个 bridge 同网段的通信，现在看看不同 bridge 跨网段的通信，如下拓扑：</p><h2 id="6-Bridge-之间的跨住机通信"><a href="#6-Bridge-之间的跨住机通信" class="headerlink" title="6. Bridge 之间的跨住机通信"></a>6. Bridge 之间的跨住机通信</h2><p><a href="https://www.cnblogs.com/iiiiher/p/8057922.html" target="_blank" rel="noopener">https://www.cnblogs.com/iiiiher/p/8057922.html</a></p><p><strong>参考资料：</strong>  </p><p><a href="http://cizixs.com/2017/02/10/network-virtualization-network-namespace" target="_blank" rel="noopener">linux 网络虚拟化： network namespace 简介</a></p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」(id: cloud_dev)&lt;/strong&gt; ，专注于干货分享，号内有大量书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文通过 IP 命令操作来简单介绍 network namespace 的基本概念和用法。&lt;/p&gt;
&lt;p&gt;深入了解可以看看我之前写的两篇文章 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;amp;mid=2247483982&amp;amp;idx=1&amp;amp;sn=35e2aac1f4c164c8afa79aa91707c90d&amp;amp;chksm=ea7436f6dd03bfe036ccc8293aaf25d0c042f21afac5277bf04a32af36643a2780c980e53d09&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Docker 基础技术之 Linux namespace 详解&lt;/a&gt; 和 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;amp;mid=2247483993&amp;amp;idx=1&amp;amp;sn=906551e374c0d8d40db00cbde934e624&amp;amp;chksm=ea7436e1dd03bff724d7ee03267115b2ecf54bd146fa3f826b69e918b5a2455d1562d085ab62&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Docker 基础技术之 Linux namespace 源码分析&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;和 network namespace 相关的操作的子命令是 &lt;code&gt;ip netns&lt;/code&gt; 。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="Namespace" scheme="https://ctimbai.github.io/tags/Namespace/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Linux 系统下实践 VLAN</title>
    <link href="https://ctimbai.github.io/2019/01/07/tech/Linux%E7%B3%BB%E7%BB%9F%E4%B8%8B%E5%AE%9E%E8%B7%B5VLAN/"/>
    <id>https://ctimbai.github.io/2019/01/07/tech/Linux系统下实践VLAN/</id>
    <published>2019-01-07T05:16:14.000Z</published>
    <updated>2019-04-17T16:28:47.797Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」</strong> ，专注于干货分享，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><h2 id="01-准备环境"><a href="#01-准备环境" class="headerlink" title="01 准备环境"></a>01 准备环境</h2><p>环境：ubuntu 16.04 环境（物理 or 虚拟）</p><p>确认 CPU 是否支持虚拟化：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># egrep -o &apos;(vmx|svm)&apos; /proc/cpuinfo</span><br><span class="line"># vmx</span><br></pre></td></tr></table></figure><p>如果不支持，开启 KVM 嵌套虚拟化之后再重启。</p><a id="more"></a><h3 id="1-1-安装-KVM-环境"><a href="#1-1-安装-KVM-环境" class="headerlink" title="1.1 安装 KVM 环境"></a>1.1 安装 KVM 环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y qemu-kvm qemu-system libvirt-bin virt-manager bridge-utils vlan</span><br></pre></td></tr></table></figure><h3 id="1-2-安装-Ubuntu-图形化界面"><a href="#1-2-安装-Ubuntu-图形化界面" class="headerlink" title="1.2 安装 Ubuntu 图形化界面"></a>1.2 安装 Ubuntu 图形化界面</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y xinit gdm kubuntu-desktop</span><br></pre></td></tr></table></figure><h2 id="02-创建-KVM-虚拟机"><a href="#02-创建-KVM-虚拟机" class="headerlink" title="02 创建 KVM 虚拟机"></a>02 创建 KVM 虚拟机</h2><p>使用 virt-manager 创建 KVM 虚拟机，方法比较简单，由于篇幅有限，大家可以查阅相关资料自行了解。</p><p>创建完之后用 <code>virsh list --all</code> 查看创建的 VM：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Id    Name                           State</span><br><span class="line">----------------------------------------------------</span><br><span class="line"> -     kvm1                           shut off</span><br><span class="line"> -     kvm2                           shut off</span><br><span class="line"> -     kvm3                           shut off</span><br></pre></td></tr></table></figure><p>我们的实验拓扑如下：</p><p><img src="/images/net/brvlan.png" alt=""></p><p>图中创建了 2 个 Linux Bridge：brvlan1 和 brvlan2，宿主机的物理网卡 eth0 抽象出两个虚拟设备 eth0.1 和 eth0.2，也就是两个 VLAN 设备，它们分别定义了两个 VLAN：VLAN1 和 VLAN2。挂接到两个 Bridge 上的网络设备自动加入到相应的 VLAN 中。VLAN1 接两个 VM，VLAN 接一个 VM。</p><p>实验的目的是要验证属于同一个 VLAN1 中 VM1 和 VM2 能 ping 通，而属于不同 VLAN 中的 VM ping 不通。</p><h2 id="03-实验开始"><a href="#03-实验开始" class="headerlink" title="03 实验开始"></a>03 实验开始</h2><h3 id="3-1-配置-VLAN"><a href="#3-1-配置-VLAN" class="headerlink" title="3.1 配置 VLAN"></a>3.1 配置 VLAN</h3><p>编辑 <code>/etc/network/interfaces</code>，加入两个 Bridge 和两个 VLAN 设备的配置，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># The primary network interface</span><br><span class="line">auto ens33</span><br><span class="line">iface ens33 inet dhcp</span><br><span class="line"></span><br><span class="line">auto ens33.1</span><br><span class="line">iface ens33.1 inet manual</span><br><span class="line">        vlan-raw-device ens33</span><br><span class="line"></span><br><span class="line">auto brvlan1</span><br><span class="line">iface brvlan1 inet manual</span><br><span class="line">        bridge_stp off</span><br><span class="line">        bridge_waitport 0</span><br><span class="line">        bridge_fd 0</span><br><span class="line">        bridge_ports ens33.1</span><br><span class="line"></span><br><span class="line">auto ens33.2</span><br><span class="line">iface ens33.2 inet manual</span><br><span class="line">        vlan-raw-device ens33</span><br><span class="line"></span><br><span class="line">auto brvlan2</span><br><span class="line">iface brvlan2 inet manual</span><br><span class="line">        bridge_stp off</span><br><span class="line">        bridge_waitport 0</span><br><span class="line">        bridge_fd 0</span><br><span class="line">        bridge_ports ens33.2</span><br></pre></td></tr></table></figure><p><strong>注意</strong>，这里务必和自己电脑的接口名称统一，比如我这里叫 ens33，就配 ens33.1 和 ens33.2 的 VLAN 设备，当然你也可以改成 eth0 的形式。</p><p>重启宿主机，<code>ifconfig</code> 查看网络接口：</p><p><img src="/images/net/vlanif.png" alt="vlanif.png"></p><p>用 <code>brctl show</code> 查看当前 Linux Bridge 的配置，ens33.1 和 ens33.2 分别挂载 brvlan1 和 brvlan2 上了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># brctl show</span><br><span class="line">bridge namebridge idSTP enabledinterfaces</span><br><span class="line">brvlan18000.000c298c57e8noens33.1</span><br><span class="line">brvlan28000.000c298c57e8noens33.2</span><br><span class="line">virbr08000.000000000000yes</span><br></pre></td></tr></table></figure><h3 id="3-2-配置-VM"><a href="#3-2-配置-VM" class="headerlink" title="3.2 配置 VM"></a>3.2 配置 VM</h3><p>我们先配置 VM1，启动 <code>virt-manager</code>，在图形界面中将 VM1 的虚拟网卡挂到 brvlan1 上：</p><p><img src="/images/net/vm1brvlan1.png" alt="vm1brvlan1.png"></p><p>同样的方式配置 VM2 和 VM3，VM2 也配到 brvlan1 上，VM3 配到 brvlan2 上。</p><h3 id="3-3-查看-VM-配置"><a href="#3-3-查看-VM-配置" class="headerlink" title="3.3 查看 VM 配置"></a>3.3 查看 VM 配置</h3><p>用 <code>virsh start xxx</code> 启动 3 个 VM：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># virsh start kvm1</span><br><span class="line"># virsh start kvm2</span><br><span class="line"># virsh start kvm3</span><br></pre></td></tr></table></figure><p>再通过 <code>brctl show</code> 查看 Bridge，这时发现 brvlan1 下接了 vnet0 和 vnet1，brvlan2 下接了 vnet2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># brctl show</span><br><span class="line">bridge namebridge idSTP enabledinterfaces</span><br><span class="line">brvlan18000.000c298c57e8noens33.1</span><br><span class="line">vnet0</span><br><span class="line">vnet1</span><br><span class="line">brvlan28000.000c298c57e8noens33.2</span><br><span class="line">vnet2</span><br><span class="line">virbr08000.000000000000yes</span><br></pre></td></tr></table></figure><p>通过 <code>virsh domiflist xxx</code> 确认这就是 VM 的虚拟网卡：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># virsh domiflist kvm1</span><br><span class="line">Interface  Type       Source     Model       MAC</span><br><span class="line">-------------------------------------------------------</span><br><span class="line">vnet0      bridge     brvlan1    rtl8139     52:54:00:b3:dd:3a</span><br><span class="line"></span><br><span class="line"># virsh domiflist kvm2</span><br><span class="line">Interface  Type       Source     Model       MAC</span><br><span class="line">-------------------------------------------------------</span><br><span class="line">vnet1      bridge     brvlan1    rtl8139     52:54:00:b7:4f:ef</span><br><span class="line"></span><br><span class="line"># virsh domiflist kvm3</span><br><span class="line">Interface  Type       Source     Model       MAC</span><br><span class="line">-------------------------------------------------------</span><br><span class="line">vnet2      bridge     brvlan2    rtl8139     52:54:00:d8:b8:2a</span><br></pre></td></tr></table></figure><h3 id="04-验证"><a href="#04-验证" class="headerlink" title="04 验证"></a>04 验证</h3><p>为了验证相同 VLAN 之间的连通性和不同 VLAN 之间的隔离性，我们为 3 个 VM 都配置同一网段的 IP。</p><p>使用 <code>virt-manager</code> 进入 VM console 控制面。</p><p>配置 VM1 的 IP：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig eth0 192.168.100.10 netmask 255.255.255.0</span><br></pre></td></tr></table></figure><p>配置 VM2 的 IP：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig eth0 192.168.100.20 netmask 255.255.255.0</span><br></pre></td></tr></table></figure><p>配置 VM3 的 IP：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig eth0 192.168.100.30 netmask 255.255.255.0</span><br></pre></td></tr></table></figure><p>使用 VM1 ping VM2 能 ping 通，VM2 ping VM3 不能 ping 通。</p><p><img src="/images/net/vlanping.png" alt="vlanping.png"></p><p>验证完毕。</p><p>大家如果有兴趣，可以抓个包看看，在发送 ping 包之前，需要知道对方的 MAC 地址，所以会先在网络中广播 ARP 包。ARP 是二层协议，VLAN 的作用就是隔离二层的广播域，ARP 包自然就不能在不同 VLAN 中流通，所以在相同 VLAN 中，通信双方能够拿到对方的 MAC 地址，也就能 ping 通，不同 VLAN 反之。</p><center>–END–</center><hr><p>后台回复「<font color="red">加群</font>」，带你进入高手如云交流群。</p><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」(id: cloud_dev)</strong> ，号内有 <strong>10T</strong> 书籍和视频资源，后台回复 <strong>「1024」</strong> 即可领取，分享的内容包括但不限于 Linux、网络、云计算虚拟化、容器Docker、OpenStack、Kubernetes、工具、SDN、OVS、DPDK、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」&lt;/strong&gt; ，专注于干货分享，号内有大量书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;01-准备环境&quot;&gt;&lt;a href=&quot;#01-准备环境&quot; class=&quot;headerlink&quot; title=&quot;01 准备环境&quot;&gt;&lt;/a&gt;01 准备环境&lt;/h2&gt;&lt;p&gt;环境：ubuntu 16.04 环境（物理 or 虚拟）&lt;/p&gt;
&lt;p&gt;确认 CPU 是否支持虚拟化：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# egrep -o &amp;apos;(vmx|svm)&amp;apos; /proc/cpuinfo&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# vmx&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如果不支持，开启 KVM 嵌套虚拟化之后再重启。&lt;/p&gt;
    
    </summary>
    
      <category term="06 网络" scheme="https://ctimbai.github.io/categories/06-%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Linux" scheme="https://ctimbai.github.io/tags/Linux/"/>
    
      <category term="网络" scheme="https://ctimbai.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="VLAN" scheme="https://ctimbai.github.io/tags/VLAN/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 笔记 012 Pod 的自动扩容与缩容</title>
    <link href="https://ctimbai.github.io/2018/09/30/tech/Kubernetes_%E7%AC%94%E8%AE%B0_012_Pod_%E7%9A%84%E8%87%AA%E5%8A%A8%E6%89%A9%E5%AE%B9%E4%B8%8E%E7%BC%A9%E5%AE%B9/"/>
    <id>https://ctimbai.github.io/2018/09/30/tech/Kubernetes_笔记_012_Pod_的自动扩容与缩容/</id>
    <published>2018-09-30T05:16:14.000Z</published>
    <updated>2019-04-11T16:01:06.222Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」</strong> ，专注于干货分享，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>Hi，大家好，我是 CloudDeveloper，欢迎大家和我一起学 K8S，这是系列第 12 篇。</p><p>上一篇我们了解了 Pod 的手动扩容和缩容，本篇来看看自动的方式。</p><a id="more"></a><p>K8S 作为一个集群式的管理软件，自动化、智能化是免不了的功能。Google 在 K8S v1.1 版本中就加入了这个 Pod 横向自动扩容的功能（Horizontal Pod Autoscaling，简称 HPA）。</p><p>HPA 与之前的 Deployment、Service 一样，也属于一种 K8S 资源对象。</p><p>HPA 的目标是希望通过追踪集群中所有 Pod 的负载变化情况，来自动化地调整 Pod 的副本数，以此来满足应用的需求和减少资源的浪费。</p><p>HAP 度量 Pod 负载变化情况的指标有两种：  </p><ul><li>CPU 利用率（CPUUtilizationPercentage）</li><li>自定义的度量指标，比如服务在每秒之内的请求数（TPS 或 QPS）</li></ul><p>如何统计和查询这些指标，要依托于一个组件——Heapster。Heapster 会监控一段时间内集群内所有 Pod 的 CPU 利用率的平均值或者其他自定义的值，在满足条件时（比如 CPU 使用率超过 80% 或 降低到 10%）会将这些信息反馈给 HPA 控制器，HPA 控制器就根据 RC 或者 Deployment 的定义调整 Pod 的数量。</p><p>HPA 实现的方式有两种：配置文件和命令行</p><ol><li>配置文件</li></ol><p>这种方式是通过定义 yaml 配置文件来创建 HPA，如下是基本定义：   </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: autoscaling/v1</span><br><span class="line">kind: HorizontalPodAutoscaler</span><br><span class="line">metadata:</span><br><span class="line">  name: php-apache</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  scaleTargetRef:               # (1)</span><br><span class="line">    kind: Deployment   </span><br><span class="line">    name: php-apache</span><br><span class="line">  minReplicas: 1                # (2)</span><br><span class="line">  maxReplicas: 10</span><br><span class="line">  targetAverageUtilization: 50  # (3)</span><br></pre></td></tr></table></figure><p>文件 kind 类型是 <code>HorizontalPodAutoscaler</code>，其中有 3 个地方需要额外注意下：  </p><p>（1）<code>scaleTargetRef</code> 字段指定需要管理的 Deployment/RC 的名字，也就是提前需要存在一个 Deployment/RC 对象。</p><p>（2） <code>minReplicas</code> 和 <code>maxReplicas</code> 字段定义 Pod 可伸缩的数量范围。这个例子中扩容最高不能超过 10 个，缩容最低不能少于 1 个。</p><p>（3）<code>targetAverageUtilization</code> 指定 CPU 使用率，也就是自动扩容和缩容的触发条件，当 CPU 使用率超过 50% 时会触发自动动态扩容的行为，当回落到 50% 以下时，又会触发自动动态缩容的行为。</p><ol start="2"><li>命令行</li></ol><p>这种方式就是通过 <code>kubectl autoscale</code> 命令来实现创建 HPA 对象，实现自动扩容和缩容行为。比如和上面的例子等价的命令如下：   </p><p><code>kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10</code></p><p>通过参数来引入各个字段。</p><p>OK，本文就到这里，更多实践的例子大家可以参考 K8S 官网。下文我们将会探索 K8S 的容错机制。</p><center>–END–</center><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」</strong> ，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，分享的内容包括但不限于云计算虚拟化、容器、OpenStack、K8S、雾计算、网络、工具、SDN、OVS、DPDK、Linux、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」&lt;/strong&gt; ，专注于干货分享，号内有大量书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hi，大家好，我是 CloudDeveloper，欢迎大家和我一起学 K8S，这是系列第 12 篇。&lt;/p&gt;
&lt;p&gt;上一篇我们了解了 Pod 的手动扩容和缩容，本篇来看看自动的方式。&lt;/p&gt;
    
    </summary>
    
      <category term="Kubernetes" scheme="https://ctimbai.github.io/categories/Kubernetes/"/>
    
    
      <category term="云计算" scheme="https://ctimbai.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Kubernetes" scheme="https://ctimbai.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 笔记 11 Pod 扩容与缩容 双十一前后的忙碌</title>
    <link href="https://ctimbai.github.io/2018/09/29/tech/Kubernetes_%E7%AC%94%E8%AE%B0_11_Pod_%E6%89%A9%E5%AE%B9%E4%B8%8E%E7%BC%A9%E5%AE%B9_%E5%8F%8C%E5%8D%81%E4%B8%80%E5%89%8D%E5%90%8E%E7%9A%84%E5%BF%99%E7%A2%8C/"/>
    <id>https://ctimbai.github.io/2018/09/29/tech/Kubernetes_笔记_11_Pod_扩容与缩容_双十一前后的忙碌/</id>
    <published>2018-09-29T05:16:14.000Z</published>
    <updated>2019-04-11T15:58:36.247Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」</strong> ，专注于干货分享，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 11 篇。</p><p>资源的伸缩在云计算环境中是至关重要的，云计算的动机就是企图提高资源的利用率，在用户请求高峰期的时候能够对资源进行横向扩容，反之，当用户请求回落低谷的时候，能够及时缩减资源，避免资源的浪费。</p><a id="more"></a><p>这就像双十一的时候，随着用户不断地涌入，阿里后台需要不断调配更多的资源来支撑用户大量的请求，当过了双十一当天，再慢慢缩减资源的使用。</p><p>Kubernetes 作为一个集群管理系统，提供了两种资源伸缩的方式：手动和自动。本文先来看手动方式。</p><p>Kubernetes 的资源伸缩本质上指的是 Pod 的扩容和缩容（scale up/down），也就是增加或减少 Pod 的副本数。</p><p>手动的方式是使用 <code>kubectl scale</code> 命令手动进行，或者基于 YAML 配置来实现。</p><p>首先，定义一个 <code>nginx-deployment.yaml</code> 配置文件：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: web_server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        images: nginx:1.12.1</span><br></pre></td></tr></table></figure><p>其中定义了 3 个副本，执行 <code>kubectl create -f nginx-deployment.yaml</code> 创建 Pod。</p><center><img src="/images/k8s/pod_scale.png" alt=""></center><p>如果现在遇到高峰请求，我们急需进行扩容，执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale deployment nginx-deployment --replicas 5</span><br></pre></td></tr></table></figure></p><p>将 Pod 扩增到 5 个。</p><center><img src="/images/k8s/pod_scale_up.png" alt=""></center><p>其中，用 <code>--replicas</code> 来指示增缩的数量，对于缩容，将 <code>--replicas</code> 设置为比当前 Pod 副本数量更小的数字即可，比如缩容到 2 个如下：</p><center><img src="/images/k8s/pod_scale_down.png" alt=""></center><p>可以看到，Pod 销毁会经历一个 <code>Terminating</code> 的过程，最终 3 个副本被删除，只保留了 2 个副本。</p><p>以上是通过命令的形式来实现手动的扩容和缩容，我们也可以修改 YAML 配置文件中的 <code>replicas</code> 来实现，只要修改完之后执行 <code>kubectl apply</code> 即可。</p><p>OK，本文到此为止，下文我们再来 Pod 伸缩的另一种方式——自动扩容和缩容。</p><p>PS：文章未经我允许，不得转载，否则后果自负。</p><center>–END–</center><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」</strong> ，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，分享的内容包括但不限于云计算虚拟化、容器、OpenStack、K8S、雾计算、网络、工具、SDN、OVS、DPDK、Linux、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」&lt;/strong&gt; ，专注于干货分享，号内有大量书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 11 篇。&lt;/p&gt;
&lt;p&gt;资源的伸缩在云计算环境中是至关重要的，云计算的动机就是企图提高资源的利用率，在用户请求高峰期的时候能够对资源进行横向扩容，反之，当用户请求回落低谷的时候，能够及时缩减资源，避免资源的浪费。&lt;/p&gt;
    
    </summary>
    
      <category term="Kubernetes" scheme="https://ctimbai.github.io/categories/Kubernetes/"/>
    
    
      <category term="云计算" scheme="https://ctimbai.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Kubernetes" scheme="https://ctimbai.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 笔记 10 Job 机器人加工厂</title>
    <link href="https://ctimbai.github.io/2018/09/26/tech/Kubernetes_%E7%AC%94%E8%AE%B0_10_Job_%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8A%A0%E5%B7%A5%E5%8E%82/"/>
    <id>https://ctimbai.github.io/2018/09/26/tech/Kubernetes_笔记_10_Job_机器人加工厂/</id>
    <published>2018-09-26T05:16:14.000Z</published>
    <updated>2019-04-11T15:59:54.399Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」</strong> ，专注于干货分享，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 10 篇。</p><p>通常，我们在执行任务时，会启用多个服务，有些任务需要长时间运行，全天 24 小时不中断，所以一般会启用 Daemon 类的 服务；而有些任务则只需要短暂执行，任务执行完，服务就没有存在的必要了。</p><a id="more"></a><p>容器提供服务运行的环境，根据任务持续运行的时间，将容器分为两类：服务类容器和工作类容器。</p><p>服务类容器需要一直运行来提供持续性的服务，而工作类容器则是运行一次性的任务，任务完成后便会退出。</p><p>前面学习的 Deployment、ReplicaSet 和 DaemonSet 都用于管理服务类容器，而工作类容器则由本文要讲得 Job 来管理。</p><p>Job 多用于执行一次性的任务，批处理任务等，Job 就像是现代化机械加工厂的机器人，当有任务来的时候，便会启动，按照预先设定好的程序执行任务，直至任务执行完，便会进入休眠状态。</p><p>进一步，Job 根据任务的类型和执行的动作又分为以下几类：   </p><ul><li>单 Job 单任务：只启动一个 Job 来完成任务，同时 Job 只启用一个 Pod ，适用于简单的任务。</li><li>多 Job 多任务：启动多个 Job 来处理批量任务，每个任务对应一个 Job，Pod 的数量可以自定义。</li><li>单 Job 多任务：采用一个任务队列来存放任务，启动一个 Job 作为消费者来处理这些任务，Job 会启动多个 Pod，Pod 的数量可以自定义。</li><li>定时 Job：也叫 CronJob，启动一个 Job 来定时执行任务，类似 Linux 的 Crontab 程序。</li></ul><p>上述 Job 的分类需要注意两点：</p><p>1）Job 执行失败的重启策略；Job 执行的是一次性的任务，但也不保证一定能执行成功，如果执行失败，应该怎么处理？这个是由前面所讲的 Pod 重启策略来决定的。在 Job Controller 中，只允许定义两种策略：  </p><ul><li>Never：Pod 执行失败，不会重启该 Pod，但会根据 Job 定义的期望数重新创建 Pod。</li><li>OnFailure：Pod 执行失败，则会尝试重启该 Pod。</li></ul><p>两种策略尝试的次数由 <code>spec.backoffLimits</code> 来限制，默认是 6 次（K8S 1.8.0 新加的特性）。</p><p>2）批量任务的多次并行处理的限制；对于批量任务，通常是一个 Pod 对应一个任务，但有时为了加快任务的处理，会启动多个 Pod 来并行处理单个任务。可以通过下面两个参数来设置并行度：</p><ul><li><code>spec.completions</code>：总的启动 Pod 数，只有当所有 Pod 执行成功结束，任务才结束。</li><li><code>spec.parallelism</code>：每个任务对应的 Pod 的并行数，当有一个 Pod 执行成功结束，该任务就执行结束。</li></ul><p>下面通过几个例子来实践一下上面的几种 Job 类别。</p><h3 id="几个例子"><a href="#几个例子" class="headerlink" title="几个例子"></a>几个例子</h3><h4 id="单-Job-单-Pod-执行一次性任务"><a href="#单-Job-单-Pod-执行一次性任务" class="headerlink" title="单 Job 单 Pod 执行一次性任务"></a>单 Job 单 Pod 执行一次性任务</h4><p>首先，定义 Job 的 yaml 配置文件 myjob.yaml：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: myjob</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: myjob</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: hello</span><br><span class="line">        images: busybox</span><br><span class="line">        command: [&quot;echo&quot;, &quot;hello, I&apos;m Linux云计算网络, Welcome&quot;]</span><br><span class="line">      restartPolicy: Never</span><br></pre></td></tr></table></figure><p>执行 <code>kubectl create -f myjob.yaml</code> 创建 job 对象：</p><center><img src="/images/k8s/job-yaml.png" alt=""></center><p>可以看到期望创建的 Job 数为 1，成功执行的 Job 数也为 1，这表明该 Job 已经执行完任务退出了。这个 Job 执行的任务就是创建一个 Pod，Pod 中创建一个 busybox 容器，并进入容器输出一段字符串：<strong>“hello, I’m Linux云计算网络, Welcome”</strong>。</p><p>查看一下 Pod 的状态：   </p><center><img src="/images/k8s/job-pod.png" alt=""></center><p>可以看到，该 Pod 的状态为 <code>Completed</code>，表示它已经执行完任务并成功退出了。那怎么看该任务的执行结果呢？可以执行 <code>kubectl logs myjob</code> 调出该 Pod 的历史执行信息进行查看：</p><center><img src="/images/k8s/job-logs.png" alt=""></center><p>看到历史输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hello, I&apos;m Linux云计算网络, Welcome</span><br></pre></td></tr></table></figure><p>以上是执行成功的情况，如果执行失败，会根据 <code>restartPolicy</code> 进行重启，重启的方式上面也说了。大家可以自己实践下。</p><h4 id="多-Job-多-Pod-执行批量任务"><a href="#多-Job-多-Pod-执行批量任务" class="headerlink" title="多 Job 多 Pod 执行批量任务"></a>多 Job 多 Pod 执行批量任务</h4><p>首先，定义 Job 的 yaml 模板文件 job.yaml.txt，然后再根据这个模板文件创建多个 Job yaml 文件。模板文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: work-item-$ITEM</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: job</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: c</span><br><span class="line">        images: busybox</span><br><span class="line">        command: [&quot;sh&quot;, &quot;-c&quot;, &quot;echo work item $ITEM &amp;&amp; sleep 2&quot;]</span><br><span class="line">      restartPolicy: Never</span><br></pre></td></tr></table></figure><p>其中，<code>$ITEM</code> 作为各个 Job 项的标识。接着，使用以下脚本，根据 Job 模板创建三个 Job 配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">for i in app book phone</span><br><span class="line">do</span><br><span class="line">  cat myjob_tmp.yaml | sed &quot;s/\$ITEM/$i/g&quot; &gt; ./jobs/job-$i.yaml</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>最后，创建三个 Job 对象，如下：</p><center><img src="/images/k8s/job-multi.png" alt=""></center><h4 id="单-Job-多-Pod-执行批量任务"><a href="#单-Job-多-Pod-执行批量任务" class="headerlink" title="单 Job 多 Pod 执行批量任务"></a>单 Job 多 Pod 执行批量任务</h4><p>这种方式是用一个队列来存放任务，然后启动一个 Job 来执行任务，Job 可以根据需求启动多个 Pod 来承载任务的执行。定义下面的配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: myjob</span><br><span class="line">spec:</span><br><span class="line">  completions: 6</span><br><span class="line">  parallelism: 2</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: myjob</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: hello</span><br><span class="line">        images: busybox</span><br><span class="line">        command: [&quot;echo&quot;, &quot;hello Linux云计算网络&quot;]</span><br><span class="line">      restartPolicy: OnFailure</span><br></pre></td></tr></table></figure><p>这里用到了上面说的两个参数：<code>completions</code> 和 <code>parallelism</code>，表示每次并行运行两个 Pod，直到总共 6 个 Pod 成功运行完成。如下：</p><center><img src="/images/k8s/job-para.png" alt=""></center><p>可以看到 DESIRED 和 SUCCESSFUL 最终均为 6，符合预期，实际上也有 6 个 Pod 成功运行并退出，呈 <code>Completed</code> 状态。</p><p>随便查看其中一个 Pod 的历史执行情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># kubectl logs myjob-5lfnp</span><br><span class="line">hello Linux云计算网络</span><br></pre></td></tr></table></figure><h4 id="定时任务-CronJob"><a href="#定时任务-CronJob" class="headerlink" title="定时任务 CronJob"></a>定时任务 CronJob</h4><p>定义一个 CronJob 配置文件，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch/v1beta1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: hello</span><br><span class="line">spec:</span><br><span class="line">  schedule: &quot;*/1 * * * *&quot;</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        spec:</span><br><span class="line">          containers:</span><br><span class="line">          - name: hello</span><br><span class="line">            images: busybox</span><br><span class="line">            command: [&quot;echo&quot;, &quot;Hello Linux云计算网络&quot;]</span><br><span class="line">          restartPolicy: OnFailure</span><br></pre></td></tr></table></figure><p>kind 类型为 CronJob，<code>spec.schedule</code> 表示定时调度，指定什么时候运行 Job，格式与 Linux 的 Crontab 命令是一样的，这里 <code>*/1 * * * *</code> 的含义是每一分钟启动一次。</p><p>创建 CronJob 对象，通过 <code>kubectl get cronjob</code> 查看 CronJob 的状态：  </p><center><img src="/images/k8s/cronjob-get.png" alt=""></center><p>过一段时间再查看 Pod 的状态：</p><center><img src="/images/k8s/cronjob.png" alt=""></center><p>可以看到，此时产生了 3 个 Pod，3 个 Jobs，这是每隔一分钟就会启动一个 Job。执行 <code>kubectl logs</code> 查看其中一个的历史执行情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># kubectl logs hello-1536764760-lm5kt</span><br><span class="line">Hello Linux云计算网络</span><br></pre></td></tr></table></figure><p>到此，本文就结束了。我们从理论结合实践，梳理了 Job 的几种类型，下文我们开始看一种有状态的 Controller——StatefulSet。</p><p>同样，需要学习资料的后台回复“K8S” 和 “K8S2”，想加群学习回复“加群”。</p><p>PS：文章未经我允许，不得转载，否则后果自负。</p><center>–END–</center><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」</strong> ，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，分享的内容包括但不限于云计算虚拟化、容器、OpenStack、K8S、雾计算、网络、工具、SDN、OVS、DPDK、Linux、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」&lt;/strong&gt; ，专注于干货分享，号内有大量书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 10 篇。&lt;/p&gt;
&lt;p&gt;通常，我们在执行任务时，会启用多个服务，有些任务需要长时间运行，全天 24 小时不中断，所以一般会启用 Daemon 类的 服务；而有些任务则只需要短暂执行，任务执行完，服务就没有存在的必要了。&lt;/p&gt;
    
    </summary>
    
      <category term="Kubernetes" scheme="https://ctimbai.github.io/categories/Kubernetes/"/>
    
    
      <category term="云计算" scheme="https://ctimbai.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Kubernetes" scheme="https://ctimbai.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 笔记 09 DaemonSet 我是一只看门狗</title>
    <link href="https://ctimbai.github.io/2018/09/19/tech/Kubernetes_%E7%AC%94%E8%AE%B0_09_DaemonSet_%E6%88%91%E6%98%AF%E4%B8%80%E5%8F%AA%E7%9C%8B%E9%97%A8%E7%8B%97/"/>
    <id>https://ctimbai.github.io/2018/09/19/tech/Kubernetes_笔记_09_DaemonSet_我是一只看门狗/</id>
    <published>2018-09-19T05:16:14.000Z</published>
    <updated>2019-04-11T16:00:32.410Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」</strong> ，专注于干货分享，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 9 篇。</p><p>和上文中的 Deployment 一样，DaemonSet 也是一种副本管理机制，和 Deployment 可以在每个 Node 上运行好几个 Pod 副本不同的是，DaemonSet 始终保证每个 Node 最多只会运行一个副本，就像它的名称一样，作为一只看门狗（Daemon）守护在主人家里。</p><a id="more"></a><p>那么，哪些应用适合用 DaemonSet 的方式来部署呢？</p><p>主要有以下几类：</p><ul><li>监控类的，比如 Prometheus，collectd，New Relic agent，Ganglia gmond 等。</li><li>系统管理类的，比如 kube-proxy, kube-flannel 等。</li><li>日志收集类的，比如 fluentd，logstash 等。</li><li>数据存储类的，比如 glusterd, ceph 等。</li><li>……</li></ul><p>其中，系统管理类的应用主要是 K8S 自身的一些系统组件，我们可以通过 <code>kubectl get daemonset --namespace=kube-system</code> 查看到：  </p><center><img src="/images/k8s/daemon-sys.png" alt=""></center><p>DaemonSet <code>kube-proxy</code> 和 <code>kube-flannel-ds</code> 有 3 个副本，分别负责在每个节点上运行 kube-proxy 和 flannel 组件。</p><p>kube-proxy 前面的文章讲过，它有负载均衡的功能，主要将外部对 Service 的访问导向后端的 Pod 上。显然，一个 Node 运行一个负载均衡器足矣。</p><p>我们可以通过 <code>kubectl edit daemonset kube-proxy --namespace=kube-system</code> 来查看 kube-proxy 的 yaml 配置文件。</p><center><img src="/images/k8s/kube-proxy-dae.png" alt=""></center><p>可以看到它的 kind 是 DaemonSet。</p><p>接着再来看 kube-flannel-ds，这是一个网络插件组件，主要用于构建 K8S 的集群网络，这里大家不懂可以跳过，不影响本文的理解，后面在讲到 K8S 网络的时候会重点讲这个网络方案。</p><p>这里我们只需要知道，各个 Pod 间的网络连通就是 flannel 来实现的。</p><p>这是一个第三方的插件，我们可以直接下载它的 yaml 文件进行安装，执行下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure><p>得到 kube-flannel.yml 文件：</p><center><img src="/images/k8s/kube-flannel-dae.png" alt=""></center><p>这里只列出了一部分内容，kind 类型是 DaemonSet。</p><p>其实 DaemonSet 配置文件的语法和结构和 Deployment 几乎完全一样，不同就在于将 kind 设为 DaemonSet。</p><p>OK，DaemonSet 的探讨就到这里，下文我们继续讨论另外一种 Controller：Job。</p><p>PS：文章未经我允许，不得转载，否则后果自负。</p><center>–END–</center><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」</strong> ，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，分享的内容包括但不限于云计算虚拟化、容器、OpenStack、K8S、雾计算、网络、工具、SDN、OVS、DPDK、Linux、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」&lt;/strong&gt; ，专注于干货分享，号内有大量书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 9 篇。&lt;/p&gt;
&lt;p&gt;和上文中的 Deployment 一样，DaemonSet 也是一种副本管理机制，和 Deployment 可以在每个 Node 上运行好几个 Pod 副本不同的是，DaemonSet 始终保证每个 Node 最多只会运行一个副本，就像它的名称一样，作为一只看门狗（Daemon）守护在主人家里。&lt;/p&gt;
    
    </summary>
    
      <category term="Kubernetes" scheme="https://ctimbai.github.io/categories/Kubernetes/"/>
    
    
      <category term="云计算" scheme="https://ctimbai.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Kubernetes" scheme="https://ctimbai.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 笔记 08 Deployment 副本管理 重新招一个员工来填坑</title>
    <link href="https://ctimbai.github.io/2018/09/16/tech/Kubernetes_%E7%AC%94%E8%AE%B0_08_Deployment_%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86_%E9%87%8D%E6%96%B0%E6%8B%9B%E4%B8%80%E4%B8%AA%E5%91%98%E5%B7%A5%E6%9D%A5%E5%A1%AB%E5%9D%91/"/>
    <id>https://ctimbai.github.io/2018/09/16/tech/Kubernetes_笔记_08_Deployment_副本管理_重新招一个员工来填坑/</id>
    <published>2018-09-16T05:16:14.000Z</published>
    <updated>2019-04-11T16:01:03.442Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文首发于我的公众号 <strong>「Linux云计算网络」</strong> ，专注于干货分享，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，欢迎大家关注，二维码文末可以扫。</p></blockquote><p>Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 8 篇。</p><p>Deployment 是 K8S v1.2 引入的概念，与之一起引入还有 ReplicaSet。这两个概念是等同的，准确说是 Deployment 内部调用 ReplicaSet 来实现。</p><a id="more"></a><p>之前这个概念是由 Replication Controller 来实现的，但由于和 K8S 代码中的模块重名，所以就改成 Deployment + ReplicaSet 的组合。</p><p>Deployment 实现了 Pod 的副本管理，使得应用的表现形态和用户期望的状态保持一致。比如用户期望应用部署为 3 副本，如果在运行过程中有一个副本挂了，那么 Deployment 会自动拉起一个副本。</p><p>Deployment 对于应用的编排、自动扩容和缩容、升级回滚等功能都是至关重要的。</p><p>下面我们通过一个例子来看看 Deployment 是如何工作的。</p><p>定义一个 <code>nginx.yaml</code> 文件（对 yaml 文件不熟悉的可以查阅这篇文章）：   </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1   </span><br><span class="line">kind: Deployment </span><br><span class="line">metadata:  </span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2  </span><br><span class="line">  template:  </span><br><span class="line">    metadata:</span><br><span class="line">      labels:  </span><br><span class="line">        app: web-server</span><br><span class="line">    spec: </span><br><span class="line">      containers:  </span><br><span class="line">      - name: nginx  </span><br><span class="line">        images: nginx:1.12.1     </span><br><span class="line">        ports:  </span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure><p>这个文件定义了一个 nginx 容器应用，两个 Pod 副本。也就是每个 Pod 中会跑一个 nginx 应用。</p><p>执行<code>kubectl create -f nginx.yaml</code>创建 Deployment 对象，在执行 <code>kubectl get deploy</code> 查看创建的 Deployment。</p><center><img src="/images/k8s/deploy-yaml.png" alt=""></center><p>可以看到，其中两个参数 <code>desired</code>（期待副本数）和 <code>current</code>（当前副本数）都为 2，保持一致，我们再执行 <code>kubectl get pod -o wide</code> 查看当前 Pod 的情况：</p><center><img src="/images/k8s/deploy-pod.png" alt=""></center><p>可以看到，创建了两个 Pod 自动调度到了 Node1 和 Node2 上。这说明每个 Pod 副本是由 Deployment 统一创建并维护的。</p><p>为了一探究竟，我们继续深挖 Deployment。</p><p>执行 <code>kubectl describe deployment nginx-deployment</code> 查看该 Deployment 的详细信息。</p><center><img src="/images/k8s/deploy-replica.png" alt=""></center><p>图中圈住的地方告诉我们，这里创建了一个 ReplicaSet，也就是说 Deployment 内部是调用 ReplicaSet 来完成 Pod 副本的创建的。是否是这样，我们继续验证。</p><p>执行 <code>kubeclt get replicaset</code> 显示创建的 ReplicaSet 对象：</p><center><img src="/images/k8s/deploy-get-replica.png" alt=""></center><p>可以看到这里的 ReplicaSet 名称和上面 Deployment 信息里显示的是一样的，同样，执行 <code>kubectl describe replicaset xxx</code> 显示该 ReplicaSet 的详细信息。</p><center><img src="/images/k8s/deploy-replica-events.png" alt=""></center><p>图中，有两处地方值得注意。一处是 <code>Controlled By</code>，表明 ReplicaSet 是由谁创建并控制的，显然这里显示是 Deployment。第二处是 <code>Events</code>，Events 记录了 K8S 中每一种对象的日志信息，这里的信息有助于排错查问题。我们可以看到这里记录了两个 Pod 副本的创建，Pod 的名称和我们在上面执行 <code>kubectl get pod</code> 看到的结果是一样的。</p><p>继续执行 <code>kubectl describe pod xxx</code> 查看其中一个 Pod 的详细信息：</p><center><img src="/images/k8s/deploy-pod-des.png" alt=""></center><p>可以看到这个 Pod 是由 ReplicaSet 创建的。</p><p>到此，我们不难得出下面这幅图：</p><center><img src="/images/k8s/deploy-pod1.png" alt=""></center><p>用户通过 kubeclt 创建 Deployment，Deployment 又创建 ReplicaSet，最终由 ReplicaSet 创建 Pod。</p><p>从命名上我们也可以看出，子对象的名字 = 父对象的名字 + 随机字符串。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文我们从实践上剖析了 Deployment 创建 Pod，实际上经过 ReplicaSet 进行创建。Deployment 最主要是对 Pod 进行副本管理，这样可以进行很多自动化管理的复杂操作，后面我们逐步从实践上去剖析 Pod 的各种操作。</p><p>PS：文章未经我允许，不得转载，否则后果自负。</p><center>–END–</center><hr><blockquote><p>我的公众号 <strong>「Linux云计算网络」</strong> ，号内有大量书籍和视频资源，后台回复<strong>「1024」</strong>即可领取，分享的内容包括但不限于云计算虚拟化、容器、OpenStack、K8S、雾计算、网络、工具、SDN、OVS、DPDK、Linux、Go、Python、C/C++编程技术等内容，欢迎大家关注。</p><p><img src="/images/weichat.png" alt=""></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文首发于我的公众号 &lt;strong&gt;「Linux云计算网络」&lt;/strong&gt; ，专注于干货分享，号内有大量书籍和视频资源，后台回复&lt;strong&gt;「1024」&lt;/strong&gt;即可领取，欢迎大家关注，二维码文末可以扫。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hi，大家好，我是 Linux云计算网络，欢迎大家和我一起学 K8S，这是系列第 8 篇。&lt;/p&gt;
&lt;p&gt;Deployment 是 K8S v1.2 引入的概念，与之一起引入还有 ReplicaSet。这两个概念是等同的，准确说是 Deployment 内部调用 ReplicaSet 来实现。&lt;/p&gt;
    
    </summary>
    
      <category term="Kubernetes" scheme="https://ctimbai.github.io/categories/Kubernetes/"/>
    
    
      <category term="云计算" scheme="https://ctimbai.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Kubernetes" scheme="https://ctimbai.github.io/tags/Kubernetes/"/>
    
  </entry>
  
</feed>
